{"generated_at":"2025-08-17T20:04:18.057896Z","root":"/home/runner/workspace","git":{"head":"7b7135163eb4227ef98e4c2d7b4ab78ea306bd73","branch":"main","status":" M corrections.db\n?? app_changes.json\n?? export_changes.py\n"},"filters":{"git_range":null,"since":null,"include_ext":[".cfg",".css",".env",".htm",".html",".ini",".jinja",".jinja2",".js",".json",".md",".py",".toml",".ts",".yaml",".yml"],"exclude_dirs":[".git",".ipynb_checkpoints",".mypy_cache",".pytest_cache",".pythonlibs",".venv","__pycache__","cache","chroma_db","data/exports","node_modules","venv"],"exclude_globs":["*.bmp","*.db","*.feather","*.gif","*.gz","*.ico","*.jpeg","*.jpg","*.jsonl","*.lock","*.log","*.parquet","*.png","*.sqlite","*.sqlite3","*.tar","*.webp","*.zip"],"max_file_bytes":400000},"summary":{"file_count":876,"total_bytes":9265289},"files":[{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/pygments/filters/__init__.py","size":40392,"sha1":"f91c3a6f1c7f848e3adf8d1bf0c5be53b088bf45","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\n    pygments.filters\n    ~~~~~~~~~~~~~~~~\n\n    Module containing filter lookup functions and default\n    filters.\n\n    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nimport re\n\nfrom pip._vendor.pygments.token import String, Comment, Keyword, Name, Error, Whitespace, \\\n    string_to_tokentype\nfrom pip._vendor.pygments.filter import Filter\nfrom pip._vendor.pygments.util import get_list_opt, get_int_opt, get_bool_opt, \\\n    get_choice_opt, ClassNotFound, OptionError\nfrom pip._vendor.pygments.plugin import find_plugin_filters\n\n\ndef find_filter_class(filtername):\n    \"\"\"Lookup a filter by name. Return None if not found.\"\"\"\n    if filtername in FILTERS:\n        return FILTERS[filtername]\n    for name, cls in find_plugin_filters():\n        if name == filtername:\n            return cls\n    return None\n\n\ndef get_filter_by_name(filtername, **options):\n    \"\"\"Return an instantiated filter.\n\n    Options are passed to the filter initializer if wanted.\n    Raise a ClassNotFound if not found.\n    \"\"\"\n    cls = find_filter_class(filtername)\n    if cls:\n        return cls(**options)\n    else:\n        raise ClassNotFound(f'filter {filtername!r} not found')\n\n\ndef get_all_filters():\n    \"\"\"Return a generator of all filter names.\"\"\"\n    yield from FILTERS\n    for name, _ in find_plugin_filters():\n        yield name\n\n\ndef _replace_special(ttype, value, regex, specialttype,\n                     replacefunc=lambda x: x):\n    last = 0\n    for match in regex.finditer(value):\n        start, end = match.start(), match.end()\n        if start != last:\n            yield ttype, value[last:start]\n        yield specialttype, replacefunc(value[start:end])\n        last = end\n    if last != len(value):\n        yield ttype, value[last:]\n\n\nclass CodeTagFilter(Filter):\n    \"\"\"Highlight special code tags in comments and docstrings.\n\n    Options accepted:\n\n    `codetags` : list of strings\n       A list of strings that are flagged as code tags.  The default is to\n       highlight ``XXX``, ``TODO``, ``FIXME``, ``BUG`` and ``NOTE``.\n\n    .. versionchanged:: 2.13\n       Now recognizes ``FIXME`` by default.\n    \"\"\"\n\n    def __init__(self, **options):\n        Filter.__init__(self, **options)\n        tags = get_list_opt(options, 'codetags',\n                            ['XXX', 'TODO', 'FIXME', 'BUG', 'NOTE'])\n        self.tag_re = re.compile(r'\\b({})\\b'.format('|'.join([\n            re.escape(tag) for tag in tags if tag\n        ])))\n\n    def filter(self, lexer, stream):\n        regex = self.tag_re\n        for ttype, value in stream:\n            if ttype in String.Doc or \\\n               ttype in Comment and \\\n               ttype not in Comment.Preproc:\n                yield from _replace_special(ttype, value, regex, Comment.Special)\n            else:\n                yield ttype, value\n\n\nclass SymbolFilter(Filter):\n    \"\"\"Convert mathematical symbols such as \\\\<longrightarrow> in Isabelle\n    or \\\\longrightarrow in LaTeX into Unicode characters.\n\n    This is mostly useful for HTML or console output when you want to\n    approximate the source rendering you'd see in an IDE.\n\n    Options accepted:\n\n    `lang` : string\n       The symbol language. Must be one of ``'isabelle'`` or\n       ``'latex'``.  The default is ``'isabelle'``.\n    \"\"\"\n\n    latex_symbols = {\n        '\\\\alpha'                : '\\U000003b1',\n        '\\\\beta'                 : '\\U000003b2',\n        '\\\\gamma'                : '\\U000003b3',\n        '\\\\delta'                : '\\U000003b4',\n        '\\\\varepsilon'           : '\\U000003b5',\n        '\\\\zeta'                 : '\\U000003b6',\n        '\\\\eta'                  : '\\U000003b7',\n        '\\\\vartheta'             : '\\U000003b8',\n        '\\\\iota'                 : '\\U000003b9',\n        '\\\\kappa'                : '\\U000003ba',\n        '\\\\lambda'               : '\\U000003bb',\n        '\\\\mu'                   : '\\U000003bc',\n        '\\\\nu'                   : '\\U000003bd',\n        '\\\\xi'                   : '\\U000003be',\n        '\\\\pi'                   : '\\U000003c0',\n        '\\\\varrho'               : '\\U000003c1',\n        '\\\\sigma'                : '\\U000003c3',\n        '\\\\tau'                  : '\\U000003c4',\n        '\\\\upsilon'              : '\\U000003c5',\n        '\\\\varphi'               : '\\U000003c6',\n        '\\\\chi'                  : '\\U000003c7',\n        '\\\\psi'                  : '\\U000003c8',\n        '\\\\omega'                : '\\U000003c9',\n        '\\\\Gamma'                : '\\U00000393',\n        '\\\\Delta'                : '\\U00000394',\n        '\\\\Theta'                : '\\U00000398',\n        '\\\\Lambda'               : '\\U0000039b',\n        '\\\\Xi'                   : '\\U0000039e',\n        '\\\\Pi'                   : '\\U000003a0',\n        '\\\\Sigma'                : '\\U000003a3',\n        '\\\\Upsilon'              : '\\U000003a5',\n        '\\\\Phi'                  : '\\U000003a6',\n        '\\\\Psi'                  : '\\U000003a8',\n        '\\\\Omega'                : '\\U000003a9',\n        '\\\\leftarrow'            : '\\U00002190',\n        '\\\\longleftarrow'        : '\\U000027f5',\n        '\\\\rightarrow'           : '\\U00002192',\n        '\\\\longrightarrow'       : '\\U000027f6',\n        '\\\\Leftarrow'            : '\\U000021d0',\n        '\\\\Longleftarrow'        : '\\U000027f8',\n        '\\\\Rightarrow'           : '\\U000021d2',\n        '\\\\Longrightarrow'       : '\\U000027f9',\n        '\\\\leftrightarrow'       : '\\U00002194',\n        '\\\\longleftrightarrow'   : '\\U000027f7',\n        '\\\\Leftrightarrow'       : '\\U000021d4',\n        '\\\\Longleftrightarrow'   : '\\U000027fa',\n        '\\\\mapsto'               : '\\U000021a6',\n        '\\\\longmapsto'           : '\\U000027fc',\n        '\\\\relbar'               : '\\U00002500',\n        '\\\\Relbar'               : '\\U00002550',\n        '\\\\hookleftarrow'        : '\\U000021a9',\n        '\\\\hookrightarrow'       : '\\U000021aa',\n        '\\\\leftharpoondown'      : '\\U000021bd',\n        '\\\\rightharpoondown'     : '\\U000021c1',\n        '\\\\leftharpoonup'        : '\\U000021bc',\n        '\\\\rightharpoonup'       : '\\U000021c0',\n        '\\\\rightleftharpoons'    : '\\U000021cc',\n        '\\\\leadsto'              : '\\U0000219d',\n        '\\\\downharpoonleft'      : '\\U000021c3',\n        '\\\\downharpoonright'     : '\\U000021c2',\n        '\\\\upharpoonleft'        : '\\U000021bf',\n        '\\\\upharpoonright'       : '\\U000021be',\n        '\\\\restriction'          : '\\U000021be',\n        '\\\\uparrow'              : '\\U00002191',\n        '\\\\Uparrow'              : '\\U000021d1',\n        '\\\\downarrow'            : '\\U00002193',\n        '\\\\Downarrow'            : '\\U000021d3',\n        '\\\\updownarrow'          : '\\U00002195',\n        '\\\\Updownarrow'          : '\\U000021d5',\n        '\\\\langle'               : '\\U000027e8',\n        '\\\\rangle'               : '\\U000027e9',\n        '\\\\lceil'                : '\\U00002308',\n        '\\\\rceil'                : '\\U00002309',\n        '\\\\lfloor'               : '\\U0000230a',\n        '\\\\rfloor'               : '\\U0000230b',\n        '\\\\flqq'                 : '\\U000000ab',\n        '\\\\frqq'                 : '\\U000000bb',\n        '\\\\bot'                  : '\\U000022a5',\n        '\\\\top'                  : '\\U000022a4',\n        '\\\\wedge'                : '\\U00002227',\n        '\\\\bigwedge'             : '\\U000022c0',\n        '\\\\vee'                  : '\\U00002228',\n        '\\\\bigvee'               : '\\U000022c1',\n        '\\\\forall'               : '\\U00002200',\n        '\\\\exists'               : '\\U00002203',\n        '\\\\nexists'              : '\\U00002204',\n        '\\\\neg'                  : '\\U000000ac',\n        '\\\\Box'                  : '\\U000025a1',\n        '\\\\Diamond'              : '\\U000025c7',\n        '\\\\vdash'                : '\\U000022a2',\n        '\\\\models'               : '\\U000022a8',\n        '\\\\dashv'                : '\\U000022a3',\n        '\\\\surd'                 : '\\U0000221a',\n        '\\\\le'                   : '\\U00002264',\n        '\\\\ge'                   : '\\U00002265',\n        '\\\\ll'                   : '\\U0000226a',\n        '\\\\gg'                   : '\\U0000226b',\n        '\\\\lesssim'              : '\\U00002272',\n        '\\\\gtrsim'               : '\\U00002273',\n        '\\\\lessapprox'           : '\\U00002a85',\n        '\\\\gtrapprox'            : '\\U00002a86',\n        '\\\\in'                   : '\\U00002208',\n        '\\\\notin'                : '\\U00002209',\n        '\\\\subset'               : '\\U00002282',\n        '\\\\supset'               : '\\U00002283',\n        '\\\\subseteq'             : '\\U00002286',\n        '\\\\supseteq'             : '\\U00002287',\n        '\\\\sqsubset'             : '\\U0000228f',\n        '\\\\sqsupset'             : '\\U00002290',\n        '\\\\sqsubseteq'           : '\\U00002291',\n        '\\\\sqsupseteq'           : '\\U00002292',\n        '\\\\cap'                  : '\\U00002229',\n        '\\\\bigcap'               : '\\U000022c2',\n        '\\\\cup'                  : '\\U0000222a',\n        '\\\\bigcup'               : '\\U000022c3',\n        '\\\\sqcup'                : '\\U00002294',\n        '\\\\bigsqcup'             : '\\U00002a06',\n        '\\\\sqcap'                : '\\U00002293',\n        '\\\\Bigsqcap'             : '\\U00002a05',\n        '\\\\setminus'             : '\\U00002216',\n        '\\\\propto'               : '\\U0000221d',\n        '\\\\uplus'                : '\\U0000228e',\n        '\\\\bigplus'              : '\\U00002a04',\n        '\\\\sim'                  : '\\U0000223c',\n        '\\\\doteq'                : '\\U00002250',\n        '\\\\simeq'                : '\\U00002243',\n        '\\\\approx'               : '\\U00002248',\n        '\\\\asymp'                : '\\U0000224d',\n        '\\\\cong'                 : '\\U00002245',\n        '\\\\equiv'                : '\\U00002261',\n        '\\\\Join'                 : '\\U000022c8',\n        '\\\\bowtie'               : '\\U00002a1d',\n        '\\\\prec'                 : '\\U0000227a',\n        '\\\\succ'                 : '\\U0000227b',\n        '\\\\preceq'               : '\\U0000227c',\n        '\\\\succeq'               : '\\U0000227d',\n        '\\\\parallel'             : '\\U00002225',\n        '\\\\mid'                  : '\\U000000a6',\n        '\\\\pm'                   : '\\U000000b1',\n        '\\\\mp'                   : '\\U00002213',\n        '\\\\times'                : '\\U000000d7',\n        '\\\\div'                  : '\\U000000f7',\n        '\\\\cdot'                 : '\\U000022c5',\n        '\\\\star'                 : '\\U000022c6',\n        '\\\\circ'                 : '\\U00002218',\n        '\\\\dagger'               : '\\U00002020',\n        '\\\\ddagger'              : '\\U00002021',\n        '\\\\lhd'                  : '\\U000022b2',\n        '\\\\rhd'                  : '\\U000022b3',\n        '\\\\unlhd'                : '\\U000022b4',\n        '\\\\unrhd'                : '\\U000022b5',\n        '\\\\triangleleft'         : '\\U000025c3',\n        '\\\\triangleright'        : '\\U000025b9',\n        '\\\\triangle'             : '\\U000025b3',\n        '\\\\triangleq'            : '\\U0000225c',\n        '\\\\oplus'                : '\\U00002295',\n        '\\\\bigoplus'             : '\\U00002a01',\n        '\\\\otimes'               : '\\U00002297',\n        '\\\\bigotimes'            : '\\U00002a02',\n        '\\\\odot'                 : '\\U00002299',\n        '\\\\bigodot'              : '\\U00002a00',\n        '\\\\ominus'               : '\\U00002296',\n        '\\\\oslash'               : '\\U00002298',\n        '\\\\dots'                 : '\\U00002026',\n        '\\\\cdots'                : '\\U000022ef',\n        '\\\\sum'                  : '\\U00002211',\n        '\\\\prod'                 : '\\U0000220f',\n        '\\\\coprod'               : '\\U00002210',\n        '\\\\infty'                : '\\U0000221e',\n        '\\\\int'                  : '\\U0000222b',\n        '\\\\oint'                 : '\\U0000222e',\n        '\\\\clubsuit'             : '\\U00002663',\n        '\\\\diamondsuit'          : '\\U00002662',\n        '\\\\heartsuit'            : '\\U00002661',\n        '\\\\spadesuit'            : '\\U00002660',\n        '\\\\aleph'                : '\\U00002135',\n        '\\\\emptyset'             : '\\U00002205',\n        '\\\\nabla'                : '\\U00002207',\n        '\\\\partial'              : '\\U00002202',\n        '\\\\flat'                 : '\\U0000266d',\n        '\\\\natural'              : '\\U0000266e',\n        '\\\\sharp'                : '\\U0000266f',\n        '\\\\angle'                : '\\U00002220',\n        '\\\\copyright'            : '\\U000000a9',\n        '\\\\textregistered'       : '\\U000000ae',\n        '\\\\textonequarter'       : '\\U000000bc',\n        '\\\\textonehalf'          : '\\U000000bd',\n        '\\\\textthreequarters'    : '\\U000000be',\n        '\\\\textordfeminine'      : '\\U000000aa',\n        '\\\\textordmasculine'     : '\\U000000ba',\n        '\\\\euro'                 : '\\U000020ac',\n        '\\\\pounds'               : '\\U000000a3',\n        '\\\\yen'                  : '\\U000000a5',\n        '\\\\textcent'             : '\\U000000a2',\n        '\\\\textcurrency'         : '\\U000000a4',\n        '\\\\textdegree'           : '\\U000000b0',\n    }\n\n    isabelle_symbols = {\n        '\\\\<zero>'                 : '\\U0001d7ec',\n        '\\\\<one>'                  : '\\U0001d7ed',\n        '\\\\<two>'                  : '\\U0001d7ee',\n        '\\\\<three>'                : '\\U0001d7ef',\n        '\\\\<four>'                 : '\\U0001d7f0',\n        '\\\\<five>'                 : '\\U0001d7f1',\n        '\\\\<six>'                  : '\\U0001d7f2',\n        '\\\\<seven>'                : '\\U0001d7f3',\n        '\\\\<eight>'                : '\\U0001d7f4',\n        '\\\\<nine>'                 : '\\U0001d7f5',\n        '\\\\<A>'                    : '\\U0001d49c',\n        '\\\\<B>'                    : '\\U0000212c',\n        '\\\\<C>'                    : '\\U0001d49e',\n        '\\\\<D>'                    : '\\U0001d49f',\n        '\\\\<E>'                    : '\\U00002130',\n        '\\\\<F>'                    : '\\U00002131',\n        '\\\\<G>'                    : '\\U0001d4a2',\n        '\\\\<H>'                    : '\\U0000210b',\n        '\\\\<I>'                    : '\\U00002110',\n        '\\\\<J>'                    : '\\U0001d4a5',\n        '\\\\<K>'                    : '\\U0001d4a6',\n        '\\\\<L>'                    : '\\U00002112',\n        '\\\\<M>'                    : '\\U00002133',\n        '\\\\<N>'                    : '\\U0001d4a9',\n        '\\\\<O>'                    : '\\U0001d4aa',\n        '\\\\<P>'                    : '\\U0001d4ab',\n        '\\\\<Q>'                    : '\\U0001d4ac',\n        '\\\\<R>'                    : '\\U0000211b',\n        '\\\\<S>'                    : '\\U0001d4ae',\n        '\\\\<T>'                    : '\\U0001d4af',\n        '\\\\<U>'                    : '\\U0001d4b0',\n        '\\\\<V>'                    : '\\U0001d4b1',\n        '\\\\<W>'                    : '\\U0001d4b2',\n        '\\\\<X>'                    : '\\U0001d4b3',\n        '\\\\<Y>'                    : '\\U0001d4b4',\n        '\\\\<Z>'                    : '\\U0001d4b5',\n        '\\\\<a>'                    : '\\U0001d5ba',\n        '\\\\<b>'                    : '\\U0001d5bb',\n        '\\\\<c>'                    : '\\U0001d5bc',\n        '\\\\<d>'                    : '\\U0001d5bd',\n        '\\\\<e>'                    : '\\U0001d5be',\n        '\\\\<f>'                    : '\\U0001d5bf',\n        '\\\\<g>'                    : '\\U0001d5c0',\n        '\\\\<h>'                    : '\\U0001d5c1',\n        '\\\\<i>'                    : '\\U0001d5c2',\n        '\\\\<j>'                    : '\\U0001d5c3',\n        '\\\\<k>'                    : '\\U0001d5c4',\n        '\\\\<l>'                    : '\\U0001d5c5',\n        '\\\\<m>'                    : '\\U0001d5c6',\n        '\\\\<n>'                    : '\\U0001d5c7',\n        '\\\\<o>'                    : '\\U0001d5c8',\n        '\\\\<p>'                    : '\\U0001d5c9',\n        '\\\\<q>'                    : '\\U0001d5ca',\n        '\\\\<r>'                    : '\\U0001d5cb',\n        '\\\\<s>'                    : '\\U0001d5cc',\n        '\\\\<t>'                    : '\\U0001d5cd',\n        '\\\\<u>'                    : '\\U0001d5ce',\n        '\\\\<v>'                    : '\\U0001d5cf',\n        '\\\\<w>'                    : '\\U0001d5d0',\n        '\\\\<x>'                    : '\\U0001d5d1',\n        '\\\\<y>'                    : '\\U0001d5d2',\n        '\\\\<z>'                    : '\\U0001d5d3',\n        '\\\\<AA>'                   : '\\U0001d504',\n        '\\\\<BB>'                   : '\\U0001d505',\n        '\\\\<CC>'                   : '\\U0000212d',\n        '\\\\<DD>'                   : '\\U0001d507',\n        '\\\\<EE>'                   : '\\U0001d508',\n        '\\\\<FF>'                   : '\\U0001d509',\n        '\\\\<GG>'                   : '\\U0001d50a',\n        '\\\\<HH>'                   : '\\U0000210c',\n        '\\\\<II>'                   : '\\U00002111',\n        '\\\\<JJ>'                   : '\\U0001d50d',\n        '\\\\<KK>'                   : '\\U0001d50e',\n        '\\\\<LL>'                   : '\\U0001d50f',\n        '\\\\<MM>'                   : '\\U0001d510',\n        '\\\\<NN>'                   : '\\U0001d511',\n        '\\\\<OO>'                   : '\\U0001d512',\n        '\\\\<PP>'                   : '\\U0001d513',\n        '\\\\<QQ>'                   : '\\U0001d514',\n        '\\\\<RR>'                   : '\\U0000211c',\n        '\\\\<SS>'                   : '\\U0001d516',\n        '\\\\<TT>'                   : '\\U0001d517',\n        '\\\\<UU>'                   : '\\U0001d518',\n        '\\\\<VV>'                   : '\\U0001d519',\n        '\\\\<WW>'                   : '\\U0001d51a',\n        '\\\\<XX>'                   : '\\U0001d51b',\n        '\\\\<YY>'                   : '\\U0001d51c',\n        '\\\\<ZZ>'                   : '\\U00002128',\n        '\\\\<aa>'                   : '\\U0001d51e',\n        '\\\\<bb>'                   : '\\U0001d51f',\n        '\\\\<cc>'                   : '\\U0001d520',\n        '\\\\<dd>'                   : '\\U0001d521',\n        '\\\\<ee>'                   : '\\U0001d522',\n        '\\\\<ff>'                   : '\\U0001d523',\n        '\\\\<gg>'                   : '\\U0001d524',\n        '\\\\<hh>'                   : '\\U0001d525',\n        '\\\\<ii>'                   : '\\U0001d526',\n        '\\\\<jj>'                   : '\\U0001d527',\n        '\\\\<kk>'                   : '\\U0001d528',\n        '\\\\<ll>'                   : '\\U0001d529',\n        '\\\\<mm>'                   : '\\U0001d52a',\n        '\\\\<nn>'                   : '\\U0001d52b',\n        '\\\\<oo>'                   : '\\U0001d52c',\n        '\\\\<pp>'                   : '\\U0001d52d',\n        '\\\\<qq>'                   : '\\U0001d52e',\n        '\\\\<rr>'                   : '\\U0001d52f',\n        '\\\\<ss>'                   : '\\U0001d530',\n        '\\\\<tt>'                   : '\\U0001d531',\n        '\\\\<uu>'                   : '\\U0001d532',\n        '\\\\<vv>'                   : '\\U0001d533',\n        '\\\\<ww>'                   : '\\U0001d534',\n        '\\\\<xx>'                   : '\\U0001d535',\n        '\\\\<yy>'                   : '\\U0001d536',\n        '\\\\<zz>'                   : '\\U0001d537',\n        '\\\\<alpha>'                : '\\U000003b1',\n        '\\\\<beta>'                 : '\\U000003b2',\n        '\\\\<gamma>'                : '\\U000003b3',\n        '\\\\<delta>'                : '\\U000003b4',\n        '\\\\<epsilon>'              : '\\U000003b5',\n        '\\\\<zeta>'                 : '\\U000003b6',\n        '\\\\<eta>'                  : '\\U000003b7',\n        '\\\\<theta>'                : '\\U000003b8',\n        '\\\\<iota>'                 : '\\U000003b9',\n        '\\\\<kappa>'                : '\\U000003ba',\n        '\\\\<lambda>'               : '\\U000003bb',\n        '\\\\<mu>'                   : '\\U000003bc',\n        '\\\\<nu>'                   : '\\U000003bd',\n        '\\\\<xi>'                   : '\\U000003be',\n        '\\\\<pi>'                   : '\\U000003c0',\n        '\\\\<rho>'                  : '\\U000003c1',\n        '\\\\<sigma>'                : '\\U000003c3',\n        '\\\\<tau>'                  : '\\U000003c4',\n        '\\\\<upsilon>'              : '\\U000003c5',\n        '\\\\<phi>'                  : '\\U000003c6',\n        '\\\\<chi>'                  : '\\U000003c7',\n        '\\\\<psi>'                  : '\\U000003c8',\n        '\\\\<omega>'                : '\\U000003c9',\n        '\\\\<Gamma>'                : '\\U00000393',\n        '\\\\<Delta>'                : '\\U00000394',\n        '\\\\<Theta>'                : '\\U00000398',\n        '\\\\<Lambda>'               : '\\U0000039b',\n        '\\\\<Xi>'                   : '\\U0000039e',\n        '\\\\<Pi>'                   : '\\U000003a0',\n        '\\\\<Sigma>'                : '\\U000003a3',\n        '\\\\<Upsilon>'              : '\\U000003a5',\n        '\\\\<Phi>'                  : '\\U000003a6',\n        '\\\\<Psi>'                  : '\\U000003a8',\n        '\\\\<Omega>'                : '\\U000003a9',\n        '\\\\<bool>'                 : '\\U0001d539',\n        '\\\\<complex>'              : '\\U00002102',\n        '\\\\<nat>'                  : '\\U00002115',\n        '\\\\<rat>'                  : '\\U0000211a',\n        '\\\\<real>'                 : '\\U0000211d',\n        '\\\\<int>'                  : '\\U00002124',\n        '\\\\<leftarrow>'            : '\\U00002190',\n        '\\\\<longleftarrow>'        : '\\U000027f5',\n        '\\\\<rightarrow>'           : '\\U00002192',\n        '\\\\<longrightarrow>'       : '\\U000027f6',\n        '\\\\<Leftarrow>'            : '\\U000021d0',\n        '\\\\<Longleftarrow>'        : '\\U000027f8',\n        '\\\\<Rightarrow>'           : '\\U000021d2',\n        '\\\\<Longrightarrow>'       : '\\U000027f9',\n        '\\\\<leftrightarrow>'       : '\\U00002194',\n        '\\\\<longleftrightarrow>'   : '\\U000027f7',\n        '\\\\<Leftrightarrow>'       : '\\U000021d4',\n        '\\\\<Longleftrightarrow>'   : '\\U000027fa',\n        '\\\\<mapsto>'               : '\\U000021a6',\n        '\\\\<longmapsto>'           : '\\U000027fc',\n        '\\\\<midarrow>'             : '\\U00002500',\n        '\\\\<Midarrow>'             : '\\U00002550',\n        '\\\\<hookleftarrow>'        : '\\U000021a9',\n        '\\\\<hookrightarrow>'       : '\\U000021aa',\n        '\\\\<leftharpoondown>'      : '\\U000021bd',\n        '\\\\<rightharpoondown>'     : '\\U000021c1',\n        '\\\\<leftharpoonup>'        : '\\U000021bc',\n        '\\\\<rightharpoonup>'       : '\\U000021c0',\n        '\\\\<rightleftharpoons>'    : '\\U000021cc',\n        '\\\\<leadsto>'              : '\\U0000219d',\n        '\\\\<downharpoonleft>'      : '\\U000021c3',\n        '\\\\<downharpoonright>'     : '\\U000021c2',\n        '\\\\<upharpoonleft>'        : '\\U000021bf',\n        '\\\\<upharpoonright>'       : '\\U000021be',\n        '\\\\<restriction>'          : '\\U000021be',\n        '\\\\<Colon>'                : '\\U00002237',\n        '\\\\<up>'                   : '\\U00002191',\n        '\\\\<Up>'                   : '\\U000021d1',\n        '\\\\<down>'                 : '\\U00002193',\n        '\\\\<Down>'                 : '\\U000021d3',\n        '\\\\<updown>'               : '\\U00002195',\n        '\\\\<Updown>'               : '\\U000021d5',\n        '\\\\<langle>'               : '\\U000027e8',\n        '\\\\<rangle>'               : '\\U000027e9',\n        '\\\\<lceil>'                : '\\U00002308',\n        '\\\\<rceil>'                : '\\U00002309',\n        '\\\\<lfloor>'               : '\\U0000230a',\n        '\\\\<rfloor>'               : '\\U0000230b',\n        '\\\\<lparr>'                : '\\U00002987',\n        '\\\\<rparr>'                : '\\U00002988',\n        '\\\\<lbrakk>'               : '\\U000027e6',\n        '\\\\<rbrakk>'               : '\\U000027e7',\n        '\\\\<lbrace>'               : '\\U00002983',\n        '\\\\<rbrace>'               : '\\U00002984',\n        '\\\\<guillemotleft>'        : '\\U000000ab',\n        '\\\\<guillemotright>'       : '\\U000000bb',\n        '\\\\<bottom>'               : '\\U000022a5',\n        '\\\\<top>'                  : '\\U000022a4',\n        '\\\\<and>'                  : '\\U00002227',\n        '\\\\<And>'                  : '\\U000022c0',\n        '\\\\<or>'                   : '\\U00002228',\n        '\\\\<Or>'                   : '\\U000022c1',\n        '\\\\<forall>'               : '\\U00002200',\n        '\\\\<exists>'               : '\\U00002203',\n        '\\\\<nexists>'              : '\\U00002204',\n        '\\\\<not>'                  : '\\U000000ac',\n        '\\\\<box>'                  : '\\U000025a1',\n        '\\\\<diamond>'              : '\\U000025c7',\n        '\\\\<turnstile>'            : '\\U000022a2',\n        '\\\\<Turnstile>'            : '\\U000022a8',\n        '\\\\<tturnstile>'           : '\\U000022a9',\n        '\\\\<TTurnstile>'           : '\\U000022ab',\n        '\\\\<stileturn>'            : '\\U000022a3',\n        '\\\\<surd>'                 : '\\U0000221a',\n        '\\\\<le>'                   : '\\U00002264',\n        '\\\\<ge>'                   : '\\U00002265',\n        '\\\\<lless>'                : '\\U0000226a',\n        '\\\\<ggreater>'             : '\\U0000226b',\n        '\\\\<lesssim>'              : '\\U00002272',\n        '\\\\<greatersim>'           : '\\U00002273',\n        '\\\\<lessapprox>'           : '\\U00002a85',\n        '\\\\<greaterapprox>'        : '\\U00002a86',\n        '\\\\<in>'                   : '\\U00002208',\n        '\\\\<notin>'                : '\\U00002209',\n        '\\\\<subset>'               : '\\U00002282',\n        '\\\\<supset>'               : '\\U00002283',\n        '\\\\<subseteq>'             : '\\U00002286',\n        '\\\\<supseteq>'             : '\\U00002287',\n        '\\\\<sqsubset>'             : '\\U0000228f',\n        '\\\\<sqsupset>'             : '\\U00002290',\n        '\\\\<sqsubseteq>'           : '\\U00002291',\n        '\\\\<sqsupseteq>'           : '\\U00002292',\n        '\\\\<inter>'                : '\\U00002229',\n        '\\\\<Inter>'                : '\\U000022c2',\n        '\\\\<union>'                : '\\U0000222a',\n        '\\\\<Union>'                : '\\U000022c3',\n        '\\\\<squnion>'              : '\\U00002294',\n        '\\\\<Squnion>'              : '\\U00002a06',\n        '\\\\<sqinter>'              : '\\U00002293',\n        '\\\\<Sqinter>'              : '\\U00002a05',\n        '\\\\<setminus>'             : '\\U00002216',\n        '\\\\<propto>'               : '\\U0000221d',\n        '\\\\<uplus>'                : '\\U0000228e',\n        '\\\\<Uplus>'                : '\\U00002a04',\n        '\\\\<noteq>'                : '\\U00002260',\n        '\\\\<sim>'                  : '\\U0000223c',\n        '\\\\<doteq>'                : '\\U00002250',\n        '\\\\<simeq>'                : '\\U00002243',\n        '\\\\<approx>'               : '\\U00002248',\n        '\\\\<asymp>'                : '\\U0000224d',\n        '\\\\<cong>'                 : '\\U00002245',\n        '\\\\<smile>'                : '\\U00002323',\n        '\\\\<equiv>'                : '\\U00002261',\n        '\\\\<frown>'                : '\\U00002322',\n        '\\\\<Join>'                 : '\\U000022c8',\n        '\\\\<bowtie>'               : '\\U00002a1d',\n        '\\\\<prec>'                 : '\\U0000227a',\n        '\\\\<succ>'                 : '\\U0000227b',\n        '\\\\<preceq>'               : '\\U0000227c',\n        '\\\\<succeq>'               : '\\U0000227d',\n        '\\\\<parallel>'             : '\\U00002225',\n        '\\\\<bar>'                  : '\\U000000a6',\n        '\\\\<plusminus>'            : '\\U000000b1',\n        '\\\\<minusplus>'            : '\\U00002213',\n        '\\\\<times>'                : '\\U000000d7',\n        '\\\\<div>'                  : '\\U000000f7',\n        '\\\\<cdot>'                 : '\\U000022c5',\n        '\\\\<star>'                 : '\\U000022c6',\n        '\\\\<bullet>'               : '\\U00002219',\n        '\\\\<circ>'                 : '\\U00002218',\n        '\\\\<dagger>'               : '\\U00002020',\n        '\\\\<ddagger>'              : '\\U00002021',\n        '\\\\<lhd>'                  : '\\U000022b2',\n        '\\\\<rhd>'                  : '\\U000022b3',\n        '\\\\<unlhd>'                : '\\U000022b4',\n        '\\\\<unrhd>'                : '\\U000022b5',\n        '\\\\<triangleleft>'         : '\\U000025c3',\n        '\\\\<triangleright>'        : '\\U000025b9',\n        '\\\\<triangle>'             : '\\U000025b3',\n        '\\\\<triangleq>'            : '\\U0000225c',\n        '\\\\<oplus>'                : '\\U00002295',\n        '\\\\<Oplus>'                : '\\U00002a01',\n        '\\\\<otimes>'               : '\\U00002297',\n        '\\\\<Otimes>'               : '\\U00002a02',\n        '\\\\<odot>'                 : '\\U00002299',\n        '\\\\<Odot>'                 : '\\U00002a00',\n        '\\\\<ominus>'               : '\\U00002296',\n        '\\\\<oslash>'               : '\\U00002298',\n        '\\\\<dots>'                 : '\\U00002026',\n        '\\\\<cdots>'                : '\\U000022ef',\n        '\\\\<Sum>'                  : '\\U00002211',\n        '\\\\<Prod>'                 : '\\U0000220f',\n        '\\\\<Coprod>'               : '\\U00002210',\n        '\\\\<infinity>'             : '\\U0000221e',\n        '\\\\<integral>'             : '\\U0000222b',\n        '\\\\<ointegral>'            : '\\U0000222e',\n        '\\\\<clubsuit>'             : '\\U00002663',\n        '\\\\<diamondsuit>'          : '\\U00002662',\n        '\\\\<heartsuit>'            : '\\U00002661',\n        '\\\\<spadesuit>'            : '\\U00002660',\n        '\\\\<aleph>'                : '\\U00002135',\n        '\\\\<emptyset>'             : '\\U00002205',\n        '\\\\<nabla>'                : '\\U00002207',\n        '\\\\<partial>'              : '\\U00002202',\n        '\\\\<flat>'                 : '\\U0000266d',\n        '\\\\<natural>'              : '\\U0000266e',\n        '\\\\<sharp>'                : '\\U0000266f',\n        '\\\\<angle>'                : '\\U00002220',\n        '\\\\<copyright>'            : '\\U000000a9',\n        '\\\\<registered>'           : '\\U000000ae',\n        '\\\\<hyphen>'               : '\\U000000ad',\n        '\\\\<inverse>'              : '\\U000000af',\n        '\\\\<onequarter>'           : '\\U000000bc',\n        '\\\\<onehalf>'              : '\\U000000bd',\n        '\\\\<threequarters>'        : '\\U000000be',\n        '\\\\<ordfeminine>'          : '\\U000000aa',\n        '\\\\<ordmasculine>'         : '\\U000000ba',\n        '\\\\<section>'              : '\\U000000a7',\n        '\\\\<paragraph>'            : '\\U000000b6',\n        '\\\\<exclamdown>'           : '\\U000000a1',\n        '\\\\<questiondown>'         : '\\U000000bf',\n        '\\\\<euro>'                 : '\\U000020ac',\n        '\\\\<pounds>'               : '\\U000000a3',\n        '\\\\<yen>'                  : '\\U000000a5',\n        '\\\\<cent>'                 : '\\U000000a2',\n        '\\\\<currency>'             : '\\U000000a4',\n        '\\\\<degree>'               : '\\U000000b0',\n        '\\\\<amalg>'                : '\\U00002a3f',\n        '\\\\<mho>'                  : '\\U00002127',\n        '\\\\<lozenge>'              : '\\U000025ca',\n        '\\\\<wp>'                   : '\\U00002118',\n        '\\\\<wrong>'                : '\\U00002240',\n        '\\\\<struct>'               : '\\U000022c4',\n        '\\\\<acute>'                : '\\U000000b4',\n        '\\\\<index>'                : '\\U00000131',\n        '\\\\<dieresis>'             : '\\U000000a8',\n        '\\\\<cedilla>'              : '\\U000000b8',\n        '\\\\<hungarumlaut>'         : '\\U000002dd',\n        '\\\\<some>'                 : '\\U000003f5',\n        '\\\\<newline>'              : '\\U000023ce',\n        '\\\\<open>'                 : '\\U00002039',\n        '\\\\<close>'                : '\\U0000203a',\n        '\\\\<here>'                 : '\\U00002302',\n        '\\\\<^sub>'                 : '\\U000021e9',\n        '\\\\<^sup>'                 : '\\U000021e7',\n        '\\\\<^bold>'                : '\\U00002759',\n        '\\\\<^bsub>'                : '\\U000021d8',\n        '\\\\<^esub>'                : '\\U000021d9',\n        '\\\\<^bsup>'                : '\\U000021d7',\n        '\\\\<^esup>'                : '\\U000021d6',\n    }\n\n    lang_map = {'isabelle' : isabelle_symbols, 'latex' : latex_symbols}\n\n    def __init__(self, **options):\n        Filter.__init__(self, **options)\n        lang = get_choice_opt(options, 'lang',\n                              ['isabelle', 'latex'], 'isabelle')\n        self.symbols = self.lang_map[lang]\n\n    def filter(self, lexer, stream):\n        for ttype, value in stream:\n            if value in self.symbols:\n                yield ttype, self.symbols[value]\n            else:\n                yield ttype, value\n\n\nclass KeywordCaseFilter(Filter):\n    \"\"\"Convert keywords to lowercase or uppercase or capitalize them, which\n    means first letter uppercase, rest lowercase.\n\n    This can be useful e.g. if you highlight Pascal code and want to adapt the\n    code to your styleguide.\n\n    Options accepted:\n\n    `case` : string\n       The casing to convert keywords to. Must be one of ``'lower'``,\n       ``'upper'`` or ``'capitalize'``.  The default is ``'lower'``.\n    \"\"\"\n\n    def __init__(self, **options):\n        Filter.__init__(self, **options)\n        case = get_choice_opt(options, 'case',\n                              ['lower', 'upper', 'capitalize'], 'lower')\n        self.convert = getattr(str, case)\n\n    def filter(self, lexer, stream):\n        for ttype, value in stream:\n            if ttype in Keyword:\n                yield ttype, self.convert(value)\n            else:\n                yield ttype, value\n\n\nclass NameHighlightFilter(Filter):\n    \"\"\"Highlight a normal Name (and Name.*) token with a different token type.\n\n    Example::\n\n        filter = NameHighlightFilter(\n            names=['foo', 'bar', 'baz'],\n            tokentype=Name.Function,\n        )\n\n    This would highlight the names \"foo\", \"bar\" and \"baz\"\n    as functions. `Name.Function` is the default token type.\n\n    Options accepted:\n\n    `names` : list of strings\n      A list of names that should be given the different token type.\n      There is no default.\n    `tokentype` : TokenType or string\n      A token type or a string containing a token type name that is\n      used for highlighting the strings in `names`.  The default is\n      `Name.Function`.\n    \"\"\"\n\n    def __init__(self, **options):\n        Filter.__init__(self, **options)\n        self.names = set(get_list_opt(options, 'names', []))\n        tokentype = options.get('tokentype')\n        if tokentype:\n            self.tokentype = string_to_tokentype(tokentype)\n        else:\n            self.tokentype = Name.Function\n\n    def filter(self, lexer, stream):\n        for ttype, value in stream:\n            if ttype in Name and value in self.names:\n                yield self.tokentype, value\n            else:\n                yield ttype, value\n\n\nclass ErrorToken(Exception):\n    pass\n\n\nclass RaiseOnErrorTokenFilter(Filter):\n    \"\"\"Raise an exception when the lexer generates an error token.\n\n    Options accepted:\n\n    `excclass` : Exception class\n      The exception class to raise.\n      The default is `pygments.filters.ErrorToken`.\n\n    .. versionadded:: 0.8\n    \"\"\"\n\n    def __init__(self, **options):\n        Filter.__init__(self, **options)\n        self.exception = options.get('excclass', ErrorToken)\n        try:\n            # issubclass() will raise TypeError if first argument is not a class\n            if not issubclass(self.exception, Exception):\n                raise TypeError\n        except TypeError:\n            raise OptionError('excclass option is not an exception class')\n\n    def filter(self, lexer, stream):\n        for ttype, value in stream:\n            if ttype is Error:\n                raise self.exception(value)\n            yield ttype, value\n\n\nclass VisibleWhitespaceFilter(Filter):\n    \"\"\"Convert tabs, newlines and/or spaces to visible characters.\n\n    Options accepted:\n\n    `spaces` : string or bool\n      If this is a one-character string, spaces will be replaces by this string.\n      If it is another true value, spaces will be replaced by ``·`` (unicode\n      MIDDLE DOT).  If it is a false value, spaces will not be replaced.  The\n      default is ``False``.\n    `tabs` : string or bool\n      The same as for `spaces`, but the default replacement character is ``»``\n      (unicode RIGHT-POINTING DOUBLE ANGLE QUOTATION MARK).  The default value\n      is ``False``.  Note: this will not work if the `tabsize` option for the\n      lexer is nonzero, as tabs will already have been expanded then.\n    `tabsize` : int\n      If tabs are to be replaced by this filter (see the `tabs` option), this\n      is the total number of characters that a tab should be expanded to.\n      The default is ``8``.\n    `newlines` : string or bool\n      The same as for `spaces`, but the default replacement character is ``¶``\n      (unicode PILCROW SIGN).  The default value is ``False``.\n    `wstokentype` : bool\n      If true, give whitespace the special `Whitespace` token type.  This allows\n      styling the visible whitespace differently (e.g. greyed out), but it can\n      disrupt background colors.  The default is ``True``.\n\n    .. versionadded:: 0.8\n    \"\"\"\n\n    def __init__(self, **options):\n        Filter.__init__(self, **options)\n        for name, default in [('spaces',   '·'),\n                              ('tabs',     '»'),\n                              ('newlines', '¶')]:\n            opt = options.get(name, False)\n            if isinstance(opt, str) and len(opt) == 1:\n                setattr(self, name, opt)\n            else:\n                setattr(self, name, (opt and default or ''))\n        tabsize = get_int_opt(options, 'tabsize', 8)\n        if self.tabs:\n            self.tabs += ' ' * (tabsize - 1)\n        if self.newlines:\n            self.newlines += '\\n'\n        self.wstt = get_bool_opt(options, 'wstokentype', True)\n\n    def filter(self, lexer, stream):\n        if self.wstt:\n            spaces = self.spaces or ' '\n            tabs = self.tabs or '\\t'\n            newlines = self.newlines or '\\n'\n            regex = re.compile(r'\\s')\n\n            def replacefunc(wschar):\n                if wschar == ' ':\n                    return spaces\n                elif wschar == '\\t':\n                    return tabs\n                elif wschar == '\\n':\n                    return newlines\n                return wschar\n\n            for ttype, value in stream:\n                yield from _replace_special(ttype, value, regex, Whitespace,\n                                            replacefunc)\n        else:\n            spaces, tabs, newlines = self.spaces, self.tabs, self.newlines\n            # simpler processing\n            for ttype, value in stream:\n                if spaces:\n                    value = value.replace(' ', spaces)\n                if tabs:\n                    value = value.replace('\\t', tabs)\n                if newlines:\n                    value = value.replace('\\n', newlines)\n                yield ttype, value\n\n\nclass GobbleFilter(Filter):\n    \"\"\"Gobbles source code lines (eats initial characters).\n\n    This filter drops the first ``n`` characters off every line of code.  This\n    may be useful when the source code fed to the lexer is indented by a fixed\n    amount of space that isn't desired in the output.\n\n    Options accepted:\n\n    `n` : int\n       The number of characters to gobble.\n\n    .. versionadded:: 1.2\n    \"\"\"\n    def __init__(self, **options):\n        Filter.__init__(self, **options)\n        self.n = get_int_opt(options, 'n', 0)\n\n    def gobble(self, value, left):\n        if left < len(value):\n            return value[left:], 0\n        else:\n            return '', left - len(value)\n\n    def filter(self, lexer, stream):\n        n = self.n\n        left = n  # How many characters left to gobble.\n        for ttype, value in stream:\n            # Remove ``left`` tokens from first line, ``n`` from all others.\n            parts = value.split('\\n')\n            (parts[0], left) = self.gobble(parts[0], left)\n            for i in range(1, len(parts)):\n                (parts[i], left) = self.gobble(parts[i], n)\n            value = '\\n'.join(parts)\n\n            if value != '':\n                yield ttype, value\n\n\nclass TokenMergeFilter(Filter):\n    \"\"\"Merges consecutive tokens with the same token type in the output\n    stream of a lexer.\n\n    .. versionadded:: 1.2\n    \"\"\"\n    def __init__(self, **options):\n        Filter.__init__(self, **options)\n\n    def filter(self, lexer, stream):\n        current_type = None\n        current_value = None\n        for ttype, value in stream:\n            if ttype is current_type:\n                current_value += value\n            else:\n                if current_type is not None:\n                    yield current_type, current_value\n                current_type = ttype\n                current_value = value\n        if current_type is not None:\n            yield current_type, current_value\n\n\nFILTERS = {\n    'codetagify':     CodeTagFilter,\n    'keywordcase':    KeywordCaseFilter,\n    'highlight':      NameHighlightFilter,\n    'raiseonerror':   RaiseOnErrorTokenFilter,\n    'whitespace':     VisibleWhitespaceFilter,\n    'gobble':         GobbleFilter,\n    'tokenmerge':     TokenMergeFilter,\n    'symbols':        SymbolFilter,\n}\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/pygments/formatter.py","size":4390,"sha1":"9d64b6124007fb61d9b7c9424e6cab047404992d","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\n    pygments.formatter\n    ~~~~~~~~~~~~~~~~~~\n\n    Base formatter class.\n\n    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nimport codecs\n\nfrom pip._vendor.pygments.util import get_bool_opt\nfrom pip._vendor.pygments.styles import get_style_by_name\n\n__all__ = ['Formatter']\n\n\ndef _lookup_style(style):\n    if isinstance(style, str):\n        return get_style_by_name(style)\n    return style\n\n\nclass Formatter:\n    \"\"\"\n    Converts a token stream to text.\n\n    Formatters should have attributes to help selecting them. These\n    are similar to the corresponding :class:`~pygments.lexer.Lexer`\n    attributes.\n\n    .. autoattribute:: name\n       :no-value:\n\n    .. autoattribute:: aliases\n       :no-value:\n\n    .. autoattribute:: filenames\n       :no-value:\n\n    You can pass options as keyword arguments to the constructor.\n    All formatters accept these basic options:\n\n    ``style``\n        The style to use, can be a string or a Style subclass\n        (default: \"default\"). Not used by e.g. the\n        TerminalFormatter.\n    ``full``\n        Tells the formatter to output a \"full\" document, i.e.\n        a complete self-contained document. This doesn't have\n        any effect for some formatters (default: false).\n    ``title``\n        If ``full`` is true, the title that should be used to\n        caption the document (default: '').\n    ``encoding``\n        If given, must be an encoding name. This will be used to\n        convert the Unicode token strings to byte strings in the\n        output. If it is \"\" or None, Unicode strings will be written\n        to the output file, which most file-like objects do not\n        support (default: None).\n    ``outencoding``\n        Overrides ``encoding`` if given.\n\n    \"\"\"\n\n    #: Full name for the formatter, in human-readable form.\n    name = None\n\n    #: A list of short, unique identifiers that can be used to lookup\n    #: the formatter from a list, e.g. using :func:`.get_formatter_by_name()`.\n    aliases = []\n\n    #: A list of fnmatch patterns that match filenames for which this\n    #: formatter can produce output. The patterns in this list should be unique\n    #: among all formatters.\n    filenames = []\n\n    #: If True, this formatter outputs Unicode strings when no encoding\n    #: option is given.\n    unicodeoutput = True\n\n    def __init__(self, **options):\n        \"\"\"\n        As with lexers, this constructor takes arbitrary optional arguments,\n        and if you override it, you should first process your own options, then\n        call the base class implementation.\n        \"\"\"\n        self.style = _lookup_style(options.get('style', 'default'))\n        self.full = get_bool_opt(options, 'full', False)\n        self.title = options.get('title', '')\n        self.encoding = options.get('encoding', None) or None\n        if self.encoding in ('guess', 'chardet'):\n            # can happen for e.g. pygmentize -O encoding=guess\n            self.encoding = 'utf-8'\n        self.encoding = options.get('outencoding') or self.encoding\n        self.options = options\n\n    def get_style_defs(self, arg=''):\n        \"\"\"\n        This method must return statements or declarations suitable to define\n        the current style for subsequent highlighted text (e.g. CSS classes\n        in the `HTMLFormatter`).\n\n        The optional argument `arg` can be used to modify the generation and\n        is formatter dependent (it is standardized because it can be given on\n        the command line).\n\n        This method is called by the ``-S`` :doc:`command-line option <cmdline>`,\n        the `arg` is then given by the ``-a`` option.\n        \"\"\"\n        return ''\n\n    def format(self, tokensource, outfile):\n        \"\"\"\n        This method must format the tokens from the `tokensource` iterable and\n        write the formatted version to the file object `outfile`.\n\n        Formatter options can control how exactly the tokens are converted.\n        \"\"\"\n        if self.encoding:\n            # wrap the outfile in a StreamWriter\n            outfile = codecs.lookup(self.encoding)[3](outfile)\n        return self.format_unencoded(tokensource, outfile)\n\n    # Allow writing Formatter[str] or Formatter[bytes]. That's equivalent to\n    # Formatter. This helps when using third-party type stubs from typeshed.\n    def __class_getitem__(cls, name):\n        return cls\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/pygments/formatters/__init__.py","size":5385,"sha1":"46136d7e6364ccda06d6e4bcf9ee87b7cee6fb19","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\n    pygments.formatters\n    ~~~~~~~~~~~~~~~~~~~\n\n    Pygments formatters.\n\n    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nimport re\nimport sys\nimport types\nimport fnmatch\nfrom os.path import basename\n\nfrom pip._vendor.pygments.formatters._mapping import FORMATTERS\nfrom pip._vendor.pygments.plugin import find_plugin_formatters\nfrom pip._vendor.pygments.util import ClassNotFound\n\n__all__ = ['get_formatter_by_name', 'get_formatter_for_filename',\n           'get_all_formatters', 'load_formatter_from_file'] + list(FORMATTERS)\n\n_formatter_cache = {}  # classes by name\n_pattern_cache = {}\n\n\ndef _fn_matches(fn, glob):\n    \"\"\"Return whether the supplied file name fn matches pattern filename.\"\"\"\n    if glob not in _pattern_cache:\n        pattern = _pattern_cache[glob] = re.compile(fnmatch.translate(glob))\n        return pattern.match(fn)\n    return _pattern_cache[glob].match(fn)\n\n\ndef _load_formatters(module_name):\n    \"\"\"Load a formatter (and all others in the module too).\"\"\"\n    mod = __import__(module_name, None, None, ['__all__'])\n    for formatter_name in mod.__all__:\n        cls = getattr(mod, formatter_name)\n        _formatter_cache[cls.name] = cls\n\n\ndef get_all_formatters():\n    \"\"\"Return a generator for all formatter classes.\"\"\"\n    # NB: this returns formatter classes, not info like get_all_lexers().\n    for info in FORMATTERS.values():\n        if info[1] not in _formatter_cache:\n            _load_formatters(info[0])\n        yield _formatter_cache[info[1]]\n    for _, formatter in find_plugin_formatters():\n        yield formatter\n\n\ndef find_formatter_class(alias):\n    \"\"\"Lookup a formatter by alias.\n\n    Returns None if not found.\n    \"\"\"\n    for module_name, name, aliases, _, _ in FORMATTERS.values():\n        if alias in aliases:\n            if name not in _formatter_cache:\n                _load_formatters(module_name)\n            return _formatter_cache[name]\n    for _, cls in find_plugin_formatters():\n        if alias in cls.aliases:\n            return cls\n\n\ndef get_formatter_by_name(_alias, **options):\n    \"\"\"\n    Return an instance of a :class:`.Formatter` subclass that has `alias` in its\n    aliases list. The formatter is given the `options` at its instantiation.\n\n    Will raise :exc:`pygments.util.ClassNotFound` if no formatter with that\n    alias is found.\n    \"\"\"\n    cls = find_formatter_class(_alias)\n    if cls is None:\n        raise ClassNotFound(f\"no formatter found for name {_alias!r}\")\n    return cls(**options)\n\n\ndef load_formatter_from_file(filename, formattername=\"CustomFormatter\", **options):\n    \"\"\"\n    Return a `Formatter` subclass instance loaded from the provided file, relative\n    to the current directory.\n\n    The file is expected to contain a Formatter class named ``formattername``\n    (by default, CustomFormatter). Users should be very careful with the input, because\n    this method is equivalent to running ``eval()`` on the input file. The formatter is\n    given the `options` at its instantiation.\n\n    :exc:`pygments.util.ClassNotFound` is raised if there are any errors loading\n    the formatter.\n\n    .. versionadded:: 2.2\n    \"\"\"\n    try:\n        # This empty dict will contain the namespace for the exec'd file\n        custom_namespace = {}\n        with open(filename, 'rb') as f:\n            exec(f.read(), custom_namespace)\n        # Retrieve the class `formattername` from that namespace\n        if formattername not in custom_namespace:\n            raise ClassNotFound(f'no valid {formattername} class found in {filename}')\n        formatter_class = custom_namespace[formattername]\n        # And finally instantiate it with the options\n        return formatter_class(**options)\n    except OSError as err:\n        raise ClassNotFound(f'cannot read {filename}: {err}')\n    except ClassNotFound:\n        raise\n    except Exception as err:\n        raise ClassNotFound(f'error when loading custom formatter: {err}')\n\n\ndef get_formatter_for_filename(fn, **options):\n    \"\"\"\n    Return a :class:`.Formatter` subclass instance that has a filename pattern\n    matching `fn`. The formatter is given the `options` at its instantiation.\n\n    Will raise :exc:`pygments.util.ClassNotFound` if no formatter for that filename\n    is found.\n    \"\"\"\n    fn = basename(fn)\n    for modname, name, _, filenames, _ in FORMATTERS.values():\n        for filename in filenames:\n            if _fn_matches(fn, filename):\n                if name not in _formatter_cache:\n                    _load_formatters(modname)\n                return _formatter_cache[name](**options)\n    for _name, cls in find_plugin_formatters():\n        for filename in cls.filenames:\n            if _fn_matches(fn, filename):\n                return cls(**options)\n    raise ClassNotFound(f\"no formatter found for file name {fn!r}\")\n\n\nclass _automodule(types.ModuleType):\n    \"\"\"Automatically import formatters.\"\"\"\n\n    def __getattr__(self, name):\n        info = FORMATTERS.get(name)\n        if info:\n            _load_formatters(info[0])\n            cls = _formatter_cache[info[1]]\n            setattr(self, name, cls)\n            return cls\n        raise AttributeError(name)\n\n\noldmod = sys.modules[__name__]\nnewmod = _automodule(__name__)\nnewmod.__dict__.update(oldmod.__dict__)\nsys.modules[__name__] = newmod\ndel newmod.newmod, newmod.oldmod, newmod.sys, newmod.types\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/pygments/formatters/_mapping.py","size":4176,"sha1":"70c2241423f14e151908d1e41ed0f70154f1858b","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"# Automatically generated by scripts/gen_mapfiles.py.\n# DO NOT EDIT BY HAND; run `tox -e mapfiles` instead.\n\nFORMATTERS = {\n    'BBCodeFormatter': ('pygments.formatters.bbcode', 'BBCode', ('bbcode', 'bb'), (), 'Format tokens with BBcodes. These formatting codes are used by many bulletin boards, so you can highlight your sourcecode with pygments before posting it there.'),\n    'BmpImageFormatter': ('pygments.formatters.img', 'img_bmp', ('bmp', 'bitmap'), ('*.bmp',), 'Create a bitmap image from source code. This uses the Python Imaging Library to generate a pixmap from the source code.'),\n    'GifImageFormatter': ('pygments.formatters.img', 'img_gif', ('gif',), ('*.gif',), 'Create a GIF image from source code. This uses the Python Imaging Library to generate a pixmap from the source code.'),\n    'GroffFormatter': ('pygments.formatters.groff', 'groff', ('groff', 'troff', 'roff'), (), 'Format tokens with groff escapes to change their color and font style.'),\n    'HtmlFormatter': ('pygments.formatters.html', 'HTML', ('html',), ('*.html', '*.htm'), \"Format tokens as HTML 4 ``<span>`` tags. By default, the content is enclosed in a ``<pre>`` tag, itself wrapped in a ``<div>`` tag (but see the `nowrap` option). The ``<div>``'s CSS class can be set by the `cssclass` option.\"),\n    'IRCFormatter': ('pygments.formatters.irc', 'IRC', ('irc', 'IRC'), (), 'Format tokens with IRC color sequences'),\n    'ImageFormatter': ('pygments.formatters.img', 'img', ('img', 'IMG', 'png'), ('*.png',), 'Create a PNG image from source code. This uses the Python Imaging Library to generate a pixmap from the source code.'),\n    'JpgImageFormatter': ('pygments.formatters.img', 'img_jpg', ('jpg', 'jpeg'), ('*.jpg',), 'Create a JPEG image from source code. This uses the Python Imaging Library to generate a pixmap from the source code.'),\n    'LatexFormatter': ('pygments.formatters.latex', 'LaTeX', ('latex', 'tex'), ('*.tex',), 'Format tokens as LaTeX code. This needs the `fancyvrb` and `color` standard packages.'),\n    'NullFormatter': ('pygments.formatters.other', 'Text only', ('text', 'null'), ('*.txt',), 'Output the text unchanged without any formatting.'),\n    'PangoMarkupFormatter': ('pygments.formatters.pangomarkup', 'Pango Markup', ('pango', 'pangomarkup'), (), 'Format tokens as Pango Markup code. It can then be rendered to an SVG.'),\n    'RawTokenFormatter': ('pygments.formatters.other', 'Raw tokens', ('raw', 'tokens'), ('*.raw',), 'Format tokens as a raw representation for storing token streams.'),\n    'RtfFormatter': ('pygments.formatters.rtf', 'RTF', ('rtf',), ('*.rtf',), 'Format tokens as RTF markup. This formatter automatically outputs full RTF documents with color information and other useful stuff. Perfect for Copy and Paste into Microsoft(R) Word(R) documents.'),\n    'SvgFormatter': ('pygments.formatters.svg', 'SVG', ('svg',), ('*.svg',), 'Format tokens as an SVG graphics file.  This formatter is still experimental. Each line of code is a ``<text>`` element with explicit ``x`` and ``y`` coordinates containing ``<tspan>`` elements with the individual token styles.'),\n    'Terminal256Formatter': ('pygments.formatters.terminal256', 'Terminal256', ('terminal256', 'console256', '256'), (), 'Format tokens with ANSI color sequences, for output in a 256-color terminal or console.  Like in `TerminalFormatter` color sequences are terminated at newlines, so that paging the output works correctly.'),\n    'TerminalFormatter': ('pygments.formatters.terminal', 'Terminal', ('terminal', 'console'), (), 'Format tokens with ANSI color sequences, for output in a text console. Color sequences are terminated at newlines, so that paging the output works correctly.'),\n    'TerminalTrueColorFormatter': ('pygments.formatters.terminal256', 'TerminalTrueColor', ('terminal16m', 'console16m', '16m'), (), 'Format tokens with ANSI color sequences, for output in a true-color terminal or console.  Like in `TerminalFormatter` color sequences are terminated at newlines, so that paging the output works correctly.'),\n    'TestcaseFormatter': ('pygments.formatters.other', 'Testcase', ('testcase',), (), 'Format tokens as appropriate for a new testcase.'),\n}\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/pygments/formatters/bbcode.py","size":3320,"sha1":"ea87a73214126ed3f58fa3d8b7d14c53193061d0","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\n    pygments.formatters.bbcode\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n    BBcode formatter.\n\n    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\n\nfrom pip._vendor.pygments.formatter import Formatter\nfrom pip._vendor.pygments.util import get_bool_opt\n\n__all__ = ['BBCodeFormatter']\n\n\nclass BBCodeFormatter(Formatter):\n    \"\"\"\n    Format tokens with BBcodes. These formatting codes are used by many\n    bulletin boards, so you can highlight your sourcecode with pygments before\n    posting it there.\n\n    This formatter has no support for background colors and borders, as there\n    are no common BBcode tags for that.\n\n    Some board systems (e.g. phpBB) don't support colors in their [code] tag,\n    so you can't use the highlighting together with that tag.\n    Text in a [code] tag usually is shown with a monospace font (which this\n    formatter can do with the ``monofont`` option) and no spaces (which you\n    need for indentation) are removed.\n\n    Additional options accepted:\n\n    `style`\n        The style to use, can be a string or a Style subclass (default:\n        ``'default'``).\n\n    `codetag`\n        If set to true, put the output into ``[code]`` tags (default:\n        ``false``)\n\n    `monofont`\n        If set to true, add a tag to show the code with a monospace font\n        (default: ``false``).\n    \"\"\"\n    name = 'BBCode'\n    aliases = ['bbcode', 'bb']\n    filenames = []\n\n    def __init__(self, **options):\n        Formatter.__init__(self, **options)\n        self._code = get_bool_opt(options, 'codetag', False)\n        self._mono = get_bool_opt(options, 'monofont', False)\n\n        self.styles = {}\n        self._make_styles()\n\n    def _make_styles(self):\n        for ttype, ndef in self.style:\n            start = end = ''\n            if ndef['color']:\n                start += '[color=#{}]'.format(ndef['color'])\n                end = '[/color]' + end\n            if ndef['bold']:\n                start += '[b]'\n                end = '[/b]' + end\n            if ndef['italic']:\n                start += '[i]'\n                end = '[/i]' + end\n            if ndef['underline']:\n                start += '[u]'\n                end = '[/u]' + end\n            # there are no common BBcodes for background-color and border\n\n            self.styles[ttype] = start, end\n\n    def format_unencoded(self, tokensource, outfile):\n        if self._code:\n            outfile.write('[code]')\n        if self._mono:\n            outfile.write('[font=monospace]')\n\n        lastval = ''\n        lasttype = None\n\n        for ttype, value in tokensource:\n            while ttype not in self.styles:\n                ttype = ttype.parent\n            if ttype == lasttype:\n                lastval += value\n            else:\n                if lastval:\n                    start, end = self.styles[lasttype]\n                    outfile.write(''.join((start, lastval, end)))\n                lastval = value\n                lasttype = ttype\n\n        if lastval:\n            start, end = self.styles[lasttype]\n            outfile.write(''.join((start, lastval, end)))\n\n        if self._mono:\n            outfile.write('[/font]')\n        if self._code:\n            outfile.write('[/code]')\n        if self._code or self._mono:\n            outfile.write('\\n')\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/pygments/formatters/groff.py","size":5106,"sha1":"052f88ae537aa4ae71f85cb54ec404e531697eb5","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\n    pygments.formatters.groff\n    ~~~~~~~~~~~~~~~~~~~~~~~~~\n\n    Formatter for groff output.\n\n    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nimport math\nfrom pip._vendor.pygments.formatter import Formatter\nfrom pip._vendor.pygments.util import get_bool_opt, get_int_opt\n\n__all__ = ['GroffFormatter']\n\n\nclass GroffFormatter(Formatter):\n    \"\"\"\n    Format tokens with groff escapes to change their color and font style.\n\n    .. versionadded:: 2.11\n\n    Additional options accepted:\n\n    `style`\n        The style to use, can be a string or a Style subclass (default:\n        ``'default'``).\n\n    `monospaced`\n        If set to true, monospace font will be used (default: ``true``).\n\n    `linenos`\n        If set to true, print the line numbers (default: ``false``).\n\n    `wrap`\n        Wrap lines to the specified number of characters. Disabled if set to 0\n        (default: ``0``).\n    \"\"\"\n\n    name = 'groff'\n    aliases = ['groff','troff','roff']\n    filenames = []\n\n    def __init__(self, **options):\n        Formatter.__init__(self, **options)\n\n        self.monospaced = get_bool_opt(options, 'monospaced', True)\n        self.linenos = get_bool_opt(options, 'linenos', False)\n        self._lineno = 0\n        self.wrap = get_int_opt(options, 'wrap', 0)\n        self._linelen = 0\n\n        self.styles = {}\n        self._make_styles()\n\n\n    def _make_styles(self):\n        regular = '\\\\f[CR]' if self.monospaced else '\\\\f[R]'\n        bold = '\\\\f[CB]' if self.monospaced else '\\\\f[B]'\n        italic = '\\\\f[CI]' if self.monospaced else '\\\\f[I]'\n\n        for ttype, ndef in self.style:\n            start = end = ''\n            if ndef['color']:\n                start += '\\\\m[{}]'.format(ndef['color'])\n                end = '\\\\m[]' + end\n            if ndef['bold']:\n                start += bold\n                end = regular + end\n            if ndef['italic']:\n                start += italic\n                end = regular + end\n            if ndef['bgcolor']:\n                start += '\\\\M[{}]'.format(ndef['bgcolor'])\n                end = '\\\\M[]' + end\n\n            self.styles[ttype] = start, end\n\n\n    def _define_colors(self, outfile):\n        colors = set()\n        for _, ndef in self.style:\n            if ndef['color'] is not None:\n                colors.add(ndef['color'])\n\n        for color in sorted(colors):\n            outfile.write('.defcolor ' + color + ' rgb #' + color + '\\n')\n\n\n    def _write_lineno(self, outfile):\n        self._lineno += 1\n        outfile.write(\"%s% 4d \" % (self._lineno != 1 and '\\n' or '', self._lineno))\n\n\n    def _wrap_line(self, line):\n        length = len(line.rstrip('\\n'))\n        space = '     ' if self.linenos else ''\n        newline = ''\n\n        if length > self.wrap:\n            for i in range(0, math.floor(length / self.wrap)):\n                chunk = line[i*self.wrap:i*self.wrap+self.wrap]\n                newline += (chunk + '\\n' + space)\n            remainder = length % self.wrap\n            if remainder > 0:\n                newline += line[-remainder-1:]\n                self._linelen = remainder\n        elif self._linelen + length > self.wrap:\n            newline = ('\\n' + space) + line\n            self._linelen = length\n        else:\n            newline = line\n            self._linelen += length\n\n        return newline\n\n\n    def _escape_chars(self, text):\n        text = text.replace('\\\\', '\\\\[u005C]'). \\\n                    replace('.', '\\\\[char46]'). \\\n                    replace('\\'', '\\\\[u0027]'). \\\n                    replace('`', '\\\\[u0060]'). \\\n                    replace('~', '\\\\[u007E]')\n        copy = text\n\n        for char in copy:\n            if len(char) != len(char.encode()):\n                uni = char.encode('unicode_escape') \\\n                    .decode()[1:] \\\n                    .replace('x', 'u00') \\\n                    .upper()\n                text = text.replace(char, '\\\\[u' + uni[1:] + ']')\n\n        return text\n\n\n    def format_unencoded(self, tokensource, outfile):\n        self._define_colors(outfile)\n\n        outfile.write('.nf\\n\\\\f[CR]\\n')\n\n        if self.linenos:\n            self._write_lineno(outfile)\n\n        for ttype, value in tokensource:\n            while ttype not in self.styles:\n                ttype = ttype.parent\n            start, end = self.styles[ttype]\n\n            for line in value.splitlines(True):\n                if self.wrap > 0:\n                    line = self._wrap_line(line)\n\n                if start and end:\n                    text = self._escape_chars(line.rstrip('\\n'))\n                    if text != '':\n                        outfile.write(''.join((start, text, end)))\n                else:\n                    outfile.write(self._escape_chars(line.rstrip('\\n')))\n\n                if line.endswith('\\n'):\n                    if self.linenos:\n                        self._write_lineno(outfile)\n                        self._linelen = 0\n                    else:\n                        outfile.write('\\n')\n                        self._linelen = 0\n\n        outfile.write('\\n.fi')\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/pygments/formatters/html.py","size":35669,"sha1":"0e29ef053dd0a8616e45da9ccc03e275b4540d31","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\n    pygments.formatters.html\n    ~~~~~~~~~~~~~~~~~~~~~~~~\n\n    Formatter for HTML output.\n\n    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nimport functools\nimport os\nimport sys\nimport os.path\nfrom io import StringIO\n\nfrom pip._vendor.pygments.formatter import Formatter\nfrom pip._vendor.pygments.token import Token, Text, STANDARD_TYPES\nfrom pip._vendor.pygments.util import get_bool_opt, get_int_opt, get_list_opt\n\ntry:\n    import ctags\nexcept ImportError:\n    ctags = None\n\n__all__ = ['HtmlFormatter']\n\n\n_escape_html_table = {\n    ord('&'): '&amp;',\n    ord('<'): '&lt;',\n    ord('>'): '&gt;',\n    ord('\"'): '&quot;',\n    ord(\"'\"): '&#39;',\n}\n\n\ndef escape_html(text, table=_escape_html_table):\n    \"\"\"Escape &, <, > as well as single and double quotes for HTML.\"\"\"\n    return text.translate(table)\n\n\ndef webify(color):\n    if color.startswith('calc') or color.startswith('var'):\n        return color\n    else:\n        return '#' + color\n\n\ndef _get_ttype_class(ttype):\n    fname = STANDARD_TYPES.get(ttype)\n    if fname:\n        return fname\n    aname = ''\n    while fname is None:\n        aname = '-' + ttype[-1] + aname\n        ttype = ttype.parent\n        fname = STANDARD_TYPES.get(ttype)\n    return fname + aname\n\n\nCSSFILE_TEMPLATE = '''\\\n/*\ngenerated by Pygments <https://pygments.org/>\nCopyright 2006-2024 by the Pygments team.\nLicensed under the BSD license, see LICENSE for details.\n*/\n%(styledefs)s\n'''\n\nDOC_HEADER = '''\\\n<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01//EN\"\n   \"http://www.w3.org/TR/html4/strict.dtd\">\n<!--\ngenerated by Pygments <https://pygments.org/>\nCopyright 2006-2024 by the Pygments team.\nLicensed under the BSD license, see LICENSE for details.\n-->\n<html>\n<head>\n  <title>%(title)s</title>\n  <meta http-equiv=\"content-type\" content=\"text/html; charset=%(encoding)s\">\n  <style type=\"text/css\">\n''' + CSSFILE_TEMPLATE + '''\n  </style>\n</head>\n<body>\n<h2>%(title)s</h2>\n\n'''\n\nDOC_HEADER_EXTERNALCSS = '''\\\n<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01//EN\"\n   \"http://www.w3.org/TR/html4/strict.dtd\">\n\n<html>\n<head>\n  <title>%(title)s</title>\n  <meta http-equiv=\"content-type\" content=\"text/html; charset=%(encoding)s\">\n  <link rel=\"stylesheet\" href=\"%(cssfile)s\" type=\"text/css\">\n</head>\n<body>\n<h2>%(title)s</h2>\n\n'''\n\nDOC_FOOTER = '''\\\n</body>\n</html>\n'''\n\n\nclass HtmlFormatter(Formatter):\n    r\"\"\"\n    Format tokens as HTML 4 ``<span>`` tags. By default, the content is enclosed\n    in a ``<pre>`` tag, itself wrapped in a ``<div>`` tag (but see the `nowrap` option).\n    The ``<div>``'s CSS class can be set by the `cssclass` option.\n\n    If the `linenos` option is set to ``\"table\"``, the ``<pre>`` is\n    additionally wrapped inside a ``<table>`` which has one row and two\n    cells: one containing the line numbers and one containing the code.\n    Example:\n\n    .. sourcecode:: html\n\n        <div class=\"highlight\" >\n        <table><tr>\n          <td class=\"linenos\" title=\"click to toggle\"\n            onclick=\"with (this.firstChild.style)\n                     { display = (display == '') ? 'none' : '' }\">\n            <pre>1\n            2</pre>\n          </td>\n          <td class=\"code\">\n            <pre><span class=\"Ke\">def </span><span class=\"NaFu\">foo</span>(bar):\n              <span class=\"Ke\">pass</span>\n            </pre>\n          </td>\n        </tr></table></div>\n\n    (whitespace added to improve clarity).\n\n    A list of lines can be specified using the `hl_lines` option to make these\n    lines highlighted (as of Pygments 0.11).\n\n    With the `full` option, a complete HTML 4 document is output, including\n    the style definitions inside a ``<style>`` tag, or in a separate file if\n    the `cssfile` option is given.\n\n    When `tagsfile` is set to the path of a ctags index file, it is used to\n    generate hyperlinks from names to their definition.  You must enable\n    `lineanchors` and run ctags with the `-n` option for this to work.  The\n    `python-ctags` module from PyPI must be installed to use this feature;\n    otherwise a `RuntimeError` will be raised.\n\n    The `get_style_defs(arg='')` method of a `HtmlFormatter` returns a string\n    containing CSS rules for the CSS classes used by the formatter. The\n    argument `arg` can be used to specify additional CSS selectors that\n    are prepended to the classes. A call `fmter.get_style_defs('td .code')`\n    would result in the following CSS classes:\n\n    .. sourcecode:: css\n\n        td .code .kw { font-weight: bold; color: #00FF00 }\n        td .code .cm { color: #999999 }\n        ...\n\n    If you have Pygments 0.6 or higher, you can also pass a list or tuple to the\n    `get_style_defs()` method to request multiple prefixes for the tokens:\n\n    .. sourcecode:: python\n\n        formatter.get_style_defs(['div.syntax pre', 'pre.syntax'])\n\n    The output would then look like this:\n\n    .. sourcecode:: css\n\n        div.syntax pre .kw,\n        pre.syntax .kw { font-weight: bold; color: #00FF00 }\n        div.syntax pre .cm,\n        pre.syntax .cm { color: #999999 }\n        ...\n\n    Additional options accepted:\n\n    `nowrap`\n        If set to ``True``, don't add a ``<pre>`` and a ``<div>`` tag\n        around the tokens. This disables most other options (default: ``False``).\n\n    `full`\n        Tells the formatter to output a \"full\" document, i.e. a complete\n        self-contained document (default: ``False``).\n\n    `title`\n        If `full` is true, the title that should be used to caption the\n        document (default: ``''``).\n\n    `style`\n        The style to use, can be a string or a Style subclass (default:\n        ``'default'``). This option has no effect if the `cssfile`\n        and `noclobber_cssfile` option are given and the file specified in\n        `cssfile` exists.\n\n    `noclasses`\n        If set to true, token ``<span>`` tags (as well as line number elements)\n        will not use CSS classes, but inline styles. This is not recommended\n        for larger pieces of code since it increases output size by quite a bit\n        (default: ``False``).\n\n    `classprefix`\n        Since the token types use relatively short class names, they may clash\n        with some of your own class names. In this case you can use the\n        `classprefix` option to give a string to prepend to all Pygments-generated\n        CSS class names for token types.\n        Note that this option also affects the output of `get_style_defs()`.\n\n    `cssclass`\n        CSS class for the wrapping ``<div>`` tag (default: ``'highlight'``).\n        If you set this option, the default selector for `get_style_defs()`\n        will be this class.\n\n        .. versionadded:: 0.9\n           If you select the ``'table'`` line numbers, the wrapping table will\n           have a CSS class of this string plus ``'table'``, the default is\n           accordingly ``'highlighttable'``.\n\n    `cssstyles`\n        Inline CSS styles for the wrapping ``<div>`` tag (default: ``''``).\n\n    `prestyles`\n        Inline CSS styles for the ``<pre>`` tag (default: ``''``).\n\n        .. versionadded:: 0.11\n\n    `cssfile`\n        If the `full` option is true and this option is given, it must be the\n        name of an external file. If the filename does not include an absolute\n        path, the file's path will be assumed to be relative to the main output\n        file's path, if the latter can be found. The stylesheet is then written\n        to this file instead of the HTML file.\n\n        .. versionadded:: 0.6\n\n    `noclobber_cssfile`\n        If `cssfile` is given and the specified file exists, the css file will\n        not be overwritten. This allows the use of the `full` option in\n        combination with a user specified css file. Default is ``False``.\n\n        .. versionadded:: 1.1\n\n    `linenos`\n        If set to ``'table'``, output line numbers as a table with two cells,\n        one containing the line numbers, the other the whole code.  This is\n        copy-and-paste-friendly, but may cause alignment problems with some\n        browsers or fonts.  If set to ``'inline'``, the line numbers will be\n        integrated in the ``<pre>`` tag that contains the code (that setting\n        is *new in Pygments 0.8*).\n\n        For compatibility with Pygments 0.7 and earlier, every true value\n        except ``'inline'`` means the same as ``'table'`` (in particular, that\n        means also ``True``).\n\n        The default value is ``False``, which means no line numbers at all.\n\n        **Note:** with the default (\"table\") line number mechanism, the line\n        numbers and code can have different line heights in Internet Explorer\n        unless you give the enclosing ``<pre>`` tags an explicit ``line-height``\n        CSS property (you get the default line spacing with ``line-height:\n        125%``).\n\n    `hl_lines`\n        Specify a list of lines to be highlighted. The line numbers are always\n        relative to the input (i.e. the first line is line 1) and are\n        independent of `linenostart`.\n\n        .. versionadded:: 0.11\n\n    `linenostart`\n        The line number for the first line (default: ``1``).\n\n    `linenostep`\n        If set to a number n > 1, only every nth line number is printed.\n\n    `linenospecial`\n        If set to a number n > 0, every nth line number is given the CSS\n        class ``\"special\"`` (default: ``0``).\n\n    `nobackground`\n        If set to ``True``, the formatter won't output the background color\n        for the wrapping element (this automatically defaults to ``False``\n        when there is no wrapping element [eg: no argument for the\n        `get_syntax_defs` method given]) (default: ``False``).\n\n        .. versionadded:: 0.6\n\n    `lineseparator`\n        This string is output between lines of code. It defaults to ``\"\\n\"``,\n        which is enough to break a line inside ``<pre>`` tags, but you can\n        e.g. set it to ``\"<br>\"`` to get HTML line breaks.\n\n        .. versionadded:: 0.7\n\n    `lineanchors`\n        If set to a nonempty string, e.g. ``foo``, the formatter will wrap each\n        output line in an anchor tag with an ``id`` (and `name`) of ``foo-linenumber``.\n        This allows easy linking to certain lines.\n\n        .. versionadded:: 0.9\n\n    `linespans`\n        If set to a nonempty string, e.g. ``foo``, the formatter will wrap each\n        output line in a span tag with an ``id`` of ``foo-linenumber``.\n        This allows easy access to lines via javascript.\n\n        .. versionadded:: 1.6\n\n    `anchorlinenos`\n        If set to `True`, will wrap line numbers in <a> tags. Used in\n        combination with `linenos` and `lineanchors`.\n\n    `tagsfile`\n        If set to the path of a ctags file, wrap names in anchor tags that\n        link to their definitions. `lineanchors` should be used, and the\n        tags file should specify line numbers (see the `-n` option to ctags).\n        The tags file is assumed to be encoded in UTF-8.\n\n        .. versionadded:: 1.6\n\n    `tagurlformat`\n        A string formatting pattern used to generate links to ctags definitions.\n        Available variables are `%(path)s`, `%(fname)s` and `%(fext)s`.\n        Defaults to an empty string, resulting in just `#prefix-number` links.\n\n        .. versionadded:: 1.6\n\n    `filename`\n        A string used to generate a filename when rendering ``<pre>`` blocks,\n        for example if displaying source code. If `linenos` is set to\n        ``'table'`` then the filename will be rendered in an initial row\n        containing a single `<th>` which spans both columns.\n\n        .. versionadded:: 2.1\n\n    `wrapcode`\n        Wrap the code inside ``<pre>`` blocks using ``<code>``, as recommended\n        by the HTML5 specification.\n\n        .. versionadded:: 2.4\n\n    `debug_token_types`\n        Add ``title`` attributes to all token ``<span>`` tags that show the\n        name of the token.\n\n        .. versionadded:: 2.10\n\n\n    **Subclassing the HTML formatter**\n\n    .. versionadded:: 0.7\n\n    The HTML formatter is now built in a way that allows easy subclassing, thus\n    customizing the output HTML code. The `format()` method calls\n    `self._format_lines()` which returns a generator that yields tuples of ``(1,\n    line)``, where the ``1`` indicates that the ``line`` is a line of the\n    formatted source code.\n\n    If the `nowrap` option is set, the generator is the iterated over and the\n    resulting HTML is output.\n\n    Otherwise, `format()` calls `self.wrap()`, which wraps the generator with\n    other generators. These may add some HTML code to the one generated by\n    `_format_lines()`, either by modifying the lines generated by the latter,\n    then yielding them again with ``(1, line)``, and/or by yielding other HTML\n    code before or after the lines, with ``(0, html)``. The distinction between\n    source lines and other code makes it possible to wrap the generator multiple\n    times.\n\n    The default `wrap()` implementation adds a ``<div>`` and a ``<pre>`` tag.\n\n    A custom `HtmlFormatter` subclass could look like this:\n\n    .. sourcecode:: python\n\n        class CodeHtmlFormatter(HtmlFormatter):\n\n            def wrap(self, source, *, include_div):\n                return self._wrap_code(source)\n\n            def _wrap_code(self, source):\n                yield 0, '<code>'\n                for i, t in source:\n                    if i == 1:\n                        # it's a line of formatted code\n                        t += '<br>'\n                    yield i, t\n                yield 0, '</code>'\n\n    This results in wrapping the formatted lines with a ``<code>`` tag, where the\n    source lines are broken using ``<br>`` tags.\n\n    After calling `wrap()`, the `format()` method also adds the \"line numbers\"\n    and/or \"full document\" wrappers if the respective options are set. Then, all\n    HTML yielded by the wrapped generator is output.\n    \"\"\"\n\n    name = 'HTML'\n    aliases = ['html']\n    filenames = ['*.html', '*.htm']\n\n    def __init__(self, **options):\n        Formatter.__init__(self, **options)\n        self.title = self._decodeifneeded(self.title)\n        self.nowrap = get_bool_opt(options, 'nowrap', False)\n        self.noclasses = get_bool_opt(options, 'noclasses', False)\n        self.classprefix = options.get('classprefix', '')\n        self.cssclass = self._decodeifneeded(options.get('cssclass', 'highlight'))\n        self.cssstyles = self._decodeifneeded(options.get('cssstyles', ''))\n        self.prestyles = self._decodeifneeded(options.get('prestyles', ''))\n        self.cssfile = self._decodeifneeded(options.get('cssfile', ''))\n        self.noclobber_cssfile = get_bool_opt(options, 'noclobber_cssfile', False)\n        self.tagsfile = self._decodeifneeded(options.get('tagsfile', ''))\n        self.tagurlformat = self._decodeifneeded(options.get('tagurlformat', ''))\n        self.filename = self._decodeifneeded(options.get('filename', ''))\n        self.wrapcode = get_bool_opt(options, 'wrapcode', False)\n        self.span_element_openers = {}\n        self.debug_token_types = get_bool_opt(options, 'debug_token_types', False)\n\n        if self.tagsfile:\n            if not ctags:\n                raise RuntimeError('The \"ctags\" package must to be installed '\n                                   'to be able to use the \"tagsfile\" feature.')\n            self._ctags = ctags.CTags(self.tagsfile)\n\n        linenos = options.get('linenos', False)\n        if linenos == 'inline':\n            self.linenos = 2\n        elif linenos:\n            # compatibility with <= 0.7\n            self.linenos = 1\n        else:\n            self.linenos = 0\n        self.linenostart = abs(get_int_opt(options, 'linenostart', 1))\n        self.linenostep = abs(get_int_opt(options, 'linenostep', 1))\n        self.linenospecial = abs(get_int_opt(options, 'linenospecial', 0))\n        self.nobackground = get_bool_opt(options, 'nobackground', False)\n        self.lineseparator = options.get('lineseparator', '\\n')\n        self.lineanchors = options.get('lineanchors', '')\n        self.linespans = options.get('linespans', '')\n        self.anchorlinenos = get_bool_opt(options, 'anchorlinenos', False)\n        self.hl_lines = set()\n        for lineno in get_list_opt(options, 'hl_lines', []):\n            try:\n                self.hl_lines.add(int(lineno))\n            except ValueError:\n                pass\n\n        self._create_stylesheet()\n\n    def _get_css_class(self, ttype):\n        \"\"\"Return the css class of this token type prefixed with\n        the classprefix option.\"\"\"\n        ttypeclass = _get_ttype_class(ttype)\n        if ttypeclass:\n            return self.classprefix + ttypeclass\n        return ''\n\n    def _get_css_classes(self, ttype):\n        \"\"\"Return the CSS classes of this token type prefixed with the classprefix option.\"\"\"\n        cls = self._get_css_class(ttype)\n        while ttype not in STANDARD_TYPES:\n            ttype = ttype.parent\n            cls = self._get_css_class(ttype) + ' ' + cls\n        return cls or ''\n\n    def _get_css_inline_styles(self, ttype):\n        \"\"\"Return the inline CSS styles for this token type.\"\"\"\n        cclass = self.ttype2class.get(ttype)\n        while cclass is None:\n            ttype = ttype.parent\n            cclass = self.ttype2class.get(ttype)\n        return cclass or ''\n\n    def _create_stylesheet(self):\n        t2c = self.ttype2class = {Token: ''}\n        c2s = self.class2style = {}\n        for ttype, ndef in self.style:\n            name = self._get_css_class(ttype)\n            style = ''\n            if ndef['color']:\n                style += 'color: {}; '.format(webify(ndef['color']))\n            if ndef['bold']:\n                style += 'font-weight: bold; '\n            if ndef['italic']:\n                style += 'font-style: italic; '\n            if ndef['underline']:\n                style += 'text-decoration: underline; '\n            if ndef['bgcolor']:\n                style += 'background-color: {}; '.format(webify(ndef['bgcolor']))\n            if ndef['border']:\n                style += 'border: 1px solid {}; '.format(webify(ndef['border']))\n            if style:\n                t2c[ttype] = name\n                # save len(ttype) to enable ordering the styles by\n                # hierarchy (necessary for CSS cascading rules!)\n                c2s[name] = (style[:-2], ttype, len(ttype))\n\n    def get_style_defs(self, arg=None):\n        \"\"\"\n        Return CSS style definitions for the classes produced by the current\n        highlighting style. ``arg`` can be a string or list of selectors to\n        insert before the token type classes.\n        \"\"\"\n        style_lines = []\n\n        style_lines.extend(self.get_linenos_style_defs())\n        style_lines.extend(self.get_background_style_defs(arg))\n        style_lines.extend(self.get_token_style_defs(arg))\n\n        return '\\n'.join(style_lines)\n\n    def get_token_style_defs(self, arg=None):\n        prefix = self.get_css_prefix(arg)\n\n        styles = [\n            (level, ttype, cls, style)\n            for cls, (style, ttype, level) in self.class2style.items()\n            if cls and style\n        ]\n        styles.sort()\n\n        lines = [\n            f'{prefix(cls)} {{ {style} }} /* {repr(ttype)[6:]} */'\n            for (level, ttype, cls, style) in styles\n        ]\n\n        return lines\n\n    def get_background_style_defs(self, arg=None):\n        prefix = self.get_css_prefix(arg)\n        bg_color = self.style.background_color\n        hl_color = self.style.highlight_color\n\n        lines = []\n\n        if arg and not self.nobackground and bg_color is not None:\n            text_style = ''\n            if Text in self.ttype2class:\n                text_style = ' ' + self.class2style[self.ttype2class[Text]][0]\n            lines.insert(\n                0, '{}{{ background: {};{} }}'.format(\n                    prefix(''), bg_color, text_style\n                )\n            )\n        if hl_color is not None:\n            lines.insert(\n                0, '{} {{ background-color: {} }}'.format(prefix('hll'), hl_color)\n            )\n\n        return lines\n\n    def get_linenos_style_defs(self):\n        lines = [\n            f'pre {{ {self._pre_style} }}',\n            f'td.linenos .normal {{ {self._linenos_style} }}',\n            f'span.linenos {{ {self._linenos_style} }}',\n            f'td.linenos .special {{ {self._linenos_special_style} }}',\n            f'span.linenos.special {{ {self._linenos_special_style} }}',\n        ]\n\n        return lines\n\n    def get_css_prefix(self, arg):\n        if arg is None:\n            arg = ('cssclass' in self.options and '.'+self.cssclass or '')\n        if isinstance(arg, str):\n            args = [arg]\n        else:\n            args = list(arg)\n\n        def prefix(cls):\n            if cls:\n                cls = '.' + cls\n            tmp = []\n            for arg in args:\n                tmp.append((arg and arg + ' ' or '') + cls)\n            return ', '.join(tmp)\n\n        return prefix\n\n    @property\n    def _pre_style(self):\n        return 'line-height: 125%;'\n\n    @property\n    def _linenos_style(self):\n        color = self.style.line_number_color\n        background_color = self.style.line_number_background_color\n        return f'color: {color}; background-color: {background_color}; padding-left: 5px; padding-right: 5px;'\n\n    @property\n    def _linenos_special_style(self):\n        color = self.style.line_number_special_color\n        background_color = self.style.line_number_special_background_color\n        return f'color: {color}; background-color: {background_color}; padding-left: 5px; padding-right: 5px;'\n\n    def _decodeifneeded(self, value):\n        if isinstance(value, bytes):\n            if self.encoding:\n                return value.decode(self.encoding)\n            return value.decode()\n        return value\n\n    def _wrap_full(self, inner, outfile):\n        if self.cssfile:\n            if os.path.isabs(self.cssfile):\n                # it's an absolute filename\n                cssfilename = self.cssfile\n            else:\n                try:\n                    filename = outfile.name\n                    if not filename or filename[0] == '<':\n                        # pseudo files, e.g. name == '<fdopen>'\n                        raise AttributeError\n                    cssfilename = os.path.join(os.path.dirname(filename),\n                                               self.cssfile)\n                except AttributeError:\n                    print('Note: Cannot determine output file name, '\n                          'using current directory as base for the CSS file name',\n                          file=sys.stderr)\n                    cssfilename = self.cssfile\n            # write CSS file only if noclobber_cssfile isn't given as an option.\n            try:\n                if not os.path.exists(cssfilename) or not self.noclobber_cssfile:\n                    with open(cssfilename, \"w\", encoding=\"utf-8\") as cf:\n                        cf.write(CSSFILE_TEMPLATE %\n                                 {'styledefs': self.get_style_defs('body')})\n            except OSError as err:\n                err.strerror = 'Error writing CSS file: ' + err.strerror\n                raise\n\n            yield 0, (DOC_HEADER_EXTERNALCSS %\n                      dict(title=self.title,\n                           cssfile=self.cssfile,\n                           encoding=self.encoding))\n        else:\n            yield 0, (DOC_HEADER %\n                      dict(title=self.title,\n                           styledefs=self.get_style_defs('body'),\n                           encoding=self.encoding))\n\n        yield from inner\n        yield 0, DOC_FOOTER\n\n    def _wrap_tablelinenos(self, inner):\n        dummyoutfile = StringIO()\n        lncount = 0\n        for t, line in inner:\n            if t:\n                lncount += 1\n            dummyoutfile.write(line)\n\n        fl = self.linenostart\n        mw = len(str(lncount + fl - 1))\n        sp = self.linenospecial\n        st = self.linenostep\n        anchor_name = self.lineanchors or self.linespans\n        aln = self.anchorlinenos\n        nocls = self.noclasses\n\n        lines = []\n\n        for i in range(fl, fl+lncount):\n            print_line = i % st == 0\n            special_line = sp and i % sp == 0\n\n            if print_line:\n                line = '%*d' % (mw, i)\n                if aln:\n                    line = '<a href=\"#%s-%d\">%s</a>' % (anchor_name, i, line)\n            else:\n                line = ' ' * mw\n\n            if nocls:\n                if special_line:\n                    style = f' style=\"{self._linenos_special_style}\"'\n                else:\n                    style = f' style=\"{self._linenos_style}\"'\n            else:\n                if special_line:\n                    style = ' class=\"special\"'\n                else:\n                    style = ' class=\"normal\"'\n\n            if style:\n                line = f'<span{style}>{line}</span>'\n\n            lines.append(line)\n\n        ls = '\\n'.join(lines)\n\n        # If a filename was specified, we can't put it into the code table as it\n        # would misalign the line numbers. Hence we emit a separate row for it.\n        filename_tr = \"\"\n        if self.filename:\n            filename_tr = (\n                '<tr><th colspan=\"2\" class=\"filename\">'\n                '<span class=\"filename\">' + self.filename + '</span>'\n                '</th></tr>')\n\n        # in case you wonder about the seemingly redundant <div> here: since the\n        # content in the other cell also is wrapped in a div, some browsers in\n        # some configurations seem to mess up the formatting...\n        yield 0, (f'<table class=\"{self.cssclass}table\">' + filename_tr +\n            '<tr><td class=\"linenos\"><div class=\"linenodiv\"><pre>' +\n            ls + '</pre></div></td><td class=\"code\">')\n        yield 0, '<div>'\n        yield 0, dummyoutfile.getvalue()\n        yield 0, '</div>'\n        yield 0, '</td></tr></table>'\n\n\n    def _wrap_inlinelinenos(self, inner):\n        # need a list of lines since we need the width of a single number :(\n        inner_lines = list(inner)\n        sp = self.linenospecial\n        st = self.linenostep\n        num = self.linenostart\n        mw = len(str(len(inner_lines) + num - 1))\n        anchor_name = self.lineanchors or self.linespans\n        aln = self.anchorlinenos\n        nocls = self.noclasses\n\n        for _, inner_line in inner_lines:\n            print_line = num % st == 0\n            special_line = sp and num % sp == 0\n\n            if print_line:\n                line = '%*d' % (mw, num)\n            else:\n                line = ' ' * mw\n\n            if nocls:\n                if special_line:\n                    style = f' style=\"{self._linenos_special_style}\"'\n                else:\n                    style = f' style=\"{self._linenos_style}\"'\n            else:\n                if special_line:\n                    style = ' class=\"linenos special\"'\n                else:\n                    style = ' class=\"linenos\"'\n\n            if style:\n                linenos = f'<span{style}>{line}</span>'\n            else:\n                linenos = line\n\n            if aln:\n                yield 1, ('<a href=\"#%s-%d\">%s</a>' % (anchor_name, num, linenos) +\n                          inner_line)\n            else:\n                yield 1, linenos + inner_line\n            num += 1\n\n    def _wrap_lineanchors(self, inner):\n        s = self.lineanchors\n        # subtract 1 since we have to increment i *before* yielding\n        i = self.linenostart - 1\n        for t, line in inner:\n            if t:\n                i += 1\n                href = \"\" if self.linenos else ' href=\"#%s-%d\"' % (s, i)\n                yield 1, '<a id=\"%s-%d\" name=\"%s-%d\"%s></a>' % (s, i, s, i, href) + line\n            else:\n                yield 0, line\n\n    def _wrap_linespans(self, inner):\n        s = self.linespans\n        i = self.linenostart - 1\n        for t, line in inner:\n            if t:\n                i += 1\n                yield 1, '<span id=\"%s-%d\">%s</span>' % (s, i, line)\n            else:\n                yield 0, line\n\n    def _wrap_div(self, inner):\n        style = []\n        if (self.noclasses and not self.nobackground and\n                self.style.background_color is not None):\n            style.append(f'background: {self.style.background_color}')\n        if self.cssstyles:\n            style.append(self.cssstyles)\n        style = '; '.join(style)\n\n        yield 0, ('<div' + (self.cssclass and f' class=\"{self.cssclass}\"') +\n                  (style and (f' style=\"{style}\"')) + '>')\n        yield from inner\n        yield 0, '</div>\\n'\n\n    def _wrap_pre(self, inner):\n        style = []\n        if self.prestyles:\n            style.append(self.prestyles)\n        if self.noclasses:\n            style.append(self._pre_style)\n        style = '; '.join(style)\n\n        if self.filename and self.linenos != 1:\n            yield 0, ('<span class=\"filename\">' + self.filename + '</span>')\n\n        # the empty span here is to keep leading empty lines from being\n        # ignored by HTML parsers\n        yield 0, ('<pre' + (style and f' style=\"{style}\"') + '><span></span>')\n        yield from inner\n        yield 0, '</pre>'\n\n    def _wrap_code(self, inner):\n        yield 0, '<code>'\n        yield from inner\n        yield 0, '</code>'\n\n    @functools.lru_cache(maxsize=100)\n    def _translate_parts(self, value):\n        \"\"\"HTML-escape a value and split it by newlines.\"\"\"\n        return value.translate(_escape_html_table).split('\\n')\n\n    def _format_lines(self, tokensource):\n        \"\"\"\n        Just format the tokens, without any wrapping tags.\n        Yield individual lines.\n        \"\"\"\n        nocls = self.noclasses\n        lsep = self.lineseparator\n        tagsfile = self.tagsfile\n\n        lspan = ''\n        line = []\n        for ttype, value in tokensource:\n            try:\n                cspan = self.span_element_openers[ttype]\n            except KeyError:\n                title = ' title=\"{}\"'.format('.'.join(ttype)) if self.debug_token_types else ''\n                if nocls:\n                    css_style = self._get_css_inline_styles(ttype)\n                    if css_style:\n                        css_style = self.class2style[css_style][0]\n                        cspan = f'<span style=\"{css_style}\"{title}>'\n                    else:\n                        cspan = ''\n                else:\n                    css_class = self._get_css_classes(ttype)\n                    if css_class:\n                        cspan = f'<span class=\"{css_class}\"{title}>'\n                    else:\n                        cspan = ''\n                self.span_element_openers[ttype] = cspan\n\n            parts = self._translate_parts(value)\n\n            if tagsfile and ttype in Token.Name:\n                filename, linenumber = self._lookup_ctag(value)\n                if linenumber:\n                    base, filename = os.path.split(filename)\n                    if base:\n                        base += '/'\n                    filename, extension = os.path.splitext(filename)\n                    url = self.tagurlformat % {'path': base, 'fname': filename,\n                                               'fext': extension}\n                    parts[0] = \"<a href=\\\"%s#%s-%d\\\">%s\" % \\\n                        (url, self.lineanchors, linenumber, parts[0])\n                    parts[-1] = parts[-1] + \"</a>\"\n\n            # for all but the last line\n            for part in parts[:-1]:\n                if line:\n                    # Also check for part being non-empty, so we avoid creating\n                    # empty <span> tags\n                    if lspan != cspan and part:\n                        line.extend(((lspan and '</span>'), cspan, part,\n                                     (cspan and '</span>'), lsep))\n                    else:  # both are the same, or the current part was empty\n                        line.extend((part, (lspan and '</span>'), lsep))\n                    yield 1, ''.join(line)\n                    line = []\n                elif part:\n                    yield 1, ''.join((cspan, part, (cspan and '</span>'), lsep))\n                else:\n                    yield 1, lsep\n            # for the last line\n            if line and parts[-1]:\n                if lspan != cspan:\n                    line.extend(((lspan and '</span>'), cspan, parts[-1]))\n                    lspan = cspan\n                else:\n                    line.append(parts[-1])\n            elif parts[-1]:\n                line = [cspan, parts[-1]]\n                lspan = cspan\n            # else we neither have to open a new span nor set lspan\n\n        if line:\n            line.extend(((lspan and '</span>'), lsep))\n            yield 1, ''.join(line)\n\n    def _lookup_ctag(self, token):\n        entry = ctags.TagEntry()\n        if self._ctags.find(entry, token.encode(), 0):\n            return entry['file'].decode(), entry['lineNumber']\n        else:\n            return None, None\n\n    def _highlight_lines(self, tokensource):\n        \"\"\"\n        Highlighted the lines specified in the `hl_lines` option by\n        post-processing the token stream coming from `_format_lines`.\n        \"\"\"\n        hls = self.hl_lines\n\n        for i, (t, value) in enumerate(tokensource):\n            if t != 1:\n                yield t, value\n            if i + 1 in hls:  # i + 1 because Python indexes start at 0\n                if self.noclasses:\n                    style = ''\n                    if self.style.highlight_color is not None:\n                        style = (f' style=\"background-color: {self.style.highlight_color}\"')\n                    yield 1, f'<span{style}>{value}</span>'\n                else:\n                    yield 1, f'<span class=\"hll\">{value}</span>'\n            else:\n                yield 1, value\n\n    def wrap(self, source):\n        \"\"\"\n        Wrap the ``source``, which is a generator yielding\n        individual lines, in custom generators. See docstring\n        for `format`. Can be overridden.\n        \"\"\"\n\n        output = source\n        if self.wrapcode:\n            output = self._wrap_code(output)\n\n        output = self._wrap_pre(output)\n\n        return output\n\n    def format_unencoded(self, tokensource, outfile):\n        \"\"\"\n        The formatting process uses several nested generators; which of\n        them are used is determined by the user's options.\n\n        Each generator should take at least one argument, ``inner``,\n        and wrap the pieces of text generated by this.\n\n        Always yield 2-tuples: (code, text). If \"code\" is 1, the text\n        is part of the original tokensource being highlighted, if it's\n        0, the text is some piece of wrapping. This makes it possible to\n        use several different wrappers that process the original source\n        linewise, e.g. line number generators.\n        \"\"\"\n        source = self._format_lines(tokensource)\n\n        # As a special case, we wrap line numbers before line highlighting\n        # so the line numbers get wrapped in the highlighting tag.\n        if not self.nowrap and self.linenos == 2:\n            source = self._wrap_inlinelinenos(source)\n\n        if self.hl_lines:\n            source = self._highlight_lines(source)\n\n        if not self.nowrap:\n            if self.lineanchors:\n                source = self._wrap_lineanchors(source)\n            if self.linespans:\n                source = self._wrap_linespans(source)\n            source = self.wrap(source)\n            if self.linenos == 1:\n                source = self._wrap_tablelinenos(source)\n            source = self._wrap_div(source)\n            if self.full:\n                source = self._wrap_full(source, outfile)\n\n        for t, piece in source:\n            outfile.write(piece)\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/pygments/formatters/img.py","size":23287,"sha1":"daf1d167a5f5e6b486558520733a1f5de434791d","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\n    pygments.formatters.img\n    ~~~~~~~~~~~~~~~~~~~~~~~\n\n    Formatter for Pixmap output.\n\n    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\nimport os\nimport sys\n\nfrom pip._vendor.pygments.formatter import Formatter\nfrom pip._vendor.pygments.util import get_bool_opt, get_int_opt, get_list_opt, \\\n    get_choice_opt\n\nimport subprocess\n\n# Import this carefully\ntry:\n    from PIL import Image, ImageDraw, ImageFont\n    pil_available = True\nexcept ImportError:\n    pil_available = False\n\ntry:\n    import _winreg\nexcept ImportError:\n    try:\n        import winreg as _winreg\n    except ImportError:\n        _winreg = None\n\n__all__ = ['ImageFormatter', 'GifImageFormatter', 'JpgImageFormatter',\n           'BmpImageFormatter']\n\n\n# For some unknown reason every font calls it something different\nSTYLES = {\n    'NORMAL':     ['', 'Roman', 'Book', 'Normal', 'Regular', 'Medium'],\n    'ITALIC':     ['Oblique', 'Italic'],\n    'BOLD':       ['Bold'],\n    'BOLDITALIC': ['Bold Oblique', 'Bold Italic'],\n}\n\n# A sane default for modern systems\nDEFAULT_FONT_NAME_NIX = 'DejaVu Sans Mono'\nDEFAULT_FONT_NAME_WIN = 'Courier New'\nDEFAULT_FONT_NAME_MAC = 'Menlo'\n\n\nclass PilNotAvailable(ImportError):\n    \"\"\"When Python imaging library is not available\"\"\"\n\n\nclass FontNotFound(Exception):\n    \"\"\"When there are no usable fonts specified\"\"\"\n\n\nclass FontManager:\n    \"\"\"\n    Manages a set of fonts: normal, italic, bold, etc...\n    \"\"\"\n\n    def __init__(self, font_name, font_size=14):\n        self.font_name = font_name\n        self.font_size = font_size\n        self.fonts = {}\n        self.encoding = None\n        self.variable = False\n        if hasattr(font_name, 'read') or os.path.isfile(font_name):\n            font = ImageFont.truetype(font_name, self.font_size)\n            self.variable = True\n            for style in STYLES:\n                self.fonts[style] = font\n\n            return\n\n        if sys.platform.startswith('win'):\n            if not font_name:\n                self.font_name = DEFAULT_FONT_NAME_WIN\n            self._create_win()\n        elif sys.platform.startswith('darwin'):\n            if not font_name:\n                self.font_name = DEFAULT_FONT_NAME_MAC\n            self._create_mac()\n        else:\n            if not font_name:\n                self.font_name = DEFAULT_FONT_NAME_NIX\n            self._create_nix()\n\n    def _get_nix_font_path(self, name, style):\n        proc = subprocess.Popen(['fc-list', f\"{name}:style={style}\", 'file'],\n                                stdout=subprocess.PIPE, stderr=None)\n        stdout, _ = proc.communicate()\n        if proc.returncode == 0:\n            lines = stdout.splitlines()\n            for line in lines:\n                if line.startswith(b'Fontconfig warning:'):\n                    continue\n                path = line.decode().strip().strip(':')\n                if path:\n                    return path\n            return None\n\n    def _create_nix(self):\n        for name in STYLES['NORMAL']:\n            path = self._get_nix_font_path(self.font_name, name)\n            if path is not None:\n                self.fonts['NORMAL'] = ImageFont.truetype(path, self.font_size)\n                break\n        else:\n            raise FontNotFound(f'No usable fonts named: \"{self.font_name}\"')\n        for style in ('ITALIC', 'BOLD', 'BOLDITALIC'):\n            for stylename in STYLES[style]:\n                path = self._get_nix_font_path(self.font_name, stylename)\n                if path is not None:\n                    self.fonts[style] = ImageFont.truetype(path, self.font_size)\n                    break\n            else:\n                if style == 'BOLDITALIC':\n                    self.fonts[style] = self.fonts['BOLD']\n                else:\n                    self.fonts[style] = self.fonts['NORMAL']\n\n    def _get_mac_font_path(self, font_map, name, style):\n        return font_map.get((name + ' ' + style).strip().lower())\n\n    def _create_mac(self):\n        font_map = {}\n        for font_dir in (os.path.join(os.getenv(\"HOME\"), 'Library/Fonts/'),\n                         '/Library/Fonts/', '/System/Library/Fonts/'):\n            font_map.update(\n                (os.path.splitext(f)[0].lower(), os.path.join(font_dir, f))\n                for f in os.listdir(font_dir)\n                if f.lower().endswith(('ttf', 'ttc')))\n\n        for name in STYLES['NORMAL']:\n            path = self._get_mac_font_path(font_map, self.font_name, name)\n            if path is not None:\n                self.fonts['NORMAL'] = ImageFont.truetype(path, self.font_size)\n                break\n        else:\n            raise FontNotFound(f'No usable fonts named: \"{self.font_name}\"')\n        for style in ('ITALIC', 'BOLD', 'BOLDITALIC'):\n            for stylename in STYLES[style]:\n                path = self._get_mac_font_path(font_map, self.font_name, stylename)\n                if path is not None:\n                    self.fonts[style] = ImageFont.truetype(path, self.font_size)\n                    break\n            else:\n                if style == 'BOLDITALIC':\n                    self.fonts[style] = self.fonts['BOLD']\n                else:\n                    self.fonts[style] = self.fonts['NORMAL']\n\n    def _lookup_win(self, key, basename, styles, fail=False):\n        for suffix in ('', ' (TrueType)'):\n            for style in styles:\n                try:\n                    valname = '{}{}{}'.format(basename, style and ' '+style, suffix)\n                    val, _ = _winreg.QueryValueEx(key, valname)\n                    return val\n                except OSError:\n                    continue\n        else:\n            if fail:\n                raise FontNotFound(f'Font {basename} ({styles[0]}) not found in registry')\n            return None\n\n    def _create_win(self):\n        lookuperror = None\n        keynames = [ (_winreg.HKEY_CURRENT_USER, r'Software\\Microsoft\\Windows NT\\CurrentVersion\\Fonts'),\n                     (_winreg.HKEY_CURRENT_USER, r'Software\\Microsoft\\Windows\\CurrentVersion\\Fonts'),\n                     (_winreg.HKEY_LOCAL_MACHINE, r'Software\\Microsoft\\Windows NT\\CurrentVersion\\Fonts'),\n                     (_winreg.HKEY_LOCAL_MACHINE, r'Software\\Microsoft\\Windows\\CurrentVersion\\Fonts') ]\n        for keyname in keynames:\n            try:\n                key = _winreg.OpenKey(*keyname)\n                try:\n                    path = self._lookup_win(key, self.font_name, STYLES['NORMAL'], True)\n                    self.fonts['NORMAL'] = ImageFont.truetype(path, self.font_size)\n                    for style in ('ITALIC', 'BOLD', 'BOLDITALIC'):\n                        path = self._lookup_win(key, self.font_name, STYLES[style])\n                        if path:\n                            self.fonts[style] = ImageFont.truetype(path, self.font_size)\n                        else:\n                            if style == 'BOLDITALIC':\n                                self.fonts[style] = self.fonts['BOLD']\n                            else:\n                                self.fonts[style] = self.fonts['NORMAL']\n                    return\n                except FontNotFound as err:\n                    lookuperror = err\n                finally:\n                    _winreg.CloseKey(key)\n            except OSError:\n                pass\n        else:\n            # If we get here, we checked all registry keys and had no luck\n            # We can be in one of two situations now:\n            # * All key lookups failed. In this case lookuperror is None and we\n            #   will raise a generic error\n            # * At least one lookup failed with a FontNotFound error. In this\n            #   case, we will raise that as a more specific error\n            if lookuperror:\n                raise lookuperror\n            raise FontNotFound('Can\\'t open Windows font registry key')\n\n    def get_char_size(self):\n        \"\"\"\n        Get the character size.\n        \"\"\"\n        return self.get_text_size('M')\n\n    def get_text_size(self, text):\n        \"\"\"\n        Get the text size (width, height).\n        \"\"\"\n        font = self.fonts['NORMAL']\n        if hasattr(font, 'getbbox'):  # Pillow >= 9.2.0\n            return font.getbbox(text)[2:4]\n        else:\n            return font.getsize(text)\n\n    def get_font(self, bold, oblique):\n        \"\"\"\n        Get the font based on bold and italic flags.\n        \"\"\"\n        if bold and oblique:\n            if self.variable:\n                return self.get_style('BOLDITALIC')\n\n            return self.fonts['BOLDITALIC']\n        elif bold:\n            if self.variable:\n                return self.get_style('BOLD')\n\n            return self.fonts['BOLD']\n        elif oblique:\n            if self.variable:\n                return self.get_style('ITALIC')\n\n            return self.fonts['ITALIC']\n        else:\n            if self.variable:\n                return self.get_style('NORMAL')\n\n            return self.fonts['NORMAL']\n\n    def get_style(self, style):\n        \"\"\"\n        Get the specified style of the font if it is a variable font.\n        If not found, return the normal font.\n        \"\"\"\n        font = self.fonts[style]\n        for style_name in STYLES[style]:\n            try:\n                font.set_variation_by_name(style_name)\n                return font\n            except ValueError:\n                pass\n            except OSError:\n                return font\n\n        return font\n\n\nclass ImageFormatter(Formatter):\n    \"\"\"\n    Create a PNG image from source code. This uses the Python Imaging Library to\n    generate a pixmap from the source code.\n\n    .. versionadded:: 0.10\n\n    Additional options accepted:\n\n    `image_format`\n        An image format to output to that is recognised by PIL, these include:\n\n        * \"PNG\" (default)\n        * \"JPEG\"\n        * \"BMP\"\n        * \"GIF\"\n\n    `line_pad`\n        The extra spacing (in pixels) between each line of text.\n\n        Default: 2\n\n    `font_name`\n        The font name to be used as the base font from which others, such as\n        bold and italic fonts will be generated.  This really should be a\n        monospace font to look sane.\n        If a filename or a file-like object is specified, the user must\n        provide different styles of the font.\n\n        Default: \"Courier New\" on Windows, \"Menlo\" on Mac OS, and\n                 \"DejaVu Sans Mono\" on \\\\*nix\n\n    `font_size`\n        The font size in points to be used.\n\n        Default: 14\n\n    `image_pad`\n        The padding, in pixels to be used at each edge of the resulting image.\n\n        Default: 10\n\n    `line_numbers`\n        Whether line numbers should be shown: True/False\n\n        Default: True\n\n    `line_number_start`\n        The line number of the first line.\n\n        Default: 1\n\n    `line_number_step`\n        The step used when printing line numbers.\n\n        Default: 1\n\n    `line_number_bg`\n        The background colour (in \"#123456\" format) of the line number bar, or\n        None to use the style background color.\n\n        Default: \"#eed\"\n\n    `line_number_fg`\n        The text color of the line numbers (in \"#123456\"-like format).\n\n        Default: \"#886\"\n\n    `line_number_chars`\n        The number of columns of line numbers allowable in the line number\n        margin.\n\n        Default: 2\n\n    `line_number_bold`\n        Whether line numbers will be bold: True/False\n\n        Default: False\n\n    `line_number_italic`\n        Whether line numbers will be italicized: True/False\n\n        Default: False\n\n    `line_number_separator`\n        Whether a line will be drawn between the line number area and the\n        source code area: True/False\n\n        Default: True\n\n    `line_number_pad`\n        The horizontal padding (in pixels) between the line number margin, and\n        the source code area.\n\n        Default: 6\n\n    `hl_lines`\n        Specify a list of lines to be highlighted.\n\n        .. versionadded:: 1.2\n\n        Default: empty list\n\n    `hl_color`\n        Specify the color for highlighting lines.\n\n        .. versionadded:: 1.2\n\n        Default: highlight color of the selected style\n    \"\"\"\n\n    # Required by the pygments mapper\n    name = 'img'\n    aliases = ['img', 'IMG', 'png']\n    filenames = ['*.png']\n\n    unicodeoutput = False\n\n    default_image_format = 'png'\n\n    def __init__(self, **options):\n        \"\"\"\n        See the class docstring for explanation of options.\n        \"\"\"\n        if not pil_available:\n            raise PilNotAvailable(\n                'Python Imaging Library is required for this formatter')\n        Formatter.__init__(self, **options)\n        self.encoding = 'latin1'  # let pygments.format() do the right thing\n        # Read the style\n        self.styles = dict(self.style)\n        if self.style.background_color is None:\n            self.background_color = '#fff'\n        else:\n            self.background_color = self.style.background_color\n        # Image options\n        self.image_format = get_choice_opt(\n            options, 'image_format', ['png', 'jpeg', 'gif', 'bmp'],\n            self.default_image_format, normcase=True)\n        self.image_pad = get_int_opt(options, 'image_pad', 10)\n        self.line_pad = get_int_opt(options, 'line_pad', 2)\n        # The fonts\n        fontsize = get_int_opt(options, 'font_size', 14)\n        self.fonts = FontManager(options.get('font_name', ''), fontsize)\n        self.fontw, self.fonth = self.fonts.get_char_size()\n        # Line number options\n        self.line_number_fg = options.get('line_number_fg', '#886')\n        self.line_number_bg = options.get('line_number_bg', '#eed')\n        self.line_number_chars = get_int_opt(options,\n                                             'line_number_chars', 2)\n        self.line_number_bold = get_bool_opt(options,\n                                             'line_number_bold', False)\n        self.line_number_italic = get_bool_opt(options,\n                                               'line_number_italic', False)\n        self.line_number_pad = get_int_opt(options, 'line_number_pad', 6)\n        self.line_numbers = get_bool_opt(options, 'line_numbers', True)\n        self.line_number_separator = get_bool_opt(options,\n                                                  'line_number_separator', True)\n        self.line_number_step = get_int_opt(options, 'line_number_step', 1)\n        self.line_number_start = get_int_opt(options, 'line_number_start', 1)\n        if self.line_numbers:\n            self.line_number_width = (self.fontw * self.line_number_chars +\n                                      self.line_number_pad * 2)\n        else:\n            self.line_number_width = 0\n        self.hl_lines = []\n        hl_lines_str = get_list_opt(options, 'hl_lines', [])\n        for line in hl_lines_str:\n            try:\n                self.hl_lines.append(int(line))\n            except ValueError:\n                pass\n        self.hl_color = options.get('hl_color',\n                                    self.style.highlight_color) or '#f90'\n        self.drawables = []\n\n    def get_style_defs(self, arg=''):\n        raise NotImplementedError('The -S option is meaningless for the image '\n                                  'formatter. Use -O style=<stylename> instead.')\n\n    def _get_line_height(self):\n        \"\"\"\n        Get the height of a line.\n        \"\"\"\n        return self.fonth + self.line_pad\n\n    def _get_line_y(self, lineno):\n        \"\"\"\n        Get the Y coordinate of a line number.\n        \"\"\"\n        return lineno * self._get_line_height() + self.image_pad\n\n    def _get_char_width(self):\n        \"\"\"\n        Get the width of a character.\n        \"\"\"\n        return self.fontw\n\n    def _get_char_x(self, linelength):\n        \"\"\"\n        Get the X coordinate of a character position.\n        \"\"\"\n        return linelength + self.image_pad + self.line_number_width\n\n    def _get_text_pos(self, linelength, lineno):\n        \"\"\"\n        Get the actual position for a character and line position.\n        \"\"\"\n        return self._get_char_x(linelength), self._get_line_y(lineno)\n\n    def _get_linenumber_pos(self, lineno):\n        \"\"\"\n        Get the actual position for the start of a line number.\n        \"\"\"\n        return (self.image_pad, self._get_line_y(lineno))\n\n    def _get_text_color(self, style):\n        \"\"\"\n        Get the correct color for the token from the style.\n        \"\"\"\n        if style['color'] is not None:\n            fill = '#' + style['color']\n        else:\n            fill = '#000'\n        return fill\n\n    def _get_text_bg_color(self, style):\n        \"\"\"\n        Get the correct background color for the token from the style.\n        \"\"\"\n        if style['bgcolor'] is not None:\n            bg_color = '#' + style['bgcolor']\n        else:\n            bg_color = None\n        return bg_color\n\n    def _get_style_font(self, style):\n        \"\"\"\n        Get the correct font for the style.\n        \"\"\"\n        return self.fonts.get_font(style['bold'], style['italic'])\n\n    def _get_image_size(self, maxlinelength, maxlineno):\n        \"\"\"\n        Get the required image size.\n        \"\"\"\n        return (self._get_char_x(maxlinelength) + self.image_pad,\n                self._get_line_y(maxlineno + 0) + self.image_pad)\n\n    def _draw_linenumber(self, posno, lineno):\n        \"\"\"\n        Remember a line number drawable to paint later.\n        \"\"\"\n        self._draw_text(\n            self._get_linenumber_pos(posno),\n            str(lineno).rjust(self.line_number_chars),\n            font=self.fonts.get_font(self.line_number_bold,\n                                     self.line_number_italic),\n            text_fg=self.line_number_fg,\n            text_bg=None,\n        )\n\n    def _draw_text(self, pos, text, font, text_fg, text_bg):\n        \"\"\"\n        Remember a single drawable tuple to paint later.\n        \"\"\"\n        self.drawables.append((pos, text, font, text_fg, text_bg))\n\n    def _create_drawables(self, tokensource):\n        \"\"\"\n        Create drawables for the token content.\n        \"\"\"\n        lineno = charno = maxcharno = 0\n        maxlinelength = linelength = 0\n        for ttype, value in tokensource:\n            while ttype not in self.styles:\n                ttype = ttype.parent\n            style = self.styles[ttype]\n            # TODO: make sure tab expansion happens earlier in the chain.  It\n            # really ought to be done on the input, as to do it right here is\n            # quite complex.\n            value = value.expandtabs(4)\n            lines = value.splitlines(True)\n            # print lines\n            for i, line in enumerate(lines):\n                temp = line.rstrip('\\n')\n                if temp:\n                    self._draw_text(\n                        self._get_text_pos(linelength, lineno),\n                        temp,\n                        font = self._get_style_font(style),\n                        text_fg = self._get_text_color(style),\n                        text_bg = self._get_text_bg_color(style),\n                    )\n                    temp_width, _ = self.fonts.get_text_size(temp)\n                    linelength += temp_width\n                    maxlinelength = max(maxlinelength, linelength)\n                    charno += len(temp)\n                    maxcharno = max(maxcharno, charno)\n                if line.endswith('\\n'):\n                    # add a line for each extra line in the value\n                    linelength = 0\n                    charno = 0\n                    lineno += 1\n        self.maxlinelength = maxlinelength\n        self.maxcharno = maxcharno\n        self.maxlineno = lineno\n\n    def _draw_line_numbers(self):\n        \"\"\"\n        Create drawables for the line numbers.\n        \"\"\"\n        if not self.line_numbers:\n            return\n        for p in range(self.maxlineno):\n            n = p + self.line_number_start\n            if (n % self.line_number_step) == 0:\n                self._draw_linenumber(p, n)\n\n    def _paint_line_number_bg(self, im):\n        \"\"\"\n        Paint the line number background on the image.\n        \"\"\"\n        if not self.line_numbers:\n            return\n        if self.line_number_fg is None:\n            return\n        draw = ImageDraw.Draw(im)\n        recth = im.size[-1]\n        rectw = self.image_pad + self.line_number_width - self.line_number_pad\n        draw.rectangle([(0, 0), (rectw, recth)],\n                       fill=self.line_number_bg)\n        if self.line_number_separator:\n            draw.line([(rectw, 0), (rectw, recth)], fill=self.line_number_fg)\n        del draw\n\n    def format(self, tokensource, outfile):\n        \"\"\"\n        Format ``tokensource``, an iterable of ``(tokentype, tokenstring)``\n        tuples and write it into ``outfile``.\n\n        This implementation calculates where it should draw each token on the\n        pixmap, then calculates the required pixmap size and draws the items.\n        \"\"\"\n        self._create_drawables(tokensource)\n        self._draw_line_numbers()\n        im = Image.new(\n            'RGB',\n            self._get_image_size(self.maxlinelength, self.maxlineno),\n            self.background_color\n        )\n        self._paint_line_number_bg(im)\n        draw = ImageDraw.Draw(im)\n        # Highlight\n        if self.hl_lines:\n            x = self.image_pad + self.line_number_width - self.line_number_pad + 1\n            recth = self._get_line_height()\n            rectw = im.size[0] - x\n            for linenumber in self.hl_lines:\n                y = self._get_line_y(linenumber - 1)\n                draw.rectangle([(x, y), (x + rectw, y + recth)],\n                               fill=self.hl_color)\n        for pos, value, font, text_fg, text_bg in self.drawables:\n            if text_bg:\n                # see deprecations https://pillow.readthedocs.io/en/stable/releasenotes/9.2.0.html#font-size-and-offset-methods\n                if hasattr(draw, 'textsize'):\n                    text_size = draw.textsize(text=value, font=font)\n                else:\n                    text_size = font.getbbox(value)[2:]\n                draw.rectangle([pos[0], pos[1], pos[0] + text_size[0], pos[1] + text_size[1]], fill=text_bg)\n            draw.text(pos, value, font=font, fill=text_fg)\n        im.save(outfile, self.image_format.upper())\n\n\n# Add one formatter per format, so that the \"-f gif\" option gives the correct result\n# when used in pygmentize.\n\nclass GifImageFormatter(ImageFormatter):\n    \"\"\"\n    Create a GIF image from source code. This uses the Python Imaging Library to\n    generate a pixmap from the source code.\n\n    .. versionadded:: 1.0\n    \"\"\"\n\n    name = 'img_gif'\n    aliases = ['gif']\n    filenames = ['*.gif']\n    default_image_format = 'gif'\n\n\nclass JpgImageFormatter(ImageFormatter):\n    \"\"\"\n    Create a JPEG image from source code. This uses the Python Imaging Library to\n    generate a pixmap from the source code.\n\n    .. versionadded:: 1.0\n    \"\"\"\n\n    name = 'img_jpg'\n    aliases = ['jpg', 'jpeg']\n    filenames = ['*.jpg']\n    default_image_format = 'jpeg'\n\n\nclass BmpImageFormatter(ImageFormatter):\n    \"\"\"\n    Create a bitmap image from source code. This uses the Python Imaging Library to\n    generate a pixmap from the source code.\n\n    .. versionadded:: 1.0\n    \"\"\"\n\n    name = 'img_bmp'\n    aliases = ['bmp', 'bitmap']\n    filenames = ['*.bmp']\n    default_image_format = 'bmp'\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/pygments/formatters/irc.py","size":4981,"sha1":"3fd2d378b9c0e3da390bcda350baaf1f98345c89","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\n    pygments.formatters.irc\n    ~~~~~~~~~~~~~~~~~~~~~~~\n\n    Formatter for IRC output\n\n    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nfrom pip._vendor.pygments.formatter import Formatter\nfrom pip._vendor.pygments.token import Keyword, Name, Comment, String, Error, \\\n    Number, Operator, Generic, Token, Whitespace\nfrom pip._vendor.pygments.util import get_choice_opt\n\n\n__all__ = ['IRCFormatter']\n\n\n#: Map token types to a tuple of color values for light and dark\n#: backgrounds.\nIRC_COLORS = {\n    Token:              ('',            ''),\n\n    Whitespace:         ('gray',   'brightblack'),\n    Comment:            ('gray',   'brightblack'),\n    Comment.Preproc:    ('cyan',        'brightcyan'),\n    Keyword:            ('blue',    'brightblue'),\n    Keyword.Type:       ('cyan',        'brightcyan'),\n    Operator.Word:      ('magenta',      'brightcyan'),\n    Name.Builtin:       ('cyan',        'brightcyan'),\n    Name.Function:      ('green',   'brightgreen'),\n    Name.Namespace:     ('_cyan_',      '_brightcyan_'),\n    Name.Class:         ('_green_', '_brightgreen_'),\n    Name.Exception:     ('cyan',        'brightcyan'),\n    Name.Decorator:     ('brightblack',    'gray'),\n    Name.Variable:      ('red',     'brightred'),\n    Name.Constant:      ('red',     'brightred'),\n    Name.Attribute:     ('cyan',        'brightcyan'),\n    Name.Tag:           ('brightblue',        'brightblue'),\n    String:             ('yellow',       'yellow'),\n    Number:             ('blue',    'brightblue'),\n\n    Generic.Deleted:    ('brightred',        'brightred'),\n    Generic.Inserted:   ('green',  'brightgreen'),\n    Generic.Heading:    ('**',         '**'),\n    Generic.Subheading: ('*magenta*',   '*brightmagenta*'),\n    Generic.Error:      ('brightred',        'brightred'),\n\n    Error:              ('_brightred_',      '_brightred_'),\n}\n\n\nIRC_COLOR_MAP = {\n    'white': 0,\n    'black': 1,\n    'blue': 2,\n    'brightgreen': 3,\n    'brightred': 4,\n    'yellow': 5,\n    'magenta': 6,\n    'orange': 7,\n    'green': 7, #compat w/ ansi\n    'brightyellow': 8,\n    'lightgreen': 9,\n    'brightcyan': 9, # compat w/ ansi\n    'cyan': 10,\n    'lightblue': 11,\n    'red': 11, # compat w/ ansi\n    'brightblue': 12,\n    'brightmagenta': 13,\n    'brightblack': 14,\n    'gray': 15,\n}\n\ndef ircformat(color, text):\n    if len(color) < 1:\n        return text\n    add = sub = ''\n    if '_' in color: # italic\n        add += '\\x1D'\n        sub = '\\x1D' + sub\n        color = color.strip('_')\n    if '*' in color: # bold\n        add += '\\x02'\n        sub = '\\x02' + sub\n        color = color.strip('*')\n    # underline (\\x1F) not supported\n    # backgrounds (\\x03FF,BB) not supported\n    if len(color) > 0: # actual color - may have issues with ircformat(\"red\", \"blah\")+\"10\" type stuff\n        add += '\\x03' + str(IRC_COLOR_MAP[color]).zfill(2)\n        sub = '\\x03' + sub\n    return add + text + sub\n    return '<'+add+'>'+text+'</'+sub+'>'\n\n\nclass IRCFormatter(Formatter):\n    r\"\"\"\n    Format tokens with IRC color sequences\n\n    The `get_style_defs()` method doesn't do anything special since there is\n    no support for common styles.\n\n    Options accepted:\n\n    `bg`\n        Set to ``\"light\"`` or ``\"dark\"`` depending on the terminal's background\n        (default: ``\"light\"``).\n\n    `colorscheme`\n        A dictionary mapping token types to (lightbg, darkbg) color names or\n        ``None`` (default: ``None`` = use builtin colorscheme).\n\n    `linenos`\n        Set to ``True`` to have line numbers in the output as well\n        (default: ``False`` = no line numbers).\n    \"\"\"\n    name = 'IRC'\n    aliases = ['irc', 'IRC']\n    filenames = []\n\n    def __init__(self, **options):\n        Formatter.__init__(self, **options)\n        self.darkbg = get_choice_opt(options, 'bg',\n                                     ['light', 'dark'], 'light') == 'dark'\n        self.colorscheme = options.get('colorscheme', None) or IRC_COLORS\n        self.linenos = options.get('linenos', False)\n        self._lineno = 0\n\n    def _write_lineno(self, outfile):\n        if self.linenos:\n            self._lineno += 1\n            outfile.write(\"%04d: \" % self._lineno)\n\n    def format_unencoded(self, tokensource, outfile):\n        self._write_lineno(outfile)\n\n        for ttype, value in tokensource:\n            color = self.colorscheme.get(ttype)\n            while color is None:\n                ttype = ttype[:-1]\n                color = self.colorscheme.get(ttype)\n            if color:\n                color = color[self.darkbg]\n                spl = value.split('\\n')\n                for line in spl[:-1]:\n                    if line:\n                        outfile.write(ircformat(color, line))\n                    outfile.write('\\n')\n                    self._write_lineno(outfile)\n                if spl[-1]:\n                    outfile.write(ircformat(color, spl[-1]))\n            else:\n                outfile.write(value)\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/pygments/formatters/latex.py","size":19306,"sha1":"75d927eb42e391935863e3735a570df94daa27ec","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\n    pygments.formatters.latex\n    ~~~~~~~~~~~~~~~~~~~~~~~~~\n\n    Formatter for LaTeX fancyvrb output.\n\n    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nfrom io import StringIO\n\nfrom pip._vendor.pygments.formatter import Formatter\nfrom pip._vendor.pygments.lexer import Lexer, do_insertions\nfrom pip._vendor.pygments.token import Token, STANDARD_TYPES\nfrom pip._vendor.pygments.util import get_bool_opt, get_int_opt\n\n\n__all__ = ['LatexFormatter']\n\n\ndef escape_tex(text, commandprefix):\n    return text.replace('\\\\', '\\x00'). \\\n                replace('{', '\\x01'). \\\n                replace('}', '\\x02'). \\\n                replace('\\x00', rf'\\{commandprefix}Zbs{{}}'). \\\n                replace('\\x01', rf'\\{commandprefix}Zob{{}}'). \\\n                replace('\\x02', rf'\\{commandprefix}Zcb{{}}'). \\\n                replace('^', rf'\\{commandprefix}Zca{{}}'). \\\n                replace('_', rf'\\{commandprefix}Zus{{}}'). \\\n                replace('&', rf'\\{commandprefix}Zam{{}}'). \\\n                replace('<', rf'\\{commandprefix}Zlt{{}}'). \\\n                replace('>', rf'\\{commandprefix}Zgt{{}}'). \\\n                replace('#', rf'\\{commandprefix}Zsh{{}}'). \\\n                replace('%', rf'\\{commandprefix}Zpc{{}}'). \\\n                replace('$', rf'\\{commandprefix}Zdl{{}}'). \\\n                replace('-', rf'\\{commandprefix}Zhy{{}}'). \\\n                replace(\"'\", rf'\\{commandprefix}Zsq{{}}'). \\\n                replace('\"', rf'\\{commandprefix}Zdq{{}}'). \\\n                replace('~', rf'\\{commandprefix}Zti{{}}')\n\n\nDOC_TEMPLATE = r'''\n\\documentclass{%(docclass)s}\n\\usepackage{fancyvrb}\n\\usepackage{color}\n\\usepackage[%(encoding)s]{inputenc}\n%(preamble)s\n\n%(styledefs)s\n\n\\begin{document}\n\n\\section*{%(title)s}\n\n%(code)s\n\\end{document}\n'''\n\n## Small explanation of the mess below :)\n#\n# The previous version of the LaTeX formatter just assigned a command to\n# each token type defined in the current style.  That obviously is\n# problematic if the highlighted code is produced for a different style\n# than the style commands themselves.\n#\n# This version works much like the HTML formatter which assigns multiple\n# CSS classes to each <span> tag, from the most specific to the least\n# specific token type, thus falling back to the parent token type if one\n# is not defined.  Here, the classes are there too and use the same short\n# forms given in token.STANDARD_TYPES.\n#\n# Highlighted code now only uses one custom command, which by default is\n# \\PY and selectable by the commandprefix option (and in addition the\n# escapes \\PYZat, \\PYZlb and \\PYZrb which haven't been renamed for\n# backwards compatibility purposes).\n#\n# \\PY has two arguments: the classes, separated by +, and the text to\n# render in that style.  The classes are resolved into the respective\n# style commands by magic, which serves to ignore unknown classes.\n#\n# The magic macros are:\n# * \\PY@it, \\PY@bf, etc. are unconditionally wrapped around the text\n#   to render in \\PY@do.  Their definition determines the style.\n# * \\PY@reset resets \\PY@it etc. to do nothing.\n# * \\PY@toks parses the list of classes, using magic inspired by the\n#   keyval package (but modified to use plusses instead of commas\n#   because fancyvrb redefines commas inside its environments).\n# * \\PY@tok processes one class, calling the \\PY@tok@classname command\n#   if it exists.\n# * \\PY@tok@classname sets the \\PY@it etc. to reflect the chosen style\n#   for its class.\n# * \\PY resets the style, parses the classnames and then calls \\PY@do.\n#\n# Tip: to read this code, print it out in substituted form using e.g.\n# >>> print STYLE_TEMPLATE % {'cp': 'PY'}\n\nSTYLE_TEMPLATE = r'''\n\\makeatletter\n\\def\\%(cp)s@reset{\\let\\%(cp)s@it=\\relax \\let\\%(cp)s@bf=\\relax%%\n    \\let\\%(cp)s@ul=\\relax \\let\\%(cp)s@tc=\\relax%%\n    \\let\\%(cp)s@bc=\\relax \\let\\%(cp)s@ff=\\relax}\n\\def\\%(cp)s@tok#1{\\csname %(cp)s@tok@#1\\endcsname}\n\\def\\%(cp)s@toks#1+{\\ifx\\relax#1\\empty\\else%%\n    \\%(cp)s@tok{#1}\\expandafter\\%(cp)s@toks\\fi}\n\\def\\%(cp)s@do#1{\\%(cp)s@bc{\\%(cp)s@tc{\\%(cp)s@ul{%%\n    \\%(cp)s@it{\\%(cp)s@bf{\\%(cp)s@ff{#1}}}}}}}\n\\def\\%(cp)s#1#2{\\%(cp)s@reset\\%(cp)s@toks#1+\\relax+\\%(cp)s@do{#2}}\n\n%(styles)s\n\n\\def\\%(cp)sZbs{\\char`\\\\}\n\\def\\%(cp)sZus{\\char`\\_}\n\\def\\%(cp)sZob{\\char`\\{}\n\\def\\%(cp)sZcb{\\char`\\}}\n\\def\\%(cp)sZca{\\char`\\^}\n\\def\\%(cp)sZam{\\char`\\&}\n\\def\\%(cp)sZlt{\\char`\\<}\n\\def\\%(cp)sZgt{\\char`\\>}\n\\def\\%(cp)sZsh{\\char`\\#}\n\\def\\%(cp)sZpc{\\char`\\%%}\n\\def\\%(cp)sZdl{\\char`\\$}\n\\def\\%(cp)sZhy{\\char`\\-}\n\\def\\%(cp)sZsq{\\char`\\'}\n\\def\\%(cp)sZdq{\\char`\\\"}\n\\def\\%(cp)sZti{\\char`\\~}\n%% for compatibility with earlier versions\n\\def\\%(cp)sZat{@}\n\\def\\%(cp)sZlb{[}\n\\def\\%(cp)sZrb{]}\n\\makeatother\n'''\n\n\ndef _get_ttype_name(ttype):\n    fname = STANDARD_TYPES.get(ttype)\n    if fname:\n        return fname\n    aname = ''\n    while fname is None:\n        aname = ttype[-1] + aname\n        ttype = ttype.parent\n        fname = STANDARD_TYPES.get(ttype)\n    return fname + aname\n\n\nclass LatexFormatter(Formatter):\n    r\"\"\"\n    Format tokens as LaTeX code. This needs the `fancyvrb` and `color`\n    standard packages.\n\n    Without the `full` option, code is formatted as one ``Verbatim``\n    environment, like this:\n\n    .. sourcecode:: latex\n\n        \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n        \\PY{k}{def }\\PY{n+nf}{foo}(\\PY{n}{bar}):\n            \\PY{k}{pass}\n        \\end{Verbatim}\n\n    Wrapping can be disabled using the `nowrap` option.\n\n    The special command used here (``\\PY``) and all the other macros it needs\n    are output by the `get_style_defs` method.\n\n    With the `full` option, a complete LaTeX document is output, including\n    the command definitions in the preamble.\n\n    The `get_style_defs()` method of a `LatexFormatter` returns a string\n    containing ``\\def`` commands defining the macros needed inside the\n    ``Verbatim`` environments.\n\n    Additional options accepted:\n\n    `nowrap`\n        If set to ``True``, don't wrap the tokens at all, not even inside a\n        ``\\begin{Verbatim}`` environment. This disables most other options\n        (default: ``False``).\n\n    `style`\n        The style to use, can be a string or a Style subclass (default:\n        ``'default'``).\n\n    `full`\n        Tells the formatter to output a \"full\" document, i.e. a complete\n        self-contained document (default: ``False``).\n\n    `title`\n        If `full` is true, the title that should be used to caption the\n        document (default: ``''``).\n\n    `docclass`\n        If the `full` option is enabled, this is the document class to use\n        (default: ``'article'``).\n\n    `preamble`\n        If the `full` option is enabled, this can be further preamble commands,\n        e.g. ``\\usepackage`` (default: ``''``).\n\n    `linenos`\n        If set to ``True``, output line numbers (default: ``False``).\n\n    `linenostart`\n        The line number for the first line (default: ``1``).\n\n    `linenostep`\n        If set to a number n > 1, only every nth line number is printed.\n\n    `verboptions`\n        Additional options given to the Verbatim environment (see the *fancyvrb*\n        docs for possible values) (default: ``''``).\n\n    `commandprefix`\n        The LaTeX commands used to produce colored output are constructed\n        using this prefix and some letters (default: ``'PY'``).\n\n        .. versionadded:: 0.7\n        .. versionchanged:: 0.10\n           The default is now ``'PY'`` instead of ``'C'``.\n\n    `texcomments`\n        If set to ``True``, enables LaTeX comment lines.  That is, LaTex markup\n        in comment tokens is not escaped so that LaTeX can render it (default:\n        ``False``).\n\n        .. versionadded:: 1.2\n\n    `mathescape`\n        If set to ``True``, enables LaTeX math mode escape in comments. That\n        is, ``'$...$'`` inside a comment will trigger math mode (default:\n        ``False``).\n\n        .. versionadded:: 1.2\n\n    `escapeinside`\n        If set to a string of length 2, enables escaping to LaTeX. Text\n        delimited by these 2 characters is read as LaTeX code and\n        typeset accordingly. It has no effect in string literals. It has\n        no effect in comments if `texcomments` or `mathescape` is\n        set. (default: ``''``).\n\n        .. versionadded:: 2.0\n\n    `envname`\n        Allows you to pick an alternative environment name replacing Verbatim.\n        The alternate environment still has to support Verbatim's option syntax.\n        (default: ``'Verbatim'``).\n\n        .. versionadded:: 2.0\n    \"\"\"\n    name = 'LaTeX'\n    aliases = ['latex', 'tex']\n    filenames = ['*.tex']\n\n    def __init__(self, **options):\n        Formatter.__init__(self, **options)\n        self.nowrap = get_bool_opt(options, 'nowrap', False)\n        self.docclass = options.get('docclass', 'article')\n        self.preamble = options.get('preamble', '')\n        self.linenos = get_bool_opt(options, 'linenos', False)\n        self.linenostart = abs(get_int_opt(options, 'linenostart', 1))\n        self.linenostep = abs(get_int_opt(options, 'linenostep', 1))\n        self.verboptions = options.get('verboptions', '')\n        self.nobackground = get_bool_opt(options, 'nobackground', False)\n        self.commandprefix = options.get('commandprefix', 'PY')\n        self.texcomments = get_bool_opt(options, 'texcomments', False)\n        self.mathescape = get_bool_opt(options, 'mathescape', False)\n        self.escapeinside = options.get('escapeinside', '')\n        if len(self.escapeinside) == 2:\n            self.left = self.escapeinside[0]\n            self.right = self.escapeinside[1]\n        else:\n            self.escapeinside = ''\n        self.envname = options.get('envname', 'Verbatim')\n\n        self._create_stylesheet()\n\n    def _create_stylesheet(self):\n        t2n = self.ttype2name = {Token: ''}\n        c2d = self.cmd2def = {}\n        cp = self.commandprefix\n\n        def rgbcolor(col):\n            if col:\n                return ','.join(['%.2f' % (int(col[i] + col[i + 1], 16) / 255.0)\n                                 for i in (0, 2, 4)])\n            else:\n                return '1,1,1'\n\n        for ttype, ndef in self.style:\n            name = _get_ttype_name(ttype)\n            cmndef = ''\n            if ndef['bold']:\n                cmndef += r'\\let\\$$@bf=\\textbf'\n            if ndef['italic']:\n                cmndef += r'\\let\\$$@it=\\textit'\n            if ndef['underline']:\n                cmndef += r'\\let\\$$@ul=\\underline'\n            if ndef['roman']:\n                cmndef += r'\\let\\$$@ff=\\textrm'\n            if ndef['sans']:\n                cmndef += r'\\let\\$$@ff=\\textsf'\n            if ndef['mono']:\n                cmndef += r'\\let\\$$@ff=\\textsf'\n            if ndef['color']:\n                cmndef += (r'\\def\\$$@tc##1{{\\textcolor[rgb]{{{}}}{{##1}}}}'.format(rgbcolor(ndef['color'])))\n            if ndef['border']:\n                cmndef += (r'\\def\\$$@bc##1{{{{\\setlength{{\\fboxsep}}{{\\string -\\fboxrule}}'\n                           r'\\fcolorbox[rgb]{{{}}}{{{}}}{{\\strut ##1}}}}}}'.format(rgbcolor(ndef['border']),\n                            rgbcolor(ndef['bgcolor'])))\n            elif ndef['bgcolor']:\n                cmndef += (r'\\def\\$$@bc##1{{{{\\setlength{{\\fboxsep}}{{0pt}}'\n                           r'\\colorbox[rgb]{{{}}}{{\\strut ##1}}}}}}'.format(rgbcolor(ndef['bgcolor'])))\n            if cmndef == '':\n                continue\n            cmndef = cmndef.replace('$$', cp)\n            t2n[ttype] = name\n            c2d[name] = cmndef\n\n    def get_style_defs(self, arg=''):\n        \"\"\"\n        Return the command sequences needed to define the commands\n        used to format text in the verbatim environment. ``arg`` is ignored.\n        \"\"\"\n        cp = self.commandprefix\n        styles = []\n        for name, definition in self.cmd2def.items():\n            styles.append(rf'\\@namedef{{{cp}@tok@{name}}}{{{definition}}}')\n        return STYLE_TEMPLATE % {'cp': self.commandprefix,\n                                 'styles': '\\n'.join(styles)}\n\n    def format_unencoded(self, tokensource, outfile):\n        # TODO: add support for background colors\n        t2n = self.ttype2name\n        cp = self.commandprefix\n\n        if self.full:\n            realoutfile = outfile\n            outfile = StringIO()\n\n        if not self.nowrap:\n            outfile.write('\\\\begin{' + self.envname + '}[commandchars=\\\\\\\\\\\\{\\\\}')\n            if self.linenos:\n                start, step = self.linenostart, self.linenostep\n                outfile.write(',numbers=left' +\n                              (start and ',firstnumber=%d' % start or '') +\n                              (step and ',stepnumber=%d' % step or ''))\n            if self.mathescape or self.texcomments or self.escapeinside:\n                outfile.write(',codes={\\\\catcode`\\\\$=3\\\\catcode`\\\\^=7'\n                              '\\\\catcode`\\\\_=8\\\\relax}')\n            if self.verboptions:\n                outfile.write(',' + self.verboptions)\n            outfile.write(']\\n')\n\n        for ttype, value in tokensource:\n            if ttype in Token.Comment:\n                if self.texcomments:\n                    # Try to guess comment starting lexeme and escape it ...\n                    start = value[0:1]\n                    for i in range(1, len(value)):\n                        if start[0] != value[i]:\n                            break\n                        start += value[i]\n\n                    value = value[len(start):]\n                    start = escape_tex(start, cp)\n\n                    # ... but do not escape inside comment.\n                    value = start + value\n                elif self.mathescape:\n                    # Only escape parts not inside a math environment.\n                    parts = value.split('$')\n                    in_math = False\n                    for i, part in enumerate(parts):\n                        if not in_math:\n                            parts[i] = escape_tex(part, cp)\n                        in_math = not in_math\n                    value = '$'.join(parts)\n                elif self.escapeinside:\n                    text = value\n                    value = ''\n                    while text:\n                        a, sep1, text = text.partition(self.left)\n                        if sep1:\n                            b, sep2, text = text.partition(self.right)\n                            if sep2:\n                                value += escape_tex(a, cp) + b\n                            else:\n                                value += escape_tex(a + sep1 + b, cp)\n                        else:\n                            value += escape_tex(a, cp)\n                else:\n                    value = escape_tex(value, cp)\n            elif ttype not in Token.Escape:\n                value = escape_tex(value, cp)\n            styles = []\n            while ttype is not Token:\n                try:\n                    styles.append(t2n[ttype])\n                except KeyError:\n                    # not in current style\n                    styles.append(_get_ttype_name(ttype))\n                ttype = ttype.parent\n            styleval = '+'.join(reversed(styles))\n            if styleval:\n                spl = value.split('\\n')\n                for line in spl[:-1]:\n                    if line:\n                        outfile.write(f\"\\\\{cp}{{{styleval}}}{{{line}}}\")\n                    outfile.write('\\n')\n                if spl[-1]:\n                    outfile.write(f\"\\\\{cp}{{{styleval}}}{{{spl[-1]}}}\")\n            else:\n                outfile.write(value)\n\n        if not self.nowrap:\n            outfile.write('\\\\end{' + self.envname + '}\\n')\n\n        if self.full:\n            encoding = self.encoding or 'utf8'\n            # map known existings encodings from LaTeX distribution\n            encoding = {\n                'utf_8': 'utf8',\n                'latin_1': 'latin1',\n                'iso_8859_1': 'latin1',\n            }.get(encoding.replace('-', '_'), encoding)\n            realoutfile.write(DOC_TEMPLATE %\n                dict(docclass  = self.docclass,\n                     preamble  = self.preamble,\n                     title     = self.title,\n                     encoding  = encoding,\n                     styledefs = self.get_style_defs(),\n                     code      = outfile.getvalue()))\n\n\nclass LatexEmbeddedLexer(Lexer):\n    \"\"\"\n    This lexer takes one lexer as argument, the lexer for the language\n    being formatted, and the left and right delimiters for escaped text.\n\n    First everything is scanned using the language lexer to obtain\n    strings and comments. All other consecutive tokens are merged and\n    the resulting text is scanned for escaped segments, which are given\n    the Token.Escape type. Finally text that is not escaped is scanned\n    again with the language lexer.\n    \"\"\"\n    def __init__(self, left, right, lang, **options):\n        self.left = left\n        self.right = right\n        self.lang = lang\n        Lexer.__init__(self, **options)\n\n    def get_tokens_unprocessed(self, text):\n        # find and remove all the escape tokens (replace with an empty string)\n        # this is very similar to DelegatingLexer.get_tokens_unprocessed.\n        buffered = ''\n        insertions = []\n        insertion_buf = []\n        for i, t, v in self._find_safe_escape_tokens(text):\n            if t is None:\n                if insertion_buf:\n                    insertions.append((len(buffered), insertion_buf))\n                    insertion_buf = []\n                buffered += v\n            else:\n                insertion_buf.append((i, t, v))\n        if insertion_buf:\n            insertions.append((len(buffered), insertion_buf))\n        return do_insertions(insertions,\n                             self.lang.get_tokens_unprocessed(buffered))\n\n    def _find_safe_escape_tokens(self, text):\n        \"\"\" find escape tokens that are not in strings or comments \"\"\"\n        for i, t, v in self._filter_to(\n            self.lang.get_tokens_unprocessed(text),\n            lambda t: t in Token.Comment or t in Token.String\n        ):\n            if t is None:\n                for i2, t2, v2 in self._find_escape_tokens(v):\n                    yield i + i2, t2, v2\n            else:\n                yield i, None, v\n\n    def _filter_to(self, it, pred):\n        \"\"\" Keep only the tokens that match `pred`, merge the others together \"\"\"\n        buf = ''\n        idx = 0\n        for i, t, v in it:\n            if pred(t):\n                if buf:\n                    yield idx, None, buf\n                    buf = ''\n                yield i, t, v\n            else:\n                if not buf:\n                    idx = i\n                buf += v\n        if buf:\n            yield idx, None, buf\n\n    def _find_escape_tokens(self, text):\n        \"\"\" Find escape tokens within text, give token=None otherwise \"\"\"\n        index = 0\n        while text:\n            a, sep1, text = text.partition(self.left)\n            if a:\n                yield index, None, a\n                index += len(a)\n            if sep1:\n                b, sep2, text = text.partition(self.right)\n                if sep2:\n                    yield index + len(sep1), Token.Escape, b\n                    index += len(sep1) + len(b) + len(sep2)\n                else:\n                    yield index, Token.Error, sep1\n                    index += len(sep1)\n                    text = b\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/pygments/formatters/other.py","size":5034,"sha1":"b94757bb473185f43e64f93f3369f659b661571b","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\n    pygments.formatters.other\n    ~~~~~~~~~~~~~~~~~~~~~~~~~\n\n    Other formatters: NullFormatter, RawTokenFormatter.\n\n    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nfrom pip._vendor.pygments.formatter import Formatter\nfrom pip._vendor.pygments.util import get_choice_opt\nfrom pip._vendor.pygments.token import Token\nfrom pip._vendor.pygments.console import colorize\n\n__all__ = ['NullFormatter', 'RawTokenFormatter', 'TestcaseFormatter']\n\n\nclass NullFormatter(Formatter):\n    \"\"\"\n    Output the text unchanged without any formatting.\n    \"\"\"\n    name = 'Text only'\n    aliases = ['text', 'null']\n    filenames = ['*.txt']\n\n    def format(self, tokensource, outfile):\n        enc = self.encoding\n        for ttype, value in tokensource:\n            if enc:\n                outfile.write(value.encode(enc))\n            else:\n                outfile.write(value)\n\n\nclass RawTokenFormatter(Formatter):\n    r\"\"\"\n    Format tokens as a raw representation for storing token streams.\n\n    The format is ``tokentype<TAB>repr(tokenstring)\\n``. The output can later\n    be converted to a token stream with the `RawTokenLexer`, described in the\n    :doc:`lexer list <lexers>`.\n\n    Only two options are accepted:\n\n    `compress`\n        If set to ``'gz'`` or ``'bz2'``, compress the output with the given\n        compression algorithm after encoding (default: ``''``).\n    `error_color`\n        If set to a color name, highlight error tokens using that color.  If\n        set but with no value, defaults to ``'red'``.\n\n        .. versionadded:: 0.11\n\n    \"\"\"\n    name = 'Raw tokens'\n    aliases = ['raw', 'tokens']\n    filenames = ['*.raw']\n\n    unicodeoutput = False\n\n    def __init__(self, **options):\n        Formatter.__init__(self, **options)\n        # We ignore self.encoding if it is set, since it gets set for lexer\n        # and formatter if given with -Oencoding on the command line.\n        # The RawTokenFormatter outputs only ASCII. Override here.\n        self.encoding = 'ascii'  # let pygments.format() do the right thing\n        self.compress = get_choice_opt(options, 'compress',\n                                       ['', 'none', 'gz', 'bz2'], '')\n        self.error_color = options.get('error_color', None)\n        if self.error_color is True:\n            self.error_color = 'red'\n        if self.error_color is not None:\n            try:\n                colorize(self.error_color, '')\n            except KeyError:\n                raise ValueError(f\"Invalid color {self.error_color!r} specified\")\n\n    def format(self, tokensource, outfile):\n        try:\n            outfile.write(b'')\n        except TypeError:\n            raise TypeError('The raw tokens formatter needs a binary '\n                            'output file')\n        if self.compress == 'gz':\n            import gzip\n            outfile = gzip.GzipFile('', 'wb', 9, outfile)\n\n            write = outfile.write\n            flush = outfile.close\n        elif self.compress == 'bz2':\n            import bz2\n            compressor = bz2.BZ2Compressor(9)\n\n            def write(text):\n                outfile.write(compressor.compress(text))\n\n            def flush():\n                outfile.write(compressor.flush())\n                outfile.flush()\n        else:\n            write = outfile.write\n            flush = outfile.flush\n\n        if self.error_color:\n            for ttype, value in tokensource:\n                line = b\"%r\\t%r\\n\" % (ttype, value)\n                if ttype is Token.Error:\n                    write(colorize(self.error_color, line))\n                else:\n                    write(line)\n        else:\n            for ttype, value in tokensource:\n                write(b\"%r\\t%r\\n\" % (ttype, value))\n        flush()\n\n\nTESTCASE_BEFORE = '''\\\n    def testNeedsName(lexer):\n        fragment = %r\n        tokens = [\n'''\nTESTCASE_AFTER = '''\\\n        ]\n        assert list(lexer.get_tokens(fragment)) == tokens\n'''\n\n\nclass TestcaseFormatter(Formatter):\n    \"\"\"\n    Format tokens as appropriate for a new testcase.\n\n    .. versionadded:: 2.0\n    \"\"\"\n    name = 'Testcase'\n    aliases = ['testcase']\n\n    def __init__(self, **options):\n        Formatter.__init__(self, **options)\n        if self.encoding is not None and self.encoding != 'utf-8':\n            raise ValueError(\"Only None and utf-8 are allowed encodings.\")\n\n    def format(self, tokensource, outfile):\n        indentation = ' ' * 12\n        rawbuf = []\n        outbuf = []\n        for ttype, value in tokensource:\n            rawbuf.append(value)\n            outbuf.append(f'{indentation}({ttype}, {value!r}),\\n')\n\n        before = TESTCASE_BEFORE % (''.join(rawbuf),)\n        during = ''.join(outbuf)\n        after = TESTCASE_AFTER\n        if self.encoding is None:\n            outfile.write(before + during + after)\n        else:\n            outfile.write(before.encode('utf-8'))\n            outfile.write(during.encode('utf-8'))\n            outfile.write(after.encode('utf-8'))\n        outfile.flush()\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/pygments/formatters/pangomarkup.py","size":2218,"sha1":"abf7757aaebfd508a2a51a862570910f71374513","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\n    pygments.formatters.pangomarkup\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n    Formatter for Pango markup output.\n\n    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nfrom pip._vendor.pygments.formatter import Formatter\n\n\n__all__ = ['PangoMarkupFormatter']\n\n\n_escape_table = {\n    ord('&'): '&amp;',\n    ord('<'): '&lt;',\n}\n\n\ndef escape_special_chars(text, table=_escape_table):\n    \"\"\"Escape & and < for Pango Markup.\"\"\"\n    return text.translate(table)\n\n\nclass PangoMarkupFormatter(Formatter):\n    \"\"\"\n    Format tokens as Pango Markup code. It can then be rendered to an SVG.\n\n    .. versionadded:: 2.9\n    \"\"\"\n\n    name = 'Pango Markup'\n    aliases = ['pango', 'pangomarkup']\n    filenames = []\n\n    def __init__(self, **options):\n        Formatter.__init__(self, **options)\n\n        self.styles = {}\n\n        for token, style in self.style:\n            start = ''\n            end = ''\n            if style['color']:\n                start += '<span fgcolor=\"#{}\">'.format(style['color'])\n                end = '</span>' + end\n            if style['bold']:\n                start += '<b>'\n                end = '</b>' + end\n            if style['italic']:\n                start += '<i>'\n                end = '</i>' + end\n            if style['underline']:\n                start += '<u>'\n                end = '</u>' + end\n            self.styles[token] = (start, end)\n\n    def format_unencoded(self, tokensource, outfile):\n        lastval = ''\n        lasttype = None\n\n        outfile.write('<tt>')\n\n        for ttype, value in tokensource:\n            while ttype not in self.styles:\n                ttype = ttype.parent\n            if ttype == lasttype:\n                lastval += escape_special_chars(value)\n            else:\n                if lastval:\n                    stylebegin, styleend = self.styles[lasttype]\n                    outfile.write(stylebegin + lastval + styleend)\n                lastval = escape_special_chars(value)\n                lasttype = ttype\n\n        if lastval:\n            stylebegin, styleend = self.styles[lasttype]\n            outfile.write(stylebegin + lastval + styleend)\n\n        outfile.write('</tt>')\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/pygments/formatters/rtf.py","size":11957,"sha1":"5bea0fe15ac7591a100579ca7848e01b47d026ba","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\n    pygments.formatters.rtf\n    ~~~~~~~~~~~~~~~~~~~~~~~\n\n    A formatter that generates RTF files.\n\n    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nfrom collections import OrderedDict\nfrom pip._vendor.pygments.formatter import Formatter\nfrom pip._vendor.pygments.style import _ansimap\nfrom pip._vendor.pygments.util import get_bool_opt, get_int_opt, get_list_opt, surrogatepair\n\n\n__all__ = ['RtfFormatter']\n\n\nclass RtfFormatter(Formatter):\n    \"\"\"\n    Format tokens as RTF markup. This formatter automatically outputs full RTF\n    documents with color information and other useful stuff. Perfect for Copy and\n    Paste into Microsoft(R) Word(R) documents.\n\n    Please note that ``encoding`` and ``outencoding`` options are ignored.\n    The RTF format is ASCII natively, but handles unicode characters correctly\n    thanks to escape sequences.\n\n    .. versionadded:: 0.6\n\n    Additional options accepted:\n\n    `style`\n        The style to use, can be a string or a Style subclass (default:\n        ``'default'``).\n\n    `fontface`\n        The used font family, for example ``Bitstream Vera Sans``. Defaults to\n        some generic font which is supposed to have fixed width.\n\n    `fontsize`\n        Size of the font used. Size is specified in half points. The\n        default is 24 half-points, giving a size 12 font.\n\n        .. versionadded:: 2.0\n\n    `linenos`\n        Turn on line numbering (default: ``False``).\n\n        .. versionadded:: 2.18\n\n    `lineno_fontsize`\n        Font size for line numbers. Size is specified in half points\n        (default: `fontsize`). \n\n        .. versionadded:: 2.18\n\n    `lineno_padding`\n        Number of spaces between the (inline) line numbers and the\n        source code (default: ``2``).\n\n        .. versionadded:: 2.18\n\n    `linenostart`\n        The line number for the first line (default: ``1``).\n\n        .. versionadded:: 2.18\n\n    `linenostep`\n        If set to a number n > 1, only every nth line number is printed.\n\n        .. versionadded:: 2.18\n\n    `lineno_color`\n        Color for line numbers specified as a hex triplet, e.g. ``'5e5e5e'``. \n        Defaults to the style's line number color if it is a hex triplet, \n        otherwise ansi bright black.\n\n        .. versionadded:: 2.18\n\n    `hl_lines`\n        Specify a list of lines to be highlighted, as line numbers separated by\n        spaces, e.g. ``'3 7 8'``. The line numbers are relative to the input \n        (i.e. the first line is line 1) unless `hl_linenostart` is set.\n\n        .. versionadded:: 2.18\n\n    `hl_color`\n        Color for highlighting the lines specified in `hl_lines`, specified as \n        a hex triplet (default: style's `highlight_color`).\n\n        .. versionadded:: 2.18\n\n    `hl_linenostart`\n        If set to ``True`` line numbers in `hl_lines` are specified\n        relative to `linenostart` (default ``False``).\n\n        .. versionadded:: 2.18\n    \"\"\"\n    name = 'RTF'\n    aliases = ['rtf']\n    filenames = ['*.rtf']\n\n    def __init__(self, **options):\n        r\"\"\"\n        Additional options accepted:\n\n        ``fontface``\n            Name of the font used. Could for example be ``'Courier New'``\n            to further specify the default which is ``'\\fmodern'``. The RTF\n            specification claims that ``\\fmodern`` are \"Fixed-pitch serif\n            and sans serif fonts\". Hope every RTF implementation thinks\n            the same about modern...\n\n        \"\"\"\n        Formatter.__init__(self, **options)\n        self.fontface = options.get('fontface') or ''\n        self.fontsize = get_int_opt(options, 'fontsize', 0)\n        self.linenos = get_bool_opt(options, 'linenos', False)\n        self.lineno_fontsize = get_int_opt(options, 'lineno_fontsize',\n                                           self.fontsize)\n        self.lineno_padding = get_int_opt(options, 'lineno_padding', 2)\n        self.linenostart = abs(get_int_opt(options, 'linenostart', 1))\n        self.linenostep = abs(get_int_opt(options, 'linenostep', 1))\n        self.hl_linenostart = get_bool_opt(options, 'hl_linenostart', False)\n\n        self.hl_color = options.get('hl_color', '')\n        if not self.hl_color:\n            self.hl_color = self.style.highlight_color\n\n        self.hl_lines = []\n        for lineno in get_list_opt(options, 'hl_lines', []):\n            try:\n                lineno = int(lineno)\n                if self.hl_linenostart:\n                    lineno = lineno - self.linenostart + 1\n                self.hl_lines.append(lineno)\n            except ValueError:\n                pass\n\n        self.lineno_color = options.get('lineno_color', '')\n        if not self.lineno_color:\n            if  self.style.line_number_color == 'inherit':\n                # style color is the css value 'inherit'\n                # default to ansi bright-black\n                self.lineno_color = _ansimap['ansibrightblack']\n            else:\n                # style color is assumed to be a hex triplet as other\n                # colors in pygments/style.py\n                self.lineno_color = self.style.line_number_color\n\n        self.color_mapping = self._create_color_mapping()\n\n    def _escape(self, text):\n        return text.replace('\\\\', '\\\\\\\\') \\\n                   .replace('{', '\\\\{') \\\n                   .replace('}', '\\\\}')\n\n    def _escape_text(self, text):\n        # empty strings, should give a small performance improvement\n        if not text:\n            return ''\n\n        # escape text\n        text = self._escape(text)\n\n        buf = []\n        for c in text:\n            cn = ord(c)\n            if cn < (2**7):\n                # ASCII character\n                buf.append(str(c))\n            elif (2**7) <= cn < (2**16):\n                # single unicode escape sequence\n                buf.append('{\\\\u%d}' % cn)\n            elif (2**16) <= cn:\n                # RTF limits unicode to 16 bits.\n                # Force surrogate pairs\n                buf.append('{\\\\u%d}{\\\\u%d}' % surrogatepair(cn))\n\n        return ''.join(buf).replace('\\n', '\\\\par')\n\n    @staticmethod\n    def hex_to_rtf_color(hex_color):\n        if hex_color[0] == \"#\":\n            hex_color = hex_color[1:]\n\n        return '\\\\red%d\\\\green%d\\\\blue%d;' % (\n                        int(hex_color[0:2], 16),\n                        int(hex_color[2:4], 16),\n                        int(hex_color[4:6], 16)\n                    )\n\n    def _split_tokens_on_newlines(self, tokensource):\n        \"\"\"\n        Split tokens containing newline characters into multiple token\n        each representing a line of the input file. Needed for numbering\n        lines of e.g. multiline comments.\n        \"\"\"\n        for ttype, value in tokensource:\n            if value == '\\n':\n                yield (ttype, value)\n            elif \"\\n\" in value:\n                lines = value.split(\"\\n\")\n                for line in lines[:-1]:\n                    yield (ttype, line+\"\\n\")\n                if lines[-1]:\n                    yield (ttype, lines[-1])\n            else:\n                yield (ttype, value)\n\n    def _create_color_mapping(self):\n        \"\"\"\n        Create a mapping of style hex colors to index/offset in\n        the RTF color table.\n        \"\"\"\n        color_mapping = OrderedDict()\n        offset = 1\n\n        if self.linenos:\n            color_mapping[self.lineno_color] = offset\n            offset += 1\n\n        if self.hl_lines:\n            color_mapping[self.hl_color] = offset\n            offset += 1\n\n        for _, style in self.style:\n            for color in style['color'], style['bgcolor'], style['border']:\n                if color and color not in color_mapping:\n                    color_mapping[color] = offset\n                    offset += 1\n\n        return color_mapping\n\n    @property\n    def _lineno_template(self):\n        if self.lineno_fontsize != self.fontsize:\n            return '{{\\\\fs{} \\\\cf{} %s{}}}'.format(self.lineno_fontsize,\n                          self.color_mapping[self.lineno_color],\n                          \" \" * self.lineno_padding)\n\n        return '{{\\\\cf{} %s{}}}'.format(self.color_mapping[self.lineno_color],\n                      \" \" * self.lineno_padding)\n\n    @property\n    def _hl_open_str(self):\n        return rf'{{\\highlight{self.color_mapping[self.hl_color]} '\n\n    @property\n    def _rtf_header(self):\n        lines = []\n        # rtf 1.8 header\n        lines.append('{\\\\rtf1\\\\ansi\\\\uc0\\\\deff0'\n                     '{\\\\fonttbl{\\\\f0\\\\fmodern\\\\fprq1\\\\fcharset0%s;}}'\n                     % (self.fontface and ' '\n                        + self._escape(self.fontface) or ''))\n\n        # color table\n        lines.append('{\\\\colortbl;')\n        for color, _ in self.color_mapping.items():\n            lines.append(self.hex_to_rtf_color(color))\n        lines.append('}')\n\n        # font and fontsize\n        lines.append('\\\\f0\\\\sa0')\n        if self.fontsize:\n            lines.append('\\\\fs%d' % self.fontsize)\n\n        # ensure Libre Office Writer imports and renders consecutive\n        # space characters the same width, needed for line numbering.\n        # https://bugs.documentfoundation.org/show_bug.cgi?id=144050\n        lines.append('\\\\dntblnsbdb')\n\n        return lines\n\n    def format_unencoded(self, tokensource, outfile):\n        for line in self._rtf_header:\n            outfile.write(line + \"\\n\")\n\n        tokensource = self._split_tokens_on_newlines(tokensource)\n\n        # first pass of tokens to count lines, needed for line numbering\n        if self.linenos:\n            line_count = 0\n            tokens = [] # for copying the token source generator\n            for ttype, value in tokensource:\n                tokens.append((ttype, value))\n                if value.endswith(\"\\n\"):\n                    line_count += 1\n\n            # width of line number strings (for padding with spaces)\n            linenos_width = len(str(line_count+self.linenostart-1))\n\n            tokensource = tokens\n\n        # highlight stream\n        lineno = 1\n        start_new_line = True\n        for ttype, value in tokensource:\n            if start_new_line and lineno in self.hl_lines:\n                outfile.write(self._hl_open_str)\n\n            if start_new_line and self.linenos:\n                if (lineno-self.linenostart+1)%self.linenostep == 0:\n                    current_lineno = lineno + self.linenostart - 1\n                    lineno_str = str(current_lineno).rjust(linenos_width)\n                else:\n                    lineno_str = \"\".rjust(linenos_width)\n                outfile.write(self._lineno_template % lineno_str)\n\n            while not self.style.styles_token(ttype) and ttype.parent:\n                ttype = ttype.parent\n            style = self.style.style_for_token(ttype)\n            buf = []\n            if style['bgcolor']:\n                buf.append('\\\\cb%d' % self.color_mapping[style['bgcolor']])\n            if style['color']:\n                buf.append('\\\\cf%d' % self.color_mapping[style['color']])\n            if style['bold']:\n                buf.append('\\\\b')\n            if style['italic']:\n                buf.append('\\\\i')\n            if style['underline']:\n                buf.append('\\\\ul')\n            if style['border']:\n                buf.append('\\\\chbrdr\\\\chcfpat%d' %\n                           self.color_mapping[style['border']])\n            start = ''.join(buf)\n            if start:\n                outfile.write(f'{{{start} ')\n            outfile.write(self._escape_text(value))\n            if start:\n                outfile.write('}')\n            start_new_line = False\n\n            # complete line of input\n            if value.endswith(\"\\n\"):\n                # close line highlighting\n                if lineno in self.hl_lines:\n                    outfile.write('}')\n                # newline in RTF file after closing }\n                outfile.write(\"\\n\")\n\n                start_new_line = True\n                lineno += 1\n\n        outfile.write('}\\n')\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/pygments/formatters/svg.py","size":7174,"sha1":"85604b64232b65e39055ae05836a8d7431b11bee","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\n    pygments.formatters.svg\n    ~~~~~~~~~~~~~~~~~~~~~~~\n\n    Formatter for SVG output.\n\n    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nfrom pip._vendor.pygments.formatter import Formatter\nfrom pip._vendor.pygments.token import Comment\nfrom pip._vendor.pygments.util import get_bool_opt, get_int_opt\n\n__all__ = ['SvgFormatter']\n\n\ndef escape_html(text):\n    \"\"\"Escape &, <, > as well as single and double quotes for HTML.\"\"\"\n    return text.replace('&', '&amp;').  \\\n                replace('<', '&lt;').   \\\n                replace('>', '&gt;').   \\\n                replace('\"', '&quot;'). \\\n                replace(\"'\", '&#39;')\n\n\nclass2style = {}\n\nclass SvgFormatter(Formatter):\n    \"\"\"\n    Format tokens as an SVG graphics file.  This formatter is still experimental.\n    Each line of code is a ``<text>`` element with explicit ``x`` and ``y``\n    coordinates containing ``<tspan>`` elements with the individual token styles.\n\n    By default, this formatter outputs a full SVG document including doctype\n    declaration and the ``<svg>`` root element.\n\n    .. versionadded:: 0.9\n\n    Additional options accepted:\n\n    `nowrap`\n        Don't wrap the SVG ``<text>`` elements in ``<svg><g>`` elements and\n        don't add a XML declaration and a doctype.  If true, the `fontfamily`\n        and `fontsize` options are ignored.  Defaults to ``False``.\n\n    `fontfamily`\n        The value to give the wrapping ``<g>`` element's ``font-family``\n        attribute, defaults to ``\"monospace\"``.\n\n    `fontsize`\n        The value to give the wrapping ``<g>`` element's ``font-size``\n        attribute, defaults to ``\"14px\"``.\n\n    `linenos`\n        If ``True``, add line numbers (default: ``False``).\n\n    `linenostart`\n        The line number for the first line (default: ``1``).\n\n    `linenostep`\n        If set to a number n > 1, only every nth line number is printed.\n\n    `linenowidth`\n        Maximum width devoted to line numbers (default: ``3*ystep``, sufficient\n        for up to 4-digit line numbers. Increase width for longer code blocks).\n\n    `xoffset`\n        Starting offset in X direction, defaults to ``0``.\n\n    `yoffset`\n        Starting offset in Y direction, defaults to the font size if it is given\n        in pixels, or ``20`` else.  (This is necessary since text coordinates\n        refer to the text baseline, not the top edge.)\n\n    `ystep`\n        Offset to add to the Y coordinate for each subsequent line.  This should\n        roughly be the text size plus 5.  It defaults to that value if the text\n        size is given in pixels, or ``25`` else.\n\n    `spacehack`\n        Convert spaces in the source to ``&#160;``, which are non-breaking\n        spaces.  SVG provides the ``xml:space`` attribute to control how\n        whitespace inside tags is handled, in theory, the ``preserve`` value\n        could be used to keep all whitespace as-is.  However, many current SVG\n        viewers don't obey that rule, so this option is provided as a workaround\n        and defaults to ``True``.\n    \"\"\"\n    name = 'SVG'\n    aliases = ['svg']\n    filenames = ['*.svg']\n\n    def __init__(self, **options):\n        Formatter.__init__(self, **options)\n        self.nowrap = get_bool_opt(options, 'nowrap', False)\n        self.fontfamily = options.get('fontfamily', 'monospace')\n        self.fontsize = options.get('fontsize', '14px')\n        self.xoffset = get_int_opt(options, 'xoffset', 0)\n        fs = self.fontsize.strip()\n        if fs.endswith('px'):\n            fs = fs[:-2].strip()\n        try:\n            int_fs = int(fs)\n        except ValueError:\n            int_fs = 20\n        self.yoffset = get_int_opt(options, 'yoffset', int_fs)\n        self.ystep = get_int_opt(options, 'ystep', int_fs + 5)\n        self.spacehack = get_bool_opt(options, 'spacehack', True)\n        self.linenos = get_bool_opt(options,'linenos',False)\n        self.linenostart = get_int_opt(options,'linenostart',1)\n        self.linenostep = get_int_opt(options,'linenostep',1)\n        self.linenowidth = get_int_opt(options,'linenowidth', 3*self.ystep)\n        self._stylecache = {}\n\n    def format_unencoded(self, tokensource, outfile):\n        \"\"\"\n        Format ``tokensource``, an iterable of ``(tokentype, tokenstring)``\n        tuples and write it into ``outfile``.\n\n        For our implementation we put all lines in their own 'line group'.\n        \"\"\"\n        x = self.xoffset\n        y = self.yoffset\n        if not self.nowrap:\n            if self.encoding:\n                outfile.write(f'<?xml version=\"1.0\" encoding=\"{self.encoding}\"?>\\n')\n            else:\n                outfile.write('<?xml version=\"1.0\"?>\\n')\n            outfile.write('<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.0//EN\" '\n                          '\"http://www.w3.org/TR/2001/REC-SVG-20010904/DTD/'\n                          'svg10.dtd\">\\n')\n            outfile.write('<svg xmlns=\"http://www.w3.org/2000/svg\">\\n')\n            outfile.write(f'<g font-family=\"{self.fontfamily}\" font-size=\"{self.fontsize}\">\\n')\n\n        counter = self.linenostart\n        counter_step = self.linenostep\n        counter_style = self._get_style(Comment)\n        line_x = x\n\n        if self.linenos:\n            if counter % counter_step == 0:\n                outfile.write(f'<text x=\"{x+self.linenowidth}\" y=\"{y}\" {counter_style} text-anchor=\"end\">{counter}</text>')\n            line_x += self.linenowidth + self.ystep\n            counter += 1\n\n        outfile.write(f'<text x=\"{line_x}\" y=\"{y}\" xml:space=\"preserve\">')\n        for ttype, value in tokensource:\n            style = self._get_style(ttype)\n            tspan = style and '<tspan' + style + '>' or ''\n            tspanend = tspan and '</tspan>' or ''\n            value = escape_html(value)\n            if self.spacehack:\n                value = value.expandtabs().replace(' ', '&#160;')\n            parts = value.split('\\n')\n            for part in parts[:-1]:\n                outfile.write(tspan + part + tspanend)\n                y += self.ystep\n                outfile.write('</text>\\n')\n                if self.linenos and counter % counter_step == 0:\n                    outfile.write(f'<text x=\"{x+self.linenowidth}\" y=\"{y}\" text-anchor=\"end\" {counter_style}>{counter}</text>')\n\n                counter += 1\n                outfile.write(f'<text x=\"{line_x}\" y=\"{y}\" ' 'xml:space=\"preserve\">')\n            outfile.write(tspan + parts[-1] + tspanend)\n        outfile.write('</text>')\n\n        if not self.nowrap:\n            outfile.write('</g></svg>\\n')\n\n    def _get_style(self, tokentype):\n        if tokentype in self._stylecache:\n            return self._stylecache[tokentype]\n        otokentype = tokentype\n        while not self.style.styles_token(tokentype):\n            tokentype = tokentype.parent\n        value = self.style.style_for_token(tokentype)\n        result = ''\n        if value['color']:\n            result = ' fill=\"#' + value['color'] + '\"'\n        if value['bold']:\n            result += ' font-weight=\"bold\"'\n        if value['italic']:\n            result += ' font-style=\"italic\"'\n        self._stylecache[otokentype] = result\n        return result\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/pygments/formatters/terminal.py","size":4674,"sha1":"e333fa865342a961bd6d3e2c11da22a66abee650","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\n    pygments.formatters.terminal\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n    Formatter for terminal output with ANSI sequences.\n\n    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nfrom pip._vendor.pygments.formatter import Formatter\nfrom pip._vendor.pygments.token import Keyword, Name, Comment, String, Error, \\\n    Number, Operator, Generic, Token, Whitespace\nfrom pip._vendor.pygments.console import ansiformat\nfrom pip._vendor.pygments.util import get_choice_opt\n\n\n__all__ = ['TerminalFormatter']\n\n\n#: Map token types to a tuple of color values for light and dark\n#: backgrounds.\nTERMINAL_COLORS = {\n    Token:              ('',            ''),\n\n    Whitespace:         ('gray',   'brightblack'),\n    Comment:            ('gray',   'brightblack'),\n    Comment.Preproc:    ('cyan',        'brightcyan'),\n    Keyword:            ('blue',    'brightblue'),\n    Keyword.Type:       ('cyan',        'brightcyan'),\n    Operator.Word:      ('magenta',      'brightmagenta'),\n    Name.Builtin:       ('cyan',        'brightcyan'),\n    Name.Function:      ('green',   'brightgreen'),\n    Name.Namespace:     ('_cyan_',      '_brightcyan_'),\n    Name.Class:         ('_green_', '_brightgreen_'),\n    Name.Exception:     ('cyan',        'brightcyan'),\n    Name.Decorator:     ('brightblack',    'gray'),\n    Name.Variable:      ('red',     'brightred'),\n    Name.Constant:      ('red',     'brightred'),\n    Name.Attribute:     ('cyan',        'brightcyan'),\n    Name.Tag:           ('brightblue',        'brightblue'),\n    String:             ('yellow',       'yellow'),\n    Number:             ('blue',    'brightblue'),\n\n    Generic.Deleted:    ('brightred',        'brightred'),\n    Generic.Inserted:   ('green',  'brightgreen'),\n    Generic.Heading:    ('**',         '**'),\n    Generic.Subheading: ('*magenta*',   '*brightmagenta*'),\n    Generic.Prompt:     ('**',         '**'),\n    Generic.Error:      ('brightred',        'brightred'),\n\n    Error:              ('_brightred_',      '_brightred_'),\n}\n\n\nclass TerminalFormatter(Formatter):\n    r\"\"\"\n    Format tokens with ANSI color sequences, for output in a text console.\n    Color sequences are terminated at newlines, so that paging the output\n    works correctly.\n\n    The `get_style_defs()` method doesn't do anything special since there is\n    no support for common styles.\n\n    Options accepted:\n\n    `bg`\n        Set to ``\"light\"`` or ``\"dark\"`` depending on the terminal's background\n        (default: ``\"light\"``).\n\n    `colorscheme`\n        A dictionary mapping token types to (lightbg, darkbg) color names or\n        ``None`` (default: ``None`` = use builtin colorscheme).\n\n    `linenos`\n        Set to ``True`` to have line numbers on the terminal output as well\n        (default: ``False`` = no line numbers).\n    \"\"\"\n    name = 'Terminal'\n    aliases = ['terminal', 'console']\n    filenames = []\n\n    def __init__(self, **options):\n        Formatter.__init__(self, **options)\n        self.darkbg = get_choice_opt(options, 'bg',\n                                     ['light', 'dark'], 'light') == 'dark'\n        self.colorscheme = options.get('colorscheme', None) or TERMINAL_COLORS\n        self.linenos = options.get('linenos', False)\n        self._lineno = 0\n\n    def format(self, tokensource, outfile):\n        return Formatter.format(self, tokensource, outfile)\n\n    def _write_lineno(self, outfile):\n        self._lineno += 1\n        outfile.write(\"%s%04d: \" % (self._lineno != 1 and '\\n' or '', self._lineno))\n\n    def _get_color(self, ttype):\n        # self.colorscheme is a dict containing usually generic types, so we\n        # have to walk the tree of dots.  The base Token type must be a key,\n        # even if it's empty string, as in the default above.\n        colors = self.colorscheme.get(ttype)\n        while colors is None:\n            ttype = ttype.parent\n            colors = self.colorscheme.get(ttype)\n        return colors[self.darkbg]\n\n    def format_unencoded(self, tokensource, outfile):\n        if self.linenos:\n            self._write_lineno(outfile)\n\n        for ttype, value in tokensource:\n            color = self._get_color(ttype)\n\n            for line in value.splitlines(True):\n                if color:\n                    outfile.write(ansiformat(color, line.rstrip('\\n')))\n                else:\n                    outfile.write(line.rstrip('\\n'))\n                if line.endswith('\\n'):\n                    if self.linenos:\n                        self._write_lineno(outfile)\n                    else:\n                        outfile.write('\\n')\n\n        if self.linenos:\n            outfile.write(\"\\n\")\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/pygments/formatters/terminal256.py","size":11753,"sha1":"00a971d9800dbf65bdb601b9aec51865bde90e8a","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\n    pygments.formatters.terminal256\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n    Formatter for 256-color terminal output with ANSI sequences.\n\n    RGB-to-XTERM color conversion routines adapted from xterm256-conv\n    tool (http://frexx.de/xterm-256-notes/data/xterm256-conv2.tar.bz2)\n    by Wolfgang Frisch.\n\n    Formatter version 1.\n\n    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\n# TODO:\n#  - Options to map style's bold/underline/italic/border attributes\n#    to some ANSI attrbutes (something like 'italic=underline')\n#  - An option to output \"style RGB to xterm RGB/index\" conversion table\n#  - An option to indicate that we are running in \"reverse background\"\n#    xterm. This means that default colors are white-on-black, not\n#    black-on-while, so colors like \"white background\" need to be converted\n#    to \"white background, black foreground\", etc...\n\nfrom pip._vendor.pygments.formatter import Formatter\nfrom pip._vendor.pygments.console import codes\nfrom pip._vendor.pygments.style import ansicolors\n\n\n__all__ = ['Terminal256Formatter', 'TerminalTrueColorFormatter']\n\n\nclass EscapeSequence:\n    def __init__(self, fg=None, bg=None, bold=False, underline=False, italic=False):\n        self.fg = fg\n        self.bg = bg\n        self.bold = bold\n        self.underline = underline\n        self.italic = italic\n\n    def escape(self, attrs):\n        if len(attrs):\n            return \"\\x1b[\" + \";\".join(attrs) + \"m\"\n        return \"\"\n\n    def color_string(self):\n        attrs = []\n        if self.fg is not None:\n            if self.fg in ansicolors:\n                esc = codes[self.fg.replace('ansi','')]\n                if ';01m' in esc:\n                    self.bold = True\n                # extract fg color code.\n                attrs.append(esc[2:4])\n            else:\n                attrs.extend((\"38\", \"5\", \"%i\" % self.fg))\n        if self.bg is not None:\n            if self.bg in ansicolors:\n                esc = codes[self.bg.replace('ansi','')]\n                # extract fg color code, add 10 for bg.\n                attrs.append(str(int(esc[2:4])+10))\n            else:\n                attrs.extend((\"48\", \"5\", \"%i\" % self.bg))\n        if self.bold:\n            attrs.append(\"01\")\n        if self.underline:\n            attrs.append(\"04\")\n        if self.italic:\n            attrs.append(\"03\")\n        return self.escape(attrs)\n\n    def true_color_string(self):\n        attrs = []\n        if self.fg:\n            attrs.extend((\"38\", \"2\", str(self.fg[0]), str(self.fg[1]), str(self.fg[2])))\n        if self.bg:\n            attrs.extend((\"48\", \"2\", str(self.bg[0]), str(self.bg[1]), str(self.bg[2])))\n        if self.bold:\n            attrs.append(\"01\")\n        if self.underline:\n            attrs.append(\"04\")\n        if self.italic:\n            attrs.append(\"03\")\n        return self.escape(attrs)\n\n    def reset_string(self):\n        attrs = []\n        if self.fg is not None:\n            attrs.append(\"39\")\n        if self.bg is not None:\n            attrs.append(\"49\")\n        if self.bold or self.underline or self.italic:\n            attrs.append(\"00\")\n        return self.escape(attrs)\n\n\nclass Terminal256Formatter(Formatter):\n    \"\"\"\n    Format tokens with ANSI color sequences, for output in a 256-color\n    terminal or console.  Like in `TerminalFormatter` color sequences\n    are terminated at newlines, so that paging the output works correctly.\n\n    The formatter takes colors from a style defined by the `style` option\n    and converts them to nearest ANSI 256-color escape sequences. Bold and\n    underline attributes from the style are preserved (and displayed).\n\n    .. versionadded:: 0.9\n\n    .. versionchanged:: 2.2\n       If the used style defines foreground colors in the form ``#ansi*``, then\n       `Terminal256Formatter` will map these to non extended foreground color.\n       See :ref:`AnsiTerminalStyle` for more information.\n\n    .. versionchanged:: 2.4\n       The ANSI color names have been updated with names that are easier to\n       understand and align with colornames of other projects and terminals.\n       See :ref:`this table <new-ansi-color-names>` for more information.\n\n\n    Options accepted:\n\n    `style`\n        The style to use, can be a string or a Style subclass (default:\n        ``'default'``).\n\n    `linenos`\n        Set to ``True`` to have line numbers on the terminal output as well\n        (default: ``False`` = no line numbers).\n    \"\"\"\n    name = 'Terminal256'\n    aliases = ['terminal256', 'console256', '256']\n    filenames = []\n\n    def __init__(self, **options):\n        Formatter.__init__(self, **options)\n\n        self.xterm_colors = []\n        self.best_match = {}\n        self.style_string = {}\n\n        self.usebold = 'nobold' not in options\n        self.useunderline = 'nounderline' not in options\n        self.useitalic = 'noitalic' not in options\n\n        self._build_color_table()  # build an RGB-to-256 color conversion table\n        self._setup_styles()  # convert selected style's colors to term. colors\n\n        self.linenos = options.get('linenos', False)\n        self._lineno = 0\n\n    def _build_color_table(self):\n        # colors 0..15: 16 basic colors\n\n        self.xterm_colors.append((0x00, 0x00, 0x00))  # 0\n        self.xterm_colors.append((0xcd, 0x00, 0x00))  # 1\n        self.xterm_colors.append((0x00, 0xcd, 0x00))  # 2\n        self.xterm_colors.append((0xcd, 0xcd, 0x00))  # 3\n        self.xterm_colors.append((0x00, 0x00, 0xee))  # 4\n        self.xterm_colors.append((0xcd, 0x00, 0xcd))  # 5\n        self.xterm_colors.append((0x00, 0xcd, 0xcd))  # 6\n        self.xterm_colors.append((0xe5, 0xe5, 0xe5))  # 7\n        self.xterm_colors.append((0x7f, 0x7f, 0x7f))  # 8\n        self.xterm_colors.append((0xff, 0x00, 0x00))  # 9\n        self.xterm_colors.append((0x00, 0xff, 0x00))  # 10\n        self.xterm_colors.append((0xff, 0xff, 0x00))  # 11\n        self.xterm_colors.append((0x5c, 0x5c, 0xff))  # 12\n        self.xterm_colors.append((0xff, 0x00, 0xff))  # 13\n        self.xterm_colors.append((0x00, 0xff, 0xff))  # 14\n        self.xterm_colors.append((0xff, 0xff, 0xff))  # 15\n\n        # colors 16..232: the 6x6x6 color cube\n\n        valuerange = (0x00, 0x5f, 0x87, 0xaf, 0xd7, 0xff)\n\n        for i in range(217):\n            r = valuerange[(i // 36) % 6]\n            g = valuerange[(i // 6) % 6]\n            b = valuerange[i % 6]\n            self.xterm_colors.append((r, g, b))\n\n        # colors 233..253: grayscale\n\n        for i in range(1, 22):\n            v = 8 + i * 10\n            self.xterm_colors.append((v, v, v))\n\n    def _closest_color(self, r, g, b):\n        distance = 257*257*3  # \"infinity\" (>distance from #000000 to #ffffff)\n        match = 0\n\n        for i in range(0, 254):\n            values = self.xterm_colors[i]\n\n            rd = r - values[0]\n            gd = g - values[1]\n            bd = b - values[2]\n            d = rd*rd + gd*gd + bd*bd\n\n            if d < distance:\n                match = i\n                distance = d\n        return match\n\n    def _color_index(self, color):\n        index = self.best_match.get(color, None)\n        if color in ansicolors:\n            # strip the `ansi/#ansi` part and look up code\n            index = color\n            self.best_match[color] = index\n        if index is None:\n            try:\n                rgb = int(str(color), 16)\n            except ValueError:\n                rgb = 0\n\n            r = (rgb >> 16) & 0xff\n            g = (rgb >> 8) & 0xff\n            b = rgb & 0xff\n            index = self._closest_color(r, g, b)\n            self.best_match[color] = index\n        return index\n\n    def _setup_styles(self):\n        for ttype, ndef in self.style:\n            escape = EscapeSequence()\n            # get foreground from ansicolor if set\n            if ndef['ansicolor']:\n                escape.fg = self._color_index(ndef['ansicolor'])\n            elif ndef['color']:\n                escape.fg = self._color_index(ndef['color'])\n            if ndef['bgansicolor']:\n                escape.bg = self._color_index(ndef['bgansicolor'])\n            elif ndef['bgcolor']:\n                escape.bg = self._color_index(ndef['bgcolor'])\n            if self.usebold and ndef['bold']:\n                escape.bold = True\n            if self.useunderline and ndef['underline']:\n                escape.underline = True\n            if self.useitalic and ndef['italic']:\n                escape.italic = True\n            self.style_string[str(ttype)] = (escape.color_string(),\n                                             escape.reset_string())\n\n    def _write_lineno(self, outfile):\n        self._lineno += 1\n        outfile.write(\"%s%04d: \" % (self._lineno != 1 and '\\n' or '', self._lineno))\n\n    def format(self, tokensource, outfile):\n        return Formatter.format(self, tokensource, outfile)\n\n    def format_unencoded(self, tokensource, outfile):\n        if self.linenos:\n            self._write_lineno(outfile)\n\n        for ttype, value in tokensource:\n            not_found = True\n            while ttype and not_found:\n                try:\n                    # outfile.write( \"<\" + str(ttype) + \">\" )\n                    on, off = self.style_string[str(ttype)]\n\n                    # Like TerminalFormatter, add \"reset colors\" escape sequence\n                    # on newline.\n                    spl = value.split('\\n')\n                    for line in spl[:-1]:\n                        if line:\n                            outfile.write(on + line + off)\n                        if self.linenos:\n                            self._write_lineno(outfile)\n                        else:\n                            outfile.write('\\n')\n\n                    if spl[-1]:\n                        outfile.write(on + spl[-1] + off)\n\n                    not_found = False\n                    # outfile.write( '#' + str(ttype) + '#' )\n\n                except KeyError:\n                    # ottype = ttype\n                    ttype = ttype.parent\n                    # outfile.write( '!' + str(ottype) + '->' + str(ttype) + '!' )\n\n            if not_found:\n                outfile.write(value)\n\n        if self.linenos:\n            outfile.write(\"\\n\")\n\n\n\nclass TerminalTrueColorFormatter(Terminal256Formatter):\n    r\"\"\"\n    Format tokens with ANSI color sequences, for output in a true-color\n    terminal or console.  Like in `TerminalFormatter` color sequences\n    are terminated at newlines, so that paging the output works correctly.\n\n    .. versionadded:: 2.1\n\n    Options accepted:\n\n    `style`\n        The style to use, can be a string or a Style subclass (default:\n        ``'default'``).\n    \"\"\"\n    name = 'TerminalTrueColor'\n    aliases = ['terminal16m', 'console16m', '16m']\n    filenames = []\n\n    def _build_color_table(self):\n        pass\n\n    def _color_tuple(self, color):\n        try:\n            rgb = int(str(color), 16)\n        except ValueError:\n            return None\n        r = (rgb >> 16) & 0xff\n        g = (rgb >> 8) & 0xff\n        b = rgb & 0xff\n        return (r, g, b)\n\n    def _setup_styles(self):\n        for ttype, ndef in self.style:\n            escape = EscapeSequence()\n            if ndef['color']:\n                escape.fg = self._color_tuple(ndef['color'])\n            if ndef['bgcolor']:\n                escape.bg = self._color_tuple(ndef['bgcolor'])\n            if self.usebold and ndef['bold']:\n                escape.bold = True\n            if self.useunderline and ndef['underline']:\n                escape.underline = True\n            if self.useitalic and ndef['italic']:\n                escape.italic = True\n            self.style_string[str(ttype)] = (escape.true_color_string(),\n                                             escape.reset_string())\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/pygments/lexer.py","size":35349,"sha1":"b1042e9d5c476a7b1bbde0c436dd15c874aeeafd","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\n    pygments.lexer\n    ~~~~~~~~~~~~~~\n\n    Base lexer classes.\n\n    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nimport re\nimport sys\nimport time\n\nfrom pip._vendor.pygments.filter import apply_filters, Filter\nfrom pip._vendor.pygments.filters import get_filter_by_name\nfrom pip._vendor.pygments.token import Error, Text, Other, Whitespace, _TokenType\nfrom pip._vendor.pygments.util import get_bool_opt, get_int_opt, get_list_opt, \\\n    make_analysator, Future, guess_decode\nfrom pip._vendor.pygments.regexopt import regex_opt\n\n__all__ = ['Lexer', 'RegexLexer', 'ExtendedRegexLexer', 'DelegatingLexer',\n           'LexerContext', 'include', 'inherit', 'bygroups', 'using', 'this',\n           'default', 'words', 'line_re']\n\nline_re = re.compile('.*?\\n')\n\n_encoding_map = [(b'\\xef\\xbb\\xbf', 'utf-8'),\n                 (b'\\xff\\xfe\\0\\0', 'utf-32'),\n                 (b'\\0\\0\\xfe\\xff', 'utf-32be'),\n                 (b'\\xff\\xfe', 'utf-16'),\n                 (b'\\xfe\\xff', 'utf-16be')]\n\n_default_analyse = staticmethod(lambda x: 0.0)\n\n\nclass LexerMeta(type):\n    \"\"\"\n    This metaclass automagically converts ``analyse_text`` methods into\n    static methods which always return float values.\n    \"\"\"\n\n    def __new__(mcs, name, bases, d):\n        if 'analyse_text' in d:\n            d['analyse_text'] = make_analysator(d['analyse_text'])\n        return type.__new__(mcs, name, bases, d)\n\n\nclass Lexer(metaclass=LexerMeta):\n    \"\"\"\n    Lexer for a specific language.\n\n    See also :doc:`lexerdevelopment`, a high-level guide to writing\n    lexers.\n\n    Lexer classes have attributes used for choosing the most appropriate\n    lexer based on various criteria.\n\n    .. autoattribute:: name\n       :no-value:\n    .. autoattribute:: aliases\n       :no-value:\n    .. autoattribute:: filenames\n       :no-value:\n    .. autoattribute:: alias_filenames\n    .. autoattribute:: mimetypes\n       :no-value:\n    .. autoattribute:: priority\n\n    Lexers included in Pygments should have two additional attributes:\n\n    .. autoattribute:: url\n       :no-value:\n    .. autoattribute:: version_added\n       :no-value:\n\n    Lexers included in Pygments may have additional attributes:\n\n    .. autoattribute:: _example\n       :no-value:\n\n    You can pass options to the constructor. The basic options recognized\n    by all lexers and processed by the base `Lexer` class are:\n\n    ``stripnl``\n        Strip leading and trailing newlines from the input (default: True).\n    ``stripall``\n        Strip all leading and trailing whitespace from the input\n        (default: False).\n    ``ensurenl``\n        Make sure that the input ends with a newline (default: True).  This\n        is required for some lexers that consume input linewise.\n\n        .. versionadded:: 1.3\n\n    ``tabsize``\n        If given and greater than 0, expand tabs in the input (default: 0).\n    ``encoding``\n        If given, must be an encoding name. This encoding will be used to\n        convert the input string to Unicode, if it is not already a Unicode\n        string (default: ``'guess'``, which uses a simple UTF-8 / Locale /\n        Latin1 detection.  Can also be ``'chardet'`` to use the chardet\n        library, if it is installed.\n    ``inencoding``\n        Overrides the ``encoding`` if given.\n    \"\"\"\n\n    #: Full name of the lexer, in human-readable form\n    name = None\n\n    #: A list of short, unique identifiers that can be used to look\n    #: up the lexer from a list, e.g., using `get_lexer_by_name()`.\n    aliases = []\n\n    #: A list of `fnmatch` patterns that match filenames which contain\n    #: content for this lexer. The patterns in this list should be unique among\n    #: all lexers.\n    filenames = []\n\n    #: A list of `fnmatch` patterns that match filenames which may or may not\n    #: contain content for this lexer. This list is used by the\n    #: :func:`.guess_lexer_for_filename()` function, to determine which lexers\n    #: are then included in guessing the correct one. That means that\n    #: e.g. every lexer for HTML and a template language should include\n    #: ``\\*.html`` in this list.\n    alias_filenames = []\n\n    #: A list of MIME types for content that can be lexed with this lexer.\n    mimetypes = []\n\n    #: Priority, should multiple lexers match and no content is provided\n    priority = 0\n\n    #: URL of the language specification/definition. Used in the Pygments\n    #: documentation. Set to an empty string to disable.\n    url = None\n\n    #: Version of Pygments in which the lexer was added.\n    version_added = None\n\n    #: Example file name. Relative to the ``tests/examplefiles`` directory.\n    #: This is used by the documentation generator to show an example.\n    _example = None\n\n    def __init__(self, **options):\n        \"\"\"\n        This constructor takes arbitrary options as keyword arguments.\n        Every subclass must first process its own options and then call\n        the `Lexer` constructor, since it processes the basic\n        options like `stripnl`.\n\n        An example looks like this:\n\n        .. sourcecode:: python\n\n           def __init__(self, **options):\n               self.compress = options.get('compress', '')\n               Lexer.__init__(self, **options)\n\n        As these options must all be specifiable as strings (due to the\n        command line usage), there are various utility functions\n        available to help with that, see `Utilities`_.\n        \"\"\"\n        self.options = options\n        self.stripnl = get_bool_opt(options, 'stripnl', True)\n        self.stripall = get_bool_opt(options, 'stripall', False)\n        self.ensurenl = get_bool_opt(options, 'ensurenl', True)\n        self.tabsize = get_int_opt(options, 'tabsize', 0)\n        self.encoding = options.get('encoding', 'guess')\n        self.encoding = options.get('inencoding') or self.encoding\n        self.filters = []\n        for filter_ in get_list_opt(options, 'filters', ()):\n            self.add_filter(filter_)\n\n    def __repr__(self):\n        if self.options:\n            return f'<pygments.lexers.{self.__class__.__name__} with {self.options!r}>'\n        else:\n            return f'<pygments.lexers.{self.__class__.__name__}>'\n\n    def add_filter(self, filter_, **options):\n        \"\"\"\n        Add a new stream filter to this lexer.\n        \"\"\"\n        if not isinstance(filter_, Filter):\n            filter_ = get_filter_by_name(filter_, **options)\n        self.filters.append(filter_)\n\n    def analyse_text(text):\n        \"\"\"\n        A static method which is called for lexer guessing.\n\n        It should analyse the text and return a float in the range\n        from ``0.0`` to ``1.0``.  If it returns ``0.0``, the lexer\n        will not be selected as the most probable one, if it returns\n        ``1.0``, it will be selected immediately.  This is used by\n        `guess_lexer`.\n\n        The `LexerMeta` metaclass automatically wraps this function so\n        that it works like a static method (no ``self`` or ``cls``\n        parameter) and the return value is automatically converted to\n        `float`. If the return value is an object that is boolean `False`\n        it's the same as if the return values was ``0.0``.\n        \"\"\"\n\n    def _preprocess_lexer_input(self, text):\n        \"\"\"Apply preprocessing such as decoding the input, removing BOM and normalizing newlines.\"\"\"\n\n        if not isinstance(text, str):\n            if self.encoding == 'guess':\n                text, _ = guess_decode(text)\n            elif self.encoding == 'chardet':\n                try:\n                    # pip vendoring note: this code is not reachable by pip,\n                    # removed import of chardet to make it clear.\n                    raise ImportError('chardet is not vendored by pip')\n                except ImportError as e:\n                    raise ImportError('To enable chardet encoding guessing, '\n                                      'please install the chardet library '\n                                      'from http://chardet.feedparser.org/') from e\n                # check for BOM first\n                decoded = None\n                for bom, encoding in _encoding_map:\n                    if text.startswith(bom):\n                        decoded = text[len(bom):].decode(encoding, 'replace')\n                        break\n                # no BOM found, so use chardet\n                if decoded is None:\n                    enc = chardet.detect(text[:1024])  # Guess using first 1KB\n                    decoded = text.decode(enc.get('encoding') or 'utf-8',\n                                          'replace')\n                text = decoded\n            else:\n                text = text.decode(self.encoding)\n                if text.startswith('\\ufeff'):\n                    text = text[len('\\ufeff'):]\n        else:\n            if text.startswith('\\ufeff'):\n                text = text[len('\\ufeff'):]\n\n        # text now *is* a unicode string\n        text = text.replace('\\r\\n', '\\n')\n        text = text.replace('\\r', '\\n')\n        if self.stripall:\n            text = text.strip()\n        elif self.stripnl:\n            text = text.strip('\\n')\n        if self.tabsize > 0:\n            text = text.expandtabs(self.tabsize)\n        if self.ensurenl and not text.endswith('\\n'):\n            text += '\\n'\n\n        return text\n\n    def get_tokens(self, text, unfiltered=False):\n        \"\"\"\n        This method is the basic interface of a lexer. It is called by\n        the `highlight()` function. It must process the text and return an\n        iterable of ``(tokentype, value)`` pairs from `text`.\n\n        Normally, you don't need to override this method. The default\n        implementation processes the options recognized by all lexers\n        (`stripnl`, `stripall` and so on), and then yields all tokens\n        from `get_tokens_unprocessed()`, with the ``index`` dropped.\n\n        If `unfiltered` is set to `True`, the filtering mechanism is\n        bypassed even if filters are defined.\n        \"\"\"\n        text = self._preprocess_lexer_input(text)\n\n        def streamer():\n            for _, t, v in self.get_tokens_unprocessed(text):\n                yield t, v\n        stream = streamer()\n        if not unfiltered:\n            stream = apply_filters(stream, self.filters, self)\n        return stream\n\n    def get_tokens_unprocessed(self, text):\n        \"\"\"\n        This method should process the text and return an iterable of\n        ``(index, tokentype, value)`` tuples where ``index`` is the starting\n        position of the token within the input text.\n\n        It must be overridden by subclasses. It is recommended to\n        implement it as a generator to maximize effectiveness.\n        \"\"\"\n        raise NotImplementedError\n\n\nclass DelegatingLexer(Lexer):\n    \"\"\"\n    This lexer takes two lexer as arguments. A root lexer and\n    a language lexer. First everything is scanned using the language\n    lexer, afterwards all ``Other`` tokens are lexed using the root\n    lexer.\n\n    The lexers from the ``template`` lexer package use this base lexer.\n    \"\"\"\n\n    def __init__(self, _root_lexer, _language_lexer, _needle=Other, **options):\n        self.root_lexer = _root_lexer(**options)\n        self.language_lexer = _language_lexer(**options)\n        self.needle = _needle\n        Lexer.__init__(self, **options)\n\n    def get_tokens_unprocessed(self, text):\n        buffered = ''\n        insertions = []\n        lng_buffer = []\n        for i, t, v in self.language_lexer.get_tokens_unprocessed(text):\n            if t is self.needle:\n                if lng_buffer:\n                    insertions.append((len(buffered), lng_buffer))\n                    lng_buffer = []\n                buffered += v\n            else:\n                lng_buffer.append((i, t, v))\n        if lng_buffer:\n            insertions.append((len(buffered), lng_buffer))\n        return do_insertions(insertions,\n                             self.root_lexer.get_tokens_unprocessed(buffered))\n\n\n# ------------------------------------------------------------------------------\n# RegexLexer and ExtendedRegexLexer\n#\n\n\nclass include(str):  # pylint: disable=invalid-name\n    \"\"\"\n    Indicates that a state should include rules from another state.\n    \"\"\"\n    pass\n\n\nclass _inherit:\n    \"\"\"\n    Indicates the a state should inherit from its superclass.\n    \"\"\"\n    def __repr__(self):\n        return 'inherit'\n\ninherit = _inherit()  # pylint: disable=invalid-name\n\n\nclass combined(tuple):  # pylint: disable=invalid-name\n    \"\"\"\n    Indicates a state combined from multiple states.\n    \"\"\"\n\n    def __new__(cls, *args):\n        return tuple.__new__(cls, args)\n\n    def __init__(self, *args):\n        # tuple.__init__ doesn't do anything\n        pass\n\n\nclass _PseudoMatch:\n    \"\"\"\n    A pseudo match object constructed from a string.\n    \"\"\"\n\n    def __init__(self, start, text):\n        self._text = text\n        self._start = start\n\n    def start(self, arg=None):\n        return self._start\n\n    def end(self, arg=None):\n        return self._start + len(self._text)\n\n    def group(self, arg=None):\n        if arg:\n            raise IndexError('No such group')\n        return self._text\n\n    def groups(self):\n        return (self._text,)\n\n    def groupdict(self):\n        return {}\n\n\ndef bygroups(*args):\n    \"\"\"\n    Callback that yields multiple actions for each group in the match.\n    \"\"\"\n    def callback(lexer, match, ctx=None):\n        for i, action in enumerate(args):\n            if action is None:\n                continue\n            elif type(action) is _TokenType:\n                data = match.group(i + 1)\n                if data:\n                    yield match.start(i + 1), action, data\n            else:\n                data = match.group(i + 1)\n                if data is not None:\n                    if ctx:\n                        ctx.pos = match.start(i + 1)\n                    for item in action(lexer,\n                                       _PseudoMatch(match.start(i + 1), data), ctx):\n                        if item:\n                            yield item\n        if ctx:\n            ctx.pos = match.end()\n    return callback\n\n\nclass _This:\n    \"\"\"\n    Special singleton used for indicating the caller class.\n    Used by ``using``.\n    \"\"\"\n\nthis = _This()\n\n\ndef using(_other, **kwargs):\n    \"\"\"\n    Callback that processes the match with a different lexer.\n\n    The keyword arguments are forwarded to the lexer, except `state` which\n    is handled separately.\n\n    `state` specifies the state that the new lexer will start in, and can\n    be an enumerable such as ('root', 'inline', 'string') or a simple\n    string which is assumed to be on top of the root state.\n\n    Note: For that to work, `_other` must not be an `ExtendedRegexLexer`.\n    \"\"\"\n    gt_kwargs = {}\n    if 'state' in kwargs:\n        s = kwargs.pop('state')\n        if isinstance(s, (list, tuple)):\n            gt_kwargs['stack'] = s\n        else:\n            gt_kwargs['stack'] = ('root', s)\n\n    if _other is this:\n        def callback(lexer, match, ctx=None):\n            # if keyword arguments are given the callback\n            # function has to create a new lexer instance\n            if kwargs:\n                # XXX: cache that somehow\n                kwargs.update(lexer.options)\n                lx = lexer.__class__(**kwargs)\n            else:\n                lx = lexer\n            s = match.start()\n            for i, t, v in lx.get_tokens_unprocessed(match.group(), **gt_kwargs):\n                yield i + s, t, v\n            if ctx:\n                ctx.pos = match.end()\n    else:\n        def callback(lexer, match, ctx=None):\n            # XXX: cache that somehow\n            kwargs.update(lexer.options)\n            lx = _other(**kwargs)\n\n            s = match.start()\n            for i, t, v in lx.get_tokens_unprocessed(match.group(), **gt_kwargs):\n                yield i + s, t, v\n            if ctx:\n                ctx.pos = match.end()\n    return callback\n\n\nclass default:\n    \"\"\"\n    Indicates a state or state action (e.g. #pop) to apply.\n    For example default('#pop') is equivalent to ('', Token, '#pop')\n    Note that state tuples may be used as well.\n\n    .. versionadded:: 2.0\n    \"\"\"\n    def __init__(self, state):\n        self.state = state\n\n\nclass words(Future):\n    \"\"\"\n    Indicates a list of literal words that is transformed into an optimized\n    regex that matches any of the words.\n\n    .. versionadded:: 2.0\n    \"\"\"\n    def __init__(self, words, prefix='', suffix=''):\n        self.words = words\n        self.prefix = prefix\n        self.suffix = suffix\n\n    def get(self):\n        return regex_opt(self.words, prefix=self.prefix, suffix=self.suffix)\n\n\nclass RegexLexerMeta(LexerMeta):\n    \"\"\"\n    Metaclass for RegexLexer, creates the self._tokens attribute from\n    self.tokens on the first instantiation.\n    \"\"\"\n\n    def _process_regex(cls, regex, rflags, state):\n        \"\"\"Preprocess the regular expression component of a token definition.\"\"\"\n        if isinstance(regex, Future):\n            regex = regex.get()\n        return re.compile(regex, rflags).match\n\n    def _process_token(cls, token):\n        \"\"\"Preprocess the token component of a token definition.\"\"\"\n        assert type(token) is _TokenType or callable(token), \\\n            f'token type must be simple type or callable, not {token!r}'\n        return token\n\n    def _process_new_state(cls, new_state, unprocessed, processed):\n        \"\"\"Preprocess the state transition action of a token definition.\"\"\"\n        if isinstance(new_state, str):\n            # an existing state\n            if new_state == '#pop':\n                return -1\n            elif new_state in unprocessed:\n                return (new_state,)\n            elif new_state == '#push':\n                return new_state\n            elif new_state[:5] == '#pop:':\n                return -int(new_state[5:])\n            else:\n                assert False, f'unknown new state {new_state!r}'\n        elif isinstance(new_state, combined):\n            # combine a new state from existing ones\n            tmp_state = '_tmp_%d' % cls._tmpname\n            cls._tmpname += 1\n            itokens = []\n            for istate in new_state:\n                assert istate != new_state, f'circular state ref {istate!r}'\n                itokens.extend(cls._process_state(unprocessed,\n                                                  processed, istate))\n            processed[tmp_state] = itokens\n            return (tmp_state,)\n        elif isinstance(new_state, tuple):\n            # push more than one state\n            for istate in new_state:\n                assert (istate in unprocessed or\n                        istate in ('#pop', '#push')), \\\n                    'unknown new state ' + istate\n            return new_state\n        else:\n            assert False, f'unknown new state def {new_state!r}'\n\n    def _process_state(cls, unprocessed, processed, state):\n        \"\"\"Preprocess a single state definition.\"\"\"\n        assert isinstance(state, str), f\"wrong state name {state!r}\"\n        assert state[0] != '#', f\"invalid state name {state!r}\"\n        if state in processed:\n            return processed[state]\n        tokens = processed[state] = []\n        rflags = cls.flags\n        for tdef in unprocessed[state]:\n            if isinstance(tdef, include):\n                # it's a state reference\n                assert tdef != state, f\"circular state reference {state!r}\"\n                tokens.extend(cls._process_state(unprocessed, processed,\n                                                 str(tdef)))\n                continue\n            if isinstance(tdef, _inherit):\n                # should be processed already, but may not in the case of:\n                # 1. the state has no counterpart in any parent\n                # 2. the state includes more than one 'inherit'\n                continue\n            if isinstance(tdef, default):\n                new_state = cls._process_new_state(tdef.state, unprocessed, processed)\n                tokens.append((re.compile('').match, None, new_state))\n                continue\n\n            assert type(tdef) is tuple, f\"wrong rule def {tdef!r}\"\n\n            try:\n                rex = cls._process_regex(tdef[0], rflags, state)\n            except Exception as err:\n                raise ValueError(f\"uncompilable regex {tdef[0]!r} in state {state!r} of {cls!r}: {err}\") from err\n\n            token = cls._process_token(tdef[1])\n\n            if len(tdef) == 2:\n                new_state = None\n            else:\n                new_state = cls._process_new_state(tdef[2],\n                                                   unprocessed, processed)\n\n            tokens.append((rex, token, new_state))\n        return tokens\n\n    def process_tokendef(cls, name, tokendefs=None):\n        \"\"\"Preprocess a dictionary of token definitions.\"\"\"\n        processed = cls._all_tokens[name] = {}\n        tokendefs = tokendefs or cls.tokens[name]\n        for state in list(tokendefs):\n            cls._process_state(tokendefs, processed, state)\n        return processed\n\n    def get_tokendefs(cls):\n        \"\"\"\n        Merge tokens from superclasses in MRO order, returning a single tokendef\n        dictionary.\n\n        Any state that is not defined by a subclass will be inherited\n        automatically.  States that *are* defined by subclasses will, by\n        default, override that state in the superclass.  If a subclass wishes to\n        inherit definitions from a superclass, it can use the special value\n        \"inherit\", which will cause the superclass' state definition to be\n        included at that point in the state.\n        \"\"\"\n        tokens = {}\n        inheritable = {}\n        for c in cls.__mro__:\n            toks = c.__dict__.get('tokens', {})\n\n            for state, items in toks.items():\n                curitems = tokens.get(state)\n                if curitems is None:\n                    # N.b. because this is assigned by reference, sufficiently\n                    # deep hierarchies are processed incrementally (e.g. for\n                    # A(B), B(C), C(RegexLexer), B will be premodified so X(B)\n                    # will not see any inherits in B).\n                    tokens[state] = items\n                    try:\n                        inherit_ndx = items.index(inherit)\n                    except ValueError:\n                        continue\n                    inheritable[state] = inherit_ndx\n                    continue\n\n                inherit_ndx = inheritable.pop(state, None)\n                if inherit_ndx is None:\n                    continue\n\n                # Replace the \"inherit\" value with the items\n                curitems[inherit_ndx:inherit_ndx+1] = items\n                try:\n                    # N.b. this is the index in items (that is, the superclass\n                    # copy), so offset required when storing below.\n                    new_inh_ndx = items.index(inherit)\n                except ValueError:\n                    pass\n                else:\n                    inheritable[state] = inherit_ndx + new_inh_ndx\n\n        return tokens\n\n    def __call__(cls, *args, **kwds):\n        \"\"\"Instantiate cls after preprocessing its token definitions.\"\"\"\n        if '_tokens' not in cls.__dict__:\n            cls._all_tokens = {}\n            cls._tmpname = 0\n            if hasattr(cls, 'token_variants') and cls.token_variants:\n                # don't process yet\n                pass\n            else:\n                cls._tokens = cls.process_tokendef('', cls.get_tokendefs())\n\n        return type.__call__(cls, *args, **kwds)\n\n\nclass RegexLexer(Lexer, metaclass=RegexLexerMeta):\n    \"\"\"\n    Base for simple stateful regular expression-based lexers.\n    Simplifies the lexing process so that you need only\n    provide a list of states and regular expressions.\n    \"\"\"\n\n    #: Flags for compiling the regular expressions.\n    #: Defaults to MULTILINE.\n    flags = re.MULTILINE\n\n    #: At all time there is a stack of states. Initially, the stack contains\n    #: a single state 'root'. The top of the stack is called \"the current state\".\n    #:\n    #: Dict of ``{'state': [(regex, tokentype, new_state), ...], ...}``\n    #:\n    #: ``new_state`` can be omitted to signify no state transition.\n    #: If ``new_state`` is a string, it is pushed on the stack. This ensure\n    #: the new current state is ``new_state``.\n    #: If ``new_state`` is a tuple of strings, all of those strings are pushed\n    #: on the stack and the current state will be the last element of the list.\n    #: ``new_state`` can also be ``combined('state1', 'state2', ...)``\n    #: to signify a new, anonymous state combined from the rules of two\n    #: or more existing ones.\n    #: Furthermore, it can be '#pop' to signify going back one step in\n    #: the state stack, or '#push' to push the current state on the stack\n    #: again. Note that if you push while in a combined state, the combined\n    #: state itself is pushed, and not only the state in which the rule is\n    #: defined.\n    #:\n    #: The tuple can also be replaced with ``include('state')``, in which\n    #: case the rules from the state named by the string are included in the\n    #: current one.\n    tokens = {}\n\n    def get_tokens_unprocessed(self, text, stack=('root',)):\n        \"\"\"\n        Split ``text`` into (tokentype, text) pairs.\n\n        ``stack`` is the initial stack (default: ``['root']``)\n        \"\"\"\n        pos = 0\n        tokendefs = self._tokens\n        statestack = list(stack)\n        statetokens = tokendefs[statestack[-1]]\n        while 1:\n            for rexmatch, action, new_state in statetokens:\n                m = rexmatch(text, pos)\n                if m:\n                    if action is not None:\n                        if type(action) is _TokenType:\n                            yield pos, action, m.group()\n                        else:\n                            yield from action(self, m)\n                    pos = m.end()\n                    if new_state is not None:\n                        # state transition\n                        if isinstance(new_state, tuple):\n                            for state in new_state:\n                                if state == '#pop':\n                                    if len(statestack) > 1:\n                                        statestack.pop()\n                                elif state == '#push':\n                                    statestack.append(statestack[-1])\n                                else:\n                                    statestack.append(state)\n                        elif isinstance(new_state, int):\n                            # pop, but keep at least one state on the stack\n                            # (random code leading to unexpected pops should\n                            # not allow exceptions)\n                            if abs(new_state) >= len(statestack):\n                                del statestack[1:]\n                            else:\n                                del statestack[new_state:]\n                        elif new_state == '#push':\n                            statestack.append(statestack[-1])\n                        else:\n                            assert False, f\"wrong state def: {new_state!r}\"\n                        statetokens = tokendefs[statestack[-1]]\n                    break\n            else:\n                # We are here only if all state tokens have been considered\n                # and there was not a match on any of them.\n                try:\n                    if text[pos] == '\\n':\n                        # at EOL, reset state to \"root\"\n                        statestack = ['root']\n                        statetokens = tokendefs['root']\n                        yield pos, Whitespace, '\\n'\n                        pos += 1\n                        continue\n                    yield pos, Error, text[pos]\n                    pos += 1\n                except IndexError:\n                    break\n\n\nclass LexerContext:\n    \"\"\"\n    A helper object that holds lexer position data.\n    \"\"\"\n\n    def __init__(self, text, pos, stack=None, end=None):\n        self.text = text\n        self.pos = pos\n        self.end = end or len(text)  # end=0 not supported ;-)\n        self.stack = stack or ['root']\n\n    def __repr__(self):\n        return f'LexerContext({self.text!r}, {self.pos!r}, {self.stack!r})'\n\n\nclass ExtendedRegexLexer(RegexLexer):\n    \"\"\"\n    A RegexLexer that uses a context object to store its state.\n    \"\"\"\n\n    def get_tokens_unprocessed(self, text=None, context=None):\n        \"\"\"\n        Split ``text`` into (tokentype, text) pairs.\n        If ``context`` is given, use this lexer context instead.\n        \"\"\"\n        tokendefs = self._tokens\n        if not context:\n            ctx = LexerContext(text, 0)\n            statetokens = tokendefs['root']\n        else:\n            ctx = context\n            statetokens = tokendefs[ctx.stack[-1]]\n            text = ctx.text\n        while 1:\n            for rexmatch, action, new_state in statetokens:\n                m = rexmatch(text, ctx.pos, ctx.end)\n                if m:\n                    if action is not None:\n                        if type(action) is _TokenType:\n                            yield ctx.pos, action, m.group()\n                            ctx.pos = m.end()\n                        else:\n                            yield from action(self, m, ctx)\n                            if not new_state:\n                                # altered the state stack?\n                                statetokens = tokendefs[ctx.stack[-1]]\n                    # CAUTION: callback must set ctx.pos!\n                    if new_state is not None:\n                        # state transition\n                        if isinstance(new_state, tuple):\n                            for state in new_state:\n                                if state == '#pop':\n                                    if len(ctx.stack) > 1:\n                                        ctx.stack.pop()\n                                elif state == '#push':\n                                    ctx.stack.append(ctx.stack[-1])\n                                else:\n                                    ctx.stack.append(state)\n                        elif isinstance(new_state, int):\n                            # see RegexLexer for why this check is made\n                            if abs(new_state) >= len(ctx.stack):\n                                del ctx.stack[1:]\n                            else:\n                                del ctx.stack[new_state:]\n                        elif new_state == '#push':\n                            ctx.stack.append(ctx.stack[-1])\n                        else:\n                            assert False, f\"wrong state def: {new_state!r}\"\n                        statetokens = tokendefs[ctx.stack[-1]]\n                    break\n            else:\n                try:\n                    if ctx.pos >= ctx.end:\n                        break\n                    if text[ctx.pos] == '\\n':\n                        # at EOL, reset state to \"root\"\n                        ctx.stack = ['root']\n                        statetokens = tokendefs['root']\n                        yield ctx.pos, Text, '\\n'\n                        ctx.pos += 1\n                        continue\n                    yield ctx.pos, Error, text[ctx.pos]\n                    ctx.pos += 1\n                except IndexError:\n                    break\n\n\ndef do_insertions(insertions, tokens):\n    \"\"\"\n    Helper for lexers which must combine the results of several\n    sublexers.\n\n    ``insertions`` is a list of ``(index, itokens)`` pairs.\n    Each ``itokens`` iterable should be inserted at position\n    ``index`` into the token stream given by the ``tokens``\n    argument.\n\n    The result is a combined token stream.\n\n    TODO: clean up the code here.\n    \"\"\"\n    insertions = iter(insertions)\n    try:\n        index, itokens = next(insertions)\n    except StopIteration:\n        # no insertions\n        yield from tokens\n        return\n\n    realpos = None\n    insleft = True\n\n    # iterate over the token stream where we want to insert\n    # the tokens from the insertion list.\n    for i, t, v in tokens:\n        # first iteration. store the position of first item\n        if realpos is None:\n            realpos = i\n        oldi = 0\n        while insleft and i + len(v) >= index:\n            tmpval = v[oldi:index - i]\n            if tmpval:\n                yield realpos, t, tmpval\n                realpos += len(tmpval)\n            for it_index, it_token, it_value in itokens:\n                yield realpos, it_token, it_value\n                realpos += len(it_value)\n            oldi = index - i\n            try:\n                index, itokens = next(insertions)\n            except StopIteration:\n                insleft = False\n                break  # not strictly necessary\n        if oldi < len(v):\n            yield realpos, t, v[oldi:]\n            realpos += len(v) - oldi\n\n    # leftover tokens\n    while insleft:\n        # no normal tokens, set realpos to zero\n        realpos = realpos or 0\n        for p, t, v in itokens:\n            yield realpos, t, v\n            realpos += len(v)\n        try:\n            index, itokens = next(insertions)\n        except StopIteration:\n            insleft = False\n            break  # not strictly necessary\n\n\nclass ProfilingRegexLexerMeta(RegexLexerMeta):\n    \"\"\"Metaclass for ProfilingRegexLexer, collects regex timing info.\"\"\"\n\n    def _process_regex(cls, regex, rflags, state):\n        if isinstance(regex, words):\n            rex = regex_opt(regex.words, prefix=regex.prefix,\n                            suffix=regex.suffix)\n        else:\n            rex = regex\n        compiled = re.compile(rex, rflags)\n\n        def match_func(text, pos, endpos=sys.maxsize):\n            info = cls._prof_data[-1].setdefault((state, rex), [0, 0.0])\n            t0 = time.time()\n            res = compiled.match(text, pos, endpos)\n            t1 = time.time()\n            info[0] += 1\n            info[1] += t1 - t0\n            return res\n        return match_func\n\n\nclass ProfilingRegexLexer(RegexLexer, metaclass=ProfilingRegexLexerMeta):\n    \"\"\"Drop-in replacement for RegexLexer that does profiling of its regexes.\"\"\"\n\n    _prof_data = []\n    _prof_sort_index = 4  # defaults to time per call\n\n    def get_tokens_unprocessed(self, text, stack=('root',)):\n        # this needs to be a stack, since using(this) will produce nested calls\n        self.__class__._prof_data.append({})\n        yield from RegexLexer.get_tokens_unprocessed(self, text, stack)\n        rawdata = self.__class__._prof_data.pop()\n        data = sorted(((s, repr(r).strip('u\\'').replace('\\\\\\\\', '\\\\')[:65],\n                        n, 1000 * t, 1000 * t / n)\n                       for ((s, r), (n, t)) in rawdata.items()),\n                      key=lambda x: x[self._prof_sort_index],\n                      reverse=True)\n        sum_total = sum(x[3] for x in data)\n\n        print()\n        print('Profiling result for %s lexing %d chars in %.3f ms' %\n              (self.__class__.__name__, len(text), sum_total))\n        print('=' * 110)\n        print('%-20s %-64s ncalls  tottime  percall' % ('state', 'regex'))\n        print('-' * 110)\n        for d in data:\n            print('%-20s %-65s %5d %8.4f %8.4f' % d)\n        print('=' * 110)\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/pygments/lexers/__init__.py","size":12115,"sha1":"8023fe8eccbd7e60e468d66b8295e814550285dd","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\n    pygments.lexers\n    ~~~~~~~~~~~~~~~\n\n    Pygments lexers.\n\n    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nimport re\nimport sys\nimport types\nimport fnmatch\nfrom os.path import basename\n\nfrom pip._vendor.pygments.lexers._mapping import LEXERS\nfrom pip._vendor.pygments.modeline import get_filetype_from_buffer\nfrom pip._vendor.pygments.plugin import find_plugin_lexers\nfrom pip._vendor.pygments.util import ClassNotFound, guess_decode\n\nCOMPAT = {\n    'Python3Lexer': 'PythonLexer',\n    'Python3TracebackLexer': 'PythonTracebackLexer',\n    'LeanLexer': 'Lean3Lexer',\n}\n\n__all__ = ['get_lexer_by_name', 'get_lexer_for_filename', 'find_lexer_class',\n           'guess_lexer', 'load_lexer_from_file'] + list(LEXERS) + list(COMPAT)\n\n_lexer_cache = {}\n_pattern_cache = {}\n\n\ndef _fn_matches(fn, glob):\n    \"\"\"Return whether the supplied file name fn matches pattern filename.\"\"\"\n    if glob not in _pattern_cache:\n        pattern = _pattern_cache[glob] = re.compile(fnmatch.translate(glob))\n        return pattern.match(fn)\n    return _pattern_cache[glob].match(fn)\n\n\ndef _load_lexers(module_name):\n    \"\"\"Load a lexer (and all others in the module too).\"\"\"\n    mod = __import__(module_name, None, None, ['__all__'])\n    for lexer_name in mod.__all__:\n        cls = getattr(mod, lexer_name)\n        _lexer_cache[cls.name] = cls\n\n\ndef get_all_lexers(plugins=True):\n    \"\"\"Return a generator of tuples in the form ``(name, aliases,\n    filenames, mimetypes)`` of all know lexers.\n\n    If *plugins* is true (the default), plugin lexers supplied by entrypoints\n    are also returned.  Otherwise, only builtin ones are considered.\n    \"\"\"\n    for item in LEXERS.values():\n        yield item[1:]\n    if plugins:\n        for lexer in find_plugin_lexers():\n            yield lexer.name, lexer.aliases, lexer.filenames, lexer.mimetypes\n\n\ndef find_lexer_class(name):\n    \"\"\"\n    Return the `Lexer` subclass that with the *name* attribute as given by\n    the *name* argument.\n    \"\"\"\n    if name in _lexer_cache:\n        return _lexer_cache[name]\n    # lookup builtin lexers\n    for module_name, lname, aliases, _, _ in LEXERS.values():\n        if name == lname:\n            _load_lexers(module_name)\n            return _lexer_cache[name]\n    # continue with lexers from setuptools entrypoints\n    for cls in find_plugin_lexers():\n        if cls.name == name:\n            return cls\n\n\ndef find_lexer_class_by_name(_alias):\n    \"\"\"\n    Return the `Lexer` subclass that has `alias` in its aliases list, without\n    instantiating it.\n\n    Like `get_lexer_by_name`, but does not instantiate the class.\n\n    Will raise :exc:`pygments.util.ClassNotFound` if no lexer with that alias is\n    found.\n\n    .. versionadded:: 2.2\n    \"\"\"\n    if not _alias:\n        raise ClassNotFound(f'no lexer for alias {_alias!r} found')\n    # lookup builtin lexers\n    for module_name, name, aliases, _, _ in LEXERS.values():\n        if _alias.lower() in aliases:\n            if name not in _lexer_cache:\n                _load_lexers(module_name)\n            return _lexer_cache[name]\n    # continue with lexers from setuptools entrypoints\n    for cls in find_plugin_lexers():\n        if _alias.lower() in cls.aliases:\n            return cls\n    raise ClassNotFound(f'no lexer for alias {_alias!r} found')\n\n\ndef get_lexer_by_name(_alias, **options):\n    \"\"\"\n    Return an instance of a `Lexer` subclass that has `alias` in its\n    aliases list. The lexer is given the `options` at its\n    instantiation.\n\n    Will raise :exc:`pygments.util.ClassNotFound` if no lexer with that alias is\n    found.\n    \"\"\"\n    if not _alias:\n        raise ClassNotFound(f'no lexer for alias {_alias!r} found')\n\n    # lookup builtin lexers\n    for module_name, name, aliases, _, _ in LEXERS.values():\n        if _alias.lower() in aliases:\n            if name not in _lexer_cache:\n                _load_lexers(module_name)\n            return _lexer_cache[name](**options)\n    # continue with lexers from setuptools entrypoints\n    for cls in find_plugin_lexers():\n        if _alias.lower() in cls.aliases:\n            return cls(**options)\n    raise ClassNotFound(f'no lexer for alias {_alias!r} found')\n\n\ndef load_lexer_from_file(filename, lexername=\"CustomLexer\", **options):\n    \"\"\"Load a lexer from a file.\n\n    This method expects a file located relative to the current working\n    directory, which contains a Lexer class. By default, it expects the\n    Lexer to be name CustomLexer; you can specify your own class name\n    as the second argument to this function.\n\n    Users should be very careful with the input, because this method\n    is equivalent to running eval on the input file.\n\n    Raises ClassNotFound if there are any problems importing the Lexer.\n\n    .. versionadded:: 2.2\n    \"\"\"\n    try:\n        # This empty dict will contain the namespace for the exec'd file\n        custom_namespace = {}\n        with open(filename, 'rb') as f:\n            exec(f.read(), custom_namespace)\n        # Retrieve the class `lexername` from that namespace\n        if lexername not in custom_namespace:\n            raise ClassNotFound(f'no valid {lexername} class found in {filename}')\n        lexer_class = custom_namespace[lexername]\n        # And finally instantiate it with the options\n        return lexer_class(**options)\n    except OSError as err:\n        raise ClassNotFound(f'cannot read {filename}: {err}')\n    except ClassNotFound:\n        raise\n    except Exception as err:\n        raise ClassNotFound(f'error when loading custom lexer: {err}')\n\n\ndef find_lexer_class_for_filename(_fn, code=None):\n    \"\"\"Get a lexer for a filename.\n\n    If multiple lexers match the filename pattern, use ``analyse_text()`` to\n    figure out which one is more appropriate.\n\n    Returns None if not found.\n    \"\"\"\n    matches = []\n    fn = basename(_fn)\n    for modname, name, _, filenames, _ in LEXERS.values():\n        for filename in filenames:\n            if _fn_matches(fn, filename):\n                if name not in _lexer_cache:\n                    _load_lexers(modname)\n                matches.append((_lexer_cache[name], filename))\n    for cls in find_plugin_lexers():\n        for filename in cls.filenames:\n            if _fn_matches(fn, filename):\n                matches.append((cls, filename))\n\n    if isinstance(code, bytes):\n        # decode it, since all analyse_text functions expect unicode\n        code = guess_decode(code)\n\n    def get_rating(info):\n        cls, filename = info\n        # explicit patterns get a bonus\n        bonus = '*' not in filename and 0.5 or 0\n        # The class _always_ defines analyse_text because it's included in\n        # the Lexer class.  The default implementation returns None which\n        # gets turned into 0.0.  Run scripts/detect_missing_analyse_text.py\n        # to find lexers which need it overridden.\n        if code:\n            return cls.analyse_text(code) + bonus, cls.__name__\n        return cls.priority + bonus, cls.__name__\n\n    if matches:\n        matches.sort(key=get_rating)\n        # print \"Possible lexers, after sort:\", matches\n        return matches[-1][0]\n\n\ndef get_lexer_for_filename(_fn, code=None, **options):\n    \"\"\"Get a lexer for a filename.\n\n    Return a `Lexer` subclass instance that has a filename pattern\n    matching `fn`. The lexer is given the `options` at its\n    instantiation.\n\n    Raise :exc:`pygments.util.ClassNotFound` if no lexer for that filename\n    is found.\n\n    If multiple lexers match the filename pattern, use their ``analyse_text()``\n    methods to figure out which one is more appropriate.\n    \"\"\"\n    res = find_lexer_class_for_filename(_fn, code)\n    if not res:\n        raise ClassNotFound(f'no lexer for filename {_fn!r} found')\n    return res(**options)\n\n\ndef get_lexer_for_mimetype(_mime, **options):\n    \"\"\"\n    Return a `Lexer` subclass instance that has `mime` in its mimetype\n    list. The lexer is given the `options` at its instantiation.\n\n    Will raise :exc:`pygments.util.ClassNotFound` if not lexer for that mimetype\n    is found.\n    \"\"\"\n    for modname, name, _, _, mimetypes in LEXERS.values():\n        if _mime in mimetypes:\n            if name not in _lexer_cache:\n                _load_lexers(modname)\n            return _lexer_cache[name](**options)\n    for cls in find_plugin_lexers():\n        if _mime in cls.mimetypes:\n            return cls(**options)\n    raise ClassNotFound(f'no lexer for mimetype {_mime!r} found')\n\n\ndef _iter_lexerclasses(plugins=True):\n    \"\"\"Return an iterator over all lexer classes.\"\"\"\n    for key in sorted(LEXERS):\n        module_name, name = LEXERS[key][:2]\n        if name not in _lexer_cache:\n            _load_lexers(module_name)\n        yield _lexer_cache[name]\n    if plugins:\n        yield from find_plugin_lexers()\n\n\ndef guess_lexer_for_filename(_fn, _text, **options):\n    \"\"\"\n    As :func:`guess_lexer()`, but only lexers which have a pattern in `filenames`\n    or `alias_filenames` that matches `filename` are taken into consideration.\n\n    :exc:`pygments.util.ClassNotFound` is raised if no lexer thinks it can\n    handle the content.\n    \"\"\"\n    fn = basename(_fn)\n    primary = {}\n    matching_lexers = set()\n    for lexer in _iter_lexerclasses():\n        for filename in lexer.filenames:\n            if _fn_matches(fn, filename):\n                matching_lexers.add(lexer)\n                primary[lexer] = True\n        for filename in lexer.alias_filenames:\n            if _fn_matches(fn, filename):\n                matching_lexers.add(lexer)\n                primary[lexer] = False\n    if not matching_lexers:\n        raise ClassNotFound(f'no lexer for filename {fn!r} found')\n    if len(matching_lexers) == 1:\n        return matching_lexers.pop()(**options)\n    result = []\n    for lexer in matching_lexers:\n        rv = lexer.analyse_text(_text)\n        if rv == 1.0:\n            return lexer(**options)\n        result.append((rv, lexer))\n\n    def type_sort(t):\n        # sort by:\n        # - analyse score\n        # - is primary filename pattern?\n        # - priority\n        # - last resort: class name\n        return (t[0], primary[t[1]], t[1].priority, t[1].__name__)\n    result.sort(key=type_sort)\n\n    return result[-1][1](**options)\n\n\ndef guess_lexer(_text, **options):\n    \"\"\"\n    Return a `Lexer` subclass instance that's guessed from the text in\n    `text`. For that, the :meth:`.analyse_text()` method of every known lexer\n    class is called with the text as argument, and the lexer which returned the\n    highest value will be instantiated and returned.\n\n    :exc:`pygments.util.ClassNotFound` is raised if no lexer thinks it can\n    handle the content.\n    \"\"\"\n\n    if not isinstance(_text, str):\n        inencoding = options.get('inencoding', options.get('encoding'))\n        if inencoding:\n            _text = _text.decode(inencoding or 'utf8')\n        else:\n            _text, _ = guess_decode(_text)\n\n    # try to get a vim modeline first\n    ft = get_filetype_from_buffer(_text)\n\n    if ft is not None:\n        try:\n            return get_lexer_by_name(ft, **options)\n        except ClassNotFound:\n            pass\n\n    best_lexer = [0.0, None]\n    for lexer in _iter_lexerclasses():\n        rv = lexer.analyse_text(_text)\n        if rv == 1.0:\n            return lexer(**options)\n        if rv > best_lexer[0]:\n            best_lexer[:] = (rv, lexer)\n    if not best_lexer[0] or best_lexer[1] is None:\n        raise ClassNotFound('no lexer matching the text found')\n    return best_lexer[1](**options)\n\n\nclass _automodule(types.ModuleType):\n    \"\"\"Automatically import lexers.\"\"\"\n\n    def __getattr__(self, name):\n        info = LEXERS.get(name)\n        if info:\n            _load_lexers(info[0])\n            cls = _lexer_cache[info[1]]\n            setattr(self, name, cls)\n            return cls\n        if name in COMPAT:\n            return getattr(self, COMPAT[name])\n        raise AttributeError(name)\n\n\noldmod = sys.modules[__name__]\nnewmod = _automodule(__name__)\nnewmod.__dict__.update(oldmod.__dict__)\nsys.modules[__name__] = newmod\ndel newmod.newmod, newmod.oldmod, newmod.sys, newmod.types\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/pygments/lexers/_mapping.py","size":76097,"sha1":"4ca4b66f4e48a4d546749cc8aadd462359089427","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"# Automatically generated by scripts/gen_mapfiles.py.\n# DO NOT EDIT BY HAND; run `tox -e mapfiles` instead.\n\nLEXERS = {\n    'ABAPLexer': ('pip._vendor.pygments.lexers.business', 'ABAP', ('abap',), ('*.abap', '*.ABAP'), ('text/x-abap',)),\n    'AMDGPULexer': ('pip._vendor.pygments.lexers.amdgpu', 'AMDGPU', ('amdgpu',), ('*.isa',), ()),\n    'APLLexer': ('pip._vendor.pygments.lexers.apl', 'APL', ('apl',), ('*.apl', '*.aplf', '*.aplo', '*.apln', '*.aplc', '*.apli', '*.dyalog'), ()),\n    'AbnfLexer': ('pip._vendor.pygments.lexers.grammar_notation', 'ABNF', ('abnf',), ('*.abnf',), ('text/x-abnf',)),\n    'ActionScript3Lexer': ('pip._vendor.pygments.lexers.actionscript', 'ActionScript 3', ('actionscript3', 'as3'), ('*.as',), ('application/x-actionscript3', 'text/x-actionscript3', 'text/actionscript3')),\n    'ActionScriptLexer': ('pip._vendor.pygments.lexers.actionscript', 'ActionScript', ('actionscript', 'as'), ('*.as',), ('application/x-actionscript', 'text/x-actionscript', 'text/actionscript')),\n    'AdaLexer': ('pip._vendor.pygments.lexers.ada', 'Ada', ('ada', 'ada95', 'ada2005'), ('*.adb', '*.ads', '*.ada'), ('text/x-ada',)),\n    'AdlLexer': ('pip._vendor.pygments.lexers.archetype', 'ADL', ('adl',), ('*.adl', '*.adls', '*.adlf', '*.adlx'), ()),\n    'AgdaLexer': ('pip._vendor.pygments.lexers.haskell', 'Agda', ('agda',), ('*.agda',), ('text/x-agda',)),\n    'AheuiLexer': ('pip._vendor.pygments.lexers.esoteric', 'Aheui', ('aheui',), ('*.aheui',), ()),\n    'AlloyLexer': ('pip._vendor.pygments.lexers.dsls', 'Alloy', ('alloy',), ('*.als',), ('text/x-alloy',)),\n    'AmbientTalkLexer': ('pip._vendor.pygments.lexers.ambient', 'AmbientTalk', ('ambienttalk', 'ambienttalk/2', 'at'), ('*.at',), ('text/x-ambienttalk',)),\n    'AmplLexer': ('pip._vendor.pygments.lexers.ampl', 'Ampl', ('ampl',), ('*.run',), ()),\n    'Angular2HtmlLexer': ('pip._vendor.pygments.lexers.templates', 'HTML + Angular2', ('html+ng2',), ('*.ng2',), ()),\n    'Angular2Lexer': ('pip._vendor.pygments.lexers.templates', 'Angular2', ('ng2',), (), ()),\n    'AntlrActionScriptLexer': ('pip._vendor.pygments.lexers.parsers', 'ANTLR With ActionScript Target', ('antlr-actionscript', 'antlr-as'), ('*.G', '*.g'), ()),\n    'AntlrCSharpLexer': ('pip._vendor.pygments.lexers.parsers', 'ANTLR With C# Target', ('antlr-csharp', 'antlr-c#'), ('*.G', '*.g'), ()),\n    'AntlrCppLexer': ('pip._vendor.pygments.lexers.parsers', 'ANTLR With CPP Target', ('antlr-cpp',), ('*.G', '*.g'), ()),\n    'AntlrJavaLexer': ('pip._vendor.pygments.lexers.parsers', 'ANTLR With Java Target', ('antlr-java',), ('*.G', '*.g'), ()),\n    'AntlrLexer': ('pip._vendor.pygments.lexers.parsers', 'ANTLR', ('antlr',), (), ()),\n    'AntlrObjectiveCLexer': ('pip._vendor.pygments.lexers.parsers', 'ANTLR With ObjectiveC Target', ('antlr-objc',), ('*.G', '*.g'), ()),\n    'AntlrPerlLexer': ('pip._vendor.pygments.lexers.parsers', 'ANTLR With Perl Target', ('antlr-perl',), ('*.G', '*.g'), ()),\n    'AntlrPythonLexer': ('pip._vendor.pygments.lexers.parsers', 'ANTLR With Python Target', ('antlr-python',), ('*.G', '*.g'), ()),\n    'AntlrRubyLexer': ('pip._vendor.pygments.lexers.parsers', 'ANTLR With Ruby Target', ('antlr-ruby', 'antlr-rb'), ('*.G', '*.g'), ()),\n    'ApacheConfLexer': ('pip._vendor.pygments.lexers.configs', 'ApacheConf', ('apacheconf', 'aconf', 'apache'), ('.htaccess', 'apache.conf', 'apache2.conf'), ('text/x-apacheconf',)),\n    'AppleScriptLexer': ('pip._vendor.pygments.lexers.scripting', 'AppleScript', ('applescript',), ('*.applescript',), ()),\n    'ArduinoLexer': ('pip._vendor.pygments.lexers.c_like', 'Arduino', ('arduino',), ('*.ino',), ('text/x-arduino',)),\n    'ArrowLexer': ('pip._vendor.pygments.lexers.arrow', 'Arrow', ('arrow',), ('*.arw',), ()),\n    'ArturoLexer': ('pip._vendor.pygments.lexers.arturo', 'Arturo', ('arturo', 'art'), ('*.art',), ()),\n    'AscLexer': ('pip._vendor.pygments.lexers.asc', 'ASCII armored', ('asc', 'pem'), ('*.asc', '*.pem', 'id_dsa', 'id_ecdsa', 'id_ecdsa_sk', 'id_ed25519', 'id_ed25519_sk', 'id_rsa'), ('application/pgp-keys', 'application/pgp-encrypted', 'application/pgp-signature', 'application/pem-certificate-chain')),\n    'Asn1Lexer': ('pip._vendor.pygments.lexers.asn1', 'ASN.1', ('asn1',), ('*.asn1',), ()),\n    'AspectJLexer': ('pip._vendor.pygments.lexers.jvm', 'AspectJ', ('aspectj',), ('*.aj',), ('text/x-aspectj',)),\n    'AsymptoteLexer': ('pip._vendor.pygments.lexers.graphics', 'Asymptote', ('asymptote', 'asy'), ('*.asy',), ('text/x-asymptote',)),\n    'AugeasLexer': ('pip._vendor.pygments.lexers.configs', 'Augeas', ('augeas',), ('*.aug',), ()),\n    'AutoItLexer': ('pip._vendor.pygments.lexers.automation', 'AutoIt', ('autoit',), ('*.au3',), ('text/x-autoit',)),\n    'AutohotkeyLexer': ('pip._vendor.pygments.lexers.automation', 'autohotkey', ('autohotkey', 'ahk'), ('*.ahk', '*.ahkl'), ('text/x-autohotkey',)),\n    'AwkLexer': ('pip._vendor.pygments.lexers.textedit', 'Awk', ('awk', 'gawk', 'mawk', 'nawk'), ('*.awk',), ('application/x-awk',)),\n    'BBCBasicLexer': ('pip._vendor.pygments.lexers.basic', 'BBC Basic', ('bbcbasic',), ('*.bbc',), ()),\n    'BBCodeLexer': ('pip._vendor.pygments.lexers.markup', 'BBCode', ('bbcode',), (), ('text/x-bbcode',)),\n    'BCLexer': ('pip._vendor.pygments.lexers.algebra', 'BC', ('bc',), ('*.bc',), ()),\n    'BQNLexer': ('pip._vendor.pygments.lexers.bqn', 'BQN', ('bqn',), ('*.bqn',), ()),\n    'BSTLexer': ('pip._vendor.pygments.lexers.bibtex', 'BST', ('bst', 'bst-pybtex'), ('*.bst',), ()),\n    'BareLexer': ('pip._vendor.pygments.lexers.bare', 'BARE', ('bare',), ('*.bare',), ()),\n    'BaseMakefileLexer': ('pip._vendor.pygments.lexers.make', 'Base Makefile', ('basemake',), (), ()),\n    'BashLexer': ('pip._vendor.pygments.lexers.shell', 'Bash', ('bash', 'sh', 'ksh', 'zsh', 'shell', 'openrc'), ('*.sh', '*.ksh', '*.bash', '*.ebuild', '*.eclass', '*.exheres-0', '*.exlib', '*.zsh', '.bashrc', 'bashrc', '.bash_*', 'bash_*', 'zshrc', '.zshrc', '.kshrc', 'kshrc', 'PKGBUILD'), ('application/x-sh', 'application/x-shellscript', 'text/x-shellscript')),\n    'BashSessionLexer': ('pip._vendor.pygments.lexers.shell', 'Bash Session', ('console', 'shell-session'), ('*.sh-session', '*.shell-session'), ('application/x-shell-session', 'application/x-sh-session')),\n    'BatchLexer': ('pip._vendor.pygments.lexers.shell', 'Batchfile', ('batch', 'bat', 'dosbatch', 'winbatch'), ('*.bat', '*.cmd'), ('application/x-dos-batch',)),\n    'BddLexer': ('pip._vendor.pygments.lexers.bdd', 'Bdd', ('bdd',), ('*.feature',), ('text/x-bdd',)),\n    'BefungeLexer': ('pip._vendor.pygments.lexers.esoteric', 'Befunge', ('befunge',), ('*.befunge',), ('application/x-befunge',)),\n    'BerryLexer': ('pip._vendor.pygments.lexers.berry', 'Berry', ('berry', 'be'), ('*.be',), ('text/x-berry', 'application/x-berry')),\n    'BibTeXLexer': ('pip._vendor.pygments.lexers.bibtex', 'BibTeX', ('bibtex', 'bib'), ('*.bib',), ('text/x-bibtex',)),\n    'BlitzBasicLexer': ('pip._vendor.pygments.lexers.basic', 'BlitzBasic', ('blitzbasic', 'b3d', 'bplus'), ('*.bb', '*.decls'), ('text/x-bb',)),\n    'BlitzMaxLexer': ('pip._vendor.pygments.lexers.basic', 'BlitzMax', ('blitzmax', 'bmax'), ('*.bmx',), ('text/x-bmx',)),\n    'BlueprintLexer': ('pip._vendor.pygments.lexers.blueprint', 'Blueprint', ('blueprint',), ('*.blp',), ('text/x-blueprint',)),\n    'BnfLexer': ('pip._vendor.pygments.lexers.grammar_notation', 'BNF', ('bnf',), ('*.bnf',), ('text/x-bnf',)),\n    'BoaLexer': ('pip._vendor.pygments.lexers.boa', 'Boa', ('boa',), ('*.boa',), ()),\n    'BooLexer': ('pip._vendor.pygments.lexers.dotnet', 'Boo', ('boo',), ('*.boo',), ('text/x-boo',)),\n    'BoogieLexer': ('pip._vendor.pygments.lexers.verification', 'Boogie', ('boogie',), ('*.bpl',), ()),\n    'BrainfuckLexer': ('pip._vendor.pygments.lexers.esoteric', 'Brainfuck', ('brainfuck', 'bf'), ('*.bf', '*.b'), ('application/x-brainfuck',)),\n    'BugsLexer': ('pip._vendor.pygments.lexers.modeling', 'BUGS', ('bugs', 'winbugs', 'openbugs'), ('*.bug',), ()),\n    'CAmkESLexer': ('pip._vendor.pygments.lexers.esoteric', 'CAmkES', ('camkes', 'idl4'), ('*.camkes', '*.idl4'), ()),\n    'CLexer': ('pip._vendor.pygments.lexers.c_cpp', 'C', ('c',), ('*.c', '*.h', '*.idc', '*.x[bp]m'), ('text/x-chdr', 'text/x-csrc', 'image/x-xbitmap', 'image/x-xpixmap')),\n    'CMakeLexer': ('pip._vendor.pygments.lexers.make', 'CMake', ('cmake',), ('*.cmake', 'CMakeLists.txt'), ('text/x-cmake',)),\n    'CObjdumpLexer': ('pip._vendor.pygments.lexers.asm', 'c-objdump', ('c-objdump',), ('*.c-objdump',), ('text/x-c-objdump',)),\n    'CPSALexer': ('pip._vendor.pygments.lexers.lisp', 'CPSA', ('cpsa',), ('*.cpsa',), ()),\n    'CSSUL4Lexer': ('pip._vendor.pygments.lexers.ul4', 'CSS+UL4', ('css+ul4',), ('*.cssul4',), ()),\n    'CSharpAspxLexer': ('pip._vendor.pygments.lexers.dotnet', 'aspx-cs', ('aspx-cs',), ('*.aspx', '*.asax', '*.ascx', '*.ashx', '*.asmx', '*.axd'), ()),\n    'CSharpLexer': ('pip._vendor.pygments.lexers.dotnet', 'C#', ('csharp', 'c#', 'cs'), ('*.cs',), ('text/x-csharp',)),\n    'Ca65Lexer': ('pip._vendor.pygments.lexers.asm', 'ca65 assembler', ('ca65',), ('*.s',), ()),\n    'CadlLexer': ('pip._vendor.pygments.lexers.archetype', 'cADL', ('cadl',), ('*.cadl',), ()),\n    'CapDLLexer': ('pip._vendor.pygments.lexers.esoteric', 'CapDL', ('capdl',), ('*.cdl',), ()),\n    'CapnProtoLexer': ('pip._vendor.pygments.lexers.capnproto', \"Cap'n Proto\", ('capnp',), ('*.capnp',), ()),\n    'CarbonLexer': ('pip._vendor.pygments.lexers.carbon', 'Carbon', ('carbon',), ('*.carbon',), ('text/x-carbon',)),\n    'CbmBasicV2Lexer': ('pip._vendor.pygments.lexers.basic', 'CBM BASIC V2', ('cbmbas',), ('*.bas',), ()),\n    'CddlLexer': ('pip._vendor.pygments.lexers.cddl', 'CDDL', ('cddl',), ('*.cddl',), ('text/x-cddl',)),\n    'CeylonLexer': ('pip._vendor.pygments.lexers.jvm', 'Ceylon', ('ceylon',), ('*.ceylon',), ('text/x-ceylon',)),\n    'Cfengine3Lexer': ('pip._vendor.pygments.lexers.configs', 'CFEngine3', ('cfengine3', 'cf3'), ('*.cf',), ()),\n    'ChaiscriptLexer': ('pip._vendor.pygments.lexers.scripting', 'ChaiScript', ('chaiscript', 'chai'), ('*.chai',), ('text/x-chaiscript', 'application/x-chaiscript')),\n    'ChapelLexer': ('pip._vendor.pygments.lexers.chapel', 'Chapel', ('chapel', 'chpl'), ('*.chpl',), ()),\n    'CharmciLexer': ('pip._vendor.pygments.lexers.c_like', 'Charmci', ('charmci',), ('*.ci',), ()),\n    'CheetahHtmlLexer': ('pip._vendor.pygments.lexers.templates', 'HTML+Cheetah', ('html+cheetah', 'html+spitfire', 'htmlcheetah'), (), ('text/html+cheetah', 'text/html+spitfire')),\n    'CheetahJavascriptLexer': ('pip._vendor.pygments.lexers.templates', 'JavaScript+Cheetah', ('javascript+cheetah', 'js+cheetah', 'javascript+spitfire', 'js+spitfire'), (), ('application/x-javascript+cheetah', 'text/x-javascript+cheetah', 'text/javascript+cheetah', 'application/x-javascript+spitfire', 'text/x-javascript+spitfire', 'text/javascript+spitfire')),\n    'CheetahLexer': ('pip._vendor.pygments.lexers.templates', 'Cheetah', ('cheetah', 'spitfire'), ('*.tmpl', '*.spt'), ('application/x-cheetah', 'application/x-spitfire')),\n    'CheetahXmlLexer': ('pip._vendor.pygments.lexers.templates', 'XML+Cheetah', ('xml+cheetah', 'xml+spitfire'), (), ('application/xml+cheetah', 'application/xml+spitfire')),\n    'CirruLexer': ('pip._vendor.pygments.lexers.webmisc', 'Cirru', ('cirru',), ('*.cirru',), ('text/x-cirru',)),\n    'ClayLexer': ('pip._vendor.pygments.lexers.c_like', 'Clay', ('clay',), ('*.clay',), ('text/x-clay',)),\n    'CleanLexer': ('pip._vendor.pygments.lexers.clean', 'Clean', ('clean',), ('*.icl', '*.dcl'), ()),\n    'ClojureLexer': ('pip._vendor.pygments.lexers.jvm', 'Clojure', ('clojure', 'clj'), ('*.clj', '*.cljc'), ('text/x-clojure', 'application/x-clojure')),\n    'ClojureScriptLexer': ('pip._vendor.pygments.lexers.jvm', 'ClojureScript', ('clojurescript', 'cljs'), ('*.cljs',), ('text/x-clojurescript', 'application/x-clojurescript')),\n    'CobolFreeformatLexer': ('pip._vendor.pygments.lexers.business', 'COBOLFree', ('cobolfree',), ('*.cbl', '*.CBL'), ()),\n    'CobolLexer': ('pip._vendor.pygments.lexers.business', 'COBOL', ('cobol',), ('*.cob', '*.COB', '*.cpy', '*.CPY'), ('text/x-cobol',)),\n    'CoffeeScriptLexer': ('pip._vendor.pygments.lexers.javascript', 'CoffeeScript', ('coffeescript', 'coffee-script', 'coffee'), ('*.coffee',), ('text/coffeescript',)),\n    'ColdfusionCFCLexer': ('pip._vendor.pygments.lexers.templates', 'Coldfusion CFC', ('cfc',), ('*.cfc',), ()),\n    'ColdfusionHtmlLexer': ('pip._vendor.pygments.lexers.templates', 'Coldfusion HTML', ('cfm',), ('*.cfm', '*.cfml'), ('application/x-coldfusion',)),\n    'ColdfusionLexer': ('pip._vendor.pygments.lexers.templates', 'cfstatement', ('cfs',), (), ()),\n    'Comal80Lexer': ('pip._vendor.pygments.lexers.comal', 'COMAL-80', ('comal', 'comal80'), ('*.cml', '*.comal'), ()),\n    'CommonLispLexer': ('pip._vendor.pygments.lexers.lisp', 'Common Lisp', ('common-lisp', 'cl', 'lisp'), ('*.cl', '*.lisp'), ('text/x-common-lisp',)),\n    'ComponentPascalLexer': ('pip._vendor.pygments.lexers.oberon', 'Component Pascal', ('componentpascal', 'cp'), ('*.cp', '*.cps'), ('text/x-component-pascal',)),\n    'CoqLexer': ('pip._vendor.pygments.lexers.theorem', 'Coq', ('coq',), ('*.v',), ('text/x-coq',)),\n    'CplintLexer': ('pip._vendor.pygments.lexers.cplint', 'cplint', ('cplint',), ('*.ecl', '*.prolog', '*.pro', '*.pl', '*.P', '*.lpad', '*.cpl'), ('text/x-cplint',)),\n    'CppLexer': ('pip._vendor.pygments.lexers.c_cpp', 'C++', ('cpp', 'c++'), ('*.cpp', '*.hpp', '*.c++', '*.h++', '*.cc', '*.hh', '*.cxx', '*.hxx', '*.C', '*.H', '*.cp', '*.CPP', '*.tpp'), ('text/x-c++hdr', 'text/x-c++src')),\n    'CppObjdumpLexer': ('pip._vendor.pygments.lexers.asm', 'cpp-objdump', ('cpp-objdump', 'c++-objdumb', 'cxx-objdump'), ('*.cpp-objdump', '*.c++-objdump', '*.cxx-objdump'), ('text/x-cpp-objdump',)),\n    'CrmshLexer': ('pip._vendor.pygments.lexers.dsls', 'Crmsh', ('crmsh', 'pcmk'), ('*.crmsh', '*.pcmk'), ()),\n    'CrocLexer': ('pip._vendor.pygments.lexers.d', 'Croc', ('croc',), ('*.croc',), ('text/x-crocsrc',)),\n    'CryptolLexer': ('pip._vendor.pygments.lexers.haskell', 'Cryptol', ('cryptol', 'cry'), ('*.cry',), ('text/x-cryptol',)),\n    'CrystalLexer': ('pip._vendor.pygments.lexers.crystal', 'Crystal', ('cr', 'crystal'), ('*.cr',), ('text/x-crystal',)),\n    'CsoundDocumentLexer': ('pip._vendor.pygments.lexers.csound', 'Csound Document', ('csound-document', 'csound-csd'), ('*.csd',), ()),\n    'CsoundOrchestraLexer': ('pip._vendor.pygments.lexers.csound', 'Csound Orchestra', ('csound', 'csound-orc'), ('*.orc', '*.udo'), ()),\n    'CsoundScoreLexer': ('pip._vendor.pygments.lexers.csound', 'Csound Score', ('csound-score', 'csound-sco'), ('*.sco',), ()),\n    'CssDjangoLexer': ('pip._vendor.pygments.lexers.templates', 'CSS+Django/Jinja', ('css+django', 'css+jinja'), ('*.css.j2', '*.css.jinja2'), ('text/css+django', 'text/css+jinja')),\n    'CssErbLexer': ('pip._vendor.pygments.lexers.templates', 'CSS+Ruby', ('css+ruby', 'css+erb'), (), ('text/css+ruby',)),\n    'CssGenshiLexer': ('pip._vendor.pygments.lexers.templates', 'CSS+Genshi Text', ('css+genshitext', 'css+genshi'), (), ('text/css+genshi',)),\n    'CssLexer': ('pip._vendor.pygments.lexers.css', 'CSS', ('css',), ('*.css',), ('text/css',)),\n    'CssPhpLexer': ('pip._vendor.pygments.lexers.templates', 'CSS+PHP', ('css+php',), (), ('text/css+php',)),\n    'CssSmartyLexer': ('pip._vendor.pygments.lexers.templates', 'CSS+Smarty', ('css+smarty',), (), ('text/css+smarty',)),\n    'CudaLexer': ('pip._vendor.pygments.lexers.c_like', 'CUDA', ('cuda', 'cu'), ('*.cu', '*.cuh'), ('text/x-cuda',)),\n    'CypherLexer': ('pip._vendor.pygments.lexers.graph', 'Cypher', ('cypher',), ('*.cyp', '*.cypher'), ()),\n    'CythonLexer': ('pip._vendor.pygments.lexers.python', 'Cython', ('cython', 'pyx', 'pyrex'), ('*.pyx', '*.pxd', '*.pxi'), ('text/x-cython', 'application/x-cython')),\n    'DLexer': ('pip._vendor.pygments.lexers.d', 'D', ('d',), ('*.d', '*.di'), ('text/x-dsrc',)),\n    'DObjdumpLexer': ('pip._vendor.pygments.lexers.asm', 'd-objdump', ('d-objdump',), ('*.d-objdump',), ('text/x-d-objdump',)),\n    'DarcsPatchLexer': ('pip._vendor.pygments.lexers.diff', 'Darcs Patch', ('dpatch',), ('*.dpatch', '*.darcspatch'), ()),\n    'DartLexer': ('pip._vendor.pygments.lexers.javascript', 'Dart', ('dart',), ('*.dart',), ('text/x-dart',)),\n    'Dasm16Lexer': ('pip._vendor.pygments.lexers.asm', 'DASM16', ('dasm16',), ('*.dasm16', '*.dasm'), ('text/x-dasm16',)),\n    'DaxLexer': ('pip._vendor.pygments.lexers.dax', 'Dax', ('dax',), ('*.dax',), ()),\n    'DebianControlLexer': ('pip._vendor.pygments.lexers.installers', 'Debian Control file', ('debcontrol', 'control'), ('control',), ()),\n    'DelphiLexer': ('pip._vendor.pygments.lexers.pascal', 'Delphi', ('delphi', 'pas', 'pascal', 'objectpascal'), ('*.pas', '*.dpr'), ('text/x-pascal',)),\n    'DesktopLexer': ('pip._vendor.pygments.lexers.configs', 'Desktop file', ('desktop',), ('*.desktop',), ('application/x-desktop',)),\n    'DevicetreeLexer': ('pip._vendor.pygments.lexers.devicetree', 'Devicetree', ('devicetree', 'dts'), ('*.dts', '*.dtsi'), ('text/x-c',)),\n    'DgLexer': ('pip._vendor.pygments.lexers.python', 'dg', ('dg',), ('*.dg',), ('text/x-dg',)),\n    'DiffLexer': ('pip._vendor.pygments.lexers.diff', 'Diff', ('diff', 'udiff'), ('*.diff', '*.patch'), ('text/x-diff', 'text/x-patch')),\n    'DjangoLexer': ('pip._vendor.pygments.lexers.templates', 'Django/Jinja', ('django', 'jinja'), (), ('application/x-django-templating', 'application/x-jinja')),\n    'DnsZoneLexer': ('pip._vendor.pygments.lexers.dns', 'Zone', ('zone',), ('*.zone',), ('text/dns',)),\n    'DockerLexer': ('pip._vendor.pygments.lexers.configs', 'Docker', ('docker', 'dockerfile'), ('Dockerfile', '*.docker'), ('text/x-dockerfile-config',)),\n    'DtdLexer': ('pip._vendor.pygments.lexers.html', 'DTD', ('dtd',), ('*.dtd',), ('application/xml-dtd',)),\n    'DuelLexer': ('pip._vendor.pygments.lexers.webmisc', 'Duel', ('duel', 'jbst', 'jsonml+bst'), ('*.duel', '*.jbst'), ('text/x-duel', 'text/x-jbst')),\n    'DylanConsoleLexer': ('pip._vendor.pygments.lexers.dylan', 'Dylan session', ('dylan-console', 'dylan-repl'), ('*.dylan-console',), ('text/x-dylan-console',)),\n    'DylanLexer': ('pip._vendor.pygments.lexers.dylan', 'Dylan', ('dylan',), ('*.dylan', '*.dyl', '*.intr'), ('text/x-dylan',)),\n    'DylanLidLexer': ('pip._vendor.pygments.lexers.dylan', 'DylanLID', ('dylan-lid', 'lid'), ('*.lid', '*.hdp'), ('text/x-dylan-lid',)),\n    'ECLLexer': ('pip._vendor.pygments.lexers.ecl', 'ECL', ('ecl',), ('*.ecl',), ('application/x-ecl',)),\n    'ECLexer': ('pip._vendor.pygments.lexers.c_like', 'eC', ('ec',), ('*.ec', '*.eh'), ('text/x-echdr', 'text/x-ecsrc')),\n    'EarlGreyLexer': ('pip._vendor.pygments.lexers.javascript', 'Earl Grey', ('earl-grey', 'earlgrey', 'eg'), ('*.eg',), ('text/x-earl-grey',)),\n    'EasytrieveLexer': ('pip._vendor.pygments.lexers.scripting', 'Easytrieve', ('easytrieve',), ('*.ezt', '*.mac'), ('text/x-easytrieve',)),\n    'EbnfLexer': ('pip._vendor.pygments.lexers.parsers', 'EBNF', ('ebnf',), ('*.ebnf',), ('text/x-ebnf',)),\n    'EiffelLexer': ('pip._vendor.pygments.lexers.eiffel', 'Eiffel', ('eiffel',), ('*.e',), ('text/x-eiffel',)),\n    'ElixirConsoleLexer': ('pip._vendor.pygments.lexers.erlang', 'Elixir iex session', ('iex',), (), ('text/x-elixir-shellsession',)),\n    'ElixirLexer': ('pip._vendor.pygments.lexers.erlang', 'Elixir', ('elixir', 'ex', 'exs'), ('*.ex', '*.eex', '*.exs', '*.leex'), ('text/x-elixir',)),\n    'ElmLexer': ('pip._vendor.pygments.lexers.elm', 'Elm', ('elm',), ('*.elm',), ('text/x-elm',)),\n    'ElpiLexer': ('pip._vendor.pygments.lexers.elpi', 'Elpi', ('elpi',), ('*.elpi',), ('text/x-elpi',)),\n    'EmacsLispLexer': ('pip._vendor.pygments.lexers.lisp', 'EmacsLisp', ('emacs-lisp', 'elisp', 'emacs'), ('*.el',), ('text/x-elisp', 'application/x-elisp')),\n    'EmailLexer': ('pip._vendor.pygments.lexers.email', 'E-mail', ('email', 'eml'), ('*.eml',), ('message/rfc822',)),\n    'ErbLexer': ('pip._vendor.pygments.lexers.templates', 'ERB', ('erb',), (), ('application/x-ruby-templating',)),\n    'ErlangLexer': ('pip._vendor.pygments.lexers.erlang', 'Erlang', ('erlang',), ('*.erl', '*.hrl', '*.es', '*.escript'), ('text/x-erlang',)),\n    'ErlangShellLexer': ('pip._vendor.pygments.lexers.erlang', 'Erlang erl session', ('erl',), ('*.erl-sh',), ('text/x-erl-shellsession',)),\n    'EvoqueHtmlLexer': ('pip._vendor.pygments.lexers.templates', 'HTML+Evoque', ('html+evoque',), ('*.html',), ('text/html+evoque',)),\n    'EvoqueLexer': ('pip._vendor.pygments.lexers.templates', 'Evoque', ('evoque',), ('*.evoque',), ('application/x-evoque',)),\n    'EvoqueXmlLexer': ('pip._vendor.pygments.lexers.templates', 'XML+Evoque', ('xml+evoque',), ('*.xml',), ('application/xml+evoque',)),\n    'ExeclineLexer': ('pip._vendor.pygments.lexers.shell', 'execline', ('execline',), ('*.exec',), ()),\n    'EzhilLexer': ('pip._vendor.pygments.lexers.ezhil', 'Ezhil', ('ezhil',), ('*.n',), ('text/x-ezhil',)),\n    'FSharpLexer': ('pip._vendor.pygments.lexers.dotnet', 'F#', ('fsharp', 'f#'), ('*.fs', '*.fsi', '*.fsx'), ('text/x-fsharp',)),\n    'FStarLexer': ('pip._vendor.pygments.lexers.ml', 'FStar', ('fstar',), ('*.fst', '*.fsti'), ('text/x-fstar',)),\n    'FactorLexer': ('pip._vendor.pygments.lexers.factor', 'Factor', ('factor',), ('*.factor',), ('text/x-factor',)),\n    'FancyLexer': ('pip._vendor.pygments.lexers.ruby', 'Fancy', ('fancy', 'fy'), ('*.fy', '*.fancypack'), ('text/x-fancysrc',)),\n    'FantomLexer': ('pip._vendor.pygments.lexers.fantom', 'Fantom', ('fan',), ('*.fan',), ('application/x-fantom',)),\n    'FelixLexer': ('pip._vendor.pygments.lexers.felix', 'Felix', ('felix', 'flx'), ('*.flx', '*.flxh'), ('text/x-felix',)),\n    'FennelLexer': ('pip._vendor.pygments.lexers.lisp', 'Fennel', ('fennel', 'fnl'), ('*.fnl',), ()),\n    'FiftLexer': ('pip._vendor.pygments.lexers.fift', 'Fift', ('fift', 'fif'), ('*.fif',), ()),\n    'FishShellLexer': ('pip._vendor.pygments.lexers.shell', 'Fish', ('fish', 'fishshell'), ('*.fish', '*.load'), ('application/x-fish',)),\n    'FlatlineLexer': ('pip._vendor.pygments.lexers.dsls', 'Flatline', ('flatline',), (), ('text/x-flatline',)),\n    'FloScriptLexer': ('pip._vendor.pygments.lexers.floscript', 'FloScript', ('floscript', 'flo'), ('*.flo',), ()),\n    'ForthLexer': ('pip._vendor.pygments.lexers.forth', 'Forth', ('forth',), ('*.frt', '*.fs'), ('application/x-forth',)),\n    'FortranFixedLexer': ('pip._vendor.pygments.lexers.fortran', 'FortranFixed', ('fortranfixed',), ('*.f', '*.F'), ()),\n    'FortranLexer': ('pip._vendor.pygments.lexers.fortran', 'Fortran', ('fortran', 'f90'), ('*.f03', '*.f90', '*.F03', '*.F90'), ('text/x-fortran',)),\n    'FoxProLexer': ('pip._vendor.pygments.lexers.foxpro', 'FoxPro', ('foxpro', 'vfp', 'clipper', 'xbase'), ('*.PRG', '*.prg'), ()),\n    'FreeFemLexer': ('pip._vendor.pygments.lexers.freefem', 'Freefem', ('freefem',), ('*.edp',), ('text/x-freefem',)),\n    'FuncLexer': ('pip._vendor.pygments.lexers.func', 'FunC', ('func', 'fc'), ('*.fc', '*.func'), ()),\n    'FutharkLexer': ('pip._vendor.pygments.lexers.futhark', 'Futhark', ('futhark',), ('*.fut',), ('text/x-futhark',)),\n    'GAPConsoleLexer': ('pip._vendor.pygments.lexers.algebra', 'GAP session', ('gap-console', 'gap-repl'), ('*.tst',), ()),\n    'GAPLexer': ('pip._vendor.pygments.lexers.algebra', 'GAP', ('gap',), ('*.g', '*.gd', '*.gi', '*.gap'), ()),\n    'GDScriptLexer': ('pip._vendor.pygments.lexers.gdscript', 'GDScript', ('gdscript', 'gd'), ('*.gd',), ('text/x-gdscript', 'application/x-gdscript')),\n    'GLShaderLexer': ('pip._vendor.pygments.lexers.graphics', 'GLSL', ('glsl',), ('*.vert', '*.frag', '*.geo'), ('text/x-glslsrc',)),\n    'GSQLLexer': ('pip._vendor.pygments.lexers.gsql', 'GSQL', ('gsql',), ('*.gsql',), ()),\n    'GasLexer': ('pip._vendor.pygments.lexers.asm', 'GAS', ('gas', 'asm'), ('*.s', '*.S'), ('text/x-gas',)),\n    'GcodeLexer': ('pip._vendor.pygments.lexers.gcodelexer', 'g-code', ('gcode',), ('*.gcode',), ()),\n    'GenshiLexer': ('pip._vendor.pygments.lexers.templates', 'Genshi', ('genshi', 'kid', 'xml+genshi', 'xml+kid'), ('*.kid',), ('application/x-genshi', 'application/x-kid')),\n    'GenshiTextLexer': ('pip._vendor.pygments.lexers.templates', 'Genshi Text', ('genshitext',), (), ('application/x-genshi-text', 'text/x-genshi')),\n    'GettextLexer': ('pip._vendor.pygments.lexers.textfmts', 'Gettext Catalog', ('pot', 'po'), ('*.pot', '*.po'), ('application/x-gettext', 'text/x-gettext', 'text/gettext')),\n    'GherkinLexer': ('pip._vendor.pygments.lexers.testing', 'Gherkin', ('gherkin', 'cucumber'), ('*.feature',), ('text/x-gherkin',)),\n    'GnuplotLexer': ('pip._vendor.pygments.lexers.graphics', 'Gnuplot', ('gnuplot',), ('*.plot', '*.plt'), ('text/x-gnuplot',)),\n    'GoLexer': ('pip._vendor.pygments.lexers.go', 'Go', ('go', 'golang'), ('*.go',), ('text/x-gosrc',)),\n    'GoloLexer': ('pip._vendor.pygments.lexers.jvm', 'Golo', ('golo',), ('*.golo',), ()),\n    'GoodDataCLLexer': ('pip._vendor.pygments.lexers.business', 'GoodData-CL', ('gooddata-cl',), ('*.gdc',), ('text/x-gooddata-cl',)),\n    'GosuLexer': ('pip._vendor.pygments.lexers.jvm', 'Gosu', ('gosu',), ('*.gs', '*.gsx', '*.gsp', '*.vark'), ('text/x-gosu',)),\n    'GosuTemplateLexer': ('pip._vendor.pygments.lexers.jvm', 'Gosu Template', ('gst',), ('*.gst',), ('text/x-gosu-template',)),\n    'GraphQLLexer': ('pip._vendor.pygments.lexers.graphql', 'GraphQL', ('graphql',), ('*.graphql',), ()),\n    'GraphvizLexer': ('pip._vendor.pygments.lexers.graphviz', 'Graphviz', ('graphviz', 'dot'), ('*.gv', '*.dot'), ('text/x-graphviz', 'text/vnd.graphviz')),\n    'GroffLexer': ('pip._vendor.pygments.lexers.markup', 'Groff', ('groff', 'nroff', 'man'), ('*.[1-9]', '*.man', '*.1p', '*.3pm'), ('application/x-troff', 'text/troff')),\n    'GroovyLexer': ('pip._vendor.pygments.lexers.jvm', 'Groovy', ('groovy',), ('*.groovy', '*.gradle'), ('text/x-groovy',)),\n    'HLSLShaderLexer': ('pip._vendor.pygments.lexers.graphics', 'HLSL', ('hlsl',), ('*.hlsl', '*.hlsli'), ('text/x-hlsl',)),\n    'HTMLUL4Lexer': ('pip._vendor.pygments.lexers.ul4', 'HTML+UL4', ('html+ul4',), ('*.htmlul4',), ()),\n    'HamlLexer': ('pip._vendor.pygments.lexers.html', 'Haml', ('haml',), ('*.haml',), ('text/x-haml',)),\n    'HandlebarsHtmlLexer': ('pip._vendor.pygments.lexers.templates', 'HTML+Handlebars', ('html+handlebars',), ('*.handlebars', '*.hbs'), ('text/html+handlebars', 'text/x-handlebars-template')),\n    'HandlebarsLexer': ('pip._vendor.pygments.lexers.templates', 'Handlebars', ('handlebars',), (), ()),\n    'HaskellLexer': ('pip._vendor.pygments.lexers.haskell', 'Haskell', ('haskell', 'hs'), ('*.hs',), ('text/x-haskell',)),\n    'HaxeLexer': ('pip._vendor.pygments.lexers.haxe', 'Haxe', ('haxe', 'hxsl', 'hx'), ('*.hx', '*.hxsl'), ('text/haxe', 'text/x-haxe', 'text/x-hx')),\n    'HexdumpLexer': ('pip._vendor.pygments.lexers.hexdump', 'Hexdump', ('hexdump',), (), ()),\n    'HsailLexer': ('pip._vendor.pygments.lexers.asm', 'HSAIL', ('hsail', 'hsa'), ('*.hsail',), ('text/x-hsail',)),\n    'HspecLexer': ('pip._vendor.pygments.lexers.haskell', 'Hspec', ('hspec',), ('*Spec.hs',), ()),\n    'HtmlDjangoLexer': ('pip._vendor.pygments.lexers.templates', 'HTML+Django/Jinja', ('html+django', 'html+jinja', 'htmldjango'), ('*.html.j2', '*.htm.j2', '*.xhtml.j2', '*.html.jinja2', '*.htm.jinja2', '*.xhtml.jinja2'), ('text/html+django', 'text/html+jinja')),\n    'HtmlGenshiLexer': ('pip._vendor.pygments.lexers.templates', 'HTML+Genshi', ('html+genshi', 'html+kid'), (), ('text/html+genshi',)),\n    'HtmlLexer': ('pip._vendor.pygments.lexers.html', 'HTML', ('html',), ('*.html', '*.htm', '*.xhtml', '*.xslt'), ('text/html', 'application/xhtml+xml')),\n    'HtmlPhpLexer': ('pip._vendor.pygments.lexers.templates', 'HTML+PHP', ('html+php',), ('*.phtml',), ('application/x-php', 'application/x-httpd-php', 'application/x-httpd-php3', 'application/x-httpd-php4', 'application/x-httpd-php5')),\n    'HtmlSmartyLexer': ('pip._vendor.pygments.lexers.templates', 'HTML+Smarty', ('html+smarty',), (), ('text/html+smarty',)),\n    'HttpLexer': ('pip._vendor.pygments.lexers.textfmts', 'HTTP', ('http',), (), ()),\n    'HxmlLexer': ('pip._vendor.pygments.lexers.haxe', 'Hxml', ('haxeml', 'hxml'), ('*.hxml',), ()),\n    'HyLexer': ('pip._vendor.pygments.lexers.lisp', 'Hy', ('hylang', 'hy'), ('*.hy',), ('text/x-hy', 'application/x-hy')),\n    'HybrisLexer': ('pip._vendor.pygments.lexers.scripting', 'Hybris', ('hybris',), ('*.hyb',), ('text/x-hybris', 'application/x-hybris')),\n    'IDLLexer': ('pip._vendor.pygments.lexers.idl', 'IDL', ('idl',), ('*.pro',), ('text/idl',)),\n    'IconLexer': ('pip._vendor.pygments.lexers.unicon', 'Icon', ('icon',), ('*.icon', '*.ICON'), ()),\n    'IdrisLexer': ('pip._vendor.pygments.lexers.haskell', 'Idris', ('idris', 'idr'), ('*.idr',), ('text/x-idris',)),\n    'IgorLexer': ('pip._vendor.pygments.lexers.igor', 'Igor', ('igor', 'igorpro'), ('*.ipf',), ('text/ipf',)),\n    'Inform6Lexer': ('pip._vendor.pygments.lexers.int_fiction', 'Inform 6', ('inform6', 'i6'), ('*.inf',), ()),\n    'Inform6TemplateLexer': ('pip._vendor.pygments.lexers.int_fiction', 'Inform 6 template', ('i6t',), ('*.i6t',), ()),\n    'Inform7Lexer': ('pip._vendor.pygments.lexers.int_fiction', 'Inform 7', ('inform7', 'i7'), ('*.ni', '*.i7x'), ()),\n    'IniLexer': ('pip._vendor.pygments.lexers.configs', 'INI', ('ini', 'cfg', 'dosini'), ('*.ini', '*.cfg', '*.inf', '.editorconfig'), ('text/x-ini', 'text/inf')),\n    'IoLexer': ('pip._vendor.pygments.lexers.iolang', 'Io', ('io',), ('*.io',), ('text/x-iosrc',)),\n    'IokeLexer': ('pip._vendor.pygments.lexers.jvm', 'Ioke', ('ioke', 'ik'), ('*.ik',), ('text/x-iokesrc',)),\n    'IrcLogsLexer': ('pip._vendor.pygments.lexers.textfmts', 'IRC logs', ('irc',), ('*.weechatlog',), ('text/x-irclog',)),\n    'IsabelleLexer': ('pip._vendor.pygments.lexers.theorem', 'Isabelle', ('isabelle',), ('*.thy',), ('text/x-isabelle',)),\n    'JLexer': ('pip._vendor.pygments.lexers.j', 'J', ('j',), ('*.ijs',), ('text/x-j',)),\n    'JMESPathLexer': ('pip._vendor.pygments.lexers.jmespath', 'JMESPath', ('jmespath', 'jp'), ('*.jp',), ()),\n    'JSLTLexer': ('pip._vendor.pygments.lexers.jslt', 'JSLT', ('jslt',), ('*.jslt',), ('text/x-jslt',)),\n    'JagsLexer': ('pip._vendor.pygments.lexers.modeling', 'JAGS', ('jags',), ('*.jag', '*.bug'), ()),\n    'JanetLexer': ('pip._vendor.pygments.lexers.lisp', 'Janet', ('janet',), ('*.janet', '*.jdn'), ('text/x-janet', 'application/x-janet')),\n    'JasminLexer': ('pip._vendor.pygments.lexers.jvm', 'Jasmin', ('jasmin', 'jasminxt'), ('*.j',), ()),\n    'JavaLexer': ('pip._vendor.pygments.lexers.jvm', 'Java', ('java',), ('*.java',), ('text/x-java',)),\n    'JavascriptDjangoLexer': ('pip._vendor.pygments.lexers.templates', 'JavaScript+Django/Jinja', ('javascript+django', 'js+django', 'javascript+jinja', 'js+jinja'), ('*.js.j2', '*.js.jinja2'), ('application/x-javascript+django', 'application/x-javascript+jinja', 'text/x-javascript+django', 'text/x-javascript+jinja', 'text/javascript+django', 'text/javascript+jinja')),\n    'JavascriptErbLexer': ('pip._vendor.pygments.lexers.templates', 'JavaScript+Ruby', ('javascript+ruby', 'js+ruby', 'javascript+erb', 'js+erb'), (), ('application/x-javascript+ruby', 'text/x-javascript+ruby', 'text/javascript+ruby')),\n    'JavascriptGenshiLexer': ('pip._vendor.pygments.lexers.templates', 'JavaScript+Genshi Text', ('js+genshitext', 'js+genshi', 'javascript+genshitext', 'javascript+genshi'), (), ('application/x-javascript+genshi', 'text/x-javascript+genshi', 'text/javascript+genshi')),\n    'JavascriptLexer': ('pip._vendor.pygments.lexers.javascript', 'JavaScript', ('javascript', 'js'), ('*.js', '*.jsm', '*.mjs', '*.cjs'), ('application/javascript', 'application/x-javascript', 'text/x-javascript', 'text/javascript')),\n    'JavascriptPhpLexer': ('pip._vendor.pygments.lexers.templates', 'JavaScript+PHP', ('javascript+php', 'js+php'), (), ('application/x-javascript+php', 'text/x-javascript+php', 'text/javascript+php')),\n    'JavascriptSmartyLexer': ('pip._vendor.pygments.lexers.templates', 'JavaScript+Smarty', ('javascript+smarty', 'js+smarty'), (), ('application/x-javascript+smarty', 'text/x-javascript+smarty', 'text/javascript+smarty')),\n    'JavascriptUL4Lexer': ('pip._vendor.pygments.lexers.ul4', 'Javascript+UL4', ('js+ul4',), ('*.jsul4',), ()),\n    'JclLexer': ('pip._vendor.pygments.lexers.scripting', 'JCL', ('jcl',), ('*.jcl',), ('text/x-jcl',)),\n    'JsgfLexer': ('pip._vendor.pygments.lexers.grammar_notation', 'JSGF', ('jsgf',), ('*.jsgf',), ('application/jsgf', 'application/x-jsgf', 'text/jsgf')),\n    'JsonBareObjectLexer': ('pip._vendor.pygments.lexers.data', 'JSONBareObject', (), (), ()),\n    'JsonLdLexer': ('pip._vendor.pygments.lexers.data', 'JSON-LD', ('jsonld', 'json-ld'), ('*.jsonld',), ('application/ld+json',)),\n    'JsonLexer': ('pip._vendor.pygments.lexers.data', 'JSON', ('json', 'json-object'), ('*.json', '*.jsonl', '*.ndjson', 'Pipfile.lock'), ('application/json', 'application/json-object', 'application/x-ndjson', 'application/jsonl', 'application/json-seq')),\n    'JsonnetLexer': ('pip._vendor.pygments.lexers.jsonnet', 'Jsonnet', ('jsonnet',), ('*.jsonnet', '*.libsonnet'), ()),\n    'JspLexer': ('pip._vendor.pygments.lexers.templates', 'Java Server Page', ('jsp',), ('*.jsp',), ('application/x-jsp',)),\n    'JsxLexer': ('pip._vendor.pygments.lexers.jsx', 'JSX', ('jsx', 'react'), ('*.jsx', '*.react'), ('text/jsx', 'text/typescript-jsx')),\n    'JuliaConsoleLexer': ('pip._vendor.pygments.lexers.julia', 'Julia console', ('jlcon', 'julia-repl'), (), ()),\n    'JuliaLexer': ('pip._vendor.pygments.lexers.julia', 'Julia', ('julia', 'jl'), ('*.jl',), ('text/x-julia', 'application/x-julia')),\n    'JuttleLexer': ('pip._vendor.pygments.lexers.javascript', 'Juttle', ('juttle',), ('*.juttle',), ('application/juttle', 'application/x-juttle', 'text/x-juttle', 'text/juttle')),\n    'KLexer': ('pip._vendor.pygments.lexers.q', 'K', ('k',), ('*.k',), ()),\n    'KalLexer': ('pip._vendor.pygments.lexers.javascript', 'Kal', ('kal',), ('*.kal',), ('text/kal', 'application/kal')),\n    'KconfigLexer': ('pip._vendor.pygments.lexers.configs', 'Kconfig', ('kconfig', 'menuconfig', 'linux-config', 'kernel-config'), ('Kconfig*', '*Config.in*', 'external.in*', 'standard-modules.in'), ('text/x-kconfig',)),\n    'KernelLogLexer': ('pip._vendor.pygments.lexers.textfmts', 'Kernel log', ('kmsg', 'dmesg'), ('*.kmsg', '*.dmesg'), ()),\n    'KokaLexer': ('pip._vendor.pygments.lexers.haskell', 'Koka', ('koka',), ('*.kk', '*.kki'), ('text/x-koka',)),\n    'KotlinLexer': ('pip._vendor.pygments.lexers.jvm', 'Kotlin', ('kotlin',), ('*.kt', '*.kts'), ('text/x-kotlin',)),\n    'KuinLexer': ('pip._vendor.pygments.lexers.kuin', 'Kuin', ('kuin',), ('*.kn',), ()),\n    'KustoLexer': ('pip._vendor.pygments.lexers.kusto', 'Kusto', ('kql', 'kusto'), ('*.kql', '*.kusto', '.csl'), ()),\n    'LSLLexer': ('pip._vendor.pygments.lexers.scripting', 'LSL', ('lsl',), ('*.lsl',), ('text/x-lsl',)),\n    'LassoCssLexer': ('pip._vendor.pygments.lexers.templates', 'CSS+Lasso', ('css+lasso',), (), ('text/css+lasso',)),\n    'LassoHtmlLexer': ('pip._vendor.pygments.lexers.templates', 'HTML+Lasso', ('html+lasso',), (), ('text/html+lasso', 'application/x-httpd-lasso', 'application/x-httpd-lasso[89]')),\n    'LassoJavascriptLexer': ('pip._vendor.pygments.lexers.templates', 'JavaScript+Lasso', ('javascript+lasso', 'js+lasso'), (), ('application/x-javascript+lasso', 'text/x-javascript+lasso', 'text/javascript+lasso')),\n    'LassoLexer': ('pip._vendor.pygments.lexers.javascript', 'Lasso', ('lasso', 'lassoscript'), ('*.lasso', '*.lasso[89]'), ('text/x-lasso',)),\n    'LassoXmlLexer': ('pip._vendor.pygments.lexers.templates', 'XML+Lasso', ('xml+lasso',), (), ('application/xml+lasso',)),\n    'LdaprcLexer': ('pip._vendor.pygments.lexers.ldap', 'LDAP configuration file', ('ldapconf', 'ldaprc'), ('.ldaprc', 'ldaprc', 'ldap.conf'), ('text/x-ldapconf',)),\n    'LdifLexer': ('pip._vendor.pygments.lexers.ldap', 'LDIF', ('ldif',), ('*.ldif',), ('text/x-ldif',)),\n    'Lean3Lexer': ('pip._vendor.pygments.lexers.lean', 'Lean', ('lean', 'lean3'), ('*.lean',), ('text/x-lean', 'text/x-lean3')),\n    'Lean4Lexer': ('pip._vendor.pygments.lexers.lean', 'Lean4', ('lean4',), ('*.lean',), ('text/x-lean4',)),\n    'LessCssLexer': ('pip._vendor.pygments.lexers.css', 'LessCss', ('less',), ('*.less',), ('text/x-less-css',)),\n    'LighttpdConfLexer': ('pip._vendor.pygments.lexers.configs', 'Lighttpd configuration file', ('lighttpd', 'lighty'), ('lighttpd.conf',), ('text/x-lighttpd-conf',)),\n    'LilyPondLexer': ('pip._vendor.pygments.lexers.lilypond', 'LilyPond', ('lilypond',), ('*.ly',), ()),\n    'LimboLexer': ('pip._vendor.pygments.lexers.inferno', 'Limbo', ('limbo',), ('*.b',), ('text/limbo',)),\n    'LiquidLexer': ('pip._vendor.pygments.lexers.templates', 'liquid', ('liquid',), ('*.liquid',), ()),\n    'LiterateAgdaLexer': ('pip._vendor.pygments.lexers.haskell', 'Literate Agda', ('literate-agda', 'lagda'), ('*.lagda',), ('text/x-literate-agda',)),\n    'LiterateCryptolLexer': ('pip._vendor.pygments.lexers.haskell', 'Literate Cryptol', ('literate-cryptol', 'lcryptol', 'lcry'), ('*.lcry',), ('text/x-literate-cryptol',)),\n    'LiterateHaskellLexer': ('pip._vendor.pygments.lexers.haskell', 'Literate Haskell', ('literate-haskell', 'lhaskell', 'lhs'), ('*.lhs',), ('text/x-literate-haskell',)),\n    'LiterateIdrisLexer': ('pip._vendor.pygments.lexers.haskell', 'Literate Idris', ('literate-idris', 'lidris', 'lidr'), ('*.lidr',), ('text/x-literate-idris',)),\n    'LiveScriptLexer': ('pip._vendor.pygments.lexers.javascript', 'LiveScript', ('livescript', 'live-script'), ('*.ls',), ('text/livescript',)),\n    'LlvmLexer': ('pip._vendor.pygments.lexers.asm', 'LLVM', ('llvm',), ('*.ll',), ('text/x-llvm',)),\n    'LlvmMirBodyLexer': ('pip._vendor.pygments.lexers.asm', 'LLVM-MIR Body', ('llvm-mir-body',), (), ()),\n    'LlvmMirLexer': ('pip._vendor.pygments.lexers.asm', 'LLVM-MIR', ('llvm-mir',), ('*.mir',), ()),\n    'LogosLexer': ('pip._vendor.pygments.lexers.objective', 'Logos', ('logos',), ('*.x', '*.xi', '*.xm', '*.xmi'), ('text/x-logos',)),\n    'LogtalkLexer': ('pip._vendor.pygments.lexers.prolog', 'Logtalk', ('logtalk',), ('*.lgt', '*.logtalk'), ('text/x-logtalk',)),\n    'LuaLexer': ('pip._vendor.pygments.lexers.scripting', 'Lua', ('lua',), ('*.lua', '*.wlua'), ('text/x-lua', 'application/x-lua')),\n    'LuauLexer': ('pip._vendor.pygments.lexers.scripting', 'Luau', ('luau',), ('*.luau',), ()),\n    'MCFunctionLexer': ('pip._vendor.pygments.lexers.minecraft', 'MCFunction', ('mcfunction', 'mcf'), ('*.mcfunction',), ('text/mcfunction',)),\n    'MCSchemaLexer': ('pip._vendor.pygments.lexers.minecraft', 'MCSchema', ('mcschema',), ('*.mcschema',), ('text/mcschema',)),\n    'MIMELexer': ('pip._vendor.pygments.lexers.mime', 'MIME', ('mime',), (), ('multipart/mixed', 'multipart/related', 'multipart/alternative')),\n    'MIPSLexer': ('pip._vendor.pygments.lexers.mips', 'MIPS', ('mips',), ('*.mips', '*.MIPS'), ()),\n    'MOOCodeLexer': ('pip._vendor.pygments.lexers.scripting', 'MOOCode', ('moocode', 'moo'), ('*.moo',), ('text/x-moocode',)),\n    'MSDOSSessionLexer': ('pip._vendor.pygments.lexers.shell', 'MSDOS Session', ('doscon',), (), ()),\n    'Macaulay2Lexer': ('pip._vendor.pygments.lexers.macaulay2', 'Macaulay2', ('macaulay2',), ('*.m2',), ()),\n    'MakefileLexer': ('pip._vendor.pygments.lexers.make', 'Makefile', ('make', 'makefile', 'mf', 'bsdmake'), ('*.mak', '*.mk', 'Makefile', 'makefile', 'Makefile.*', 'GNUmakefile'), ('text/x-makefile',)),\n    'MakoCssLexer': ('pip._vendor.pygments.lexers.templates', 'CSS+Mako', ('css+mako',), (), ('text/css+mako',)),\n    'MakoHtmlLexer': ('pip._vendor.pygments.lexers.templates', 'HTML+Mako', ('html+mako',), (), ('text/html+mako',)),\n    'MakoJavascriptLexer': ('pip._vendor.pygments.lexers.templates', 'JavaScript+Mako', ('javascript+mako', 'js+mako'), (), ('application/x-javascript+mako', 'text/x-javascript+mako', 'text/javascript+mako')),\n    'MakoLexer': ('pip._vendor.pygments.lexers.templates', 'Mako', ('mako',), ('*.mao',), ('application/x-mako',)),\n    'MakoXmlLexer': ('pip._vendor.pygments.lexers.templates', 'XML+Mako', ('xml+mako',), (), ('application/xml+mako',)),\n    'MaqlLexer': ('pip._vendor.pygments.lexers.business', 'MAQL', ('maql',), ('*.maql',), ('text/x-gooddata-maql', 'application/x-gooddata-maql')),\n    'MarkdownLexer': ('pip._vendor.pygments.lexers.markup', 'Markdown', ('markdown', 'md'), ('*.md', '*.markdown'), ('text/x-markdown',)),\n    'MaskLexer': ('pip._vendor.pygments.lexers.javascript', 'Mask', ('mask',), ('*.mask',), ('text/x-mask',)),\n    'MasonLexer': ('pip._vendor.pygments.lexers.templates', 'Mason', ('mason',), ('*.m', '*.mhtml', '*.mc', '*.mi', 'autohandler', 'dhandler'), ('application/x-mason',)),\n    'MathematicaLexer': ('pip._vendor.pygments.lexers.algebra', 'Mathematica', ('mathematica', 'mma', 'nb'), ('*.nb', '*.cdf', '*.nbp', '*.ma'), ('application/mathematica', 'application/vnd.wolfram.mathematica', 'application/vnd.wolfram.mathematica.package', 'application/vnd.wolfram.cdf')),\n    'MatlabLexer': ('pip._vendor.pygments.lexers.matlab', 'Matlab', ('matlab',), ('*.m',), ('text/matlab',)),\n    'MatlabSessionLexer': ('pip._vendor.pygments.lexers.matlab', 'Matlab session', ('matlabsession',), (), ()),\n    'MaximaLexer': ('pip._vendor.pygments.lexers.maxima', 'Maxima', ('maxima', 'macsyma'), ('*.mac', '*.max'), ()),\n    'MesonLexer': ('pip._vendor.pygments.lexers.meson', 'Meson', ('meson', 'meson.build'), ('meson.build', 'meson_options.txt'), ('text/x-meson',)),\n    'MiniDLexer': ('pip._vendor.pygments.lexers.d', 'MiniD', ('minid',), (), ('text/x-minidsrc',)),\n    'MiniScriptLexer': ('pip._vendor.pygments.lexers.scripting', 'MiniScript', ('miniscript', 'ms'), ('*.ms',), ('text/x-minicript', 'application/x-miniscript')),\n    'ModelicaLexer': ('pip._vendor.pygments.lexers.modeling', 'Modelica', ('modelica',), ('*.mo',), ('text/x-modelica',)),\n    'Modula2Lexer': ('pip._vendor.pygments.lexers.modula2', 'Modula-2', ('modula2', 'm2'), ('*.def', '*.mod'), ('text/x-modula2',)),\n    'MoinWikiLexer': ('pip._vendor.pygments.lexers.markup', 'MoinMoin/Trac Wiki markup', ('trac-wiki', 'moin'), (), ('text/x-trac-wiki',)),\n    'MojoLexer': ('pip._vendor.pygments.lexers.mojo', 'Mojo', ('mojo', '🔥'), ('*.mojo', '*.🔥'), ('text/x-mojo', 'application/x-mojo')),\n    'MonkeyLexer': ('pip._vendor.pygments.lexers.basic', 'Monkey', ('monkey',), ('*.monkey',), ('text/x-monkey',)),\n    'MonteLexer': ('pip._vendor.pygments.lexers.monte', 'Monte', ('monte',), ('*.mt',), ()),\n    'MoonScriptLexer': ('pip._vendor.pygments.lexers.scripting', 'MoonScript', ('moonscript', 'moon'), ('*.moon',), ('text/x-moonscript', 'application/x-moonscript')),\n    'MoselLexer': ('pip._vendor.pygments.lexers.mosel', 'Mosel', ('mosel',), ('*.mos',), ()),\n    'MozPreprocCssLexer': ('pip._vendor.pygments.lexers.markup', 'CSS+mozpreproc', ('css+mozpreproc',), ('*.css.in',), ()),\n    'MozPreprocHashLexer': ('pip._vendor.pygments.lexers.markup', 'mozhashpreproc', ('mozhashpreproc',), (), ()),\n    'MozPreprocJavascriptLexer': ('pip._vendor.pygments.lexers.markup', 'Javascript+mozpreproc', ('javascript+mozpreproc',), ('*.js.in',), ()),\n    'MozPreprocPercentLexer': ('pip._vendor.pygments.lexers.markup', 'mozpercentpreproc', ('mozpercentpreproc',), (), ()),\n    'MozPreprocXulLexer': ('pip._vendor.pygments.lexers.markup', 'XUL+mozpreproc', ('xul+mozpreproc',), ('*.xul.in',), ()),\n    'MqlLexer': ('pip._vendor.pygments.lexers.c_like', 'MQL', ('mql', 'mq4', 'mq5', 'mql4', 'mql5'), ('*.mq4', '*.mq5', '*.mqh'), ('text/x-mql',)),\n    'MscgenLexer': ('pip._vendor.pygments.lexers.dsls', 'Mscgen', ('mscgen', 'msc'), ('*.msc',), ()),\n    'MuPADLexer': ('pip._vendor.pygments.lexers.algebra', 'MuPAD', ('mupad',), ('*.mu',), ()),\n    'MxmlLexer': ('pip._vendor.pygments.lexers.actionscript', 'MXML', ('mxml',), ('*.mxml',), ()),\n    'MySqlLexer': ('pip._vendor.pygments.lexers.sql', 'MySQL', ('mysql',), (), ('text/x-mysql',)),\n    'MyghtyCssLexer': ('pip._vendor.pygments.lexers.templates', 'CSS+Myghty', ('css+myghty',), (), ('text/css+myghty',)),\n    'MyghtyHtmlLexer': ('pip._vendor.pygments.lexers.templates', 'HTML+Myghty', ('html+myghty',), (), ('text/html+myghty',)),\n    'MyghtyJavascriptLexer': ('pip._vendor.pygments.lexers.templates', 'JavaScript+Myghty', ('javascript+myghty', 'js+myghty'), (), ('application/x-javascript+myghty', 'text/x-javascript+myghty', 'text/javascript+mygthy')),\n    'MyghtyLexer': ('pip._vendor.pygments.lexers.templates', 'Myghty', ('myghty',), ('*.myt', 'autodelegate'), ('application/x-myghty',)),\n    'MyghtyXmlLexer': ('pip._vendor.pygments.lexers.templates', 'XML+Myghty', ('xml+myghty',), (), ('application/xml+myghty',)),\n    'NCLLexer': ('pip._vendor.pygments.lexers.ncl', 'NCL', ('ncl',), ('*.ncl',), ('text/ncl',)),\n    'NSISLexer': ('pip._vendor.pygments.lexers.installers', 'NSIS', ('nsis', 'nsi', 'nsh'), ('*.nsi', '*.nsh'), ('text/x-nsis',)),\n    'NasmLexer': ('pip._vendor.pygments.lexers.asm', 'NASM', ('nasm',), ('*.asm', '*.ASM', '*.nasm'), ('text/x-nasm',)),\n    'NasmObjdumpLexer': ('pip._vendor.pygments.lexers.asm', 'objdump-nasm', ('objdump-nasm',), ('*.objdump-intel',), ('text/x-nasm-objdump',)),\n    'NemerleLexer': ('pip._vendor.pygments.lexers.dotnet', 'Nemerle', ('nemerle',), ('*.n',), ('text/x-nemerle',)),\n    'NesCLexer': ('pip._vendor.pygments.lexers.c_like', 'nesC', ('nesc',), ('*.nc',), ('text/x-nescsrc',)),\n    'NestedTextLexer': ('pip._vendor.pygments.lexers.configs', 'NestedText', ('nestedtext', 'nt'), ('*.nt',), ()),\n    'NewLispLexer': ('pip._vendor.pygments.lexers.lisp', 'NewLisp', ('newlisp',), ('*.lsp', '*.nl', '*.kif'), ('text/x-newlisp', 'application/x-newlisp')),\n    'NewspeakLexer': ('pip._vendor.pygments.lexers.smalltalk', 'Newspeak', ('newspeak',), ('*.ns2',), ('text/x-newspeak',)),\n    'NginxConfLexer': ('pip._vendor.pygments.lexers.configs', 'Nginx configuration file', ('nginx',), ('nginx.conf',), ('text/x-nginx-conf',)),\n    'NimrodLexer': ('pip._vendor.pygments.lexers.nimrod', 'Nimrod', ('nimrod', 'nim'), ('*.nim', '*.nimrod'), ('text/x-nim',)),\n    'NitLexer': ('pip._vendor.pygments.lexers.nit', 'Nit', ('nit',), ('*.nit',), ()),\n    'NixLexer': ('pip._vendor.pygments.lexers.nix', 'Nix', ('nixos', 'nix'), ('*.nix',), ('text/x-nix',)),\n    'NodeConsoleLexer': ('pip._vendor.pygments.lexers.javascript', 'Node.js REPL console session', ('nodejsrepl',), (), ('text/x-nodejsrepl',)),\n    'NotmuchLexer': ('pip._vendor.pygments.lexers.textfmts', 'Notmuch', ('notmuch',), (), ()),\n    'NuSMVLexer': ('pip._vendor.pygments.lexers.smv', 'NuSMV', ('nusmv',), ('*.smv',), ()),\n    'NumPyLexer': ('pip._vendor.pygments.lexers.python', 'NumPy', ('numpy',), (), ()),\n    'ObjdumpLexer': ('pip._vendor.pygments.lexers.asm', 'objdump', ('objdump',), ('*.objdump',), ('text/x-objdump',)),\n    'ObjectiveCLexer': ('pip._vendor.pygments.lexers.objective', 'Objective-C', ('objective-c', 'objectivec', 'obj-c', 'objc'), ('*.m', '*.h'), ('text/x-objective-c',)),\n    'ObjectiveCppLexer': ('pip._vendor.pygments.lexers.objective', 'Objective-C++', ('objective-c++', 'objectivec++', 'obj-c++', 'objc++'), ('*.mm', '*.hh'), ('text/x-objective-c++',)),\n    'ObjectiveJLexer': ('pip._vendor.pygments.lexers.javascript', 'Objective-J', ('objective-j', 'objectivej', 'obj-j', 'objj'), ('*.j',), ('text/x-objective-j',)),\n    'OcamlLexer': ('pip._vendor.pygments.lexers.ml', 'OCaml', ('ocaml',), ('*.ml', '*.mli', '*.mll', '*.mly'), ('text/x-ocaml',)),\n    'OctaveLexer': ('pip._vendor.pygments.lexers.matlab', 'Octave', ('octave',), ('*.m',), ('text/octave',)),\n    'OdinLexer': ('pip._vendor.pygments.lexers.archetype', 'ODIN', ('odin',), ('*.odin',), ('text/odin',)),\n    'OmgIdlLexer': ('pip._vendor.pygments.lexers.c_like', 'OMG Interface Definition Language', ('omg-idl',), ('*.idl', '*.pidl'), ()),\n    'OocLexer': ('pip._vendor.pygments.lexers.ooc', 'Ooc', ('ooc',), ('*.ooc',), ('text/x-ooc',)),\n    'OpaLexer': ('pip._vendor.pygments.lexers.ml', 'Opa', ('opa',), ('*.opa',), ('text/x-opa',)),\n    'OpenEdgeLexer': ('pip._vendor.pygments.lexers.business', 'OpenEdge ABL', ('openedge', 'abl', 'progress'), ('*.p', '*.cls'), ('text/x-openedge', 'application/x-openedge')),\n    'OpenScadLexer': ('pip._vendor.pygments.lexers.openscad', 'OpenSCAD', ('openscad',), ('*.scad',), ('application/x-openscad',)),\n    'OrgLexer': ('pip._vendor.pygments.lexers.markup', 'Org Mode', ('org', 'orgmode', 'org-mode'), ('*.org',), ('text/org',)),\n    'OutputLexer': ('pip._vendor.pygments.lexers.special', 'Text output', ('output',), (), ()),\n    'PacmanConfLexer': ('pip._vendor.pygments.lexers.configs', 'PacmanConf', ('pacmanconf',), ('pacman.conf',), ()),\n    'PanLexer': ('pip._vendor.pygments.lexers.dsls', 'Pan', ('pan',), ('*.pan',), ()),\n    'ParaSailLexer': ('pip._vendor.pygments.lexers.parasail', 'ParaSail', ('parasail',), ('*.psi', '*.psl'), ('text/x-parasail',)),\n    'PawnLexer': ('pip._vendor.pygments.lexers.pawn', 'Pawn', ('pawn',), ('*.p', '*.pwn', '*.inc'), ('text/x-pawn',)),\n    'PegLexer': ('pip._vendor.pygments.lexers.grammar_notation', 'PEG', ('peg',), ('*.peg',), ('text/x-peg',)),\n    'Perl6Lexer': ('pip._vendor.pygments.lexers.perl', 'Perl6', ('perl6', 'pl6', 'raku'), ('*.pl', '*.pm', '*.nqp', '*.p6', '*.6pl', '*.p6l', '*.pl6', '*.6pm', '*.p6m', '*.pm6', '*.t', '*.raku', '*.rakumod', '*.rakutest', '*.rakudoc'), ('text/x-perl6', 'application/x-perl6')),\n    'PerlLexer': ('pip._vendor.pygments.lexers.perl', 'Perl', ('perl', 'pl'), ('*.pl', '*.pm', '*.t', '*.perl'), ('text/x-perl', 'application/x-perl')),\n    'PhixLexer': ('pip._vendor.pygments.lexers.phix', 'Phix', ('phix',), ('*.exw',), ('text/x-phix',)),\n    'PhpLexer': ('pip._vendor.pygments.lexers.php', 'PHP', ('php', 'php3', 'php4', 'php5'), ('*.php', '*.php[345]', '*.inc'), ('text/x-php',)),\n    'PigLexer': ('pip._vendor.pygments.lexers.jvm', 'Pig', ('pig',), ('*.pig',), ('text/x-pig',)),\n    'PikeLexer': ('pip._vendor.pygments.lexers.c_like', 'Pike', ('pike',), ('*.pike', '*.pmod'), ('text/x-pike',)),\n    'PkgConfigLexer': ('pip._vendor.pygments.lexers.configs', 'PkgConfig', ('pkgconfig',), ('*.pc',), ()),\n    'PlPgsqlLexer': ('pip._vendor.pygments.lexers.sql', 'PL/pgSQL', ('plpgsql',), (), ('text/x-plpgsql',)),\n    'PointlessLexer': ('pip._vendor.pygments.lexers.pointless', 'Pointless', ('pointless',), ('*.ptls',), ()),\n    'PonyLexer': ('pip._vendor.pygments.lexers.pony', 'Pony', ('pony',), ('*.pony',), ()),\n    'PortugolLexer': ('pip._vendor.pygments.lexers.pascal', 'Portugol', ('portugol',), ('*.alg', '*.portugol'), ()),\n    'PostScriptLexer': ('pip._vendor.pygments.lexers.graphics', 'PostScript', ('postscript', 'postscr'), ('*.ps', '*.eps'), ('application/postscript',)),\n    'PostgresConsoleLexer': ('pip._vendor.pygments.lexers.sql', 'PostgreSQL console (psql)', ('psql', 'postgresql-console', 'postgres-console'), (), ('text/x-postgresql-psql',)),\n    'PostgresExplainLexer': ('pip._vendor.pygments.lexers.sql', 'PostgreSQL EXPLAIN dialect', ('postgres-explain',), ('*.explain',), ('text/x-postgresql-explain',)),\n    'PostgresLexer': ('pip._vendor.pygments.lexers.sql', 'PostgreSQL SQL dialect', ('postgresql', 'postgres'), (), ('text/x-postgresql',)),\n    'PovrayLexer': ('pip._vendor.pygments.lexers.graphics', 'POVRay', ('pov',), ('*.pov', '*.inc'), ('text/x-povray',)),\n    'PowerShellLexer': ('pip._vendor.pygments.lexers.shell', 'PowerShell', ('powershell', 'pwsh', 'posh', 'ps1', 'psm1'), ('*.ps1', '*.psm1'), ('text/x-powershell',)),\n    'PowerShellSessionLexer': ('pip._vendor.pygments.lexers.shell', 'PowerShell Session', ('pwsh-session', 'ps1con'), (), ()),\n    'PraatLexer': ('pip._vendor.pygments.lexers.praat', 'Praat', ('praat',), ('*.praat', '*.proc', '*.psc'), ()),\n    'ProcfileLexer': ('pip._vendor.pygments.lexers.procfile', 'Procfile', ('procfile',), ('Procfile',), ()),\n    'PrologLexer': ('pip._vendor.pygments.lexers.prolog', 'Prolog', ('prolog',), ('*.ecl', '*.prolog', '*.pro', '*.pl'), ('text/x-prolog',)),\n    'PromQLLexer': ('pip._vendor.pygments.lexers.promql', 'PromQL', ('promql',), ('*.promql',), ()),\n    'PromelaLexer': ('pip._vendor.pygments.lexers.c_like', 'Promela', ('promela',), ('*.pml', '*.prom', '*.prm', '*.promela', '*.pr', '*.pm'), ('text/x-promela',)),\n    'PropertiesLexer': ('pip._vendor.pygments.lexers.configs', 'Properties', ('properties', 'jproperties'), ('*.properties',), ('text/x-java-properties',)),\n    'ProtoBufLexer': ('pip._vendor.pygments.lexers.dsls', 'Protocol Buffer', ('protobuf', 'proto'), ('*.proto',), ()),\n    'PrqlLexer': ('pip._vendor.pygments.lexers.prql', 'PRQL', ('prql',), ('*.prql',), ('application/prql', 'application/x-prql')),\n    'PsyshConsoleLexer': ('pip._vendor.pygments.lexers.php', 'PsySH console session for PHP', ('psysh',), (), ()),\n    'PtxLexer': ('pip._vendor.pygments.lexers.ptx', 'PTX', ('ptx',), ('*.ptx',), ('text/x-ptx',)),\n    'PugLexer': ('pip._vendor.pygments.lexers.html', 'Pug', ('pug', 'jade'), ('*.pug', '*.jade'), ('text/x-pug', 'text/x-jade')),\n    'PuppetLexer': ('pip._vendor.pygments.lexers.dsls', 'Puppet', ('puppet',), ('*.pp',), ()),\n    'PyPyLogLexer': ('pip._vendor.pygments.lexers.console', 'PyPy Log', ('pypylog', 'pypy'), ('*.pypylog',), ('application/x-pypylog',)),\n    'Python2Lexer': ('pip._vendor.pygments.lexers.python', 'Python 2.x', ('python2', 'py2'), (), ('text/x-python2', 'application/x-python2')),\n    'Python2TracebackLexer': ('pip._vendor.pygments.lexers.python', 'Python 2.x Traceback', ('py2tb',), ('*.py2tb',), ('text/x-python2-traceback',)),\n    'PythonConsoleLexer': ('pip._vendor.pygments.lexers.python', 'Python console session', ('pycon', 'python-console'), (), ('text/x-python-doctest',)),\n    'PythonLexer': ('pip._vendor.pygments.lexers.python', 'Python', ('python', 'py', 'sage', 'python3', 'py3', 'bazel', 'starlark'), ('*.py', '*.pyw', '*.pyi', '*.jy', '*.sage', '*.sc', 'SConstruct', 'SConscript', '*.bzl', 'BUCK', 'BUILD', 'BUILD.bazel', 'WORKSPACE', '*.tac'), ('text/x-python', 'application/x-python', 'text/x-python3', 'application/x-python3')),\n    'PythonTracebackLexer': ('pip._vendor.pygments.lexers.python', 'Python Traceback', ('pytb', 'py3tb'), ('*.pytb', '*.py3tb'), ('text/x-python-traceback', 'text/x-python3-traceback')),\n    'PythonUL4Lexer': ('pip._vendor.pygments.lexers.ul4', 'Python+UL4', ('py+ul4',), ('*.pyul4',), ()),\n    'QBasicLexer': ('pip._vendor.pygments.lexers.basic', 'QBasic', ('qbasic', 'basic'), ('*.BAS', '*.bas'), ('text/basic',)),\n    'QLexer': ('pip._vendor.pygments.lexers.q', 'Q', ('q',), ('*.q',), ()),\n    'QVToLexer': ('pip._vendor.pygments.lexers.qvt', 'QVTO', ('qvto', 'qvt'), ('*.qvto',), ()),\n    'QlikLexer': ('pip._vendor.pygments.lexers.qlik', 'Qlik', ('qlik', 'qlikview', 'qliksense', 'qlikscript'), ('*.qvs', '*.qvw'), ()),\n    'QmlLexer': ('pip._vendor.pygments.lexers.webmisc', 'QML', ('qml', 'qbs'), ('*.qml', '*.qbs'), ('application/x-qml', 'application/x-qt.qbs+qml')),\n    'RConsoleLexer': ('pip._vendor.pygments.lexers.r', 'RConsole', ('rconsole', 'rout'), ('*.Rout',), ()),\n    'RNCCompactLexer': ('pip._vendor.pygments.lexers.rnc', 'Relax-NG Compact', ('rng-compact', 'rnc'), ('*.rnc',), ()),\n    'RPMSpecLexer': ('pip._vendor.pygments.lexers.installers', 'RPMSpec', ('spec',), ('*.spec',), ('text/x-rpm-spec',)),\n    'RacketLexer': ('pip._vendor.pygments.lexers.lisp', 'Racket', ('racket', 'rkt'), ('*.rkt', '*.rktd', '*.rktl'), ('text/x-racket', 'application/x-racket')),\n    'RagelCLexer': ('pip._vendor.pygments.lexers.parsers', 'Ragel in C Host', ('ragel-c',), ('*.rl',), ()),\n    'RagelCppLexer': ('pip._vendor.pygments.lexers.parsers', 'Ragel in CPP Host', ('ragel-cpp',), ('*.rl',), ()),\n    'RagelDLexer': ('pip._vendor.pygments.lexers.parsers', 'Ragel in D Host', ('ragel-d',), ('*.rl',), ()),\n    'RagelEmbeddedLexer': ('pip._vendor.pygments.lexers.parsers', 'Embedded Ragel', ('ragel-em',), ('*.rl',), ()),\n    'RagelJavaLexer': ('pip._vendor.pygments.lexers.parsers', 'Ragel in Java Host', ('ragel-java',), ('*.rl',), ()),\n    'RagelLexer': ('pip._vendor.pygments.lexers.parsers', 'Ragel', ('ragel',), (), ()),\n    'RagelObjectiveCLexer': ('pip._vendor.pygments.lexers.parsers', 'Ragel in Objective C Host', ('ragel-objc',), ('*.rl',), ()),\n    'RagelRubyLexer': ('pip._vendor.pygments.lexers.parsers', 'Ragel in Ruby Host', ('ragel-ruby', 'ragel-rb'), ('*.rl',), ()),\n    'RawTokenLexer': ('pip._vendor.pygments.lexers.special', 'Raw token data', (), (), ('application/x-pygments-tokens',)),\n    'RdLexer': ('pip._vendor.pygments.lexers.r', 'Rd', ('rd',), ('*.Rd',), ('text/x-r-doc',)),\n    'ReasonLexer': ('pip._vendor.pygments.lexers.ml', 'ReasonML', ('reasonml', 'reason'), ('*.re', '*.rei'), ('text/x-reasonml',)),\n    'RebolLexer': ('pip._vendor.pygments.lexers.rebol', 'REBOL', ('rebol',), ('*.r', '*.r3', '*.reb'), ('text/x-rebol',)),\n    'RedLexer': ('pip._vendor.pygments.lexers.rebol', 'Red', ('red', 'red/system'), ('*.red', '*.reds'), ('text/x-red', 'text/x-red-system')),\n    'RedcodeLexer': ('pip._vendor.pygments.lexers.esoteric', 'Redcode', ('redcode',), ('*.cw',), ()),\n    'RegeditLexer': ('pip._vendor.pygments.lexers.configs', 'reg', ('registry',), ('*.reg',), ('text/x-windows-registry',)),\n    'ResourceLexer': ('pip._vendor.pygments.lexers.resource', 'ResourceBundle', ('resourcebundle', 'resource'), (), ()),\n    'RexxLexer': ('pip._vendor.pygments.lexers.scripting', 'Rexx', ('rexx', 'arexx'), ('*.rexx', '*.rex', '*.rx', '*.arexx'), ('text/x-rexx',)),\n    'RhtmlLexer': ('pip._vendor.pygments.lexers.templates', 'RHTML', ('rhtml', 'html+erb', 'html+ruby'), ('*.rhtml',), ('text/html+ruby',)),\n    'RideLexer': ('pip._vendor.pygments.lexers.ride', 'Ride', ('ride',), ('*.ride',), ('text/x-ride',)),\n    'RitaLexer': ('pip._vendor.pygments.lexers.rita', 'Rita', ('rita',), ('*.rita',), ('text/rita',)),\n    'RoboconfGraphLexer': ('pip._vendor.pygments.lexers.roboconf', 'Roboconf Graph', ('roboconf-graph',), ('*.graph',), ()),\n    'RoboconfInstancesLexer': ('pip._vendor.pygments.lexers.roboconf', 'Roboconf Instances', ('roboconf-instances',), ('*.instances',), ()),\n    'RobotFrameworkLexer': ('pip._vendor.pygments.lexers.robotframework', 'RobotFramework', ('robotframework',), ('*.robot', '*.resource'), ('text/x-robotframework',)),\n    'RqlLexer': ('pip._vendor.pygments.lexers.sql', 'RQL', ('rql',), ('*.rql',), ('text/x-rql',)),\n    'RslLexer': ('pip._vendor.pygments.lexers.dsls', 'RSL', ('rsl',), ('*.rsl',), ('text/rsl',)),\n    'RstLexer': ('pip._vendor.pygments.lexers.markup', 'reStructuredText', ('restructuredtext', 'rst', 'rest'), ('*.rst', '*.rest'), ('text/x-rst', 'text/prs.fallenstein.rst')),\n    'RtsLexer': ('pip._vendor.pygments.lexers.trafficscript', 'TrafficScript', ('trafficscript', 'rts'), ('*.rts',), ()),\n    'RubyConsoleLexer': ('pip._vendor.pygments.lexers.ruby', 'Ruby irb session', ('rbcon', 'irb'), (), ('text/x-ruby-shellsession',)),\n    'RubyLexer': ('pip._vendor.pygments.lexers.ruby', 'Ruby', ('ruby', 'rb', 'duby'), ('*.rb', '*.rbw', 'Rakefile', '*.rake', '*.gemspec', '*.rbx', '*.duby', 'Gemfile', 'Vagrantfile'), ('text/x-ruby', 'application/x-ruby')),\n    'RustLexer': ('pip._vendor.pygments.lexers.rust', 'Rust', ('rust', 'rs'), ('*.rs', '*.rs.in'), ('text/rust', 'text/x-rust')),\n    'SASLexer': ('pip._vendor.pygments.lexers.sas', 'SAS', ('sas',), ('*.SAS', '*.sas'), ('text/x-sas', 'text/sas', 'application/x-sas')),\n    'SLexer': ('pip._vendor.pygments.lexers.r', 'S', ('splus', 's', 'r'), ('*.S', '*.R', '.Rhistory', '.Rprofile', '.Renviron'), ('text/S-plus', 'text/S', 'text/x-r-source', 'text/x-r', 'text/x-R', 'text/x-r-history', 'text/x-r-profile')),\n    'SMLLexer': ('pip._vendor.pygments.lexers.ml', 'Standard ML', ('sml',), ('*.sml', '*.sig', '*.fun'), ('text/x-standardml', 'application/x-standardml')),\n    'SNBTLexer': ('pip._vendor.pygments.lexers.minecraft', 'SNBT', ('snbt',), ('*.snbt',), ('text/snbt',)),\n    'SarlLexer': ('pip._vendor.pygments.lexers.jvm', 'SARL', ('sarl',), ('*.sarl',), ('text/x-sarl',)),\n    'SassLexer': ('pip._vendor.pygments.lexers.css', 'Sass', ('sass',), ('*.sass',), ('text/x-sass',)),\n    'SaviLexer': ('pip._vendor.pygments.lexers.savi', 'Savi', ('savi',), ('*.savi',), ()),\n    'ScalaLexer': ('pip._vendor.pygments.lexers.jvm', 'Scala', ('scala',), ('*.scala',), ('text/x-scala',)),\n    'ScamlLexer': ('pip._vendor.pygments.lexers.html', 'Scaml', ('scaml',), ('*.scaml',), ('text/x-scaml',)),\n    'ScdocLexer': ('pip._vendor.pygments.lexers.scdoc', 'scdoc', ('scdoc', 'scd'), ('*.scd', '*.scdoc'), ()),\n    'SchemeLexer': ('pip._vendor.pygments.lexers.lisp', 'Scheme', ('scheme', 'scm'), ('*.scm', '*.ss'), ('text/x-scheme', 'application/x-scheme')),\n    'ScilabLexer': ('pip._vendor.pygments.lexers.matlab', 'Scilab', ('scilab',), ('*.sci', '*.sce', '*.tst'), ('text/scilab',)),\n    'ScssLexer': ('pip._vendor.pygments.lexers.css', 'SCSS', ('scss',), ('*.scss',), ('text/x-scss',)),\n    'SedLexer': ('pip._vendor.pygments.lexers.textedit', 'Sed', ('sed', 'gsed', 'ssed'), ('*.sed', '*.[gs]sed'), ('text/x-sed',)),\n    'ShExCLexer': ('pip._vendor.pygments.lexers.rdf', 'ShExC', ('shexc', 'shex'), ('*.shex',), ('text/shex',)),\n    'ShenLexer': ('pip._vendor.pygments.lexers.lisp', 'Shen', ('shen',), ('*.shen',), ('text/x-shen', 'application/x-shen')),\n    'SieveLexer': ('pip._vendor.pygments.lexers.sieve', 'Sieve', ('sieve',), ('*.siv', '*.sieve'), ()),\n    'SilverLexer': ('pip._vendor.pygments.lexers.verification', 'Silver', ('silver',), ('*.sil', '*.vpr'), ()),\n    'SingularityLexer': ('pip._vendor.pygments.lexers.configs', 'Singularity', ('singularity',), ('*.def', 'Singularity'), ()),\n    'SlashLexer': ('pip._vendor.pygments.lexers.slash', 'Slash', ('slash',), ('*.sla',), ()),\n    'SlimLexer': ('pip._vendor.pygments.lexers.webmisc', 'Slim', ('slim',), ('*.slim',), ('text/x-slim',)),\n    'SlurmBashLexer': ('pip._vendor.pygments.lexers.shell', 'Slurm', ('slurm', 'sbatch'), ('*.sl',), ()),\n    'SmaliLexer': ('pip._vendor.pygments.lexers.dalvik', 'Smali', ('smali',), ('*.smali',), ('text/smali',)),\n    'SmalltalkLexer': ('pip._vendor.pygments.lexers.smalltalk', 'Smalltalk', ('smalltalk', 'squeak', 'st'), ('*.st',), ('text/x-smalltalk',)),\n    'SmartGameFormatLexer': ('pip._vendor.pygments.lexers.sgf', 'SmartGameFormat', ('sgf',), ('*.sgf',), ()),\n    'SmartyLexer': ('pip._vendor.pygments.lexers.templates', 'Smarty', ('smarty',), ('*.tpl',), ('application/x-smarty',)),\n    'SmithyLexer': ('pip._vendor.pygments.lexers.smithy', 'Smithy', ('smithy',), ('*.smithy',), ()),\n    'SnobolLexer': ('pip._vendor.pygments.lexers.snobol', 'Snobol', ('snobol',), ('*.snobol',), ('text/x-snobol',)),\n    'SnowballLexer': ('pip._vendor.pygments.lexers.dsls', 'Snowball', ('snowball',), ('*.sbl',), ()),\n    'SolidityLexer': ('pip._vendor.pygments.lexers.solidity', 'Solidity', ('solidity',), ('*.sol',), ()),\n    'SoongLexer': ('pip._vendor.pygments.lexers.soong', 'Soong', ('androidbp', 'bp', 'soong'), ('Android.bp',), ()),\n    'SophiaLexer': ('pip._vendor.pygments.lexers.sophia', 'Sophia', ('sophia',), ('*.aes',), ()),\n    'SourcePawnLexer': ('pip._vendor.pygments.lexers.pawn', 'SourcePawn', ('sp',), ('*.sp',), ('text/x-sourcepawn',)),\n    'SourcesListLexer': ('pip._vendor.pygments.lexers.installers', 'Debian Sourcelist', ('debsources', 'sourceslist', 'sources.list'), ('sources.list',), ()),\n    'SparqlLexer': ('pip._vendor.pygments.lexers.rdf', 'SPARQL', ('sparql',), ('*.rq', '*.sparql'), ('application/sparql-query',)),\n    'SpiceLexer': ('pip._vendor.pygments.lexers.spice', 'Spice', ('spice', 'spicelang'), ('*.spice',), ('text/x-spice',)),\n    'SqlJinjaLexer': ('pip._vendor.pygments.lexers.templates', 'SQL+Jinja', ('sql+jinja',), ('*.sql', '*.sql.j2', '*.sql.jinja2'), ()),\n    'SqlLexer': ('pip._vendor.pygments.lexers.sql', 'SQL', ('sql',), ('*.sql',), ('text/x-sql',)),\n    'SqliteConsoleLexer': ('pip._vendor.pygments.lexers.sql', 'sqlite3con', ('sqlite3',), ('*.sqlite3-console',), ('text/x-sqlite3-console',)),\n    'SquidConfLexer': ('pip._vendor.pygments.lexers.configs', 'SquidConf', ('squidconf', 'squid.conf', 'squid'), ('squid.conf',), ('text/x-squidconf',)),\n    'SrcinfoLexer': ('pip._vendor.pygments.lexers.srcinfo', 'Srcinfo', ('srcinfo',), ('.SRCINFO',), ()),\n    'SspLexer': ('pip._vendor.pygments.lexers.templates', 'Scalate Server Page', ('ssp',), ('*.ssp',), ('application/x-ssp',)),\n    'StanLexer': ('pip._vendor.pygments.lexers.modeling', 'Stan', ('stan',), ('*.stan',), ()),\n    'StataLexer': ('pip._vendor.pygments.lexers.stata', 'Stata', ('stata', 'do'), ('*.do', '*.ado'), ('text/x-stata', 'text/stata', 'application/x-stata')),\n    'SuperColliderLexer': ('pip._vendor.pygments.lexers.supercollider', 'SuperCollider', ('supercollider', 'sc'), ('*.sc', '*.scd'), ('application/supercollider', 'text/supercollider')),\n    'SwiftLexer': ('pip._vendor.pygments.lexers.objective', 'Swift', ('swift',), ('*.swift',), ('text/x-swift',)),\n    'SwigLexer': ('pip._vendor.pygments.lexers.c_like', 'SWIG', ('swig',), ('*.swg', '*.i'), ('text/swig',)),\n    'SystemVerilogLexer': ('pip._vendor.pygments.lexers.hdl', 'systemverilog', ('systemverilog', 'sv'), ('*.sv', '*.svh'), ('text/x-systemverilog',)),\n    'SystemdLexer': ('pip._vendor.pygments.lexers.configs', 'Systemd', ('systemd',), ('*.service', '*.socket', '*.device', '*.mount', '*.automount', '*.swap', '*.target', '*.path', '*.timer', '*.slice', '*.scope'), ()),\n    'TAPLexer': ('pip._vendor.pygments.lexers.testing', 'TAP', ('tap',), ('*.tap',), ()),\n    'TNTLexer': ('pip._vendor.pygments.lexers.tnt', 'Typographic Number Theory', ('tnt',), ('*.tnt',), ()),\n    'TOMLLexer': ('pip._vendor.pygments.lexers.configs', 'TOML', ('toml',), ('*.toml', 'Pipfile', 'poetry.lock'), ('application/toml',)),\n    'TactLexer': ('pip._vendor.pygments.lexers.tact', 'Tact', ('tact',), ('*.tact',), ()),\n    'Tads3Lexer': ('pip._vendor.pygments.lexers.int_fiction', 'TADS 3', ('tads3',), ('*.t',), ()),\n    'TalLexer': ('pip._vendor.pygments.lexers.tal', 'Tal', ('tal', 'uxntal'), ('*.tal',), ('text/x-uxntal',)),\n    'TasmLexer': ('pip._vendor.pygments.lexers.asm', 'TASM', ('tasm',), ('*.asm', '*.ASM', '*.tasm'), ('text/x-tasm',)),\n    'TclLexer': ('pip._vendor.pygments.lexers.tcl', 'Tcl', ('tcl',), ('*.tcl', '*.rvt'), ('text/x-tcl', 'text/x-script.tcl', 'application/x-tcl')),\n    'TcshLexer': ('pip._vendor.pygments.lexers.shell', 'Tcsh', ('tcsh', 'csh'), ('*.tcsh', '*.csh'), ('application/x-csh',)),\n    'TcshSessionLexer': ('pip._vendor.pygments.lexers.shell', 'Tcsh Session', ('tcshcon',), (), ()),\n    'TeaTemplateLexer': ('pip._vendor.pygments.lexers.templates', 'Tea', ('tea',), ('*.tea',), ('text/x-tea',)),\n    'TealLexer': ('pip._vendor.pygments.lexers.teal', 'teal', ('teal',), ('*.teal',), ()),\n    'TeraTermLexer': ('pip._vendor.pygments.lexers.teraterm', 'Tera Term macro', ('teratermmacro', 'teraterm', 'ttl'), ('*.ttl',), ('text/x-teratermmacro',)),\n    'TermcapLexer': ('pip._vendor.pygments.lexers.configs', 'Termcap', ('termcap',), ('termcap', 'termcap.src'), ()),\n    'TerminfoLexer': ('pip._vendor.pygments.lexers.configs', 'Terminfo', ('terminfo',), ('terminfo', 'terminfo.src'), ()),\n    'TerraformLexer': ('pip._vendor.pygments.lexers.configs', 'Terraform', ('terraform', 'tf', 'hcl'), ('*.tf', '*.hcl'), ('application/x-tf', 'application/x-terraform')),\n    'TexLexer': ('pip._vendor.pygments.lexers.markup', 'TeX', ('tex', 'latex'), ('*.tex', '*.aux', '*.toc'), ('text/x-tex', 'text/x-latex')),\n    'TextLexer': ('pip._vendor.pygments.lexers.special', 'Text only', ('text',), ('*.txt',), ('text/plain',)),\n    'ThingsDBLexer': ('pip._vendor.pygments.lexers.thingsdb', 'ThingsDB', ('ti', 'thingsdb'), ('*.ti',), ()),\n    'ThriftLexer': ('pip._vendor.pygments.lexers.dsls', 'Thrift', ('thrift',), ('*.thrift',), ('application/x-thrift',)),\n    'TiddlyWiki5Lexer': ('pip._vendor.pygments.lexers.markup', 'tiddler', ('tid',), ('*.tid',), ('text/vnd.tiddlywiki',)),\n    'TlbLexer': ('pip._vendor.pygments.lexers.tlb', 'Tl-b', ('tlb',), ('*.tlb',), ()),\n    'TlsLexer': ('pip._vendor.pygments.lexers.tls', 'TLS Presentation Language', ('tls',), (), ()),\n    'TodotxtLexer': ('pip._vendor.pygments.lexers.textfmts', 'Todotxt', ('todotxt',), ('todo.txt', '*.todotxt'), ('text/x-todo',)),\n    'TransactSqlLexer': ('pip._vendor.pygments.lexers.sql', 'Transact-SQL', ('tsql', 't-sql'), ('*.sql',), ('text/x-tsql',)),\n    'TreetopLexer': ('pip._vendor.pygments.lexers.parsers', 'Treetop', ('treetop',), ('*.treetop', '*.tt'), ()),\n    'TurtleLexer': ('pip._vendor.pygments.lexers.rdf', 'Turtle', ('turtle',), ('*.ttl',), ('text/turtle', 'application/x-turtle')),\n    'TwigHtmlLexer': ('pip._vendor.pygments.lexers.templates', 'HTML+Twig', ('html+twig',), ('*.twig',), ('text/html+twig',)),\n    'TwigLexer': ('pip._vendor.pygments.lexers.templates', 'Twig', ('twig',), (), ('application/x-twig',)),\n    'TypeScriptLexer': ('pip._vendor.pygments.lexers.javascript', 'TypeScript', ('typescript', 'ts'), ('*.ts',), ('application/x-typescript', 'text/x-typescript')),\n    'TypoScriptCssDataLexer': ('pip._vendor.pygments.lexers.typoscript', 'TypoScriptCssData', ('typoscriptcssdata',), (), ()),\n    'TypoScriptHtmlDataLexer': ('pip._vendor.pygments.lexers.typoscript', 'TypoScriptHtmlData', ('typoscripthtmldata',), (), ()),\n    'TypoScriptLexer': ('pip._vendor.pygments.lexers.typoscript', 'TypoScript', ('typoscript',), ('*.typoscript',), ('text/x-typoscript',)),\n    'TypstLexer': ('pip._vendor.pygments.lexers.typst', 'Typst', ('typst',), ('*.typ',), ('text/x-typst',)),\n    'UL4Lexer': ('pip._vendor.pygments.lexers.ul4', 'UL4', ('ul4',), ('*.ul4',), ()),\n    'UcodeLexer': ('pip._vendor.pygments.lexers.unicon', 'ucode', ('ucode',), ('*.u', '*.u1', '*.u2'), ()),\n    'UniconLexer': ('pip._vendor.pygments.lexers.unicon', 'Unicon', ('unicon',), ('*.icn',), ('text/unicon',)),\n    'UnixConfigLexer': ('pip._vendor.pygments.lexers.configs', 'Unix/Linux config files', ('unixconfig', 'linuxconfig'), (), ()),\n    'UrbiscriptLexer': ('pip._vendor.pygments.lexers.urbi', 'UrbiScript', ('urbiscript',), ('*.u',), ('application/x-urbiscript',)),\n    'UrlEncodedLexer': ('pip._vendor.pygments.lexers.html', 'urlencoded', ('urlencoded',), (), ('application/x-www-form-urlencoded',)),\n    'UsdLexer': ('pip._vendor.pygments.lexers.usd', 'USD', ('usd', 'usda'), ('*.usd', '*.usda'), ()),\n    'VBScriptLexer': ('pip._vendor.pygments.lexers.basic', 'VBScript', ('vbscript',), ('*.vbs', '*.VBS'), ()),\n    'VCLLexer': ('pip._vendor.pygments.lexers.varnish', 'VCL', ('vcl',), ('*.vcl',), ('text/x-vclsrc',)),\n    'VCLSnippetLexer': ('pip._vendor.pygments.lexers.varnish', 'VCLSnippets', ('vclsnippets', 'vclsnippet'), (), ('text/x-vclsnippet',)),\n    'VCTreeStatusLexer': ('pip._vendor.pygments.lexers.console', 'VCTreeStatus', ('vctreestatus',), (), ()),\n    'VGLLexer': ('pip._vendor.pygments.lexers.dsls', 'VGL', ('vgl',), ('*.rpf',), ()),\n    'ValaLexer': ('pip._vendor.pygments.lexers.c_like', 'Vala', ('vala', 'vapi'), ('*.vala', '*.vapi'), ('text/x-vala',)),\n    'VbNetAspxLexer': ('pip._vendor.pygments.lexers.dotnet', 'aspx-vb', ('aspx-vb',), ('*.aspx', '*.asax', '*.ascx', '*.ashx', '*.asmx', '*.axd'), ()),\n    'VbNetLexer': ('pip._vendor.pygments.lexers.dotnet', 'VB.net', ('vb.net', 'vbnet', 'lobas', 'oobas', 'sobas', 'visual-basic', 'visualbasic'), ('*.vb', '*.bas'), ('text/x-vbnet', 'text/x-vba')),\n    'VelocityHtmlLexer': ('pip._vendor.pygments.lexers.templates', 'HTML+Velocity', ('html+velocity',), (), ('text/html+velocity',)),\n    'VelocityLexer': ('pip._vendor.pygments.lexers.templates', 'Velocity', ('velocity',), ('*.vm', '*.fhtml'), ()),\n    'VelocityXmlLexer': ('pip._vendor.pygments.lexers.templates', 'XML+Velocity', ('xml+velocity',), (), ('application/xml+velocity',)),\n    'VerifpalLexer': ('pip._vendor.pygments.lexers.verifpal', 'Verifpal', ('verifpal',), ('*.vp',), ('text/x-verifpal',)),\n    'VerilogLexer': ('pip._vendor.pygments.lexers.hdl', 'verilog', ('verilog', 'v'), ('*.v',), ('text/x-verilog',)),\n    'VhdlLexer': ('pip._vendor.pygments.lexers.hdl', 'vhdl', ('vhdl',), ('*.vhdl', '*.vhd'), ('text/x-vhdl',)),\n    'VimLexer': ('pip._vendor.pygments.lexers.textedit', 'VimL', ('vim',), ('*.vim', '.vimrc', '.exrc', '.gvimrc', '_vimrc', '_exrc', '_gvimrc', 'vimrc', 'gvimrc'), ('text/x-vim',)),\n    'VisualPrologGrammarLexer': ('pip._vendor.pygments.lexers.vip', 'Visual Prolog Grammar', ('visualprologgrammar',), ('*.vipgrm',), ()),\n    'VisualPrologLexer': ('pip._vendor.pygments.lexers.vip', 'Visual Prolog', ('visualprolog',), ('*.pro', '*.cl', '*.i', '*.pack', '*.ph'), ()),\n    'VyperLexer': ('pip._vendor.pygments.lexers.vyper', 'Vyper', ('vyper',), ('*.vy',), ()),\n    'WDiffLexer': ('pip._vendor.pygments.lexers.diff', 'WDiff', ('wdiff',), ('*.wdiff',), ()),\n    'WatLexer': ('pip._vendor.pygments.lexers.webassembly', 'WebAssembly', ('wast', 'wat'), ('*.wat', '*.wast'), ()),\n    'WebIDLLexer': ('pip._vendor.pygments.lexers.webidl', 'Web IDL', ('webidl',), ('*.webidl',), ()),\n    'WgslLexer': ('pip._vendor.pygments.lexers.wgsl', 'WebGPU Shading Language', ('wgsl',), ('*.wgsl',), ('text/wgsl',)),\n    'WhileyLexer': ('pip._vendor.pygments.lexers.whiley', 'Whiley', ('whiley',), ('*.whiley',), ('text/x-whiley',)),\n    'WikitextLexer': ('pip._vendor.pygments.lexers.markup', 'Wikitext', ('wikitext', 'mediawiki'), (), ('text/x-wiki',)),\n    'WoWTocLexer': ('pip._vendor.pygments.lexers.wowtoc', 'World of Warcraft TOC', ('wowtoc',), ('*.toc',), ()),\n    'WrenLexer': ('pip._vendor.pygments.lexers.wren', 'Wren', ('wren',), ('*.wren',), ()),\n    'X10Lexer': ('pip._vendor.pygments.lexers.x10', 'X10', ('x10', 'xten'), ('*.x10',), ('text/x-x10',)),\n    'XMLUL4Lexer': ('pip._vendor.pygments.lexers.ul4', 'XML+UL4', ('xml+ul4',), ('*.xmlul4',), ()),\n    'XQueryLexer': ('pip._vendor.pygments.lexers.webmisc', 'XQuery', ('xquery', 'xqy', 'xq', 'xql', 'xqm'), ('*.xqy', '*.xquery', '*.xq', '*.xql', '*.xqm'), ('text/xquery', 'application/xquery')),\n    'XmlDjangoLexer': ('pip._vendor.pygments.lexers.templates', 'XML+Django/Jinja', ('xml+django', 'xml+jinja'), ('*.xml.j2', '*.xml.jinja2'), ('application/xml+django', 'application/xml+jinja')),\n    'XmlErbLexer': ('pip._vendor.pygments.lexers.templates', 'XML+Ruby', ('xml+ruby', 'xml+erb'), (), ('application/xml+ruby',)),\n    'XmlLexer': ('pip._vendor.pygments.lexers.html', 'XML', ('xml',), ('*.xml', '*.xsl', '*.rss', '*.xslt', '*.xsd', '*.wsdl', '*.wsf'), ('text/xml', 'application/xml', 'image/svg+xml', 'application/rss+xml', 'application/atom+xml')),\n    'XmlPhpLexer': ('pip._vendor.pygments.lexers.templates', 'XML+PHP', ('xml+php',), (), ('application/xml+php',)),\n    'XmlSmartyLexer': ('pip._vendor.pygments.lexers.templates', 'XML+Smarty', ('xml+smarty',), (), ('application/xml+smarty',)),\n    'XorgLexer': ('pip._vendor.pygments.lexers.xorg', 'Xorg', ('xorg.conf',), ('xorg.conf',), ()),\n    'XppLexer': ('pip._vendor.pygments.lexers.dotnet', 'X++', ('xpp', 'x++'), ('*.xpp',), ()),\n    'XsltLexer': ('pip._vendor.pygments.lexers.html', 'XSLT', ('xslt',), ('*.xsl', '*.xslt', '*.xpl'), ('application/xsl+xml', 'application/xslt+xml')),\n    'XtendLexer': ('pip._vendor.pygments.lexers.jvm', 'Xtend', ('xtend',), ('*.xtend',), ('text/x-xtend',)),\n    'XtlangLexer': ('pip._vendor.pygments.lexers.lisp', 'xtlang', ('extempore',), ('*.xtm',), ()),\n    'YamlJinjaLexer': ('pip._vendor.pygments.lexers.templates', 'YAML+Jinja', ('yaml+jinja', 'salt', 'sls'), ('*.sls', '*.yaml.j2', '*.yml.j2', '*.yaml.jinja2', '*.yml.jinja2'), ('text/x-yaml+jinja', 'text/x-sls')),\n    'YamlLexer': ('pip._vendor.pygments.lexers.data', 'YAML', ('yaml',), ('*.yaml', '*.yml'), ('text/x-yaml',)),\n    'YangLexer': ('pip._vendor.pygments.lexers.yang', 'YANG', ('yang',), ('*.yang',), ('application/yang',)),\n    'YaraLexer': ('pip._vendor.pygments.lexers.yara', 'YARA', ('yara', 'yar'), ('*.yar',), ('text/x-yara',)),\n    'ZeekLexer': ('pip._vendor.pygments.lexers.dsls', 'Zeek', ('zeek', 'bro'), ('*.zeek', '*.bro'), ()),\n    'ZephirLexer': ('pip._vendor.pygments.lexers.php', 'Zephir', ('zephir',), ('*.zep',), ()),\n    'ZigLexer': ('pip._vendor.pygments.lexers.zig', 'Zig', ('zig',), ('*.zig',), ('text/zig',)),\n    'apdlexer': ('pip._vendor.pygments.lexers.apdlexer', 'ANSYS parametric design language', ('ansys', 'apdl'), ('*.ans',), ()),\n}\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/pygments/lexers/python.py","size":53687,"sha1":"14313f1ee64c0d3efe8e72338fe59925b836f544","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\n    pygments.lexers.python\n    ~~~~~~~~~~~~~~~~~~~~~~\n\n    Lexers for Python and related languages.\n\n    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nimport keyword\n\nfrom pip._vendor.pygments.lexer import DelegatingLexer, RegexLexer, include, \\\n    bygroups, using, default, words, combined, this\nfrom pip._vendor.pygments.util import get_bool_opt, shebang_matches\nfrom pip._vendor.pygments.token import Text, Comment, Operator, Keyword, Name, String, \\\n    Number, Punctuation, Generic, Other, Error, Whitespace\nfrom pip._vendor.pygments import unistring as uni\n\n__all__ = ['PythonLexer', 'PythonConsoleLexer', 'PythonTracebackLexer',\n           'Python2Lexer', 'Python2TracebackLexer',\n           'CythonLexer', 'DgLexer', 'NumPyLexer']\n\n\nclass PythonLexer(RegexLexer):\n    \"\"\"\n    For Python source code (version 3.x).\n\n    .. versionchanged:: 2.5\n       This is now the default ``PythonLexer``.  It is still available as the\n       alias ``Python3Lexer``.\n    \"\"\"\n\n    name = 'Python'\n    url = 'https://www.python.org'\n    aliases = ['python', 'py', 'sage', 'python3', 'py3', 'bazel', 'starlark']\n    filenames = [\n        '*.py',\n        '*.pyw',\n        # Type stubs\n        '*.pyi',\n        # Jython\n        '*.jy',\n        # Sage\n        '*.sage',\n        # SCons\n        '*.sc',\n        'SConstruct',\n        'SConscript',\n        # Skylark/Starlark (used by Bazel, Buck, and Pants)\n        '*.bzl',\n        'BUCK',\n        'BUILD',\n        'BUILD.bazel',\n        'WORKSPACE',\n        # Twisted Application infrastructure\n        '*.tac',\n    ]\n    mimetypes = ['text/x-python', 'application/x-python',\n                 'text/x-python3', 'application/x-python3']\n    version_added = '0.10'\n\n    uni_name = f\"[{uni.xid_start}][{uni.xid_continue}]*\"\n\n    def innerstring_rules(ttype):\n        return [\n            # the old style '%s' % (...) string formatting (still valid in Py3)\n            (r'%(\\(\\w+\\))?[-#0 +]*([0-9]+|[*])?(\\.([0-9]+|[*]))?'\n             '[hlL]?[E-GXc-giorsaux%]', String.Interpol),\n            # the new style '{}'.format(...) string formatting\n            (r'\\{'\n             r'((\\w+)((\\.\\w+)|(\\[[^\\]]+\\]))*)?'  # field name\n             r'(\\![sra])?'                       # conversion\n             r'(\\:(.?[<>=\\^])?[-+ ]?#?0?(\\d+)?,?(\\.\\d+)?[E-GXb-gnosx%]?)?'\n             r'\\}', String.Interpol),\n\n            # backslashes, quotes and formatting signs must be parsed one at a time\n            (r'[^\\\\\\'\"%{\\n]+', ttype),\n            (r'[\\'\"\\\\]', ttype),\n            # unhandled string formatting sign\n            (r'%|(\\{{1,2})', ttype)\n            # newlines are an error (use \"nl\" state)\n        ]\n\n    def fstring_rules(ttype):\n        return [\n            # Assuming that a '}' is the closing brace after format specifier.\n            # Sadly, this means that we won't detect syntax error. But it's\n            # more important to parse correct syntax correctly, than to\n            # highlight invalid syntax.\n            (r'\\}', String.Interpol),\n            (r'\\{', String.Interpol, 'expr-inside-fstring'),\n            # backslashes, quotes and formatting signs must be parsed one at a time\n            (r'[^\\\\\\'\"{}\\n]+', ttype),\n            (r'[\\'\"\\\\]', ttype),\n            # newlines are an error (use \"nl\" state)\n        ]\n\n    tokens = {\n        'root': [\n            (r'\\n', Whitespace),\n            (r'^(\\s*)([rRuUbB]{,2})(\"\"\"(?:.|\\n)*?\"\"\")',\n             bygroups(Whitespace, String.Affix, String.Doc)),\n            (r\"^(\\s*)([rRuUbB]{,2})('''(?:.|\\n)*?''')\",\n             bygroups(Whitespace, String.Affix, String.Doc)),\n            (r'\\A#!.+$', Comment.Hashbang),\n            (r'#.*$', Comment.Single),\n            (r'\\\\\\n', Text),\n            (r'\\\\', Text),\n            include('keywords'),\n            include('soft-keywords'),\n            (r'(def)((?:\\s|\\\\\\s)+)', bygroups(Keyword, Text), 'funcname'),\n            (r'(class)((?:\\s|\\\\\\s)+)', bygroups(Keyword, Text), 'classname'),\n            (r'(from)((?:\\s|\\\\\\s)+)', bygroups(Keyword.Namespace, Text),\n             'fromimport'),\n            (r'(import)((?:\\s|\\\\\\s)+)', bygroups(Keyword.Namespace, Text),\n             'import'),\n            include('expr'),\n        ],\n        'expr': [\n            # raw f-strings\n            ('(?i)(rf|fr)(\"\"\")',\n             bygroups(String.Affix, String.Double),\n             combined('rfstringescape', 'tdqf')),\n            (\"(?i)(rf|fr)(''')\",\n             bygroups(String.Affix, String.Single),\n             combined('rfstringescape', 'tsqf')),\n            ('(?i)(rf|fr)(\")',\n             bygroups(String.Affix, String.Double),\n             combined('rfstringescape', 'dqf')),\n            (\"(?i)(rf|fr)(')\",\n             bygroups(String.Affix, String.Single),\n             combined('rfstringescape', 'sqf')),\n            # non-raw f-strings\n            ('([fF])(\"\"\")', bygroups(String.Affix, String.Double),\n             combined('fstringescape', 'tdqf')),\n            (\"([fF])(''')\", bygroups(String.Affix, String.Single),\n             combined('fstringescape', 'tsqf')),\n            ('([fF])(\")', bygroups(String.Affix, String.Double),\n             combined('fstringescape', 'dqf')),\n            (\"([fF])(')\", bygroups(String.Affix, String.Single),\n             combined('fstringescape', 'sqf')),\n            # raw bytes and strings\n            ('(?i)(rb|br|r)(\"\"\")',\n             bygroups(String.Affix, String.Double), 'tdqs'),\n            (\"(?i)(rb|br|r)(''')\",\n             bygroups(String.Affix, String.Single), 'tsqs'),\n            ('(?i)(rb|br|r)(\")',\n             bygroups(String.Affix, String.Double), 'dqs'),\n            (\"(?i)(rb|br|r)(')\",\n             bygroups(String.Affix, String.Single), 'sqs'),\n            # non-raw strings\n            ('([uU]?)(\"\"\")', bygroups(String.Affix, String.Double),\n             combined('stringescape', 'tdqs')),\n            (\"([uU]?)(''')\", bygroups(String.Affix, String.Single),\n             combined('stringescape', 'tsqs')),\n            ('([uU]?)(\")', bygroups(String.Affix, String.Double),\n             combined('stringescape', 'dqs')),\n            (\"([uU]?)(')\", bygroups(String.Affix, String.Single),\n             combined('stringescape', 'sqs')),\n            # non-raw bytes\n            ('([bB])(\"\"\")', bygroups(String.Affix, String.Double),\n             combined('bytesescape', 'tdqs')),\n            (\"([bB])(''')\", bygroups(String.Affix, String.Single),\n             combined('bytesescape', 'tsqs')),\n            ('([bB])(\")', bygroups(String.Affix, String.Double),\n             combined('bytesescape', 'dqs')),\n            (\"([bB])(')\", bygroups(String.Affix, String.Single),\n             combined('bytesescape', 'sqs')),\n\n            (r'[^\\S\\n]+', Text),\n            include('numbers'),\n            (r'!=|==|<<|>>|:=|[-~+/*%=<>&^|.]', Operator),\n            (r'[]{}:(),;[]', Punctuation),\n            (r'(in|is|and|or|not)\\b', Operator.Word),\n            include('expr-keywords'),\n            include('builtins'),\n            include('magicfuncs'),\n            include('magicvars'),\n            include('name'),\n        ],\n        'expr-inside-fstring': [\n            (r'[{([]', Punctuation, 'expr-inside-fstring-inner'),\n            # without format specifier\n            (r'(=\\s*)?'         # debug (https://bugs.python.org/issue36817)\n             r'(\\![sraf])?'     # conversion\n             r'\\}', String.Interpol, '#pop'),\n            # with format specifier\n            # we'll catch the remaining '}' in the outer scope\n            (r'(=\\s*)?'         # debug (https://bugs.python.org/issue36817)\n             r'(\\![sraf])?'     # conversion\n             r':', String.Interpol, '#pop'),\n            (r'\\s+', Whitespace),  # allow new lines\n            include('expr'),\n        ],\n        'expr-inside-fstring-inner': [\n            (r'[{([]', Punctuation, 'expr-inside-fstring-inner'),\n            (r'[])}]', Punctuation, '#pop'),\n            (r'\\s+', Whitespace),  # allow new lines\n            include('expr'),\n        ],\n        'expr-keywords': [\n            # Based on https://docs.python.org/3/reference/expressions.html\n            (words((\n                'async for', 'await', 'else', 'for', 'if', 'lambda',\n                'yield', 'yield from'), suffix=r'\\b'),\n             Keyword),\n            (words(('True', 'False', 'None'), suffix=r'\\b'), Keyword.Constant),\n        ],\n        'keywords': [\n            (words((\n                'assert', 'async', 'await', 'break', 'continue', 'del', 'elif',\n                'else', 'except', 'finally', 'for', 'global', 'if', 'lambda',\n                'pass', 'raise', 'nonlocal', 'return', 'try', 'while', 'yield',\n                'yield from', 'as', 'with'), suffix=r'\\b'),\n             Keyword),\n            (words(('True', 'False', 'None'), suffix=r'\\b'), Keyword.Constant),\n        ],\n        'soft-keywords': [\n            # `match`, `case` and `_` soft keywords\n            (r'(^[ \\t]*)'              # at beginning of line + possible indentation\n             r'(match|case)\\b'         # a possible keyword\n             r'(?![ \\t]*(?:'           # not followed by...\n             r'[:,;=^&|@~)\\]}]|(?:' +  # characters and keywords that mean this isn't\n                                       # pattern matching (but None/True/False is ok)\n             r'|'.join(k for k in keyword.kwlist if k[0].islower()) + r')\\b))',\n             bygroups(Text, Keyword), 'soft-keywords-inner'),\n        ],\n        'soft-keywords-inner': [\n            # optional `_` keyword\n            (r'(\\s+)([^\\n_]*)(_\\b)', bygroups(Whitespace, using(this), Keyword)),\n            default('#pop')\n        ],\n        'builtins': [\n            (words((\n                '__import__', 'abs', 'aiter', 'all', 'any', 'bin', 'bool', 'bytearray',\n                'breakpoint', 'bytes', 'callable', 'chr', 'classmethod', 'compile',\n                'complex', 'delattr', 'dict', 'dir', 'divmod', 'enumerate', 'eval',\n                'filter', 'float', 'format', 'frozenset', 'getattr', 'globals',\n                'hasattr', 'hash', 'hex', 'id', 'input', 'int', 'isinstance',\n                'issubclass', 'iter', 'len', 'list', 'locals', 'map', 'max',\n                'memoryview', 'min', 'next', 'object', 'oct', 'open', 'ord', 'pow',\n                'print', 'property', 'range', 'repr', 'reversed', 'round', 'set',\n                'setattr', 'slice', 'sorted', 'staticmethod', 'str', 'sum', 'super',\n                'tuple', 'type', 'vars', 'zip'), prefix=r'(?<!\\.)', suffix=r'\\b'),\n             Name.Builtin),\n            (r'(?<!\\.)(self|Ellipsis|NotImplemented|cls)\\b', Name.Builtin.Pseudo),\n            (words((\n                'ArithmeticError', 'AssertionError', 'AttributeError',\n                'BaseException', 'BufferError', 'BytesWarning', 'DeprecationWarning',\n                'EOFError', 'EnvironmentError', 'Exception', 'FloatingPointError',\n                'FutureWarning', 'GeneratorExit', 'IOError', 'ImportError',\n                'ImportWarning', 'IndentationError', 'IndexError', 'KeyError',\n                'KeyboardInterrupt', 'LookupError', 'MemoryError', 'NameError',\n                'NotImplementedError', 'OSError', 'OverflowError',\n                'PendingDeprecationWarning', 'ReferenceError', 'ResourceWarning',\n                'RuntimeError', 'RuntimeWarning', 'StopIteration',\n                'SyntaxError', 'SyntaxWarning', 'SystemError', 'SystemExit',\n                'TabError', 'TypeError', 'UnboundLocalError', 'UnicodeDecodeError',\n                'UnicodeEncodeError', 'UnicodeError', 'UnicodeTranslateError',\n                'UnicodeWarning', 'UserWarning', 'ValueError', 'VMSError',\n                'Warning', 'WindowsError', 'ZeroDivisionError',\n                # new builtin exceptions from PEP 3151\n                'BlockingIOError', 'ChildProcessError', 'ConnectionError',\n                'BrokenPipeError', 'ConnectionAbortedError', 'ConnectionRefusedError',\n                'ConnectionResetError', 'FileExistsError', 'FileNotFoundError',\n                'InterruptedError', 'IsADirectoryError', 'NotADirectoryError',\n                'PermissionError', 'ProcessLookupError', 'TimeoutError',\n                # others new in Python 3\n                'StopAsyncIteration', 'ModuleNotFoundError', 'RecursionError',\n                'EncodingWarning'),\n                prefix=r'(?<!\\.)', suffix=r'\\b'),\n             Name.Exception),\n        ],\n        'magicfuncs': [\n            (words((\n                '__abs__', '__add__', '__aenter__', '__aexit__', '__aiter__',\n                '__and__', '__anext__', '__await__', '__bool__', '__bytes__',\n                '__call__', '__complex__', '__contains__', '__del__', '__delattr__',\n                '__delete__', '__delitem__', '__dir__', '__divmod__', '__enter__',\n                '__eq__', '__exit__', '__float__', '__floordiv__', '__format__',\n                '__ge__', '__get__', '__getattr__', '__getattribute__',\n                '__getitem__', '__gt__', '__hash__', '__iadd__', '__iand__',\n                '__ifloordiv__', '__ilshift__', '__imatmul__', '__imod__',\n                '__imul__', '__index__', '__init__', '__instancecheck__',\n                '__int__', '__invert__', '__ior__', '__ipow__', '__irshift__',\n                '__isub__', '__iter__', '__itruediv__', '__ixor__', '__le__',\n                '__len__', '__length_hint__', '__lshift__', '__lt__', '__matmul__',\n                '__missing__', '__mod__', '__mul__', '__ne__', '__neg__',\n                '__new__', '__next__', '__or__', '__pos__', '__pow__',\n                '__prepare__', '__radd__', '__rand__', '__rdivmod__', '__repr__',\n                '__reversed__', '__rfloordiv__', '__rlshift__', '__rmatmul__',\n                '__rmod__', '__rmul__', '__ror__', '__round__', '__rpow__',\n                '__rrshift__', '__rshift__', '__rsub__', '__rtruediv__',\n                '__rxor__', '__set__', '__setattr__', '__setitem__', '__str__',\n                '__sub__', '__subclasscheck__', '__truediv__',\n                '__xor__'), suffix=r'\\b'),\n             Name.Function.Magic),\n        ],\n        'magicvars': [\n            (words((\n                '__annotations__', '__bases__', '__class__', '__closure__',\n                '__code__', '__defaults__', '__dict__', '__doc__', '__file__',\n                '__func__', '__globals__', '__kwdefaults__', '__module__',\n                '__mro__', '__name__', '__objclass__', '__qualname__',\n                '__self__', '__slots__', '__weakref__'), suffix=r'\\b'),\n             Name.Variable.Magic),\n        ],\n        'numbers': [\n            (r'(\\d(?:_?\\d)*\\.(?:\\d(?:_?\\d)*)?|(?:\\d(?:_?\\d)*)?\\.\\d(?:_?\\d)*)'\n             r'([eE][+-]?\\d(?:_?\\d)*)?', Number.Float),\n            (r'\\d(?:_?\\d)*[eE][+-]?\\d(?:_?\\d)*j?', Number.Float),\n            (r'0[oO](?:_?[0-7])+', Number.Oct),\n            (r'0[bB](?:_?[01])+', Number.Bin),\n            (r'0[xX](?:_?[a-fA-F0-9])+', Number.Hex),\n            (r'\\d(?:_?\\d)*', Number.Integer),\n        ],\n        'name': [\n            (r'@' + uni_name, Name.Decorator),\n            (r'@', Operator),  # new matrix multiplication operator\n            (uni_name, Name),\n        ],\n        'funcname': [\n            include('magicfuncs'),\n            (uni_name, Name.Function, '#pop'),\n            default('#pop'),\n        ],\n        'classname': [\n            (uni_name, Name.Class, '#pop'),\n        ],\n        'import': [\n            (r'(\\s+)(as)(\\s+)', bygroups(Text, Keyword, Text)),\n            (r'\\.', Name.Namespace),\n            (uni_name, Name.Namespace),\n            (r'(\\s*)(,)(\\s*)', bygroups(Text, Operator, Text)),\n            default('#pop')  # all else: go back\n        ],\n        'fromimport': [\n            (r'(\\s+)(import)\\b', bygroups(Text, Keyword.Namespace), '#pop'),\n            (r'\\.', Name.Namespace),\n            # if None occurs here, it's \"raise x from None\", since None can\n            # never be a module name\n            (r'None\\b', Keyword.Constant, '#pop'),\n            (uni_name, Name.Namespace),\n            default('#pop'),\n        ],\n        'rfstringescape': [\n            (r'\\{\\{', String.Escape),\n            (r'\\}\\}', String.Escape),\n        ],\n        'fstringescape': [\n            include('rfstringescape'),\n            include('stringescape'),\n        ],\n        'bytesescape': [\n            (r'\\\\([\\\\abfnrtv\"\\']|\\n|x[a-fA-F0-9]{2}|[0-7]{1,3})', String.Escape)\n        ],\n        'stringescape': [\n            (r'\\\\(N\\{.*?\\}|u[a-fA-F0-9]{4}|U[a-fA-F0-9]{8})', String.Escape),\n            include('bytesescape')\n        ],\n        'fstrings-single': fstring_rules(String.Single),\n        'fstrings-double': fstring_rules(String.Double),\n        'strings-single': innerstring_rules(String.Single),\n        'strings-double': innerstring_rules(String.Double),\n        'dqf': [\n            (r'\"', String.Double, '#pop'),\n            (r'\\\\\\\\|\\\\\"|\\\\\\n', String.Escape),  # included here for raw strings\n            include('fstrings-double')\n        ],\n        'sqf': [\n            (r\"'\", String.Single, '#pop'),\n            (r\"\\\\\\\\|\\\\'|\\\\\\n\", String.Escape),  # included here for raw strings\n            include('fstrings-single')\n        ],\n        'dqs': [\n            (r'\"', String.Double, '#pop'),\n            (r'\\\\\\\\|\\\\\"|\\\\\\n', String.Escape),  # included here for raw strings\n            include('strings-double')\n        ],\n        'sqs': [\n            (r\"'\", String.Single, '#pop'),\n            (r\"\\\\\\\\|\\\\'|\\\\\\n\", String.Escape),  # included here for raw strings\n            include('strings-single')\n        ],\n        'tdqf': [\n            (r'\"\"\"', String.Double, '#pop'),\n            include('fstrings-double'),\n            (r'\\n', String.Double)\n        ],\n        'tsqf': [\n            (r\"'''\", String.Single, '#pop'),\n            include('fstrings-single'),\n            (r'\\n', String.Single)\n        ],\n        'tdqs': [\n            (r'\"\"\"', String.Double, '#pop'),\n            include('strings-double'),\n            (r'\\n', String.Double)\n        ],\n        'tsqs': [\n            (r\"'''\", String.Single, '#pop'),\n            include('strings-single'),\n            (r'\\n', String.Single)\n        ],\n    }\n\n    def analyse_text(text):\n        return shebang_matches(text, r'pythonw?(3(\\.\\d)?)?') or \\\n            'import ' in text[:1000]\n\n\nPython3Lexer = PythonLexer\n\n\nclass Python2Lexer(RegexLexer):\n    \"\"\"\n    For Python 2.x source code.\n\n    .. versionchanged:: 2.5\n       This class has been renamed from ``PythonLexer``.  ``PythonLexer`` now\n       refers to the Python 3 variant.  File name patterns like ``*.py`` have\n       been moved to Python 3 as well.\n    \"\"\"\n\n    name = 'Python 2.x'\n    url = 'https://www.python.org'\n    aliases = ['python2', 'py2']\n    filenames = []  # now taken over by PythonLexer (3.x)\n    mimetypes = ['text/x-python2', 'application/x-python2']\n    version_added = ''\n\n    def innerstring_rules(ttype):\n        return [\n            # the old style '%s' % (...) string formatting\n            (r'%(\\(\\w+\\))?[-#0 +]*([0-9]+|[*])?(\\.([0-9]+|[*]))?'\n             '[hlL]?[E-GXc-giorsux%]', String.Interpol),\n            # backslashes, quotes and formatting signs must be parsed one at a time\n            (r'[^\\\\\\'\"%\\n]+', ttype),\n            (r'[\\'\"\\\\]', ttype),\n            # unhandled string formatting sign\n            (r'%', ttype),\n            # newlines are an error (use \"nl\" state)\n        ]\n\n    tokens = {\n        'root': [\n            (r'\\n', Whitespace),\n            (r'^(\\s*)([rRuUbB]{,2})(\"\"\"(?:.|\\n)*?\"\"\")',\n             bygroups(Whitespace, String.Affix, String.Doc)),\n            (r\"^(\\s*)([rRuUbB]{,2})('''(?:.|\\n)*?''')\",\n             bygroups(Whitespace, String.Affix, String.Doc)),\n            (r'[^\\S\\n]+', Text),\n            (r'\\A#!.+$', Comment.Hashbang),\n            (r'#.*$', Comment.Single),\n            (r'[]{}:(),;[]', Punctuation),\n            (r'\\\\\\n', Text),\n            (r'\\\\', Text),\n            (r'(in|is|and|or|not)\\b', Operator.Word),\n            (r'!=|==|<<|>>|[-~+/*%=<>&^|.]', Operator),\n            include('keywords'),\n            (r'(def)((?:\\s|\\\\\\s)+)', bygroups(Keyword, Text), 'funcname'),\n            (r'(class)((?:\\s|\\\\\\s)+)', bygroups(Keyword, Text), 'classname'),\n            (r'(from)((?:\\s|\\\\\\s)+)', bygroups(Keyword.Namespace, Text),\n             'fromimport'),\n            (r'(import)((?:\\s|\\\\\\s)+)', bygroups(Keyword.Namespace, Text),\n             'import'),\n            include('builtins'),\n            include('magicfuncs'),\n            include('magicvars'),\n            include('backtick'),\n            ('([rR]|[uUbB][rR]|[rR][uUbB])(\"\"\")',\n             bygroups(String.Affix, String.Double), 'tdqs'),\n            (\"([rR]|[uUbB][rR]|[rR][uUbB])(''')\",\n             bygroups(String.Affix, String.Single), 'tsqs'),\n            ('([rR]|[uUbB][rR]|[rR][uUbB])(\")',\n             bygroups(String.Affix, String.Double), 'dqs'),\n            (\"([rR]|[uUbB][rR]|[rR][uUbB])(')\",\n             bygroups(String.Affix, String.Single), 'sqs'),\n            ('([uUbB]?)(\"\"\")', bygroups(String.Affix, String.Double),\n             combined('stringescape', 'tdqs')),\n            (\"([uUbB]?)(''')\", bygroups(String.Affix, String.Single),\n             combined('stringescape', 'tsqs')),\n            ('([uUbB]?)(\")', bygroups(String.Affix, String.Double),\n             combined('stringescape', 'dqs')),\n            (\"([uUbB]?)(')\", bygroups(String.Affix, String.Single),\n             combined('stringescape', 'sqs')),\n            include('name'),\n            include('numbers'),\n        ],\n        'keywords': [\n            (words((\n                'assert', 'break', 'continue', 'del', 'elif', 'else', 'except',\n                'exec', 'finally', 'for', 'global', 'if', 'lambda', 'pass',\n                'print', 'raise', 'return', 'try', 'while', 'yield',\n                'yield from', 'as', 'with'), suffix=r'\\b'),\n             Keyword),\n        ],\n        'builtins': [\n            (words((\n                '__import__', 'abs', 'all', 'any', 'apply', 'basestring', 'bin',\n                'bool', 'buffer', 'bytearray', 'bytes', 'callable', 'chr', 'classmethod',\n                'cmp', 'coerce', 'compile', 'complex', 'delattr', 'dict', 'dir', 'divmod',\n                'enumerate', 'eval', 'execfile', 'exit', 'file', 'filter', 'float',\n                'frozenset', 'getattr', 'globals', 'hasattr', 'hash', 'hex', 'id',\n                'input', 'int', 'intern', 'isinstance', 'issubclass', 'iter', 'len',\n                'list', 'locals', 'long', 'map', 'max', 'min', 'next', 'object',\n                'oct', 'open', 'ord', 'pow', 'property', 'range', 'raw_input', 'reduce',\n                'reload', 'repr', 'reversed', 'round', 'set', 'setattr', 'slice',\n                'sorted', 'staticmethod', 'str', 'sum', 'super', 'tuple', 'type',\n                'unichr', 'unicode', 'vars', 'xrange', 'zip'),\n                prefix=r'(?<!\\.)', suffix=r'\\b'),\n             Name.Builtin),\n            (r'(?<!\\.)(self|None|Ellipsis|NotImplemented|False|True|cls'\n             r')\\b', Name.Builtin.Pseudo),\n            (words((\n                'ArithmeticError', 'AssertionError', 'AttributeError',\n                'BaseException', 'DeprecationWarning', 'EOFError', 'EnvironmentError',\n                'Exception', 'FloatingPointError', 'FutureWarning', 'GeneratorExit',\n                'IOError', 'ImportError', 'ImportWarning', 'IndentationError',\n                'IndexError', 'KeyError', 'KeyboardInterrupt', 'LookupError',\n                'MemoryError', 'NameError',\n                'NotImplementedError', 'OSError', 'OverflowError', 'OverflowWarning',\n                'PendingDeprecationWarning', 'ReferenceError',\n                'RuntimeError', 'RuntimeWarning', 'StandardError', 'StopIteration',\n                'SyntaxError', 'SyntaxWarning', 'SystemError', 'SystemExit',\n                'TabError', 'TypeError', 'UnboundLocalError', 'UnicodeDecodeError',\n                'UnicodeEncodeError', 'UnicodeError', 'UnicodeTranslateError',\n                'UnicodeWarning', 'UserWarning', 'ValueError', 'VMSError', 'Warning',\n                'WindowsError', 'ZeroDivisionError'), prefix=r'(?<!\\.)', suffix=r'\\b'),\n             Name.Exception),\n        ],\n        'magicfuncs': [\n            (words((\n                '__abs__', '__add__', '__and__', '__call__', '__cmp__', '__coerce__',\n                '__complex__', '__contains__', '__del__', '__delattr__', '__delete__',\n                '__delitem__', '__delslice__', '__div__', '__divmod__', '__enter__',\n                '__eq__', '__exit__', '__float__', '__floordiv__', '__ge__', '__get__',\n                '__getattr__', '__getattribute__', '__getitem__', '__getslice__', '__gt__',\n                '__hash__', '__hex__', '__iadd__', '__iand__', '__idiv__', '__ifloordiv__',\n                '__ilshift__', '__imod__', '__imul__', '__index__', '__init__',\n                '__instancecheck__', '__int__', '__invert__', '__iop__', '__ior__',\n                '__ipow__', '__irshift__', '__isub__', '__iter__', '__itruediv__',\n                '__ixor__', '__le__', '__len__', '__long__', '__lshift__', '__lt__',\n                '__missing__', '__mod__', '__mul__', '__ne__', '__neg__', '__new__',\n                '__nonzero__', '__oct__', '__op__', '__or__', '__pos__', '__pow__',\n                '__radd__', '__rand__', '__rcmp__', '__rdiv__', '__rdivmod__', '__repr__',\n                '__reversed__', '__rfloordiv__', '__rlshift__', '__rmod__', '__rmul__',\n                '__rop__', '__ror__', '__rpow__', '__rrshift__', '__rshift__', '__rsub__',\n                '__rtruediv__', '__rxor__', '__set__', '__setattr__', '__setitem__',\n                '__setslice__', '__str__', '__sub__', '__subclasscheck__', '__truediv__',\n                '__unicode__', '__xor__'), suffix=r'\\b'),\n             Name.Function.Magic),\n        ],\n        'magicvars': [\n            (words((\n                '__bases__', '__class__', '__closure__', '__code__', '__defaults__',\n                '__dict__', '__doc__', '__file__', '__func__', '__globals__',\n                '__metaclass__', '__module__', '__mro__', '__name__', '__self__',\n                '__slots__', '__weakref__'),\n                suffix=r'\\b'),\n             Name.Variable.Magic),\n        ],\n        'numbers': [\n            (r'(\\d+\\.\\d*|\\d*\\.\\d+)([eE][+-]?[0-9]+)?j?', Number.Float),\n            (r'\\d+[eE][+-]?[0-9]+j?', Number.Float),\n            (r'0[0-7]+j?', Number.Oct),\n            (r'0[bB][01]+', Number.Bin),\n            (r'0[xX][a-fA-F0-9]+', Number.Hex),\n            (r'\\d+L', Number.Integer.Long),\n            (r'\\d+j?', Number.Integer)\n        ],\n        'backtick': [\n            ('`.*?`', String.Backtick),\n        ],\n        'name': [\n            (r'@[\\w.]+', Name.Decorator),\n            (r'[a-zA-Z_]\\w*', Name),\n        ],\n        'funcname': [\n            include('magicfuncs'),\n            (r'[a-zA-Z_]\\w*', Name.Function, '#pop'),\n            default('#pop'),\n        ],\n        'classname': [\n            (r'[a-zA-Z_]\\w*', Name.Class, '#pop')\n        ],\n        'import': [\n            (r'(?:[ \\t]|\\\\\\n)+', Text),\n            (r'as\\b', Keyword.Namespace),\n            (r',', Operator),\n            (r'[a-zA-Z_][\\w.]*', Name.Namespace),\n            default('#pop')  # all else: go back\n        ],\n        'fromimport': [\n            (r'(?:[ \\t]|\\\\\\n)+', Text),\n            (r'import\\b', Keyword.Namespace, '#pop'),\n            # if None occurs here, it's \"raise x from None\", since None can\n            # never be a module name\n            (r'None\\b', Name.Builtin.Pseudo, '#pop'),\n            # sadly, in \"raise x from y\" y will be highlighted as namespace too\n            (r'[a-zA-Z_.][\\w.]*', Name.Namespace),\n            # anything else here also means \"raise x from y\" and is therefore\n            # not an error\n            default('#pop'),\n        ],\n        'stringescape': [\n            (r'\\\\([\\\\abfnrtv\"\\']|\\n|N\\{.*?\\}|u[a-fA-F0-9]{4}|'\n             r'U[a-fA-F0-9]{8}|x[a-fA-F0-9]{2}|[0-7]{1,3})', String.Escape)\n        ],\n        'strings-single': innerstring_rules(String.Single),\n        'strings-double': innerstring_rules(String.Double),\n        'dqs': [\n            (r'\"', String.Double, '#pop'),\n            (r'\\\\\\\\|\\\\\"|\\\\\\n', String.Escape),  # included here for raw strings\n            include('strings-double')\n        ],\n        'sqs': [\n            (r\"'\", String.Single, '#pop'),\n            (r\"\\\\\\\\|\\\\'|\\\\\\n\", String.Escape),  # included here for raw strings\n            include('strings-single')\n        ],\n        'tdqs': [\n            (r'\"\"\"', String.Double, '#pop'),\n            include('strings-double'),\n            (r'\\n', String.Double)\n        ],\n        'tsqs': [\n            (r\"'''\", String.Single, '#pop'),\n            include('strings-single'),\n            (r'\\n', String.Single)\n        ],\n    }\n\n    def analyse_text(text):\n        return shebang_matches(text, r'pythonw?2(\\.\\d)?')\n\nclass _PythonConsoleLexerBase(RegexLexer):\n    name = 'Python console session'\n    aliases = ['pycon', 'python-console']\n    mimetypes = ['text/x-python-doctest']\n\n    \"\"\"Auxiliary lexer for `PythonConsoleLexer`.\n\n    Code tokens are output as ``Token.Other.Code``, traceback tokens as\n    ``Token.Other.Traceback``.\n    \"\"\"\n    tokens = {\n        'root': [\n            (r'(>>> )(.*\\n)', bygroups(Generic.Prompt, Other.Code), 'continuations'),\n            # This happens, e.g., when tracebacks are embedded in documentation;\n            # trailing whitespaces are often stripped in such contexts.\n            (r'(>>>)(\\n)', bygroups(Generic.Prompt, Whitespace)),\n            (r'(\\^C)?Traceback \\(most recent call last\\):\\n', Other.Traceback, 'traceback'),\n            # SyntaxError starts with this\n            (r'  File \"[^\"]+\", line \\d+', Other.Traceback, 'traceback'),\n            (r'.*\\n', Generic.Output),\n        ],\n        'continuations': [\n            (r'(\\.\\.\\. )(.*\\n)', bygroups(Generic.Prompt, Other.Code)),\n            # See above.\n            (r'(\\.\\.\\.)(\\n)', bygroups(Generic.Prompt, Whitespace)),\n            default('#pop'),\n        ],\n        'traceback': [\n            # As soon as we see a traceback, consume everything until the next\n            # >>> prompt.\n            (r'(?=>>>( |$))', Text, '#pop'),\n            (r'(KeyboardInterrupt)(\\n)', bygroups(Name.Class, Whitespace)),\n            (r'.*\\n', Other.Traceback),\n        ],\n    }\n\nclass PythonConsoleLexer(DelegatingLexer):\n    \"\"\"\n    For Python console output or doctests, such as:\n\n    .. sourcecode:: pycon\n\n        >>> a = 'foo'\n        >>> print(a)\n        foo\n        >>> 1 / 0\n        Traceback (most recent call last):\n          File \"<stdin>\", line 1, in <module>\n        ZeroDivisionError: integer division or modulo by zero\n\n    Additional options:\n\n    `python3`\n        Use Python 3 lexer for code.  Default is ``True``.\n\n        .. versionadded:: 1.0\n        .. versionchanged:: 2.5\n           Now defaults to ``True``.\n    \"\"\"\n\n    name = 'Python console session'\n    aliases = ['pycon', 'python-console']\n    mimetypes = ['text/x-python-doctest']\n    url = 'https://python.org'\n    version_added = ''\n\n    def __init__(self, **options):\n        python3 = get_bool_opt(options, 'python3', True)\n        if python3:\n            pylexer = PythonLexer\n            tblexer = PythonTracebackLexer\n        else:\n            pylexer = Python2Lexer\n            tblexer = Python2TracebackLexer\n        # We have two auxiliary lexers. Use DelegatingLexer twice with\n        # different tokens.  TODO: DelegatingLexer should support this\n        # directly, by accepting a tuplet of auxiliary lexers and a tuple of\n        # distinguishing tokens. Then we wouldn't need this intermediary\n        # class.\n        class _ReplaceInnerCode(DelegatingLexer):\n            def __init__(self, **options):\n                super().__init__(pylexer, _PythonConsoleLexerBase, Other.Code, **options)\n        super().__init__(tblexer, _ReplaceInnerCode, Other.Traceback, **options)\n\nclass PythonTracebackLexer(RegexLexer):\n    \"\"\"\n    For Python 3.x tracebacks, with support for chained exceptions.\n\n    .. versionchanged:: 2.5\n       This is now the default ``PythonTracebackLexer``.  It is still available\n       as the alias ``Python3TracebackLexer``.\n    \"\"\"\n\n    name = 'Python Traceback'\n    aliases = ['pytb', 'py3tb']\n    filenames = ['*.pytb', '*.py3tb']\n    mimetypes = ['text/x-python-traceback', 'text/x-python3-traceback']\n    url = 'https://python.org'\n    version_added = '1.0'\n\n    tokens = {\n        'root': [\n            (r'\\n', Whitespace),\n            (r'^(\\^C)?Traceback \\(most recent call last\\):\\n', Generic.Traceback, 'intb'),\n            (r'^During handling of the above exception, another '\n             r'exception occurred:\\n\\n', Generic.Traceback),\n            (r'^The above exception was the direct cause of the '\n             r'following exception:\\n\\n', Generic.Traceback),\n            (r'^(?=  File \"[^\"]+\", line \\d+)', Generic.Traceback, 'intb'),\n            (r'^.*\\n', Other),\n        ],\n        'intb': [\n            (r'^(  File )(\"[^\"]+\")(, line )(\\d+)(, in )(.+)(\\n)',\n             bygroups(Text, Name.Builtin, Text, Number, Text, Name, Whitespace)),\n            (r'^(  File )(\"[^\"]+\")(, line )(\\d+)(\\n)',\n             bygroups(Text, Name.Builtin, Text, Number, Whitespace)),\n            (r'^(    )(.+)(\\n)',\n             bygroups(Whitespace, using(PythonLexer), Whitespace), 'markers'),\n            (r'^([ \\t]*)(\\.\\.\\.)(\\n)',\n             bygroups(Whitespace, Comment, Whitespace)),  # for doctests...\n            (r'^([^:]+)(: )(.+)(\\n)',\n             bygroups(Generic.Error, Text, Name, Whitespace), '#pop'),\n            (r'^([a-zA-Z_][\\w.]*)(:?\\n)',\n             bygroups(Generic.Error, Whitespace), '#pop'),\n            default('#pop'),\n        ],\n        'markers': [\n            # Either `PEP 657 <https://www.python.org/dev/peps/pep-0657/>`\n            # error locations in Python 3.11+, or single-caret markers\n            # for syntax errors before that.\n            (r'^( {4,})([~^]+)(\\n)',\n             bygroups(Whitespace, Punctuation.Marker, Whitespace),\n             '#pop'),\n            default('#pop'),\n        ],\n    }\n\n\nPython3TracebackLexer = PythonTracebackLexer\n\n\nclass Python2TracebackLexer(RegexLexer):\n    \"\"\"\n    For Python tracebacks.\n\n    .. versionchanged:: 2.5\n       This class has been renamed from ``PythonTracebackLexer``.\n       ``PythonTracebackLexer`` now refers to the Python 3 variant.\n    \"\"\"\n\n    name = 'Python 2.x Traceback'\n    aliases = ['py2tb']\n    filenames = ['*.py2tb']\n    mimetypes = ['text/x-python2-traceback']\n    url = 'https://python.org'\n    version_added = '0.7'\n\n    tokens = {\n        'root': [\n            # Cover both (most recent call last) and (innermost last)\n            # The optional ^C allows us to catch keyboard interrupt signals.\n            (r'^(\\^C)?(Traceback.*\\n)',\n             bygroups(Text, Generic.Traceback), 'intb'),\n            # SyntaxError starts with this.\n            (r'^(?=  File \"[^\"]+\", line \\d+)', Generic.Traceback, 'intb'),\n            (r'^.*\\n', Other),\n        ],\n        'intb': [\n            (r'^(  File )(\"[^\"]+\")(, line )(\\d+)(, in )(.+)(\\n)',\n             bygroups(Text, Name.Builtin, Text, Number, Text, Name, Whitespace)),\n            (r'^(  File )(\"[^\"]+\")(, line )(\\d+)(\\n)',\n             bygroups(Text, Name.Builtin, Text, Number, Whitespace)),\n            (r'^(    )(.+)(\\n)',\n             bygroups(Text, using(Python2Lexer), Whitespace), 'marker'),\n            (r'^([ \\t]*)(\\.\\.\\.)(\\n)',\n             bygroups(Text, Comment, Whitespace)),  # for doctests...\n            (r'^([^:]+)(: )(.+)(\\n)',\n             bygroups(Generic.Error, Text, Name, Whitespace), '#pop'),\n            (r'^([a-zA-Z_]\\w*)(:?\\n)',\n             bygroups(Generic.Error, Whitespace), '#pop')\n        ],\n        'marker': [\n            # For syntax errors.\n            (r'( {4,})(\\^)', bygroups(Text, Punctuation.Marker), '#pop'),\n            default('#pop'),\n        ],\n    }\n\n\nclass CythonLexer(RegexLexer):\n    \"\"\"\n    For Pyrex and Cython source code.\n    \"\"\"\n\n    name = 'Cython'\n    url = 'https://cython.org'\n    aliases = ['cython', 'pyx', 'pyrex']\n    filenames = ['*.pyx', '*.pxd', '*.pxi']\n    mimetypes = ['text/x-cython', 'application/x-cython']\n    version_added = '1.1'\n\n    tokens = {\n        'root': [\n            (r'\\n', Whitespace),\n            (r'^(\\s*)(\"\"\"(?:.|\\n)*?\"\"\")', bygroups(Whitespace, String.Doc)),\n            (r\"^(\\s*)('''(?:.|\\n)*?''')\", bygroups(Whitespace, String.Doc)),\n            (r'[^\\S\\n]+', Text),\n            (r'#.*$', Comment),\n            (r'[]{}:(),;[]', Punctuation),\n            (r'\\\\\\n', Whitespace),\n            (r'\\\\', Text),\n            (r'(in|is|and|or|not)\\b', Operator.Word),\n            (r'(<)([a-zA-Z0-9.?]+)(>)',\n             bygroups(Punctuation, Keyword.Type, Punctuation)),\n            (r'!=|==|<<|>>|[-~+/*%=<>&^|.?]', Operator),\n            (r'(from)(\\d+)(<=)(\\s+)(<)(\\d+)(:)',\n             bygroups(Keyword, Number.Integer, Operator, Name, Operator,\n                      Name, Punctuation)),\n            include('keywords'),\n            (r'(def|property)(\\s+)', bygroups(Keyword, Text), 'funcname'),\n            (r'(cp?def)(\\s+)', bygroups(Keyword, Text), 'cdef'),\n            # (should actually start a block with only cdefs)\n            (r'(cdef)(:)', bygroups(Keyword, Punctuation)),\n            (r'(class|struct)(\\s+)', bygroups(Keyword, Text), 'classname'),\n            (r'(from)(\\s+)', bygroups(Keyword, Text), 'fromimport'),\n            (r'(c?import)(\\s+)', bygroups(Keyword, Text), 'import'),\n            include('builtins'),\n            include('backtick'),\n            ('(?:[rR]|[uU][rR]|[rR][uU])\"\"\"', String, 'tdqs'),\n            (\"(?:[rR]|[uU][rR]|[rR][uU])'''\", String, 'tsqs'),\n            ('(?:[rR]|[uU][rR]|[rR][uU])\"', String, 'dqs'),\n            (\"(?:[rR]|[uU][rR]|[rR][uU])'\", String, 'sqs'),\n            ('[uU]?\"\"\"', String, combined('stringescape', 'tdqs')),\n            (\"[uU]?'''\", String, combined('stringescape', 'tsqs')),\n            ('[uU]?\"', String, combined('stringescape', 'dqs')),\n            (\"[uU]?'\", String, combined('stringescape', 'sqs')),\n            include('name'),\n            include('numbers'),\n        ],\n        'keywords': [\n            (words((\n                'assert', 'async', 'await', 'break', 'by', 'continue', 'ctypedef', 'del', 'elif',\n                'else', 'except', 'except?', 'exec', 'finally', 'for', 'fused', 'gil',\n                'global', 'if', 'include', 'lambda', 'nogil', 'pass', 'print',\n                'raise', 'return', 'try', 'while', 'yield', 'as', 'with'), suffix=r'\\b'),\n             Keyword),\n            (r'(DEF|IF|ELIF|ELSE)\\b', Comment.Preproc),\n        ],\n        'builtins': [\n            (words((\n                '__import__', 'abs', 'all', 'any', 'apply', 'basestring', 'bin', 'bint',\n                'bool', 'buffer', 'bytearray', 'bytes', 'callable', 'chr',\n                'classmethod', 'cmp', 'coerce', 'compile', 'complex', 'delattr',\n                'dict', 'dir', 'divmod', 'enumerate', 'eval', 'execfile', 'exit',\n                'file', 'filter', 'float', 'frozenset', 'getattr', 'globals',\n                'hasattr', 'hash', 'hex', 'id', 'input', 'int', 'intern', 'isinstance',\n                'issubclass', 'iter', 'len', 'list', 'locals', 'long', 'map', 'max',\n                'min', 'next', 'object', 'oct', 'open', 'ord', 'pow', 'property', 'Py_ssize_t',\n                'range', 'raw_input', 'reduce', 'reload', 'repr', 'reversed',\n                'round', 'set', 'setattr', 'slice', 'sorted', 'staticmethod',\n                'str', 'sum', 'super', 'tuple', 'type', 'unichr', 'unicode', 'unsigned',\n                'vars', 'xrange', 'zip'), prefix=r'(?<!\\.)', suffix=r'\\b'),\n             Name.Builtin),\n            (r'(?<!\\.)(self|None|Ellipsis|NotImplemented|False|True|NULL'\n             r')\\b', Name.Builtin.Pseudo),\n            (words((\n                'ArithmeticError', 'AssertionError', 'AttributeError',\n                'BaseException', 'DeprecationWarning', 'EOFError', 'EnvironmentError',\n                'Exception', 'FloatingPointError', 'FutureWarning', 'GeneratorExit',\n                'IOError', 'ImportError', 'ImportWarning', 'IndentationError',\n                'IndexError', 'KeyError', 'KeyboardInterrupt', 'LookupError',\n                'MemoryError', 'NameError', 'NotImplemented', 'NotImplementedError',\n                'OSError', 'OverflowError', 'OverflowWarning',\n                'PendingDeprecationWarning', 'ReferenceError', 'RuntimeError',\n                'RuntimeWarning', 'StandardError', 'StopIteration', 'SyntaxError',\n                'SyntaxWarning', 'SystemError', 'SystemExit', 'TabError',\n                'TypeError', 'UnboundLocalError', 'UnicodeDecodeError',\n                'UnicodeEncodeError', 'UnicodeError', 'UnicodeTranslateError',\n                'UnicodeWarning', 'UserWarning', 'ValueError', 'Warning',\n                'ZeroDivisionError'), prefix=r'(?<!\\.)', suffix=r'\\b'),\n             Name.Exception),\n        ],\n        'numbers': [\n            (r'(\\d+\\.?\\d*|\\d*\\.\\d+)([eE][+-]?[0-9]+)?', Number.Float),\n            (r'0\\d+', Number.Oct),\n            (r'0[xX][a-fA-F0-9]+', Number.Hex),\n            (r'\\d+L', Number.Integer.Long),\n            (r'\\d+', Number.Integer)\n        ],\n        'backtick': [\n            ('`.*?`', String.Backtick),\n        ],\n        'name': [\n            (r'@\\w+', Name.Decorator),\n            (r'[a-zA-Z_]\\w*', Name),\n        ],\n        'funcname': [\n            (r'[a-zA-Z_]\\w*', Name.Function, '#pop')\n        ],\n        'cdef': [\n            (r'(public|readonly|extern|api|inline)\\b', Keyword.Reserved),\n            (r'(struct|enum|union|class)\\b', Keyword),\n            (r'([a-zA-Z_]\\w*)(\\s*)(?=[(:#=]|$)',\n             bygroups(Name.Function, Text), '#pop'),\n            (r'([a-zA-Z_]\\w*)(\\s*)(,)',\n             bygroups(Name.Function, Text, Punctuation)),\n            (r'from\\b', Keyword, '#pop'),\n            (r'as\\b', Keyword),\n            (r':', Punctuation, '#pop'),\n            (r'(?=[\"\\'])', Text, '#pop'),\n            (r'[a-zA-Z_]\\w*', Keyword.Type),\n            (r'.', Text),\n        ],\n        'classname': [\n            (r'[a-zA-Z_]\\w*', Name.Class, '#pop')\n        ],\n        'import': [\n            (r'(\\s+)(as)(\\s+)', bygroups(Text, Keyword, Text)),\n            (r'[a-zA-Z_][\\w.]*', Name.Namespace),\n            (r'(\\s*)(,)(\\s*)', bygroups(Text, Operator, Text)),\n            default('#pop')  # all else: go back\n        ],\n        'fromimport': [\n            (r'(\\s+)(c?import)\\b', bygroups(Text, Keyword), '#pop'),\n            (r'[a-zA-Z_.][\\w.]*', Name.Namespace),\n            # ``cdef foo from \"header\"``, or ``for foo from 0 < i < 10``\n            default('#pop'),\n        ],\n        'stringescape': [\n            (r'\\\\([\\\\abfnrtv\"\\']|\\n|N\\{.*?\\}|u[a-fA-F0-9]{4}|'\n             r'U[a-fA-F0-9]{8}|x[a-fA-F0-9]{2}|[0-7]{1,3})', String.Escape)\n        ],\n        'strings': [\n            (r'%(\\([a-zA-Z0-9]+\\))?[-#0 +]*([0-9]+|[*])?(\\.([0-9]+|[*]))?'\n             '[hlL]?[E-GXc-giorsux%]', String.Interpol),\n            (r'[^\\\\\\'\"%\\n]+', String),\n            # quotes, percents and backslashes must be parsed one at a time\n            (r'[\\'\"\\\\]', String),\n            # unhandled string formatting sign\n            (r'%', String)\n            # newlines are an error (use \"nl\" state)\n        ],\n        'nl': [\n            (r'\\n', String)\n        ],\n        'dqs': [\n            (r'\"', String, '#pop'),\n            (r'\\\\\\\\|\\\\\"|\\\\\\n', String.Escape),  # included here again for raw strings\n            include('strings')\n        ],\n        'sqs': [\n            (r\"'\", String, '#pop'),\n            (r\"\\\\\\\\|\\\\'|\\\\\\n\", String.Escape),  # included here again for raw strings\n            include('strings')\n        ],\n        'tdqs': [\n            (r'\"\"\"', String, '#pop'),\n            include('strings'),\n            include('nl')\n        ],\n        'tsqs': [\n            (r\"'''\", String, '#pop'),\n            include('strings'),\n            include('nl')\n        ],\n    }\n\n\nclass DgLexer(RegexLexer):\n    \"\"\"\n    Lexer for dg,\n    a functional and object-oriented programming language\n    running on the CPython 3 VM.\n    \"\"\"\n    name = 'dg'\n    aliases = ['dg']\n    filenames = ['*.dg']\n    mimetypes = ['text/x-dg']\n    url = 'http://pyos.github.io/dg'\n    version_added = '1.6'\n\n    tokens = {\n        'root': [\n            (r'\\s+', Text),\n            (r'#.*?$', Comment.Single),\n\n            (r'(?i)0b[01]+', Number.Bin),\n            (r'(?i)0o[0-7]+', Number.Oct),\n            (r'(?i)0x[0-9a-f]+', Number.Hex),\n            (r'(?i)[+-]?[0-9]+\\.[0-9]+(e[+-]?[0-9]+)?j?', Number.Float),\n            (r'(?i)[+-]?[0-9]+e[+-]?\\d+j?', Number.Float),\n            (r'(?i)[+-]?[0-9]+j?', Number.Integer),\n\n            (r\"(?i)(br|r?b?)'''\", String, combined('stringescape', 'tsqs', 'string')),\n            (r'(?i)(br|r?b?)\"\"\"', String, combined('stringescape', 'tdqs', 'string')),\n            (r\"(?i)(br|r?b?)'\", String, combined('stringescape', 'sqs', 'string')),\n            (r'(?i)(br|r?b?)\"', String, combined('stringescape', 'dqs', 'string')),\n\n            (r\"`\\w+'*`\", Operator),\n            (r'\\b(and|in|is|or|where)\\b', Operator.Word),\n            (r'[!$%&*+\\-./:<-@\\\\^|~;,]+', Operator),\n\n            (words((\n                'bool', 'bytearray', 'bytes', 'classmethod', 'complex', 'dict', 'dict\\'',\n                'float', 'frozenset', 'int', 'list', 'list\\'', 'memoryview', 'object',\n                'property', 'range', 'set', 'set\\'', 'slice', 'staticmethod', 'str',\n                'super', 'tuple', 'tuple\\'', 'type'),\n                   prefix=r'(?<!\\.)', suffix=r'(?![\\'\\w])'),\n             Name.Builtin),\n            (words((\n                '__import__', 'abs', 'all', 'any', 'bin', 'bind', 'chr', 'cmp', 'compile',\n                'complex', 'delattr', 'dir', 'divmod', 'drop', 'dropwhile', 'enumerate',\n                'eval', 'exhaust', 'filter', 'flip', 'foldl1?', 'format', 'fst',\n                'getattr', 'globals', 'hasattr', 'hash', 'head', 'hex', 'id', 'init',\n                'input', 'isinstance', 'issubclass', 'iter', 'iterate', 'last', 'len',\n                'locals', 'map', 'max', 'min', 'next', 'oct', 'open', 'ord', 'pow',\n                'print', 'repr', 'reversed', 'round', 'setattr', 'scanl1?', 'snd',\n                'sorted', 'sum', 'tail', 'take', 'takewhile', 'vars', 'zip'),\n                   prefix=r'(?<!\\.)', suffix=r'(?![\\'\\w])'),\n             Name.Builtin),\n            (r\"(?<!\\.)(self|Ellipsis|NotImplemented|None|True|False)(?!['\\w])\",\n             Name.Builtin.Pseudo),\n\n            (r\"(?<!\\.)[A-Z]\\w*(Error|Exception|Warning)'*(?!['\\w])\",\n             Name.Exception),\n            (r\"(?<!\\.)(Exception|GeneratorExit|KeyboardInterrupt|StopIteration|\"\n             r\"SystemExit)(?!['\\w])\", Name.Exception),\n\n            (r\"(?<![\\w.])(except|finally|for|if|import|not|otherwise|raise|\"\n             r\"subclass|while|with|yield)(?!['\\w])\", Keyword.Reserved),\n\n            (r\"[A-Z_]+'*(?!['\\w])\", Name),\n            (r\"[A-Z]\\w+'*(?!['\\w])\", Keyword.Type),\n            (r\"\\w+'*\", Name),\n\n            (r'[()]', Punctuation),\n            (r'.', Error),\n        ],\n        'stringescape': [\n            (r'\\\\([\\\\abfnrtv\"\\']|\\n|N\\{.*?\\}|u[a-fA-F0-9]{4}|'\n             r'U[a-fA-F0-9]{8}|x[a-fA-F0-9]{2}|[0-7]{1,3})', String.Escape)\n        ],\n        'string': [\n            (r'%(\\(\\w+\\))?[-#0 +]*([0-9]+|[*])?(\\.([0-9]+|[*]))?'\n             '[hlL]?[E-GXc-giorsux%]', String.Interpol),\n            (r'[^\\\\\\'\"%\\n]+', String),\n            # quotes, percents and backslashes must be parsed one at a time\n            (r'[\\'\"\\\\]', String),\n            # unhandled string formatting sign\n            (r'%', String),\n            (r'\\n', String)\n        ],\n        'dqs': [\n            (r'\"', String, '#pop')\n        ],\n        'sqs': [\n            (r\"'\", String, '#pop')\n        ],\n        'tdqs': [\n            (r'\"\"\"', String, '#pop')\n        ],\n        'tsqs': [\n            (r\"'''\", String, '#pop')\n        ],\n    }\n\n\nclass NumPyLexer(PythonLexer):\n    \"\"\"\n    A Python lexer recognizing Numerical Python builtins.\n    \"\"\"\n\n    name = 'NumPy'\n    url = 'https://numpy.org/'\n    aliases = ['numpy']\n    version_added = '0.10'\n\n    # override the mimetypes to not inherit them from python\n    mimetypes = []\n    filenames = []\n\n    EXTRA_KEYWORDS = {\n        'abs', 'absolute', 'accumulate', 'add', 'alen', 'all', 'allclose',\n        'alltrue', 'alterdot', 'amax', 'amin', 'angle', 'any', 'append',\n        'apply_along_axis', 'apply_over_axes', 'arange', 'arccos', 'arccosh',\n        'arcsin', 'arcsinh', 'arctan', 'arctan2', 'arctanh', 'argmax', 'argmin',\n        'argsort', 'argwhere', 'around', 'array', 'array2string', 'array_equal',\n        'array_equiv', 'array_repr', 'array_split', 'array_str', 'arrayrange',\n        'asanyarray', 'asarray', 'asarray_chkfinite', 'ascontiguousarray',\n        'asfarray', 'asfortranarray', 'asmatrix', 'asscalar', 'astype',\n        'atleast_1d', 'atleast_2d', 'atleast_3d', 'average', 'bartlett',\n        'base_repr', 'beta', 'binary_repr', 'bincount', 'binomial',\n        'bitwise_and', 'bitwise_not', 'bitwise_or', 'bitwise_xor', 'blackman',\n        'bmat', 'broadcast', 'byte_bounds', 'bytes', 'byteswap', 'c_',\n        'can_cast', 'ceil', 'choose', 'clip', 'column_stack', 'common_type',\n        'compare_chararrays', 'compress', 'concatenate', 'conj', 'conjugate',\n        'convolve', 'copy', 'corrcoef', 'correlate', 'cos', 'cosh', 'cov',\n        'cross', 'cumprod', 'cumproduct', 'cumsum', 'delete', 'deprecate',\n        'diag', 'diagflat', 'diagonal', 'diff', 'digitize', 'disp', 'divide',\n        'dot', 'dsplit', 'dstack', 'dtype', 'dump', 'dumps', 'ediff1d', 'empty',\n        'empty_like', 'equal', 'exp', 'expand_dims', 'expm1', 'extract', 'eye',\n        'fabs', 'fastCopyAndTranspose', 'fft', 'fftfreq', 'fftshift', 'fill',\n        'finfo', 'fix', 'flat', 'flatnonzero', 'flatten', 'fliplr', 'flipud',\n        'floor', 'floor_divide', 'fmod', 'frexp', 'fromarrays', 'frombuffer',\n        'fromfile', 'fromfunction', 'fromiter', 'frompyfunc', 'fromstring',\n        'generic', 'get_array_wrap', 'get_include', 'get_numarray_include',\n        'get_numpy_include', 'get_printoptions', 'getbuffer', 'getbufsize',\n        'geterr', 'geterrcall', 'geterrobj', 'getfield', 'gradient', 'greater',\n        'greater_equal', 'gumbel', 'hamming', 'hanning', 'histogram',\n        'histogram2d', 'histogramdd', 'hsplit', 'hstack', 'hypot', 'i0',\n        'identity', 'ifft', 'imag', 'index_exp', 'indices', 'inf', 'info',\n        'inner', 'insert', 'int_asbuffer', 'interp', 'intersect1d',\n        'intersect1d_nu', 'inv', 'invert', 'iscomplex', 'iscomplexobj',\n        'isfinite', 'isfortran', 'isinf', 'isnan', 'isneginf', 'isposinf',\n        'isreal', 'isrealobj', 'isscalar', 'issctype', 'issubclass_',\n        'issubdtype', 'issubsctype', 'item', 'itemset', 'iterable', 'ix_',\n        'kaiser', 'kron', 'ldexp', 'left_shift', 'less', 'less_equal', 'lexsort',\n        'linspace', 'load', 'loads', 'loadtxt', 'log', 'log10', 'log1p', 'log2',\n        'logical_and', 'logical_not', 'logical_or', 'logical_xor', 'logspace',\n        'lstsq', 'mat', 'matrix', 'max', 'maximum', 'maximum_sctype',\n        'may_share_memory', 'mean', 'median', 'meshgrid', 'mgrid', 'min',\n        'minimum', 'mintypecode', 'mod', 'modf', 'msort', 'multiply', 'nan',\n        'nan_to_num', 'nanargmax', 'nanargmin', 'nanmax', 'nanmin', 'nansum',\n        'ndenumerate', 'ndim', 'ndindex', 'negative', 'newaxis', 'newbuffer',\n        'newbyteorder', 'nonzero', 'not_equal', 'obj2sctype', 'ogrid', 'ones',\n        'ones_like', 'outer', 'permutation', 'piecewise', 'pinv', 'pkgload',\n        'place', 'poisson', 'poly', 'poly1d', 'polyadd', 'polyder', 'polydiv',\n        'polyfit', 'polyint', 'polymul', 'polysub', 'polyval', 'power', 'prod',\n        'product', 'ptp', 'put', 'putmask', 'r_', 'randint', 'random_integers',\n        'random_sample', 'ranf', 'rank', 'ravel', 'real', 'real_if_close',\n        'recarray', 'reciprocal', 'reduce', 'remainder', 'repeat', 'require',\n        'reshape', 'resize', 'restoredot', 'right_shift', 'rint', 'roll',\n        'rollaxis', 'roots', 'rot90', 'round', 'round_', 'row_stack', 's_',\n        'sample', 'savetxt', 'sctype2char', 'searchsorted', 'seed', 'select',\n        'set_numeric_ops', 'set_printoptions', 'set_string_function',\n        'setbufsize', 'setdiff1d', 'seterr', 'seterrcall', 'seterrobj',\n        'setfield', 'setflags', 'setmember1d', 'setxor1d', 'shape',\n        'show_config', 'shuffle', 'sign', 'signbit', 'sin', 'sinc', 'sinh',\n        'size', 'slice', 'solve', 'sometrue', 'sort', 'sort_complex', 'source',\n        'split', 'sqrt', 'square', 'squeeze', 'standard_normal', 'std',\n        'subtract', 'sum', 'svd', 'swapaxes', 'take', 'tan', 'tanh', 'tensordot',\n        'test', 'tile', 'tofile', 'tolist', 'tostring', 'trace', 'transpose',\n        'trapz', 'tri', 'tril', 'trim_zeros', 'triu', 'true_divide', 'typeDict',\n        'typename', 'uniform', 'union1d', 'unique', 'unique1d', 'unravel_index',\n        'unwrap', 'vander', 'var', 'vdot', 'vectorize', 'view', 'vonmises',\n        'vsplit', 'vstack', 'weibull', 'where', 'who', 'zeros', 'zeros_like'\n    }\n\n    def get_tokens_unprocessed(self, text):\n        for index, token, value in \\\n                PythonLexer.get_tokens_unprocessed(self, text):\n            if token is Name and value in self.EXTRA_KEYWORDS:\n                yield index, Keyword.Pseudo, value\n            else:\n                yield index, token, value\n\n    def analyse_text(text):\n        ltext = text[:1000]\n        return (shebang_matches(text, r'pythonw?(3(\\.\\d)?)?') or\n                'import ' in ltext) \\\n            and ('import numpy' in ltext or 'from numpy import' in ltext)\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/pygments/modeline.py","size":1005,"sha1":"61607c3bf13d97f7845ee2fbe45d04d2d60c747e","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\n    pygments.modeline\n    ~~~~~~~~~~~~~~~~~\n\n    A simple modeline parser (based on pymodeline).\n\n    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nimport re\n\n__all__ = ['get_filetype_from_buffer']\n\n\nmodeline_re = re.compile(r'''\n    (?: vi | vim | ex ) (?: [<=>]? \\d* )? :\n    .* (?: ft | filetype | syn | syntax ) = ( [^:\\s]+ )\n''', re.VERBOSE)\n\n\ndef get_filetype_from_line(l): # noqa: E741\n    m = modeline_re.search(l)\n    if m:\n        return m.group(1)\n\n\ndef get_filetype_from_buffer(buf, max_lines=5):\n    \"\"\"\n    Scan the buffer for modelines and return filetype if one is found.\n    \"\"\"\n    lines = buf.splitlines()\n    for line in lines[-1:-max_lines-1:-1]:\n        ret = get_filetype_from_line(line)\n        if ret:\n            return ret\n    for i in range(max_lines, -1, -1):\n        if i < len(lines):\n            ret = get_filetype_from_line(lines[i])\n            if ret:\n                return ret\n\n    return None\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/pygments/plugin.py","size":1891,"sha1":"661a9a8764ae439e46ce4af785b5071e26cf6c85","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\n    pygments.plugin\n    ~~~~~~~~~~~~~~~\n\n    Pygments plugin interface.\n\n    lexer plugins::\n\n        [pygments.lexers]\n        yourlexer = yourmodule:YourLexer\n\n    formatter plugins::\n\n        [pygments.formatters]\n        yourformatter = yourformatter:YourFormatter\n        /.ext = yourformatter:YourFormatter\n\n    As you can see, you can define extensions for the formatter\n    with a leading slash.\n\n    syntax plugins::\n\n        [pygments.styles]\n        yourstyle = yourstyle:YourStyle\n\n    filter plugin::\n\n        [pygments.filter]\n        yourfilter = yourfilter:YourFilter\n\n\n    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\nfrom importlib.metadata import entry_points\n\nLEXER_ENTRY_POINT = 'pygments.lexers'\nFORMATTER_ENTRY_POINT = 'pygments.formatters'\nSTYLE_ENTRY_POINT = 'pygments.styles'\nFILTER_ENTRY_POINT = 'pygments.filters'\n\n\ndef iter_entry_points(group_name):\n    groups = entry_points()\n    if hasattr(groups, 'select'):\n        # New interface in Python 3.10 and newer versions of the\n        # importlib_metadata backport.\n        return groups.select(group=group_name)\n    else:\n        # Older interface, deprecated in Python 3.10 and recent\n        # importlib_metadata, but we need it in Python 3.8 and 3.9.\n        return groups.get(group_name, [])\n\n\ndef find_plugin_lexers():\n    for entrypoint in iter_entry_points(LEXER_ENTRY_POINT):\n        yield entrypoint.load()\n\n\ndef find_plugin_formatters():\n    for entrypoint in iter_entry_points(FORMATTER_ENTRY_POINT):\n        yield entrypoint.name, entrypoint.load()\n\n\ndef find_plugin_styles():\n    for entrypoint in iter_entry_points(STYLE_ENTRY_POINT):\n        yield entrypoint.name, entrypoint.load()\n\n\ndef find_plugin_filters():\n    for entrypoint in iter_entry_points(FILTER_ENTRY_POINT):\n        yield entrypoint.name, entrypoint.load()\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/pygments/regexopt.py","size":3072,"sha1":"7743261fccbdb967dbbd879fbc3fd97dd274afb2","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\n    pygments.regexopt\n    ~~~~~~~~~~~~~~~~~\n\n    An algorithm that generates optimized regexes for matching long lists of\n    literal strings.\n\n    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nimport re\nfrom re import escape\nfrom os.path import commonprefix\nfrom itertools import groupby\nfrom operator import itemgetter\n\nCS_ESCAPE = re.compile(r'[\\[\\^\\\\\\-\\]]')\nFIRST_ELEMENT = itemgetter(0)\n\n\ndef make_charset(letters):\n    return '[' + CS_ESCAPE.sub(lambda m: '\\\\' + m.group(), ''.join(letters)) + ']'\n\n\ndef regex_opt_inner(strings, open_paren):\n    \"\"\"Return a regex that matches any string in the sorted list of strings.\"\"\"\n    close_paren = open_paren and ')' or ''\n    # print strings, repr(open_paren)\n    if not strings:\n        # print '-> nothing left'\n        return ''\n    first = strings[0]\n    if len(strings) == 1:\n        # print '-> only 1 string'\n        return open_paren + escape(first) + close_paren\n    if not first:\n        # print '-> first string empty'\n        return open_paren + regex_opt_inner(strings[1:], '(?:') \\\n            + '?' + close_paren\n    if len(first) == 1:\n        # multiple one-char strings? make a charset\n        oneletter = []\n        rest = []\n        for s in strings:\n            if len(s) == 1:\n                oneletter.append(s)\n            else:\n                rest.append(s)\n        if len(oneletter) > 1:  # do we have more than one oneletter string?\n            if rest:\n                # print '-> 1-character + rest'\n                return open_paren + regex_opt_inner(rest, '') + '|' \\\n                    + make_charset(oneletter) + close_paren\n            # print '-> only 1-character'\n            return open_paren + make_charset(oneletter) + close_paren\n    prefix = commonprefix(strings)\n    if prefix:\n        plen = len(prefix)\n        # we have a prefix for all strings\n        # print '-> prefix:', prefix\n        return open_paren + escape(prefix) \\\n            + regex_opt_inner([s[plen:] for s in strings], '(?:') \\\n            + close_paren\n    # is there a suffix?\n    strings_rev = [s[::-1] for s in strings]\n    suffix = commonprefix(strings_rev)\n    if suffix:\n        slen = len(suffix)\n        # print '-> suffix:', suffix[::-1]\n        return open_paren \\\n            + regex_opt_inner(sorted(s[:-slen] for s in strings), '(?:') \\\n            + escape(suffix[::-1]) + close_paren\n    # recurse on common 1-string prefixes\n    # print '-> last resort'\n    return open_paren + \\\n        '|'.join(regex_opt_inner(list(group[1]), '')\n                 for group in groupby(strings, lambda s: s[0] == first[0])) \\\n        + close_paren\n\n\ndef regex_opt(strings, prefix='', suffix=''):\n    \"\"\"Return a compiled regex that matches any string in the given list.\n\n    The strings to match must be literal strings, not regexes.  They will be\n    regex-escaped.\n\n    *prefix* and *suffix* are pre- and appended to the final regex.\n    \"\"\"\n    strings = sorted(strings)\n    return prefix + regex_opt_inner(strings, '(') + suffix\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/pygments/scanner.py","size":3092,"sha1":"8e6a47d991ed9aeaa6f5ee37434992e66a5fe5b8","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\n    pygments.scanner\n    ~~~~~~~~~~~~~~~~\n\n    This library implements a regex based scanner. Some languages\n    like Pascal are easy to parse but have some keywords that\n    depend on the context. Because of this it's impossible to lex\n    that just by using a regular expression lexer like the\n    `RegexLexer`.\n\n    Have a look at the `DelphiLexer` to get an idea of how to use\n    this scanner.\n\n    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\nimport re\n\n\nclass EndOfText(RuntimeError):\n    \"\"\"\n    Raise if end of text is reached and the user\n    tried to call a match function.\n    \"\"\"\n\n\nclass Scanner:\n    \"\"\"\n    Simple scanner\n\n    All method patterns are regular expression strings (not\n    compiled expressions!)\n    \"\"\"\n\n    def __init__(self, text, flags=0):\n        \"\"\"\n        :param text:    The text which should be scanned\n        :param flags:   default regular expression flags\n        \"\"\"\n        self.data = text\n        self.data_length = len(text)\n        self.start_pos = 0\n        self.pos = 0\n        self.flags = flags\n        self.last = None\n        self.match = None\n        self._re_cache = {}\n\n    def eos(self):\n        \"\"\"`True` if the scanner reached the end of text.\"\"\"\n        return self.pos >= self.data_length\n    eos = property(eos, eos.__doc__)\n\n    def check(self, pattern):\n        \"\"\"\n        Apply `pattern` on the current position and return\n        the match object. (Doesn't touch pos). Use this for\n        lookahead.\n        \"\"\"\n        if self.eos:\n            raise EndOfText()\n        if pattern not in self._re_cache:\n            self._re_cache[pattern] = re.compile(pattern, self.flags)\n        return self._re_cache[pattern].match(self.data, self.pos)\n\n    def test(self, pattern):\n        \"\"\"Apply a pattern on the current position and check\n        if it patches. Doesn't touch pos.\n        \"\"\"\n        return self.check(pattern) is not None\n\n    def scan(self, pattern):\n        \"\"\"\n        Scan the text for the given pattern and update pos/match\n        and related fields. The return value is a boolean that\n        indicates if the pattern matched. The matched value is\n        stored on the instance as ``match``, the last value is\n        stored as ``last``. ``start_pos`` is the position of the\n        pointer before the pattern was matched, ``pos`` is the\n        end position.\n        \"\"\"\n        if self.eos:\n            raise EndOfText()\n        if pattern not in self._re_cache:\n            self._re_cache[pattern] = re.compile(pattern, self.flags)\n        self.last = self.match\n        m = self._re_cache[pattern].match(self.data, self.pos)\n        if m is None:\n            return False\n        self.start_pos = m.start()\n        self.pos = m.end()\n        self.match = m.group()\n        return True\n\n    def get_char(self):\n        \"\"\"Scan exactly one char.\"\"\"\n        self.scan('.')\n\n    def __repr__(self):\n        return '<%s %d/%d>' % (\n            self.__class__.__name__,\n            self.pos,\n            self.data_length\n        )\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/pygments/sphinxext.py","size":7981,"sha1":"ee0ffca3b8a9fba5b2e9287dfd388b9540675864","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\n    pygments.sphinxext\n    ~~~~~~~~~~~~~~~~~~\n\n    Sphinx extension to generate automatic documentation of lexers,\n    formatters and filters.\n\n    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nimport sys\n\nfrom docutils import nodes\nfrom docutils.statemachine import ViewList\nfrom docutils.parsers.rst import Directive\nfrom sphinx.util.nodes import nested_parse_with_titles\n\n\nMODULEDOC = '''\n.. module:: %s\n\n%s\n%s\n'''\n\nLEXERDOC = '''\n.. class:: %s\n\n    :Short names: %s\n    :Filenames:   %s\n    :MIME types:  %s\n\n    %s\n\n    %s\n\n'''\n\nFMTERDOC = '''\n.. class:: %s\n\n    :Short names: %s\n    :Filenames: %s\n\n    %s\n\n'''\n\nFILTERDOC = '''\n.. class:: %s\n\n    :Name: %s\n\n    %s\n\n'''\n\n\nclass PygmentsDoc(Directive):\n    \"\"\"\n    A directive to collect all lexers/formatters/filters and generate\n    autoclass directives for them.\n    \"\"\"\n    has_content = False\n    required_arguments = 1\n    optional_arguments = 0\n    final_argument_whitespace = False\n    option_spec = {}\n\n    def run(self):\n        self.filenames = set()\n        if self.arguments[0] == 'lexers':\n            out = self.document_lexers()\n        elif self.arguments[0] == 'formatters':\n            out = self.document_formatters()\n        elif self.arguments[0] == 'filters':\n            out = self.document_filters()\n        elif self.arguments[0] == 'lexers_overview':\n            out = self.document_lexers_overview()\n        else:\n            raise Exception('invalid argument for \"pygmentsdoc\" directive')\n        node = nodes.compound()\n        vl = ViewList(out.split('\\n'), source='')\n        nested_parse_with_titles(self.state, vl, node)\n        for fn in self.filenames:\n            self.state.document.settings.record_dependencies.add(fn)\n        return node.children\n\n    def document_lexers_overview(self):\n        \"\"\"Generate a tabular overview of all lexers.\n\n        The columns are the lexer name, the extensions handled by this lexer\n        (or \"None\"), the aliases and a link to the lexer class.\"\"\"\n        from pip._vendor.pygments.lexers._mapping import LEXERS\n        from pip._vendor.pygments.lexers import find_lexer_class\n        out = []\n\n        table = []\n\n        def format_link(name, url):\n            if url:\n                return f'`{name} <{url}>`_'\n            return name\n\n        for classname, data in sorted(LEXERS.items(), key=lambda x: x[1][1].lower()):\n            lexer_cls = find_lexer_class(data[1])\n            extensions = lexer_cls.filenames + lexer_cls.alias_filenames\n\n            table.append({\n                'name': format_link(data[1], lexer_cls.url),\n                'extensions': ', '.join(extensions).replace('*', '\\\\*').replace('_', '\\\\') or 'None',\n                'aliases': ', '.join(data[2]),\n                'class': f'{data[0]}.{classname}'\n            })\n\n        column_names = ['name', 'extensions', 'aliases', 'class']\n        column_lengths = [max([len(row[column]) for row in table if row[column]])\n                          for column in column_names]\n\n        def write_row(*columns):\n            \"\"\"Format a table row\"\"\"\n            out = []\n            for length, col in zip(column_lengths, columns):\n                if col:\n                    out.append(col.ljust(length))\n                else:\n                    out.append(' '*length)\n\n            return ' '.join(out)\n\n        def write_seperator():\n            \"\"\"Write a table separator row\"\"\"\n            sep = ['='*c for c in column_lengths]\n            return write_row(*sep)\n\n        out.append(write_seperator())\n        out.append(write_row('Name', 'Extension(s)', 'Short name(s)', 'Lexer class'))\n        out.append(write_seperator())\n        for row in table:\n            out.append(write_row(\n                row['name'],\n                row['extensions'],\n                row['aliases'],\n                f':class:`~{row[\"class\"]}`'))\n        out.append(write_seperator())\n\n        return '\\n'.join(out)\n\n    def document_lexers(self):\n        from pip._vendor.pygments.lexers._mapping import LEXERS\n        from pip._vendor import pygments\n        import inspect\n        import pathlib\n\n        out = []\n        modules = {}\n        moduledocstrings = {}\n        for classname, data in sorted(LEXERS.items(), key=lambda x: x[0]):\n            module = data[0]\n            mod = __import__(module, None, None, [classname])\n            self.filenames.add(mod.__file__)\n            cls = getattr(mod, classname)\n            if not cls.__doc__:\n                print(f\"Warning: {classname} does not have a docstring.\")\n            docstring = cls.__doc__\n            if isinstance(docstring, bytes):\n                docstring = docstring.decode('utf8')\n\n            example_file = getattr(cls, '_example', None)\n            if example_file:\n                p = pathlib.Path(inspect.getabsfile(pygments)).parent.parent /\\\n                    'tests' / 'examplefiles' / example_file\n                content = p.read_text(encoding='utf-8')\n                if not content:\n                    raise Exception(\n                        f\"Empty example file '{example_file}' for lexer \"\n                        f\"{classname}\")\n\n                if data[2]:\n                    lexer_name = data[2][0]\n                    docstring += '\\n\\n    .. admonition:: Example\\n'\n                    docstring += f'\\n      .. code-block:: {lexer_name}\\n\\n'\n                    for line in content.splitlines():\n                        docstring += f'          {line}\\n'\n\n            if cls.version_added:\n                version_line = f'.. versionadded:: {cls.version_added}'\n            else:\n                version_line = ''\n\n            modules.setdefault(module, []).append((\n                classname,\n                ', '.join(data[2]) or 'None',\n                ', '.join(data[3]).replace('*', '\\\\*').replace('_', '\\\\') or 'None',\n                ', '.join(data[4]) or 'None',\n                docstring,\n                version_line))\n            if module not in moduledocstrings:\n                moddoc = mod.__doc__\n                if isinstance(moddoc, bytes):\n                    moddoc = moddoc.decode('utf8')\n                moduledocstrings[module] = moddoc\n\n        for module, lexers in sorted(modules.items(), key=lambda x: x[0]):\n            if moduledocstrings[module] is None:\n                raise Exception(f\"Missing docstring for {module}\")\n            heading = moduledocstrings[module].splitlines()[4].strip().rstrip('.')\n            out.append(MODULEDOC % (module, heading, '-'*len(heading)))\n            for data in lexers:\n                out.append(LEXERDOC % data)\n\n        return ''.join(out)\n\n    def document_formatters(self):\n        from pip._vendor.pygments.formatters import FORMATTERS\n\n        out = []\n        for classname, data in sorted(FORMATTERS.items(), key=lambda x: x[0]):\n            module = data[0]\n            mod = __import__(module, None, None, [classname])\n            self.filenames.add(mod.__file__)\n            cls = getattr(mod, classname)\n            docstring = cls.__doc__\n            if isinstance(docstring, bytes):\n                docstring = docstring.decode('utf8')\n            heading = cls.__name__\n            out.append(FMTERDOC % (heading, ', '.join(data[2]) or 'None',\n                                   ', '.join(data[3]).replace('*', '\\\\*') or 'None',\n                                   docstring))\n        return ''.join(out)\n\n    def document_filters(self):\n        from pip._vendor.pygments.filters import FILTERS\n\n        out = []\n        for name, cls in FILTERS.items():\n            self.filenames.add(sys.modules[cls.__module__].__file__)\n            docstring = cls.__doc__\n            if isinstance(docstring, bytes):\n                docstring = docstring.decode('utf8')\n            out.append(FILTERDOC % (cls.__name__, name, docstring))\n        return ''.join(out)\n\n\ndef setup(app):\n    app.add_directive('pygmentsdoc', PygmentsDoc)\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/pygments/style.py","size":6420,"sha1":"38fcec67a28098a81e93e1ffdfa3347ecdfdee3d","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\n    pygments.style\n    ~~~~~~~~~~~~~~\n\n    Basic style object.\n\n    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nfrom pip._vendor.pygments.token import Token, STANDARD_TYPES\n\n# Default mapping of ansixxx to RGB colors.\n_ansimap = {\n    # dark\n    'ansiblack': '000000',\n    'ansired': '7f0000',\n    'ansigreen': '007f00',\n    'ansiyellow': '7f7fe0',\n    'ansiblue': '00007f',\n    'ansimagenta': '7f007f',\n    'ansicyan': '007f7f',\n    'ansigray': 'e5e5e5',\n    # normal\n    'ansibrightblack': '555555',\n    'ansibrightred': 'ff0000',\n    'ansibrightgreen': '00ff00',\n    'ansibrightyellow': 'ffff00',\n    'ansibrightblue': '0000ff',\n    'ansibrightmagenta': 'ff00ff',\n    'ansibrightcyan': '00ffff',\n    'ansiwhite': 'ffffff',\n}\n# mapping of deprecated #ansixxx colors to new color names\n_deprecated_ansicolors = {\n    # dark\n    '#ansiblack': 'ansiblack',\n    '#ansidarkred': 'ansired',\n    '#ansidarkgreen': 'ansigreen',\n    '#ansibrown': 'ansiyellow',\n    '#ansidarkblue': 'ansiblue',\n    '#ansipurple': 'ansimagenta',\n    '#ansiteal': 'ansicyan',\n    '#ansilightgray': 'ansigray',\n    # normal\n    '#ansidarkgray': 'ansibrightblack',\n    '#ansired': 'ansibrightred',\n    '#ansigreen': 'ansibrightgreen',\n    '#ansiyellow': 'ansibrightyellow',\n    '#ansiblue': 'ansibrightblue',\n    '#ansifuchsia': 'ansibrightmagenta',\n    '#ansiturquoise': 'ansibrightcyan',\n    '#ansiwhite': 'ansiwhite',\n}\nansicolors = set(_ansimap)\n\n\nclass StyleMeta(type):\n\n    def __new__(mcs, name, bases, dct):\n        obj = type.__new__(mcs, name, bases, dct)\n        for token in STANDARD_TYPES:\n            if token not in obj.styles:\n                obj.styles[token] = ''\n\n        def colorformat(text):\n            if text in ansicolors:\n                return text\n            if text[0:1] == '#':\n                col = text[1:]\n                if len(col) == 6:\n                    return col\n                elif len(col) == 3:\n                    return col[0] * 2 + col[1] * 2 + col[2] * 2\n            elif text == '':\n                return ''\n            elif text.startswith('var') or text.startswith('calc'):\n                return text\n            assert False, f\"wrong color format {text!r}\"\n\n        _styles = obj._styles = {}\n\n        for ttype in obj.styles:\n            for token in ttype.split():\n                if token in _styles:\n                    continue\n                ndef = _styles.get(token.parent, None)\n                styledefs = obj.styles.get(token, '').split()\n                if not ndef or token is None:\n                    ndef = ['', 0, 0, 0, '', '', 0, 0, 0]\n                elif 'noinherit' in styledefs and token is not Token:\n                    ndef = _styles[Token][:]\n                else:\n                    ndef = ndef[:]\n                _styles[token] = ndef\n                for styledef in obj.styles.get(token, '').split():\n                    if styledef == 'noinherit':\n                        pass\n                    elif styledef == 'bold':\n                        ndef[1] = 1\n                    elif styledef == 'nobold':\n                        ndef[1] = 0\n                    elif styledef == 'italic':\n                        ndef[2] = 1\n                    elif styledef == 'noitalic':\n                        ndef[2] = 0\n                    elif styledef == 'underline':\n                        ndef[3] = 1\n                    elif styledef == 'nounderline':\n                        ndef[3] = 0\n                    elif styledef[:3] == 'bg:':\n                        ndef[4] = colorformat(styledef[3:])\n                    elif styledef[:7] == 'border:':\n                        ndef[5] = colorformat(styledef[7:])\n                    elif styledef == 'roman':\n                        ndef[6] = 1\n                    elif styledef == 'sans':\n                        ndef[7] = 1\n                    elif styledef == 'mono':\n                        ndef[8] = 1\n                    else:\n                        ndef[0] = colorformat(styledef)\n\n        return obj\n\n    def style_for_token(cls, token):\n        t = cls._styles[token]\n        ansicolor = bgansicolor = None\n        color = t[0]\n        if color in _deprecated_ansicolors:\n            color = _deprecated_ansicolors[color]\n        if color in ansicolors:\n            ansicolor = color\n            color = _ansimap[color]\n        bgcolor = t[4]\n        if bgcolor in _deprecated_ansicolors:\n            bgcolor = _deprecated_ansicolors[bgcolor]\n        if bgcolor in ansicolors:\n            bgansicolor = bgcolor\n            bgcolor = _ansimap[bgcolor]\n\n        return {\n            'color':        color or None,\n            'bold':         bool(t[1]),\n            'italic':       bool(t[2]),\n            'underline':    bool(t[3]),\n            'bgcolor':      bgcolor or None,\n            'border':       t[5] or None,\n            'roman':        bool(t[6]) or None,\n            'sans':         bool(t[7]) or None,\n            'mono':         bool(t[8]) or None,\n            'ansicolor':    ansicolor,\n            'bgansicolor':  bgansicolor,\n        }\n\n    def list_styles(cls):\n        return list(cls)\n\n    def styles_token(cls, ttype):\n        return ttype in cls._styles\n\n    def __iter__(cls):\n        for token in cls._styles:\n            yield token, cls.style_for_token(token)\n\n    def __len__(cls):\n        return len(cls._styles)\n\n\nclass Style(metaclass=StyleMeta):\n\n    #: overall background color (``None`` means transparent)\n    background_color = '#ffffff'\n\n    #: highlight background color\n    highlight_color = '#ffffcc'\n\n    #: line number font color\n    line_number_color = 'inherit'\n\n    #: line number background color\n    line_number_background_color = 'transparent'\n\n    #: special line number font color\n    line_number_special_color = '#000000'\n\n    #: special line number background color\n    line_number_special_background_color = '#ffffc0'\n\n    #: Style definitions for individual token types.\n    styles = {}\n\n    #: user-friendly style name (used when selecting the style, so this\n    # should be all-lowercase, no spaces, hyphens)\n    name = 'unnamed'\n\n    aliases = []\n\n    # Attribute for lexers defined within Pygments. If set\n    # to True, the style is not shown in the style gallery\n    # on the website. This is intended for language-specific\n    # styles.\n    web_style_gallery_exclude = False\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/pygments/styles/__init__.py","size":2042,"sha1":"edfb6dcd0fb9fd773de266d3d2b225701abb80af","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\n    pygments.styles\n    ~~~~~~~~~~~~~~~\n\n    Contains built-in styles.\n\n    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nfrom pip._vendor.pygments.plugin import find_plugin_styles\nfrom pip._vendor.pygments.util import ClassNotFound\nfrom pip._vendor.pygments.styles._mapping import STYLES\n\n#: A dictionary of built-in styles, mapping style names to\n#: ``'submodule::classname'`` strings.\n#: This list is deprecated. Use `pygments.styles.STYLES` instead\nSTYLE_MAP = {v[1]: v[0].split('.')[-1] + '::' + k for k, v in STYLES.items()}\n\n#: Internal reverse mapping to make `get_style_by_name` more efficient\n_STYLE_NAME_TO_MODULE_MAP = {v[1]: (v[0], k) for k, v in STYLES.items()}\n\n\ndef get_style_by_name(name):\n    \"\"\"\n    Return a style class by its short name. The names of the builtin styles\n    are listed in :data:`pygments.styles.STYLE_MAP`.\n\n    Will raise :exc:`pygments.util.ClassNotFound` if no style of that name is\n    found.\n    \"\"\"\n    if name in _STYLE_NAME_TO_MODULE_MAP:\n        mod, cls = _STYLE_NAME_TO_MODULE_MAP[name]\n        builtin = \"yes\"\n    else:\n        for found_name, style in find_plugin_styles():\n            if name == found_name:\n                return style\n        # perhaps it got dropped into our styles package\n        builtin = \"\"\n        mod = 'pygments.styles.' + name\n        cls = name.title() + \"Style\"\n\n    try:\n        mod = __import__(mod, None, None, [cls])\n    except ImportError:\n        raise ClassNotFound(f\"Could not find style module {mod!r}\" +\n                            (builtin and \", though it should be builtin\")\n                            + \".\")\n    try:\n        return getattr(mod, cls)\n    except AttributeError:\n        raise ClassNotFound(f\"Could not find style class {cls!r} in style module.\")\n\n\ndef get_all_styles():\n    \"\"\"Return a generator for all styles by name, both builtin and plugin.\"\"\"\n    for v in STYLES.values():\n        yield v[1]\n    for name, _ in find_plugin_styles():\n        yield name\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/pygments/styles/_mapping.py","size":3312,"sha1":"651359ef16bca5a164c8eb41a6a1fef2593860ff","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"# Automatically generated by scripts/gen_mapfiles.py.\n# DO NOT EDIT BY HAND; run `tox -e mapfiles` instead.\n\nSTYLES = {\n    'AbapStyle': ('pygments.styles.abap', 'abap', ()),\n    'AlgolStyle': ('pygments.styles.algol', 'algol', ()),\n    'Algol_NuStyle': ('pygments.styles.algol_nu', 'algol_nu', ()),\n    'ArduinoStyle': ('pygments.styles.arduino', 'arduino', ()),\n    'AutumnStyle': ('pygments.styles.autumn', 'autumn', ()),\n    'BlackWhiteStyle': ('pygments.styles.bw', 'bw', ()),\n    'BorlandStyle': ('pygments.styles.borland', 'borland', ()),\n    'CoffeeStyle': ('pygments.styles.coffee', 'coffee', ()),\n    'ColorfulStyle': ('pygments.styles.colorful', 'colorful', ()),\n    'DefaultStyle': ('pygments.styles.default', 'default', ()),\n    'DraculaStyle': ('pygments.styles.dracula', 'dracula', ()),\n    'EmacsStyle': ('pygments.styles.emacs', 'emacs', ()),\n    'FriendlyGrayscaleStyle': ('pygments.styles.friendly_grayscale', 'friendly_grayscale', ()),\n    'FriendlyStyle': ('pygments.styles.friendly', 'friendly', ()),\n    'FruityStyle': ('pygments.styles.fruity', 'fruity', ()),\n    'GhDarkStyle': ('pygments.styles.gh_dark', 'github-dark', ()),\n    'GruvboxDarkStyle': ('pygments.styles.gruvbox', 'gruvbox-dark', ()),\n    'GruvboxLightStyle': ('pygments.styles.gruvbox', 'gruvbox-light', ()),\n    'IgorStyle': ('pygments.styles.igor', 'igor', ()),\n    'InkPotStyle': ('pygments.styles.inkpot', 'inkpot', ()),\n    'LightbulbStyle': ('pygments.styles.lightbulb', 'lightbulb', ()),\n    'LilyPondStyle': ('pygments.styles.lilypond', 'lilypond', ()),\n    'LovelaceStyle': ('pygments.styles.lovelace', 'lovelace', ()),\n    'ManniStyle': ('pygments.styles.manni', 'manni', ()),\n    'MaterialStyle': ('pygments.styles.material', 'material', ()),\n    'MonokaiStyle': ('pygments.styles.monokai', 'monokai', ()),\n    'MurphyStyle': ('pygments.styles.murphy', 'murphy', ()),\n    'NativeStyle': ('pygments.styles.native', 'native', ()),\n    'NordDarkerStyle': ('pygments.styles.nord', 'nord-darker', ()),\n    'NordStyle': ('pygments.styles.nord', 'nord', ()),\n    'OneDarkStyle': ('pygments.styles.onedark', 'one-dark', ()),\n    'ParaisoDarkStyle': ('pygments.styles.paraiso_dark', 'paraiso-dark', ()),\n    'ParaisoLightStyle': ('pygments.styles.paraiso_light', 'paraiso-light', ()),\n    'PastieStyle': ('pygments.styles.pastie', 'pastie', ()),\n    'PerldocStyle': ('pygments.styles.perldoc', 'perldoc', ()),\n    'RainbowDashStyle': ('pygments.styles.rainbow_dash', 'rainbow_dash', ()),\n    'RrtStyle': ('pygments.styles.rrt', 'rrt', ()),\n    'SasStyle': ('pygments.styles.sas', 'sas', ()),\n    'SolarizedDarkStyle': ('pygments.styles.solarized', 'solarized-dark', ()),\n    'SolarizedLightStyle': ('pygments.styles.solarized', 'solarized-light', ()),\n    'StarofficeStyle': ('pygments.styles.staroffice', 'staroffice', ()),\n    'StataDarkStyle': ('pygments.styles.stata_dark', 'stata-dark', ()),\n    'StataLightStyle': ('pygments.styles.stata_light', 'stata-light', ()),\n    'TangoStyle': ('pygments.styles.tango', 'tango', ()),\n    'TracStyle': ('pygments.styles.trac', 'trac', ()),\n    'VimStyle': ('pygments.styles.vim', 'vim', ()),\n    'VisualStudioStyle': ('pygments.styles.vs', 'vs', ()),\n    'XcodeStyle': ('pygments.styles.xcode', 'xcode', ()),\n    'ZenburnStyle': ('pygments.styles.zenburn', 'zenburn', ()),\n}\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/pygments/token.py","size":6226,"sha1":"fd9e68b884c6ee7ce19dd510759cc7724079645f","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\n    pygments.token\n    ~~~~~~~~~~~~~~\n\n    Basic token types and the standard tokens.\n\n    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\n\nclass _TokenType(tuple):\n    parent = None\n\n    def split(self):\n        buf = []\n        node = self\n        while node is not None:\n            buf.append(node)\n            node = node.parent\n        buf.reverse()\n        return buf\n\n    def __init__(self, *args):\n        # no need to call super.__init__\n        self.subtypes = set()\n\n    def __contains__(self, val):\n        return self is val or (\n            type(val) is self.__class__ and\n            val[:len(self)] == self\n        )\n\n    def __getattr__(self, val):\n        if not val or not val[0].isupper():\n            return tuple.__getattribute__(self, val)\n        new = _TokenType(self + (val,))\n        setattr(self, val, new)\n        self.subtypes.add(new)\n        new.parent = self\n        return new\n\n    def __repr__(self):\n        return 'Token' + (self and '.' or '') + '.'.join(self)\n\n    def __copy__(self):\n        # These instances are supposed to be singletons\n        return self\n\n    def __deepcopy__(self, memo):\n        # These instances are supposed to be singletons\n        return self\n\n\nToken = _TokenType()\n\n# Special token types\nText = Token.Text\nWhitespace = Text.Whitespace\nEscape = Token.Escape\nError = Token.Error\n# Text that doesn't belong to this lexer (e.g. HTML in PHP)\nOther = Token.Other\n\n# Common token types for source code\nKeyword = Token.Keyword\nName = Token.Name\nLiteral = Token.Literal\nString = Literal.String\nNumber = Literal.Number\nPunctuation = Token.Punctuation\nOperator = Token.Operator\nComment = Token.Comment\n\n# Generic types for non-source code\nGeneric = Token.Generic\n\n# String and some others are not direct children of Token.\n# alias them:\nToken.Token = Token\nToken.String = String\nToken.Number = Number\n\n\ndef is_token_subtype(ttype, other):\n    \"\"\"\n    Return True if ``ttype`` is a subtype of ``other``.\n\n    exists for backwards compatibility. use ``ttype in other`` now.\n    \"\"\"\n    return ttype in other\n\n\ndef string_to_tokentype(s):\n    \"\"\"\n    Convert a string into a token type::\n\n        >>> string_to_token('String.Double')\n        Token.Literal.String.Double\n        >>> string_to_token('Token.Literal.Number')\n        Token.Literal.Number\n        >>> string_to_token('')\n        Token\n\n    Tokens that are already tokens are returned unchanged:\n\n        >>> string_to_token(String)\n        Token.Literal.String\n    \"\"\"\n    if isinstance(s, _TokenType):\n        return s\n    if not s:\n        return Token\n    node = Token\n    for item in s.split('.'):\n        node = getattr(node, item)\n    return node\n\n\n# Map standard token types to short names, used in CSS class naming.\n# If you add a new item, please be sure to run this file to perform\n# a consistency check for duplicate values.\nSTANDARD_TYPES = {\n    Token:                         '',\n\n    Text:                          '',\n    Whitespace:                    'w',\n    Escape:                        'esc',\n    Error:                         'err',\n    Other:                         'x',\n\n    Keyword:                       'k',\n    Keyword.Constant:              'kc',\n    Keyword.Declaration:           'kd',\n    Keyword.Namespace:             'kn',\n    Keyword.Pseudo:                'kp',\n    Keyword.Reserved:              'kr',\n    Keyword.Type:                  'kt',\n\n    Name:                          'n',\n    Name.Attribute:                'na',\n    Name.Builtin:                  'nb',\n    Name.Builtin.Pseudo:           'bp',\n    Name.Class:                    'nc',\n    Name.Constant:                 'no',\n    Name.Decorator:                'nd',\n    Name.Entity:                   'ni',\n    Name.Exception:                'ne',\n    Name.Function:                 'nf',\n    Name.Function.Magic:           'fm',\n    Name.Property:                 'py',\n    Name.Label:                    'nl',\n    Name.Namespace:                'nn',\n    Name.Other:                    'nx',\n    Name.Tag:                      'nt',\n    Name.Variable:                 'nv',\n    Name.Variable.Class:           'vc',\n    Name.Variable.Global:          'vg',\n    Name.Variable.Instance:        'vi',\n    Name.Variable.Magic:           'vm',\n\n    Literal:                       'l',\n    Literal.Date:                  'ld',\n\n    String:                        's',\n    String.Affix:                  'sa',\n    String.Backtick:               'sb',\n    String.Char:                   'sc',\n    String.Delimiter:              'dl',\n    String.Doc:                    'sd',\n    String.Double:                 's2',\n    String.Escape:                 'se',\n    String.Heredoc:                'sh',\n    String.Interpol:               'si',\n    String.Other:                  'sx',\n    String.Regex:                  'sr',\n    String.Single:                 's1',\n    String.Symbol:                 'ss',\n\n    Number:                        'm',\n    Number.Bin:                    'mb',\n    Number.Float:                  'mf',\n    Number.Hex:                    'mh',\n    Number.Integer:                'mi',\n    Number.Integer.Long:           'il',\n    Number.Oct:                    'mo',\n\n    Operator:                      'o',\n    Operator.Word:                 'ow',\n\n    Punctuation:                   'p',\n    Punctuation.Marker:            'pm',\n\n    Comment:                       'c',\n    Comment.Hashbang:              'ch',\n    Comment.Multiline:             'cm',\n    Comment.Preproc:               'cp',\n    Comment.PreprocFile:           'cpf',\n    Comment.Single:                'c1',\n    Comment.Special:               'cs',\n\n    Generic:                       'g',\n    Generic.Deleted:               'gd',\n    Generic.Emph:                  'ge',\n    Generic.Error:                 'gr',\n    Generic.Heading:               'gh',\n    Generic.Inserted:              'gi',\n    Generic.Output:                'go',\n    Generic.Prompt:                'gp',\n    Generic.Strong:                'gs',\n    Generic.Subheading:            'gu',\n    Generic.EmphStrong:            'ges',\n    Generic.Traceback:             'gt',\n}\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/pygments/unistring.py","size":63208,"sha1":"72db5d8a70be596b7c459e0587d5f74fc8037602","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\n    pygments.unistring\n    ~~~~~~~~~~~~~~~~~~\n\n    Strings of all Unicode characters of a certain category.\n    Used for matching in Unicode-aware languages. Run to regenerate.\n\n    Inspired by chartypes_create.py from the MoinMoin project.\n\n    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nCc = '\\x00-\\x1f\\x7f-\\x9f'\n\nCf = '\\xad\\u0600-\\u0605\\u061c\\u06dd\\u070f\\u08e2\\u180e\\u200b-\\u200f\\u202a-\\u202e\\u2060-\\u2064\\u2066-\\u206f\\ufeff\\ufff9-\\ufffb\\U000110bd\\U000110cd\\U0001bca0-\\U0001bca3\\U0001d173-\\U0001d17a\\U000e0001\\U000e0020-\\U000e007f'\n\nCn = '\\u0378-\\u0379\\u0380-\\u0383\\u038b\\u038d\\u03a2\\u0530\\u0557-\\u0558\\u058b-\\u058c\\u0590\\u05c8-\\u05cf\\u05eb-\\u05ee\\u05f5-\\u05ff\\u061d\\u070e\\u074b-\\u074c\\u07b2-\\u07bf\\u07fb-\\u07fc\\u082e-\\u082f\\u083f\\u085c-\\u085d\\u085f\\u086b-\\u089f\\u08b5\\u08be-\\u08d2\\u0984\\u098d-\\u098e\\u0991-\\u0992\\u09a9\\u09b1\\u09b3-\\u09b5\\u09ba-\\u09bb\\u09c5-\\u09c6\\u09c9-\\u09ca\\u09cf-\\u09d6\\u09d8-\\u09db\\u09de\\u09e4-\\u09e5\\u09ff-\\u0a00\\u0a04\\u0a0b-\\u0a0e\\u0a11-\\u0a12\\u0a29\\u0a31\\u0a34\\u0a37\\u0a3a-\\u0a3b\\u0a3d\\u0a43-\\u0a46\\u0a49-\\u0a4a\\u0a4e-\\u0a50\\u0a52-\\u0a58\\u0a5d\\u0a5f-\\u0a65\\u0a77-\\u0a80\\u0a84\\u0a8e\\u0a92\\u0aa9\\u0ab1\\u0ab4\\u0aba-\\u0abb\\u0ac6\\u0aca\\u0ace-\\u0acf\\u0ad1-\\u0adf\\u0ae4-\\u0ae5\\u0af2-\\u0af8\\u0b00\\u0b04\\u0b0d-\\u0b0e\\u0b11-\\u0b12\\u0b29\\u0b31\\u0b34\\u0b3a-\\u0b3b\\u0b45-\\u0b46\\u0b49-\\u0b4a\\u0b4e-\\u0b55\\u0b58-\\u0b5b\\u0b5e\\u0b64-\\u0b65\\u0b78-\\u0b81\\u0b84\\u0b8b-\\u0b8d\\u0b91\\u0b96-\\u0b98\\u0b9b\\u0b9d\\u0ba0-\\u0ba2\\u0ba5-\\u0ba7\\u0bab-\\u0bad\\u0bba-\\u0bbd\\u0bc3-\\u0bc5\\u0bc9\\u0bce-\\u0bcf\\u0bd1-\\u0bd6\\u0bd8-\\u0be5\\u0bfb-\\u0bff\\u0c0d\\u0c11\\u0c29\\u0c3a-\\u0c3c\\u0c45\\u0c49\\u0c4e-\\u0c54\\u0c57\\u0c5b-\\u0c5f\\u0c64-\\u0c65\\u0c70-\\u0c77\\u0c8d\\u0c91\\u0ca9\\u0cb4\\u0cba-\\u0cbb\\u0cc5\\u0cc9\\u0cce-\\u0cd4\\u0cd7-\\u0cdd\\u0cdf\\u0ce4-\\u0ce5\\u0cf0\\u0cf3-\\u0cff\\u0d04\\u0d0d\\u0d11\\u0d45\\u0d49\\u0d50-\\u0d53\\u0d64-\\u0d65\\u0d80-\\u0d81\\u0d84\\u0d97-\\u0d99\\u0db2\\u0dbc\\u0dbe-\\u0dbf\\u0dc7-\\u0dc9\\u0dcb-\\u0dce\\u0dd5\\u0dd7\\u0de0-\\u0de5\\u0df0-\\u0df1\\u0df5-\\u0e00\\u0e3b-\\u0e3e\\u0e5c-\\u0e80\\u0e83\\u0e85-\\u0e86\\u0e89\\u0e8b-\\u0e8c\\u0e8e-\\u0e93\\u0e98\\u0ea0\\u0ea4\\u0ea6\\u0ea8-\\u0ea9\\u0eac\\u0eba\\u0ebe-\\u0ebf\\u0ec5\\u0ec7\\u0ece-\\u0ecf\\u0eda-\\u0edb\\u0ee0-\\u0eff\\u0f48\\u0f6d-\\u0f70\\u0f98\\u0fbd\\u0fcd\\u0fdb-\\u0fff\\u10c6\\u10c8-\\u10cc\\u10ce-\\u10cf\\u1249\\u124e-\\u124f\\u1257\\u1259\\u125e-\\u125f\\u1289\\u128e-\\u128f\\u12b1\\u12b6-\\u12b7\\u12bf\\u12c1\\u12c6-\\u12c7\\u12d7\\u1311\\u1316-\\u1317\\u135b-\\u135c\\u137d-\\u137f\\u139a-\\u139f\\u13f6-\\u13f7\\u13fe-\\u13ff\\u169d-\\u169f\\u16f9-\\u16ff\\u170d\\u1715-\\u171f\\u1737-\\u173f\\u1754-\\u175f\\u176d\\u1771\\u1774-\\u177f\\u17de-\\u17df\\u17ea-\\u17ef\\u17fa-\\u17ff\\u180f\\u181a-\\u181f\\u1879-\\u187f\\u18ab-\\u18af\\u18f6-\\u18ff\\u191f\\u192c-\\u192f\\u193c-\\u193f\\u1941-\\u1943\\u196e-\\u196f\\u1975-\\u197f\\u19ac-\\u19af\\u19ca-\\u19cf\\u19db-\\u19dd\\u1a1c-\\u1a1d\\u1a5f\\u1a7d-\\u1a7e\\u1a8a-\\u1a8f\\u1a9a-\\u1a9f\\u1aae-\\u1aaf\\u1abf-\\u1aff\\u1b4c-\\u1b4f\\u1b7d-\\u1b7f\\u1bf4-\\u1bfb\\u1c38-\\u1c3a\\u1c4a-\\u1c4c\\u1c89-\\u1c8f\\u1cbb-\\u1cbc\\u1cc8-\\u1ccf\\u1cfa-\\u1cff\\u1dfa\\u1f16-\\u1f17\\u1f1e-\\u1f1f\\u1f46-\\u1f47\\u1f4e-\\u1f4f\\u1f58\\u1f5a\\u1f5c\\u1f5e\\u1f7e-\\u1f7f\\u1fb5\\u1fc5\\u1fd4-\\u1fd5\\u1fdc\\u1ff0-\\u1ff1\\u1ff5\\u1fff\\u2065\\u2072-\\u2073\\u208f\\u209d-\\u209f\\u20c0-\\u20cf\\u20f1-\\u20ff\\u218c-\\u218f\\u2427-\\u243f\\u244b-\\u245f\\u2b74-\\u2b75\\u2b96-\\u2b97\\u2bc9\\u2bff\\u2c2f\\u2c5f\\u2cf4-\\u2cf8\\u2d26\\u2d28-\\u2d2c\\u2d2e-\\u2d2f\\u2d68-\\u2d6e\\u2d71-\\u2d7e\\u2d97-\\u2d9f\\u2da7\\u2daf\\u2db7\\u2dbf\\u2dc7\\u2dcf\\u2dd7\\u2ddf\\u2e4f-\\u2e7f\\u2e9a\\u2ef4-\\u2eff\\u2fd6-\\u2fef\\u2ffc-\\u2fff\\u3040\\u3097-\\u3098\\u3100-\\u3104\\u3130\\u318f\\u31bb-\\u31bf\\u31e4-\\u31ef\\u321f\\u32ff\\u4db6-\\u4dbf\\u9ff0-\\u9fff\\ua48d-\\ua48f\\ua4c7-\\ua4cf\\ua62c-\\ua63f\\ua6f8-\\ua6ff\\ua7ba-\\ua7f6\\ua82c-\\ua82f\\ua83a-\\ua83f\\ua878-\\ua87f\\ua8c6-\\ua8cd\\ua8da-\\ua8df\\ua954-\\ua95e\\ua97d-\\ua97f\\ua9ce\\ua9da-\\ua9dd\\ua9ff\\uaa37-\\uaa3f\\uaa4e-\\uaa4f\\uaa5a-\\uaa5b\\uaac3-\\uaada\\uaaf7-\\uab00\\uab07-\\uab08\\uab0f-\\uab10\\uab17-\\uab1f\\uab27\\uab2f\\uab66-\\uab6f\\uabee-\\uabef\\uabfa-\\uabff\\ud7a4-\\ud7af\\ud7c7-\\ud7ca\\ud7fc-\\ud7ff\\ufa6e-\\ufa6f\\ufada-\\ufaff\\ufb07-\\ufb12\\ufb18-\\ufb1c\\ufb37\\ufb3d\\ufb3f\\ufb42\\ufb45\\ufbc2-\\ufbd2\\ufd40-\\ufd4f\\ufd90-\\ufd91\\ufdc8-\\ufdef\\ufdfe-\\ufdff\\ufe1a-\\ufe1f\\ufe53\\ufe67\\ufe6c-\\ufe6f\\ufe75\\ufefd-\\ufefe\\uff00\\uffbf-\\uffc1\\uffc8-\\uffc9\\uffd0-\\uffd1\\uffd8-\\uffd9\\uffdd-\\uffdf\\uffe7\\uffef-\\ufff8\\ufffe-\\uffff\\U0001000c\\U00010027\\U0001003b\\U0001003e\\U0001004e-\\U0001004f\\U0001005e-\\U0001007f\\U000100fb-\\U000100ff\\U00010103-\\U00010106\\U00010134-\\U00010136\\U0001018f\\U0001019c-\\U0001019f\\U000101a1-\\U000101cf\\U000101fe-\\U0001027f\\U0001029d-\\U0001029f\\U000102d1-\\U000102df\\U000102fc-\\U000102ff\\U00010324-\\U0001032c\\U0001034b-\\U0001034f\\U0001037b-\\U0001037f\\U0001039e\\U000103c4-\\U000103c7\\U000103d6-\\U000103ff\\U0001049e-\\U0001049f\\U000104aa-\\U000104af\\U000104d4-\\U000104d7\\U000104fc-\\U000104ff\\U00010528-\\U0001052f\\U00010564-\\U0001056e\\U00010570-\\U000105ff\\U00010737-\\U0001073f\\U00010756-\\U0001075f\\U00010768-\\U000107ff\\U00010806-\\U00010807\\U00010809\\U00010836\\U00010839-\\U0001083b\\U0001083d-\\U0001083e\\U00010856\\U0001089f-\\U000108a6\\U000108b0-\\U000108df\\U000108f3\\U000108f6-\\U000108fa\\U0001091c-\\U0001091e\\U0001093a-\\U0001093e\\U00010940-\\U0001097f\\U000109b8-\\U000109bb\\U000109d0-\\U000109d1\\U00010a04\\U00010a07-\\U00010a0b\\U00010a14\\U00010a18\\U00010a36-\\U00010a37\\U00010a3b-\\U00010a3e\\U00010a49-\\U00010a4f\\U00010a59-\\U00010a5f\\U00010aa0-\\U00010abf\\U00010ae7-\\U00010aea\\U00010af7-\\U00010aff\\U00010b36-\\U00010b38\\U00010b56-\\U00010b57\\U00010b73-\\U00010b77\\U00010b92-\\U00010b98\\U00010b9d-\\U00010ba8\\U00010bb0-\\U00010bff\\U00010c49-\\U00010c7f\\U00010cb3-\\U00010cbf\\U00010cf3-\\U00010cf9\\U00010d28-\\U00010d2f\\U00010d3a-\\U00010e5f\\U00010e7f-\\U00010eff\\U00010f28-\\U00010f2f\\U00010f5a-\\U00010fff\\U0001104e-\\U00011051\\U00011070-\\U0001107e\\U000110c2-\\U000110cc\\U000110ce-\\U000110cf\\U000110e9-\\U000110ef\\U000110fa-\\U000110ff\\U00011135\\U00011147-\\U0001114f\\U00011177-\\U0001117f\\U000111ce-\\U000111cf\\U000111e0\\U000111f5-\\U000111ff\\U00011212\\U0001123f-\\U0001127f\\U00011287\\U00011289\\U0001128e\\U0001129e\\U000112aa-\\U000112af\\U000112eb-\\U000112ef\\U000112fa-\\U000112ff\\U00011304\\U0001130d-\\U0001130e\\U00011311-\\U00011312\\U00011329\\U00011331\\U00011334\\U0001133a\\U00011345-\\U00011346\\U00011349-\\U0001134a\\U0001134e-\\U0001134f\\U00011351-\\U00011356\\U00011358-\\U0001135c\\U00011364-\\U00011365\\U0001136d-\\U0001136f\\U00011375-\\U000113ff\\U0001145a\\U0001145c\\U0001145f-\\U0001147f\\U000114c8-\\U000114cf\\U000114da-\\U0001157f\\U000115b6-\\U000115b7\\U000115de-\\U000115ff\\U00011645-\\U0001164f\\U0001165a-\\U0001165f\\U0001166d-\\U0001167f\\U000116b8-\\U000116bf\\U000116ca-\\U000116ff\\U0001171b-\\U0001171c\\U0001172c-\\U0001172f\\U00011740-\\U000117ff\\U0001183c-\\U0001189f\\U000118f3-\\U000118fe\\U00011900-\\U000119ff\\U00011a48-\\U00011a4f\\U00011a84-\\U00011a85\\U00011aa3-\\U00011abf\\U00011af9-\\U00011bff\\U00011c09\\U00011c37\\U00011c46-\\U00011c4f\\U00011c6d-\\U00011c6f\\U00011c90-\\U00011c91\\U00011ca8\\U00011cb7-\\U00011cff\\U00011d07\\U00011d0a\\U00011d37-\\U00011d39\\U00011d3b\\U00011d3e\\U00011d48-\\U00011d4f\\U00011d5a-\\U00011d5f\\U00011d66\\U00011d69\\U00011d8f\\U00011d92\\U00011d99-\\U00011d9f\\U00011daa-\\U00011edf\\U00011ef9-\\U00011fff\\U0001239a-\\U000123ff\\U0001246f\\U00012475-\\U0001247f\\U00012544-\\U00012fff\\U0001342f-\\U000143ff\\U00014647-\\U000167ff\\U00016a39-\\U00016a3f\\U00016a5f\\U00016a6a-\\U00016a6d\\U00016a70-\\U00016acf\\U00016aee-\\U00016aef\\U00016af6-\\U00016aff\\U00016b46-\\U00016b4f\\U00016b5a\\U00016b62\\U00016b78-\\U00016b7c\\U00016b90-\\U00016e3f\\U00016e9b-\\U00016eff\\U00016f45-\\U00016f4f\\U00016f7f-\\U00016f8e\\U00016fa0-\\U00016fdf\\U00016fe2-\\U00016fff\\U000187f2-\\U000187ff\\U00018af3-\\U0001afff\\U0001b11f-\\U0001b16f\\U0001b2fc-\\U0001bbff\\U0001bc6b-\\U0001bc6f\\U0001bc7d-\\U0001bc7f\\U0001bc89-\\U0001bc8f\\U0001bc9a-\\U0001bc9b\\U0001bca4-\\U0001cfff\\U0001d0f6-\\U0001d0ff\\U0001d127-\\U0001d128\\U0001d1e9-\\U0001d1ff\\U0001d246-\\U0001d2df\\U0001d2f4-\\U0001d2ff\\U0001d357-\\U0001d35f\\U0001d379-\\U0001d3ff\\U0001d455\\U0001d49d\\U0001d4a0-\\U0001d4a1\\U0001d4a3-\\U0001d4a4\\U0001d4a7-\\U0001d4a8\\U0001d4ad\\U0001d4ba\\U0001d4bc\\U0001d4c4\\U0001d506\\U0001d50b-\\U0001d50c\\U0001d515\\U0001d51d\\U0001d53a\\U0001d53f\\U0001d545\\U0001d547-\\U0001d549\\U0001d551\\U0001d6a6-\\U0001d6a7\\U0001d7cc-\\U0001d7cd\\U0001da8c-\\U0001da9a\\U0001daa0\\U0001dab0-\\U0001dfff\\U0001e007\\U0001e019-\\U0001e01a\\U0001e022\\U0001e025\\U0001e02b-\\U0001e7ff\\U0001e8c5-\\U0001e8c6\\U0001e8d7-\\U0001e8ff\\U0001e94b-\\U0001e94f\\U0001e95a-\\U0001e95d\\U0001e960-\\U0001ec70\\U0001ecb5-\\U0001edff\\U0001ee04\\U0001ee20\\U0001ee23\\U0001ee25-\\U0001ee26\\U0001ee28\\U0001ee33\\U0001ee38\\U0001ee3a\\U0001ee3c-\\U0001ee41\\U0001ee43-\\U0001ee46\\U0001ee48\\U0001ee4a\\U0001ee4c\\U0001ee50\\U0001ee53\\U0001ee55-\\U0001ee56\\U0001ee58\\U0001ee5a\\U0001ee5c\\U0001ee5e\\U0001ee60\\U0001ee63\\U0001ee65-\\U0001ee66\\U0001ee6b\\U0001ee73\\U0001ee78\\U0001ee7d\\U0001ee7f\\U0001ee8a\\U0001ee9c-\\U0001eea0\\U0001eea4\\U0001eeaa\\U0001eebc-\\U0001eeef\\U0001eef2-\\U0001efff\\U0001f02c-\\U0001f02f\\U0001f094-\\U0001f09f\\U0001f0af-\\U0001f0b0\\U0001f0c0\\U0001f0d0\\U0001f0f6-\\U0001f0ff\\U0001f10d-\\U0001f10f\\U0001f16c-\\U0001f16f\\U0001f1ad-\\U0001f1e5\\U0001f203-\\U0001f20f\\U0001f23c-\\U0001f23f\\U0001f249-\\U0001f24f\\U0001f252-\\U0001f25f\\U0001f266-\\U0001f2ff\\U0001f6d5-\\U0001f6df\\U0001f6ed-\\U0001f6ef\\U0001f6fa-\\U0001f6ff\\U0001f774-\\U0001f77f\\U0001f7d9-\\U0001f7ff\\U0001f80c-\\U0001f80f\\U0001f848-\\U0001f84f\\U0001f85a-\\U0001f85f\\U0001f888-\\U0001f88f\\U0001f8ae-\\U0001f8ff\\U0001f90c-\\U0001f90f\\U0001f93f\\U0001f971-\\U0001f972\\U0001f977-\\U0001f979\\U0001f97b\\U0001f9a3-\\U0001f9af\\U0001f9ba-\\U0001f9bf\\U0001f9c3-\\U0001f9cf\\U0001fa00-\\U0001fa5f\\U0001fa6e-\\U0001ffff\\U0002a6d7-\\U0002a6ff\\U0002b735-\\U0002b73f\\U0002b81e-\\U0002b81f\\U0002cea2-\\U0002ceaf\\U0002ebe1-\\U0002f7ff\\U0002fa1e-\\U000e0000\\U000e0002-\\U000e001f\\U000e0080-\\U000e00ff\\U000e01f0-\\U000effff\\U000ffffe-\\U000fffff\\U0010fffe-\\U0010ffff'\n\nCo = '\\ue000-\\uf8ff\\U000f0000-\\U000ffffd\\U00100000-\\U0010fffd'\n\nCs = '\\ud800-\\udbff\\\\\\udc00\\udc01-\\udfff'\n\nLl = 'a-z\\xb5\\xdf-\\xf6\\xf8-\\xff\\u0101\\u0103\\u0105\\u0107\\u0109\\u010b\\u010d\\u010f\\u0111\\u0113\\u0115\\u0117\\u0119\\u011b\\u011d\\u011f\\u0121\\u0123\\u0125\\u0127\\u0129\\u012b\\u012d\\u012f\\u0131\\u0133\\u0135\\u0137-\\u0138\\u013a\\u013c\\u013e\\u0140\\u0142\\u0144\\u0146\\u0148-\\u0149\\u014b\\u014d\\u014f\\u0151\\u0153\\u0155\\u0157\\u0159\\u015b\\u015d\\u015f\\u0161\\u0163\\u0165\\u0167\\u0169\\u016b\\u016d\\u016f\\u0171\\u0173\\u0175\\u0177\\u017a\\u017c\\u017e-\\u0180\\u0183\\u0185\\u0188\\u018c-\\u018d\\u0192\\u0195\\u0199-\\u019b\\u019e\\u01a1\\u01a3\\u01a5\\u01a8\\u01aa-\\u01ab\\u01ad\\u01b0\\u01b4\\u01b6\\u01b9-\\u01ba\\u01bd-\\u01bf\\u01c6\\u01c9\\u01cc\\u01ce\\u01d0\\u01d2\\u01d4\\u01d6\\u01d8\\u01da\\u01dc-\\u01dd\\u01df\\u01e1\\u01e3\\u01e5\\u01e7\\u01e9\\u01eb\\u01ed\\u01ef-\\u01f0\\u01f3\\u01f5\\u01f9\\u01fb\\u01fd\\u01ff\\u0201\\u0203\\u0205\\u0207\\u0209\\u020b\\u020d\\u020f\\u0211\\u0213\\u0215\\u0217\\u0219\\u021b\\u021d\\u021f\\u0221\\u0223\\u0225\\u0227\\u0229\\u022b\\u022d\\u022f\\u0231\\u0233-\\u0239\\u023c\\u023f-\\u0240\\u0242\\u0247\\u0249\\u024b\\u024d\\u024f-\\u0293\\u0295-\\u02af\\u0371\\u0373\\u0377\\u037b-\\u037d\\u0390\\u03ac-\\u03ce\\u03d0-\\u03d1\\u03d5-\\u03d7\\u03d9\\u03db\\u03dd\\u03df\\u03e1\\u03e3\\u03e5\\u03e7\\u03e9\\u03eb\\u03ed\\u03ef-\\u03f3\\u03f5\\u03f8\\u03fb-\\u03fc\\u0430-\\u045f\\u0461\\u0463\\u0465\\u0467\\u0469\\u046b\\u046d\\u046f\\u0471\\u0473\\u0475\\u0477\\u0479\\u047b\\u047d\\u047f\\u0481\\u048b\\u048d\\u048f\\u0491\\u0493\\u0495\\u0497\\u0499\\u049b\\u049d\\u049f\\u04a1\\u04a3\\u04a5\\u04a7\\u04a9\\u04ab\\u04ad\\u04af\\u04b1\\u04b3\\u04b5\\u04b7\\u04b9\\u04bb\\u04bd\\u04bf\\u04c2\\u04c4\\u04c6\\u04c8\\u04ca\\u04cc\\u04ce-\\u04cf\\u04d1\\u04d3\\u04d5\\u04d7\\u04d9\\u04db\\u04dd\\u04df\\u04e1\\u04e3\\u04e5\\u04e7\\u04e9\\u04eb\\u04ed\\u04ef\\u04f1\\u04f3\\u04f5\\u04f7\\u04f9\\u04fb\\u04fd\\u04ff\\u0501\\u0503\\u0505\\u0507\\u0509\\u050b\\u050d\\u050f\\u0511\\u0513\\u0515\\u0517\\u0519\\u051b\\u051d\\u051f\\u0521\\u0523\\u0525\\u0527\\u0529\\u052b\\u052d\\u052f\\u0560-\\u0588\\u10d0-\\u10fa\\u10fd-\\u10ff\\u13f8-\\u13fd\\u1c80-\\u1c88\\u1d00-\\u1d2b\\u1d6b-\\u1d77\\u1d79-\\u1d9a\\u1e01\\u1e03\\u1e05\\u1e07\\u1e09\\u1e0b\\u1e0d\\u1e0f\\u1e11\\u1e13\\u1e15\\u1e17\\u1e19\\u1e1b\\u1e1d\\u1e1f\\u1e21\\u1e23\\u1e25\\u1e27\\u1e29\\u1e2b\\u1e2d\\u1e2f\\u1e31\\u1e33\\u1e35\\u1e37\\u1e39\\u1e3b\\u1e3d\\u1e3f\\u1e41\\u1e43\\u1e45\\u1e47\\u1e49\\u1e4b\\u1e4d\\u1e4f\\u1e51\\u1e53\\u1e55\\u1e57\\u1e59\\u1e5b\\u1e5d\\u1e5f\\u1e61\\u1e63\\u1e65\\u1e67\\u1e69\\u1e6b\\u1e6d\\u1e6f\\u1e71\\u1e73\\u1e75\\u1e77\\u1e79\\u1e7b\\u1e7d\\u1e7f\\u1e81\\u1e83\\u1e85\\u1e87\\u1e89\\u1e8b\\u1e8d\\u1e8f\\u1e91\\u1e93\\u1e95-\\u1e9d\\u1e9f\\u1ea1\\u1ea3\\u1ea5\\u1ea7\\u1ea9\\u1eab\\u1ead\\u1eaf\\u1eb1\\u1eb3\\u1eb5\\u1eb7\\u1eb9\\u1ebb\\u1ebd\\u1ebf\\u1ec1\\u1ec3\\u1ec5\\u1ec7\\u1ec9\\u1ecb\\u1ecd\\u1ecf\\u1ed1\\u1ed3\\u1ed5\\u1ed7\\u1ed9\\u1edb\\u1edd\\u1edf\\u1ee1\\u1ee3\\u1ee5\\u1ee7\\u1ee9\\u1eeb\\u1eed\\u1eef\\u1ef1\\u1ef3\\u1ef5\\u1ef7\\u1ef9\\u1efb\\u1efd\\u1eff-\\u1f07\\u1f10-\\u1f15\\u1f20-\\u1f27\\u1f30-\\u1f37\\u1f40-\\u1f45\\u1f50-\\u1f57\\u1f60-\\u1f67\\u1f70-\\u1f7d\\u1f80-\\u1f87\\u1f90-\\u1f97\\u1fa0-\\u1fa7\\u1fb0-\\u1fb4\\u1fb6-\\u1fb7\\u1fbe\\u1fc2-\\u1fc4\\u1fc6-\\u1fc7\\u1fd0-\\u1fd3\\u1fd6-\\u1fd7\\u1fe0-\\u1fe7\\u1ff2-\\u1ff4\\u1ff6-\\u1ff7\\u210a\\u210e-\\u210f\\u2113\\u212f\\u2134\\u2139\\u213c-\\u213d\\u2146-\\u2149\\u214e\\u2184\\u2c30-\\u2c5e\\u2c61\\u2c65-\\u2c66\\u2c68\\u2c6a\\u2c6c\\u2c71\\u2c73-\\u2c74\\u2c76-\\u2c7b\\u2c81\\u2c83\\u2c85\\u2c87\\u2c89\\u2c8b\\u2c8d\\u2c8f\\u2c91\\u2c93\\u2c95\\u2c97\\u2c99\\u2c9b\\u2c9d\\u2c9f\\u2ca1\\u2ca3\\u2ca5\\u2ca7\\u2ca9\\u2cab\\u2cad\\u2caf\\u2cb1\\u2cb3\\u2cb5\\u2cb7\\u2cb9\\u2cbb\\u2cbd\\u2cbf\\u2cc1\\u2cc3\\u2cc5\\u2cc7\\u2cc9\\u2ccb\\u2ccd\\u2ccf\\u2cd1\\u2cd3\\u2cd5\\u2cd7\\u2cd9\\u2cdb\\u2cdd\\u2cdf\\u2ce1\\u2ce3-\\u2ce4\\u2cec\\u2cee\\u2cf3\\u2d00-\\u2d25\\u2d27\\u2d2d\\ua641\\ua643\\ua645\\ua647\\ua649\\ua64b\\ua64d\\ua64f\\ua651\\ua653\\ua655\\ua657\\ua659\\ua65b\\ua65d\\ua65f\\ua661\\ua663\\ua665\\ua667\\ua669\\ua66b\\ua66d\\ua681\\ua683\\ua685\\ua687\\ua689\\ua68b\\ua68d\\ua68f\\ua691\\ua693\\ua695\\ua697\\ua699\\ua69b\\ua723\\ua725\\ua727\\ua729\\ua72b\\ua72d\\ua72f-\\ua731\\ua733\\ua735\\ua737\\ua739\\ua73b\\ua73d\\ua73f\\ua741\\ua743\\ua745\\ua747\\ua749\\ua74b\\ua74d\\ua74f\\ua751\\ua753\\ua755\\ua757\\ua759\\ua75b\\ua75d\\ua75f\\ua761\\ua763\\ua765\\ua767\\ua769\\ua76b\\ua76d\\ua76f\\ua771-\\ua778\\ua77a\\ua77c\\ua77f\\ua781\\ua783\\ua785\\ua787\\ua78c\\ua78e\\ua791\\ua793-\\ua795\\ua797\\ua799\\ua79b\\ua79d\\ua79f\\ua7a1\\ua7a3\\ua7a5\\ua7a7\\ua7a9\\ua7af\\ua7b5\\ua7b7\\ua7b9\\ua7fa\\uab30-\\uab5a\\uab60-\\uab65\\uab70-\\uabbf\\ufb00-\\ufb06\\ufb13-\\ufb17\\uff41-\\uff5a\\U00010428-\\U0001044f\\U000104d8-\\U000104fb\\U00010cc0-\\U00010cf2\\U000118c0-\\U000118df\\U00016e60-\\U00016e7f\\U0001d41a-\\U0001d433\\U0001d44e-\\U0001d454\\U0001d456-\\U0001d467\\U0001d482-\\U0001d49b\\U0001d4b6-\\U0001d4b9\\U0001d4bb\\U0001d4bd-\\U0001d4c3\\U0001d4c5-\\U0001d4cf\\U0001d4ea-\\U0001d503\\U0001d51e-\\U0001d537\\U0001d552-\\U0001d56b\\U0001d586-\\U0001d59f\\U0001d5ba-\\U0001d5d3\\U0001d5ee-\\U0001d607\\U0001d622-\\U0001d63b\\U0001d656-\\U0001d66f\\U0001d68a-\\U0001d6a5\\U0001d6c2-\\U0001d6da\\U0001d6dc-\\U0001d6e1\\U0001d6fc-\\U0001d714\\U0001d716-\\U0001d71b\\U0001d736-\\U0001d74e\\U0001d750-\\U0001d755\\U0001d770-\\U0001d788\\U0001d78a-\\U0001d78f\\U0001d7aa-\\U0001d7c2\\U0001d7c4-\\U0001d7c9\\U0001d7cb\\U0001e922-\\U0001e943'\n\nLm = '\\u02b0-\\u02c1\\u02c6-\\u02d1\\u02e0-\\u02e4\\u02ec\\u02ee\\u0374\\u037a\\u0559\\u0640\\u06e5-\\u06e6\\u07f4-\\u07f5\\u07fa\\u081a\\u0824\\u0828\\u0971\\u0e46\\u0ec6\\u10fc\\u17d7\\u1843\\u1aa7\\u1c78-\\u1c7d\\u1d2c-\\u1d6a\\u1d78\\u1d9b-\\u1dbf\\u2071\\u207f\\u2090-\\u209c\\u2c7c-\\u2c7d\\u2d6f\\u2e2f\\u3005\\u3031-\\u3035\\u303b\\u309d-\\u309e\\u30fc-\\u30fe\\ua015\\ua4f8-\\ua4fd\\ua60c\\ua67f\\ua69c-\\ua69d\\ua717-\\ua71f\\ua770\\ua788\\ua7f8-\\ua7f9\\ua9cf\\ua9e6\\uaa70\\uaadd\\uaaf3-\\uaaf4\\uab5c-\\uab5f\\uff70\\uff9e-\\uff9f\\U00016b40-\\U00016b43\\U00016f93-\\U00016f9f\\U00016fe0-\\U00016fe1'\n\nLo = '\\xaa\\xba\\u01bb\\u01c0-\\u01c3\\u0294\\u05d0-\\u05ea\\u05ef-\\u05f2\\u0620-\\u063f\\u0641-\\u064a\\u066e-\\u066f\\u0671-\\u06d3\\u06d5\\u06ee-\\u06ef\\u06fa-\\u06fc\\u06ff\\u0710\\u0712-\\u072f\\u074d-\\u07a5\\u07b1\\u07ca-\\u07ea\\u0800-\\u0815\\u0840-\\u0858\\u0860-\\u086a\\u08a0-\\u08b4\\u08b6-\\u08bd\\u0904-\\u0939\\u093d\\u0950\\u0958-\\u0961\\u0972-\\u0980\\u0985-\\u098c\\u098f-\\u0990\\u0993-\\u09a8\\u09aa-\\u09b0\\u09b2\\u09b6-\\u09b9\\u09bd\\u09ce\\u09dc-\\u09dd\\u09df-\\u09e1\\u09f0-\\u09f1\\u09fc\\u0a05-\\u0a0a\\u0a0f-\\u0a10\\u0a13-\\u0a28\\u0a2a-\\u0a30\\u0a32-\\u0a33\\u0a35-\\u0a36\\u0a38-\\u0a39\\u0a59-\\u0a5c\\u0a5e\\u0a72-\\u0a74\\u0a85-\\u0a8d\\u0a8f-\\u0a91\\u0a93-\\u0aa8\\u0aaa-\\u0ab0\\u0ab2-\\u0ab3\\u0ab5-\\u0ab9\\u0abd\\u0ad0\\u0ae0-\\u0ae1\\u0af9\\u0b05-\\u0b0c\\u0b0f-\\u0b10\\u0b13-\\u0b28\\u0b2a-\\u0b30\\u0b32-\\u0b33\\u0b35-\\u0b39\\u0b3d\\u0b5c-\\u0b5d\\u0b5f-\\u0b61\\u0b71\\u0b83\\u0b85-\\u0b8a\\u0b8e-\\u0b90\\u0b92-\\u0b95\\u0b99-\\u0b9a\\u0b9c\\u0b9e-\\u0b9f\\u0ba3-\\u0ba4\\u0ba8-\\u0baa\\u0bae-\\u0bb9\\u0bd0\\u0c05-\\u0c0c\\u0c0e-\\u0c10\\u0c12-\\u0c28\\u0c2a-\\u0c39\\u0c3d\\u0c58-\\u0c5a\\u0c60-\\u0c61\\u0c80\\u0c85-\\u0c8c\\u0c8e-\\u0c90\\u0c92-\\u0ca8\\u0caa-\\u0cb3\\u0cb5-\\u0cb9\\u0cbd\\u0cde\\u0ce0-\\u0ce1\\u0cf1-\\u0cf2\\u0d05-\\u0d0c\\u0d0e-\\u0d10\\u0d12-\\u0d3a\\u0d3d\\u0d4e\\u0d54-\\u0d56\\u0d5f-\\u0d61\\u0d7a-\\u0d7f\\u0d85-\\u0d96\\u0d9a-\\u0db1\\u0db3-\\u0dbb\\u0dbd\\u0dc0-\\u0dc6\\u0e01-\\u0e30\\u0e32-\\u0e33\\u0e40-\\u0e45\\u0e81-\\u0e82\\u0e84\\u0e87-\\u0e88\\u0e8a\\u0e8d\\u0e94-\\u0e97\\u0e99-\\u0e9f\\u0ea1-\\u0ea3\\u0ea5\\u0ea7\\u0eaa-\\u0eab\\u0ead-\\u0eb0\\u0eb2-\\u0eb3\\u0ebd\\u0ec0-\\u0ec4\\u0edc-\\u0edf\\u0f00\\u0f40-\\u0f47\\u0f49-\\u0f6c\\u0f88-\\u0f8c\\u1000-\\u102a\\u103f\\u1050-\\u1055\\u105a-\\u105d\\u1061\\u1065-\\u1066\\u106e-\\u1070\\u1075-\\u1081\\u108e\\u1100-\\u1248\\u124a-\\u124d\\u1250-\\u1256\\u1258\\u125a-\\u125d\\u1260-\\u1288\\u128a-\\u128d\\u1290-\\u12b0\\u12b2-\\u12b5\\u12b8-\\u12be\\u12c0\\u12c2-\\u12c5\\u12c8-\\u12d6\\u12d8-\\u1310\\u1312-\\u1315\\u1318-\\u135a\\u1380-\\u138f\\u1401-\\u166c\\u166f-\\u167f\\u1681-\\u169a\\u16a0-\\u16ea\\u16f1-\\u16f8\\u1700-\\u170c\\u170e-\\u1711\\u1720-\\u1731\\u1740-\\u1751\\u1760-\\u176c\\u176e-\\u1770\\u1780-\\u17b3\\u17dc\\u1820-\\u1842\\u1844-\\u1878\\u1880-\\u1884\\u1887-\\u18a8\\u18aa\\u18b0-\\u18f5\\u1900-\\u191e\\u1950-\\u196d\\u1970-\\u1974\\u1980-\\u19ab\\u19b0-\\u19c9\\u1a00-\\u1a16\\u1a20-\\u1a54\\u1b05-\\u1b33\\u1b45-\\u1b4b\\u1b83-\\u1ba0\\u1bae-\\u1baf\\u1bba-\\u1be5\\u1c00-\\u1c23\\u1c4d-\\u1c4f\\u1c5a-\\u1c77\\u1ce9-\\u1cec\\u1cee-\\u1cf1\\u1cf5-\\u1cf6\\u2135-\\u2138\\u2d30-\\u2d67\\u2d80-\\u2d96\\u2da0-\\u2da6\\u2da8-\\u2dae\\u2db0-\\u2db6\\u2db8-\\u2dbe\\u2dc0-\\u2dc6\\u2dc8-\\u2dce\\u2dd0-\\u2dd6\\u2dd8-\\u2dde\\u3006\\u303c\\u3041-\\u3096\\u309f\\u30a1-\\u30fa\\u30ff\\u3105-\\u312f\\u3131-\\u318e\\u31a0-\\u31ba\\u31f0-\\u31ff\\u3400-\\u4db5\\u4e00-\\u9fef\\ua000-\\ua014\\ua016-\\ua48c\\ua4d0-\\ua4f7\\ua500-\\ua60b\\ua610-\\ua61f\\ua62a-\\ua62b\\ua66e\\ua6a0-\\ua6e5\\ua78f\\ua7f7\\ua7fb-\\ua801\\ua803-\\ua805\\ua807-\\ua80a\\ua80c-\\ua822\\ua840-\\ua873\\ua882-\\ua8b3\\ua8f2-\\ua8f7\\ua8fb\\ua8fd-\\ua8fe\\ua90a-\\ua925\\ua930-\\ua946\\ua960-\\ua97c\\ua984-\\ua9b2\\ua9e0-\\ua9e4\\ua9e7-\\ua9ef\\ua9fa-\\ua9fe\\uaa00-\\uaa28\\uaa40-\\uaa42\\uaa44-\\uaa4b\\uaa60-\\uaa6f\\uaa71-\\uaa76\\uaa7a\\uaa7e-\\uaaaf\\uaab1\\uaab5-\\uaab6\\uaab9-\\uaabd\\uaac0\\uaac2\\uaadb-\\uaadc\\uaae0-\\uaaea\\uaaf2\\uab01-\\uab06\\uab09-\\uab0e\\uab11-\\uab16\\uab20-\\uab26\\uab28-\\uab2e\\uabc0-\\uabe2\\uac00-\\ud7a3\\ud7b0-\\ud7c6\\ud7cb-\\ud7fb\\uf900-\\ufa6d\\ufa70-\\ufad9\\ufb1d\\ufb1f-\\ufb28\\ufb2a-\\ufb36\\ufb38-\\ufb3c\\ufb3e\\ufb40-\\ufb41\\ufb43-\\ufb44\\ufb46-\\ufbb1\\ufbd3-\\ufd3d\\ufd50-\\ufd8f\\ufd92-\\ufdc7\\ufdf0-\\ufdfb\\ufe70-\\ufe74\\ufe76-\\ufefc\\uff66-\\uff6f\\uff71-\\uff9d\\uffa0-\\uffbe\\uffc2-\\uffc7\\uffca-\\uffcf\\uffd2-\\uffd7\\uffda-\\uffdc\\U00010000-\\U0001000b\\U0001000d-\\U00010026\\U00010028-\\U0001003a\\U0001003c-\\U0001003d\\U0001003f-\\U0001004d\\U00010050-\\U0001005d\\U00010080-\\U000100fa\\U00010280-\\U0001029c\\U000102a0-\\U000102d0\\U00010300-\\U0001031f\\U0001032d-\\U00010340\\U00010342-\\U00010349\\U00010350-\\U00010375\\U00010380-\\U0001039d\\U000103a0-\\U000103c3\\U000103c8-\\U000103cf\\U00010450-\\U0001049d\\U00010500-\\U00010527\\U00010530-\\U00010563\\U00010600-\\U00010736\\U00010740-\\U00010755\\U00010760-\\U00010767\\U00010800-\\U00010805\\U00010808\\U0001080a-\\U00010835\\U00010837-\\U00010838\\U0001083c\\U0001083f-\\U00010855\\U00010860-\\U00010876\\U00010880-\\U0001089e\\U000108e0-\\U000108f2\\U000108f4-\\U000108f5\\U00010900-\\U00010915\\U00010920-\\U00010939\\U00010980-\\U000109b7\\U000109be-\\U000109bf\\U00010a00\\U00010a10-\\U00010a13\\U00010a15-\\U00010a17\\U00010a19-\\U00010a35\\U00010a60-\\U00010a7c\\U00010a80-\\U00010a9c\\U00010ac0-\\U00010ac7\\U00010ac9-\\U00010ae4\\U00010b00-\\U00010b35\\U00010b40-\\U00010b55\\U00010b60-\\U00010b72\\U00010b80-\\U00010b91\\U00010c00-\\U00010c48\\U00010d00-\\U00010d23\\U00010f00-\\U00010f1c\\U00010f27\\U00010f30-\\U00010f45\\U00011003-\\U00011037\\U00011083-\\U000110af\\U000110d0-\\U000110e8\\U00011103-\\U00011126\\U00011144\\U00011150-\\U00011172\\U00011176\\U00011183-\\U000111b2\\U000111c1-\\U000111c4\\U000111da\\U000111dc\\U00011200-\\U00011211\\U00011213-\\U0001122b\\U00011280-\\U00011286\\U00011288\\U0001128a-\\U0001128d\\U0001128f-\\U0001129d\\U0001129f-\\U000112a8\\U000112b0-\\U000112de\\U00011305-\\U0001130c\\U0001130f-\\U00011310\\U00011313-\\U00011328\\U0001132a-\\U00011330\\U00011332-\\U00011333\\U00011335-\\U00011339\\U0001133d\\U00011350\\U0001135d-\\U00011361\\U00011400-\\U00011434\\U00011447-\\U0001144a\\U00011480-\\U000114af\\U000114c4-\\U000114c5\\U000114c7\\U00011580-\\U000115ae\\U000115d8-\\U000115db\\U00011600-\\U0001162f\\U00011644\\U00011680-\\U000116aa\\U00011700-\\U0001171a\\U00011800-\\U0001182b\\U000118ff\\U00011a00\\U00011a0b-\\U00011a32\\U00011a3a\\U00011a50\\U00011a5c-\\U00011a83\\U00011a86-\\U00011a89\\U00011a9d\\U00011ac0-\\U00011af8\\U00011c00-\\U00011c08\\U00011c0a-\\U00011c2e\\U00011c40\\U00011c72-\\U00011c8f\\U00011d00-\\U00011d06\\U00011d08-\\U00011d09\\U00011d0b-\\U00011d30\\U00011d46\\U00011d60-\\U00011d65\\U00011d67-\\U00011d68\\U00011d6a-\\U00011d89\\U00011d98\\U00011ee0-\\U00011ef2\\U00012000-\\U00012399\\U00012480-\\U00012543\\U00013000-\\U0001342e\\U00014400-\\U00014646\\U00016800-\\U00016a38\\U00016a40-\\U00016a5e\\U00016ad0-\\U00016aed\\U00016b00-\\U00016b2f\\U00016b63-\\U00016b77\\U00016b7d-\\U00016b8f\\U00016f00-\\U00016f44\\U00016f50\\U00017000-\\U000187f1\\U00018800-\\U00018af2\\U0001b000-\\U0001b11e\\U0001b170-\\U0001b2fb\\U0001bc00-\\U0001bc6a\\U0001bc70-\\U0001bc7c\\U0001bc80-\\U0001bc88\\U0001bc90-\\U0001bc99\\U0001e800-\\U0001e8c4\\U0001ee00-\\U0001ee03\\U0001ee05-\\U0001ee1f\\U0001ee21-\\U0001ee22\\U0001ee24\\U0001ee27\\U0001ee29-\\U0001ee32\\U0001ee34-\\U0001ee37\\U0001ee39\\U0001ee3b\\U0001ee42\\U0001ee47\\U0001ee49\\U0001ee4b\\U0001ee4d-\\U0001ee4f\\U0001ee51-\\U0001ee52\\U0001ee54\\U0001ee57\\U0001ee59\\U0001ee5b\\U0001ee5d\\U0001ee5f\\U0001ee61-\\U0001ee62\\U0001ee64\\U0001ee67-\\U0001ee6a\\U0001ee6c-\\U0001ee72\\U0001ee74-\\U0001ee77\\U0001ee79-\\U0001ee7c\\U0001ee7e\\U0001ee80-\\U0001ee89\\U0001ee8b-\\U0001ee9b\\U0001eea1-\\U0001eea3\\U0001eea5-\\U0001eea9\\U0001eeab-\\U0001eebb\\U00020000-\\U0002a6d6\\U0002a700-\\U0002b734\\U0002b740-\\U0002b81d\\U0002b820-\\U0002cea1\\U0002ceb0-\\U0002ebe0\\U0002f800-\\U0002fa1d'\n\nLt = '\\u01c5\\u01c8\\u01cb\\u01f2\\u1f88-\\u1f8f\\u1f98-\\u1f9f\\u1fa8-\\u1faf\\u1fbc\\u1fcc\\u1ffc'\n\nLu = 'A-Z\\xc0-\\xd6\\xd8-\\xde\\u0100\\u0102\\u0104\\u0106\\u0108\\u010a\\u010c\\u010e\\u0110\\u0112\\u0114\\u0116\\u0118\\u011a\\u011c\\u011e\\u0120\\u0122\\u0124\\u0126\\u0128\\u012a\\u012c\\u012e\\u0130\\u0132\\u0134\\u0136\\u0139\\u013b\\u013d\\u013f\\u0141\\u0143\\u0145\\u0147\\u014a\\u014c\\u014e\\u0150\\u0152\\u0154\\u0156\\u0158\\u015a\\u015c\\u015e\\u0160\\u0162\\u0164\\u0166\\u0168\\u016a\\u016c\\u016e\\u0170\\u0172\\u0174\\u0176\\u0178-\\u0179\\u017b\\u017d\\u0181-\\u0182\\u0184\\u0186-\\u0187\\u0189-\\u018b\\u018e-\\u0191\\u0193-\\u0194\\u0196-\\u0198\\u019c-\\u019d\\u019f-\\u01a0\\u01a2\\u01a4\\u01a6-\\u01a7\\u01a9\\u01ac\\u01ae-\\u01af\\u01b1-\\u01b3\\u01b5\\u01b7-\\u01b8\\u01bc\\u01c4\\u01c7\\u01ca\\u01cd\\u01cf\\u01d1\\u01d3\\u01d5\\u01d7\\u01d9\\u01db\\u01de\\u01e0\\u01e2\\u01e4\\u01e6\\u01e8\\u01ea\\u01ec\\u01ee\\u01f1\\u01f4\\u01f6-\\u01f8\\u01fa\\u01fc\\u01fe\\u0200\\u0202\\u0204\\u0206\\u0208\\u020a\\u020c\\u020e\\u0210\\u0212\\u0214\\u0216\\u0218\\u021a\\u021c\\u021e\\u0220\\u0222\\u0224\\u0226\\u0228\\u022a\\u022c\\u022e\\u0230\\u0232\\u023a-\\u023b\\u023d-\\u023e\\u0241\\u0243-\\u0246\\u0248\\u024a\\u024c\\u024e\\u0370\\u0372\\u0376\\u037f\\u0386\\u0388-\\u038a\\u038c\\u038e-\\u038f\\u0391-\\u03a1\\u03a3-\\u03ab\\u03cf\\u03d2-\\u03d4\\u03d8\\u03da\\u03dc\\u03de\\u03e0\\u03e2\\u03e4\\u03e6\\u03e8\\u03ea\\u03ec\\u03ee\\u03f4\\u03f7\\u03f9-\\u03fa\\u03fd-\\u042f\\u0460\\u0462\\u0464\\u0466\\u0468\\u046a\\u046c\\u046e\\u0470\\u0472\\u0474\\u0476\\u0478\\u047a\\u047c\\u047e\\u0480\\u048a\\u048c\\u048e\\u0490\\u0492\\u0494\\u0496\\u0498\\u049a\\u049c\\u049e\\u04a0\\u04a2\\u04a4\\u04a6\\u04a8\\u04aa\\u04ac\\u04ae\\u04b0\\u04b2\\u04b4\\u04b6\\u04b8\\u04ba\\u04bc\\u04be\\u04c0-\\u04c1\\u04c3\\u04c5\\u04c7\\u04c9\\u04cb\\u04cd\\u04d0\\u04d2\\u04d4\\u04d6\\u04d8\\u04da\\u04dc\\u04de\\u04e0\\u04e2\\u04e4\\u04e6\\u04e8\\u04ea\\u04ec\\u04ee\\u04f0\\u04f2\\u04f4\\u04f6\\u04f8\\u04fa\\u04fc\\u04fe\\u0500\\u0502\\u0504\\u0506\\u0508\\u050a\\u050c\\u050e\\u0510\\u0512\\u0514\\u0516\\u0518\\u051a\\u051c\\u051e\\u0520\\u0522\\u0524\\u0526\\u0528\\u052a\\u052c\\u052e\\u0531-\\u0556\\u10a0-\\u10c5\\u10c7\\u10cd\\u13a0-\\u13f5\\u1c90-\\u1cba\\u1cbd-\\u1cbf\\u1e00\\u1e02\\u1e04\\u1e06\\u1e08\\u1e0a\\u1e0c\\u1e0e\\u1e10\\u1e12\\u1e14\\u1e16\\u1e18\\u1e1a\\u1e1c\\u1e1e\\u1e20\\u1e22\\u1e24\\u1e26\\u1e28\\u1e2a\\u1e2c\\u1e2e\\u1e30\\u1e32\\u1e34\\u1e36\\u1e38\\u1e3a\\u1e3c\\u1e3e\\u1e40\\u1e42\\u1e44\\u1e46\\u1e48\\u1e4a\\u1e4c\\u1e4e\\u1e50\\u1e52\\u1e54\\u1e56\\u1e58\\u1e5a\\u1e5c\\u1e5e\\u1e60\\u1e62\\u1e64\\u1e66\\u1e68\\u1e6a\\u1e6c\\u1e6e\\u1e70\\u1e72\\u1e74\\u1e76\\u1e78\\u1e7a\\u1e7c\\u1e7e\\u1e80\\u1e82\\u1e84\\u1e86\\u1e88\\u1e8a\\u1e8c\\u1e8e\\u1e90\\u1e92\\u1e94\\u1e9e\\u1ea0\\u1ea2\\u1ea4\\u1ea6\\u1ea8\\u1eaa\\u1eac\\u1eae\\u1eb0\\u1eb2\\u1eb4\\u1eb6\\u1eb8\\u1eba\\u1ebc\\u1ebe\\u1ec0\\u1ec2\\u1ec4\\u1ec6\\u1ec8\\u1eca\\u1ecc\\u1ece\\u1ed0\\u1ed2\\u1ed4\\u1ed6\\u1ed8\\u1eda\\u1edc\\u1ede\\u1ee0\\u1ee2\\u1ee4\\u1ee6\\u1ee8\\u1eea\\u1eec\\u1eee\\u1ef0\\u1ef2\\u1ef4\\u1ef6\\u1ef8\\u1efa\\u1efc\\u1efe\\u1f08-\\u1f0f\\u1f18-\\u1f1d\\u1f28-\\u1f2f\\u1f38-\\u1f3f\\u1f48-\\u1f4d\\u1f59\\u1f5b\\u1f5d\\u1f5f\\u1f68-\\u1f6f\\u1fb8-\\u1fbb\\u1fc8-\\u1fcb\\u1fd8-\\u1fdb\\u1fe8-\\u1fec\\u1ff8-\\u1ffb\\u2102\\u2107\\u210b-\\u210d\\u2110-\\u2112\\u2115\\u2119-\\u211d\\u2124\\u2126\\u2128\\u212a-\\u212d\\u2130-\\u2133\\u213e-\\u213f\\u2145\\u2183\\u2c00-\\u2c2e\\u2c60\\u2c62-\\u2c64\\u2c67\\u2c69\\u2c6b\\u2c6d-\\u2c70\\u2c72\\u2c75\\u2c7e-\\u2c80\\u2c82\\u2c84\\u2c86\\u2c88\\u2c8a\\u2c8c\\u2c8e\\u2c90\\u2c92\\u2c94\\u2c96\\u2c98\\u2c9a\\u2c9c\\u2c9e\\u2ca0\\u2ca2\\u2ca4\\u2ca6\\u2ca8\\u2caa\\u2cac\\u2cae\\u2cb0\\u2cb2\\u2cb4\\u2cb6\\u2cb8\\u2cba\\u2cbc\\u2cbe\\u2cc0\\u2cc2\\u2cc4\\u2cc6\\u2cc8\\u2cca\\u2ccc\\u2cce\\u2cd0\\u2cd2\\u2cd4\\u2cd6\\u2cd8\\u2cda\\u2cdc\\u2cde\\u2ce0\\u2ce2\\u2ceb\\u2ced\\u2cf2\\ua640\\ua642\\ua644\\ua646\\ua648\\ua64a\\ua64c\\ua64e\\ua650\\ua652\\ua654\\ua656\\ua658\\ua65a\\ua65c\\ua65e\\ua660\\ua662\\ua664\\ua666\\ua668\\ua66a\\ua66c\\ua680\\ua682\\ua684\\ua686\\ua688\\ua68a\\ua68c\\ua68e\\ua690\\ua692\\ua694\\ua696\\ua698\\ua69a\\ua722\\ua724\\ua726\\ua728\\ua72a\\ua72c\\ua72e\\ua732\\ua734\\ua736\\ua738\\ua73a\\ua73c\\ua73e\\ua740\\ua742\\ua744\\ua746\\ua748\\ua74a\\ua74c\\ua74e\\ua750\\ua752\\ua754\\ua756\\ua758\\ua75a\\ua75c\\ua75e\\ua760\\ua762\\ua764\\ua766\\ua768\\ua76a\\ua76c\\ua76e\\ua779\\ua77b\\ua77d-\\ua77e\\ua780\\ua782\\ua784\\ua786\\ua78b\\ua78d\\ua790\\ua792\\ua796\\ua798\\ua79a\\ua79c\\ua79e\\ua7a0\\ua7a2\\ua7a4\\ua7a6\\ua7a8\\ua7aa-\\ua7ae\\ua7b0-\\ua7b4\\ua7b6\\ua7b8\\uff21-\\uff3a\\U00010400-\\U00010427\\U000104b0-\\U000104d3\\U00010c80-\\U00010cb2\\U000118a0-\\U000118bf\\U00016e40-\\U00016e5f\\U0001d400-\\U0001d419\\U0001d434-\\U0001d44d\\U0001d468-\\U0001d481\\U0001d49c\\U0001d49e-\\U0001d49f\\U0001d4a2\\U0001d4a5-\\U0001d4a6\\U0001d4a9-\\U0001d4ac\\U0001d4ae-\\U0001d4b5\\U0001d4d0-\\U0001d4e9\\U0001d504-\\U0001d505\\U0001d507-\\U0001d50a\\U0001d50d-\\U0001d514\\U0001d516-\\U0001d51c\\U0001d538-\\U0001d539\\U0001d53b-\\U0001d53e\\U0001d540-\\U0001d544\\U0001d546\\U0001d54a-\\U0001d550\\U0001d56c-\\U0001d585\\U0001d5a0-\\U0001d5b9\\U0001d5d4-\\U0001d5ed\\U0001d608-\\U0001d621\\U0001d63c-\\U0001d655\\U0001d670-\\U0001d689\\U0001d6a8-\\U0001d6c0\\U0001d6e2-\\U0001d6fa\\U0001d71c-\\U0001d734\\U0001d756-\\U0001d76e\\U0001d790-\\U0001d7a8\\U0001d7ca\\U0001e900-\\U0001e921'\n\nMc = '\\u0903\\u093b\\u093e-\\u0940\\u0949-\\u094c\\u094e-\\u094f\\u0982-\\u0983\\u09be-\\u09c0\\u09c7-\\u09c8\\u09cb-\\u09cc\\u09d7\\u0a03\\u0a3e-\\u0a40\\u0a83\\u0abe-\\u0ac0\\u0ac9\\u0acb-\\u0acc\\u0b02-\\u0b03\\u0b3e\\u0b40\\u0b47-\\u0b48\\u0b4b-\\u0b4c\\u0b57\\u0bbe-\\u0bbf\\u0bc1-\\u0bc2\\u0bc6-\\u0bc8\\u0bca-\\u0bcc\\u0bd7\\u0c01-\\u0c03\\u0c41-\\u0c44\\u0c82-\\u0c83\\u0cbe\\u0cc0-\\u0cc4\\u0cc7-\\u0cc8\\u0cca-\\u0ccb\\u0cd5-\\u0cd6\\u0d02-\\u0d03\\u0d3e-\\u0d40\\u0d46-\\u0d48\\u0d4a-\\u0d4c\\u0d57\\u0d82-\\u0d83\\u0dcf-\\u0dd1\\u0dd8-\\u0ddf\\u0df2-\\u0df3\\u0f3e-\\u0f3f\\u0f7f\\u102b-\\u102c\\u1031\\u1038\\u103b-\\u103c\\u1056-\\u1057\\u1062-\\u1064\\u1067-\\u106d\\u1083-\\u1084\\u1087-\\u108c\\u108f\\u109a-\\u109c\\u17b6\\u17be-\\u17c5\\u17c7-\\u17c8\\u1923-\\u1926\\u1929-\\u192b\\u1930-\\u1931\\u1933-\\u1938\\u1a19-\\u1a1a\\u1a55\\u1a57\\u1a61\\u1a63-\\u1a64\\u1a6d-\\u1a72\\u1b04\\u1b35\\u1b3b\\u1b3d-\\u1b41\\u1b43-\\u1b44\\u1b82\\u1ba1\\u1ba6-\\u1ba7\\u1baa\\u1be7\\u1bea-\\u1bec\\u1bee\\u1bf2-\\u1bf3\\u1c24-\\u1c2b\\u1c34-\\u1c35\\u1ce1\\u1cf2-\\u1cf3\\u1cf7\\u302e-\\u302f\\ua823-\\ua824\\ua827\\ua880-\\ua881\\ua8b4-\\ua8c3\\ua952-\\ua953\\ua983\\ua9b4-\\ua9b5\\ua9ba-\\ua9bb\\ua9bd-\\ua9c0\\uaa2f-\\uaa30\\uaa33-\\uaa34\\uaa4d\\uaa7b\\uaa7d\\uaaeb\\uaaee-\\uaaef\\uaaf5\\uabe3-\\uabe4\\uabe6-\\uabe7\\uabe9-\\uabea\\uabec\\U00011000\\U00011002\\U00011082\\U000110b0-\\U000110b2\\U000110b7-\\U000110b8\\U0001112c\\U00011145-\\U00011146\\U00011182\\U000111b3-\\U000111b5\\U000111bf-\\U000111c0\\U0001122c-\\U0001122e\\U00011232-\\U00011233\\U00011235\\U000112e0-\\U000112e2\\U00011302-\\U00011303\\U0001133e-\\U0001133f\\U00011341-\\U00011344\\U00011347-\\U00011348\\U0001134b-\\U0001134d\\U00011357\\U00011362-\\U00011363\\U00011435-\\U00011437\\U00011440-\\U00011441\\U00011445\\U000114b0-\\U000114b2\\U000114b9\\U000114bb-\\U000114be\\U000114c1\\U000115af-\\U000115b1\\U000115b8-\\U000115bb\\U000115be\\U00011630-\\U00011632\\U0001163b-\\U0001163c\\U0001163e\\U000116ac\\U000116ae-\\U000116af\\U000116b6\\U00011720-\\U00011721\\U00011726\\U0001182c-\\U0001182e\\U00011838\\U00011a39\\U00011a57-\\U00011a58\\U00011a97\\U00011c2f\\U00011c3e\\U00011ca9\\U00011cb1\\U00011cb4\\U00011d8a-\\U00011d8e\\U00011d93-\\U00011d94\\U00011d96\\U00011ef5-\\U00011ef6\\U00016f51-\\U00016f7e\\U0001d165-\\U0001d166\\U0001d16d-\\U0001d172'\n\nMe = '\\u0488-\\u0489\\u1abe\\u20dd-\\u20e0\\u20e2-\\u20e4\\ua670-\\ua672'\n\nMn = '\\u0300-\\u036f\\u0483-\\u0487\\u0591-\\u05bd\\u05bf\\u05c1-\\u05c2\\u05c4-\\u05c5\\u05c7\\u0610-\\u061a\\u064b-\\u065f\\u0670\\u06d6-\\u06dc\\u06df-\\u06e4\\u06e7-\\u06e8\\u06ea-\\u06ed\\u0711\\u0730-\\u074a\\u07a6-\\u07b0\\u07eb-\\u07f3\\u07fd\\u0816-\\u0819\\u081b-\\u0823\\u0825-\\u0827\\u0829-\\u082d\\u0859-\\u085b\\u08d3-\\u08e1\\u08e3-\\u0902\\u093a\\u093c\\u0941-\\u0948\\u094d\\u0951-\\u0957\\u0962-\\u0963\\u0981\\u09bc\\u09c1-\\u09c4\\u09cd\\u09e2-\\u09e3\\u09fe\\u0a01-\\u0a02\\u0a3c\\u0a41-\\u0a42\\u0a47-\\u0a48\\u0a4b-\\u0a4d\\u0a51\\u0a70-\\u0a71\\u0a75\\u0a81-\\u0a82\\u0abc\\u0ac1-\\u0ac5\\u0ac7-\\u0ac8\\u0acd\\u0ae2-\\u0ae3\\u0afa-\\u0aff\\u0b01\\u0b3c\\u0b3f\\u0b41-\\u0b44\\u0b4d\\u0b56\\u0b62-\\u0b63\\u0b82\\u0bc0\\u0bcd\\u0c00\\u0c04\\u0c3e-\\u0c40\\u0c46-\\u0c48\\u0c4a-\\u0c4d\\u0c55-\\u0c56\\u0c62-\\u0c63\\u0c81\\u0cbc\\u0cbf\\u0cc6\\u0ccc-\\u0ccd\\u0ce2-\\u0ce3\\u0d00-\\u0d01\\u0d3b-\\u0d3c\\u0d41-\\u0d44\\u0d4d\\u0d62-\\u0d63\\u0dca\\u0dd2-\\u0dd4\\u0dd6\\u0e31\\u0e34-\\u0e3a\\u0e47-\\u0e4e\\u0eb1\\u0eb4-\\u0eb9\\u0ebb-\\u0ebc\\u0ec8-\\u0ecd\\u0f18-\\u0f19\\u0f35\\u0f37\\u0f39\\u0f71-\\u0f7e\\u0f80-\\u0f84\\u0f86-\\u0f87\\u0f8d-\\u0f97\\u0f99-\\u0fbc\\u0fc6\\u102d-\\u1030\\u1032-\\u1037\\u1039-\\u103a\\u103d-\\u103e\\u1058-\\u1059\\u105e-\\u1060\\u1071-\\u1074\\u1082\\u1085-\\u1086\\u108d\\u109d\\u135d-\\u135f\\u1712-\\u1714\\u1732-\\u1734\\u1752-\\u1753\\u1772-\\u1773\\u17b4-\\u17b5\\u17b7-\\u17bd\\u17c6\\u17c9-\\u17d3\\u17dd\\u180b-\\u180d\\u1885-\\u1886\\u18a9\\u1920-\\u1922\\u1927-\\u1928\\u1932\\u1939-\\u193b\\u1a17-\\u1a18\\u1a1b\\u1a56\\u1a58-\\u1a5e\\u1a60\\u1a62\\u1a65-\\u1a6c\\u1a73-\\u1a7c\\u1a7f\\u1ab0-\\u1abd\\u1b00-\\u1b03\\u1b34\\u1b36-\\u1b3a\\u1b3c\\u1b42\\u1b6b-\\u1b73\\u1b80-\\u1b81\\u1ba2-\\u1ba5\\u1ba8-\\u1ba9\\u1bab-\\u1bad\\u1be6\\u1be8-\\u1be9\\u1bed\\u1bef-\\u1bf1\\u1c2c-\\u1c33\\u1c36-\\u1c37\\u1cd0-\\u1cd2\\u1cd4-\\u1ce0\\u1ce2-\\u1ce8\\u1ced\\u1cf4\\u1cf8-\\u1cf9\\u1dc0-\\u1df9\\u1dfb-\\u1dff\\u20d0-\\u20dc\\u20e1\\u20e5-\\u20f0\\u2cef-\\u2cf1\\u2d7f\\u2de0-\\u2dff\\u302a-\\u302d\\u3099-\\u309a\\ua66f\\ua674-\\ua67d\\ua69e-\\ua69f\\ua6f0-\\ua6f1\\ua802\\ua806\\ua80b\\ua825-\\ua826\\ua8c4-\\ua8c5\\ua8e0-\\ua8f1\\ua8ff\\ua926-\\ua92d\\ua947-\\ua951\\ua980-\\ua982\\ua9b3\\ua9b6-\\ua9b9\\ua9bc\\ua9e5\\uaa29-\\uaa2e\\uaa31-\\uaa32\\uaa35-\\uaa36\\uaa43\\uaa4c\\uaa7c\\uaab0\\uaab2-\\uaab4\\uaab7-\\uaab8\\uaabe-\\uaabf\\uaac1\\uaaec-\\uaaed\\uaaf6\\uabe5\\uabe8\\uabed\\ufb1e\\ufe00-\\ufe0f\\ufe20-\\ufe2f\\U000101fd\\U000102e0\\U00010376-\\U0001037a\\U00010a01-\\U00010a03\\U00010a05-\\U00010a06\\U00010a0c-\\U00010a0f\\U00010a38-\\U00010a3a\\U00010a3f\\U00010ae5-\\U00010ae6\\U00010d24-\\U00010d27\\U00010f46-\\U00010f50\\U00011001\\U00011038-\\U00011046\\U0001107f-\\U00011081\\U000110b3-\\U000110b6\\U000110b9-\\U000110ba\\U00011100-\\U00011102\\U00011127-\\U0001112b\\U0001112d-\\U00011134\\U00011173\\U00011180-\\U00011181\\U000111b6-\\U000111be\\U000111c9-\\U000111cc\\U0001122f-\\U00011231\\U00011234\\U00011236-\\U00011237\\U0001123e\\U000112df\\U000112e3-\\U000112ea\\U00011300-\\U00011301\\U0001133b-\\U0001133c\\U00011340\\U00011366-\\U0001136c\\U00011370-\\U00011374\\U00011438-\\U0001143f\\U00011442-\\U00011444\\U00011446\\U0001145e\\U000114b3-\\U000114b8\\U000114ba\\U000114bf-\\U000114c0\\U000114c2-\\U000114c3\\U000115b2-\\U000115b5\\U000115bc-\\U000115bd\\U000115bf-\\U000115c0\\U000115dc-\\U000115dd\\U00011633-\\U0001163a\\U0001163d\\U0001163f-\\U00011640\\U000116ab\\U000116ad\\U000116b0-\\U000116b5\\U000116b7\\U0001171d-\\U0001171f\\U00011722-\\U00011725\\U00011727-\\U0001172b\\U0001182f-\\U00011837\\U00011839-\\U0001183a\\U00011a01-\\U00011a0a\\U00011a33-\\U00011a38\\U00011a3b-\\U00011a3e\\U00011a47\\U00011a51-\\U00011a56\\U00011a59-\\U00011a5b\\U00011a8a-\\U00011a96\\U00011a98-\\U00011a99\\U00011c30-\\U00011c36\\U00011c38-\\U00011c3d\\U00011c3f\\U00011c92-\\U00011ca7\\U00011caa-\\U00011cb0\\U00011cb2-\\U00011cb3\\U00011cb5-\\U00011cb6\\U00011d31-\\U00011d36\\U00011d3a\\U00011d3c-\\U00011d3d\\U00011d3f-\\U00011d45\\U00011d47\\U00011d90-\\U00011d91\\U00011d95\\U00011d97\\U00011ef3-\\U00011ef4\\U00016af0-\\U00016af4\\U00016b30-\\U00016b36\\U00016f8f-\\U00016f92\\U0001bc9d-\\U0001bc9e\\U0001d167-\\U0001d169\\U0001d17b-\\U0001d182\\U0001d185-\\U0001d18b\\U0001d1aa-\\U0001d1ad\\U0001d242-\\U0001d244\\U0001da00-\\U0001da36\\U0001da3b-\\U0001da6c\\U0001da75\\U0001da84\\U0001da9b-\\U0001da9f\\U0001daa1-\\U0001daaf\\U0001e000-\\U0001e006\\U0001e008-\\U0001e018\\U0001e01b-\\U0001e021\\U0001e023-\\U0001e024\\U0001e026-\\U0001e02a\\U0001e8d0-\\U0001e8d6\\U0001e944-\\U0001e94a\\U000e0100-\\U000e01ef'\n\nNd = '0-9\\u0660-\\u0669\\u06f0-\\u06f9\\u07c0-\\u07c9\\u0966-\\u096f\\u09e6-\\u09ef\\u0a66-\\u0a6f\\u0ae6-\\u0aef\\u0b66-\\u0b6f\\u0be6-\\u0bef\\u0c66-\\u0c6f\\u0ce6-\\u0cef\\u0d66-\\u0d6f\\u0de6-\\u0def\\u0e50-\\u0e59\\u0ed0-\\u0ed9\\u0f20-\\u0f29\\u1040-\\u1049\\u1090-\\u1099\\u17e0-\\u17e9\\u1810-\\u1819\\u1946-\\u194f\\u19d0-\\u19d9\\u1a80-\\u1a89\\u1a90-\\u1a99\\u1b50-\\u1b59\\u1bb0-\\u1bb9\\u1c40-\\u1c49\\u1c50-\\u1c59\\ua620-\\ua629\\ua8d0-\\ua8d9\\ua900-\\ua909\\ua9d0-\\ua9d9\\ua9f0-\\ua9f9\\uaa50-\\uaa59\\uabf0-\\uabf9\\uff10-\\uff19\\U000104a0-\\U000104a9\\U00010d30-\\U00010d39\\U00011066-\\U0001106f\\U000110f0-\\U000110f9\\U00011136-\\U0001113f\\U000111d0-\\U000111d9\\U000112f0-\\U000112f9\\U00011450-\\U00011459\\U000114d0-\\U000114d9\\U00011650-\\U00011659\\U000116c0-\\U000116c9\\U00011730-\\U00011739\\U000118e0-\\U000118e9\\U00011c50-\\U00011c59\\U00011d50-\\U00011d59\\U00011da0-\\U00011da9\\U00016a60-\\U00016a69\\U00016b50-\\U00016b59\\U0001d7ce-\\U0001d7ff\\U0001e950-\\U0001e959'\n\nNl = '\\u16ee-\\u16f0\\u2160-\\u2182\\u2185-\\u2188\\u3007\\u3021-\\u3029\\u3038-\\u303a\\ua6e6-\\ua6ef\\U00010140-\\U00010174\\U00010341\\U0001034a\\U000103d1-\\U000103d5\\U00012400-\\U0001246e'\n\nNo = '\\xb2-\\xb3\\xb9\\xbc-\\xbe\\u09f4-\\u09f9\\u0b72-\\u0b77\\u0bf0-\\u0bf2\\u0c78-\\u0c7e\\u0d58-\\u0d5e\\u0d70-\\u0d78\\u0f2a-\\u0f33\\u1369-\\u137c\\u17f0-\\u17f9\\u19da\\u2070\\u2074-\\u2079\\u2080-\\u2089\\u2150-\\u215f\\u2189\\u2460-\\u249b\\u24ea-\\u24ff\\u2776-\\u2793\\u2cfd\\u3192-\\u3195\\u3220-\\u3229\\u3248-\\u324f\\u3251-\\u325f\\u3280-\\u3289\\u32b1-\\u32bf\\ua830-\\ua835\\U00010107-\\U00010133\\U00010175-\\U00010178\\U0001018a-\\U0001018b\\U000102e1-\\U000102fb\\U00010320-\\U00010323\\U00010858-\\U0001085f\\U00010879-\\U0001087f\\U000108a7-\\U000108af\\U000108fb-\\U000108ff\\U00010916-\\U0001091b\\U000109bc-\\U000109bd\\U000109c0-\\U000109cf\\U000109d2-\\U000109ff\\U00010a40-\\U00010a48\\U00010a7d-\\U00010a7e\\U00010a9d-\\U00010a9f\\U00010aeb-\\U00010aef\\U00010b58-\\U00010b5f\\U00010b78-\\U00010b7f\\U00010ba9-\\U00010baf\\U00010cfa-\\U00010cff\\U00010e60-\\U00010e7e\\U00010f1d-\\U00010f26\\U00010f51-\\U00010f54\\U00011052-\\U00011065\\U000111e1-\\U000111f4\\U0001173a-\\U0001173b\\U000118ea-\\U000118f2\\U00011c5a-\\U00011c6c\\U00016b5b-\\U00016b61\\U00016e80-\\U00016e96\\U0001d2e0-\\U0001d2f3\\U0001d360-\\U0001d378\\U0001e8c7-\\U0001e8cf\\U0001ec71-\\U0001ecab\\U0001ecad-\\U0001ecaf\\U0001ecb1-\\U0001ecb4\\U0001f100-\\U0001f10c'\n\nPc = '_\\u203f-\\u2040\\u2054\\ufe33-\\ufe34\\ufe4d-\\ufe4f\\uff3f'\n\nPd = '\\\\-\\u058a\\u05be\\u1400\\u1806\\u2010-\\u2015\\u2e17\\u2e1a\\u2e3a-\\u2e3b\\u2e40\\u301c\\u3030\\u30a0\\ufe31-\\ufe32\\ufe58\\ufe63\\uff0d'\n\nPe = ')\\\\]}\\u0f3b\\u0f3d\\u169c\\u2046\\u207e\\u208e\\u2309\\u230b\\u232a\\u2769\\u276b\\u276d\\u276f\\u2771\\u2773\\u2775\\u27c6\\u27e7\\u27e9\\u27eb\\u27ed\\u27ef\\u2984\\u2986\\u2988\\u298a\\u298c\\u298e\\u2990\\u2992\\u2994\\u2996\\u2998\\u29d9\\u29db\\u29fd\\u2e23\\u2e25\\u2e27\\u2e29\\u3009\\u300b\\u300d\\u300f\\u3011\\u3015\\u3017\\u3019\\u301b\\u301e-\\u301f\\ufd3e\\ufe18\\ufe36\\ufe38\\ufe3a\\ufe3c\\ufe3e\\ufe40\\ufe42\\ufe44\\ufe48\\ufe5a\\ufe5c\\ufe5e\\uff09\\uff3d\\uff5d\\uff60\\uff63'\n\nPf = '\\xbb\\u2019\\u201d\\u203a\\u2e03\\u2e05\\u2e0a\\u2e0d\\u2e1d\\u2e21'\n\nPi = '\\xab\\u2018\\u201b-\\u201c\\u201f\\u2039\\u2e02\\u2e04\\u2e09\\u2e0c\\u2e1c\\u2e20'\n\nPo = \"!-#%-'*,.-/:-;?-@\\\\\\\\\\xa1\\xa7\\xb6-\\xb7\\xbf\\u037e\\u0387\\u055a-\\u055f\\u0589\\u05c0\\u05c3\\u05c6\\u05f3-\\u05f4\\u0609-\\u060a\\u060c-\\u060d\\u061b\\u061e-\\u061f\\u066a-\\u066d\\u06d4\\u0700-\\u070d\\u07f7-\\u07f9\\u0830-\\u083e\\u085e\\u0964-\\u0965\\u0970\\u09fd\\u0a76\\u0af0\\u0c84\\u0df4\\u0e4f\\u0e5a-\\u0e5b\\u0f04-\\u0f12\\u0f14\\u0f85\\u0fd0-\\u0fd4\\u0fd9-\\u0fda\\u104a-\\u104f\\u10fb\\u1360-\\u1368\\u166d-\\u166e\\u16eb-\\u16ed\\u1735-\\u1736\\u17d4-\\u17d6\\u17d8-\\u17da\\u1800-\\u1805\\u1807-\\u180a\\u1944-\\u1945\\u1a1e-\\u1a1f\\u1aa0-\\u1aa6\\u1aa8-\\u1aad\\u1b5a-\\u1b60\\u1bfc-\\u1bff\\u1c3b-\\u1c3f\\u1c7e-\\u1c7f\\u1cc0-\\u1cc7\\u1cd3\\u2016-\\u2017\\u2020-\\u2027\\u2030-\\u2038\\u203b-\\u203e\\u2041-\\u2043\\u2047-\\u2051\\u2053\\u2055-\\u205e\\u2cf9-\\u2cfc\\u2cfe-\\u2cff\\u2d70\\u2e00-\\u2e01\\u2e06-\\u2e08\\u2e0b\\u2e0e-\\u2e16\\u2e18-\\u2e19\\u2e1b\\u2e1e-\\u2e1f\\u2e2a-\\u2e2e\\u2e30-\\u2e39\\u2e3c-\\u2e3f\\u2e41\\u2e43-\\u2e4e\\u3001-\\u3003\\u303d\\u30fb\\ua4fe-\\ua4ff\\ua60d-\\ua60f\\ua673\\ua67e\\ua6f2-\\ua6f7\\ua874-\\ua877\\ua8ce-\\ua8cf\\ua8f8-\\ua8fa\\ua8fc\\ua92e-\\ua92f\\ua95f\\ua9c1-\\ua9cd\\ua9de-\\ua9df\\uaa5c-\\uaa5f\\uaade-\\uaadf\\uaaf0-\\uaaf1\\uabeb\\ufe10-\\ufe16\\ufe19\\ufe30\\ufe45-\\ufe46\\ufe49-\\ufe4c\\ufe50-\\ufe52\\ufe54-\\ufe57\\ufe5f-\\ufe61\\ufe68\\ufe6a-\\ufe6b\\uff01-\\uff03\\uff05-\\uff07\\uff0a\\uff0c\\uff0e-\\uff0f\\uff1a-\\uff1b\\uff1f-\\uff20\\uff3c\\uff61\\uff64-\\uff65\\U00010100-\\U00010102\\U0001039f\\U000103d0\\U0001056f\\U00010857\\U0001091f\\U0001093f\\U00010a50-\\U00010a58\\U00010a7f\\U00010af0-\\U00010af6\\U00010b39-\\U00010b3f\\U00010b99-\\U00010b9c\\U00010f55-\\U00010f59\\U00011047-\\U0001104d\\U000110bb-\\U000110bc\\U000110be-\\U000110c1\\U00011140-\\U00011143\\U00011174-\\U00011175\\U000111c5-\\U000111c8\\U000111cd\\U000111db\\U000111dd-\\U000111df\\U00011238-\\U0001123d\\U000112a9\\U0001144b-\\U0001144f\\U0001145b\\U0001145d\\U000114c6\\U000115c1-\\U000115d7\\U00011641-\\U00011643\\U00011660-\\U0001166c\\U0001173c-\\U0001173e\\U0001183b\\U00011a3f-\\U00011a46\\U00011a9a-\\U00011a9c\\U00011a9e-\\U00011aa2\\U00011c41-\\U00011c45\\U00011c70-\\U00011c71\\U00011ef7-\\U00011ef8\\U00012470-\\U00012474\\U00016a6e-\\U00016a6f\\U00016af5\\U00016b37-\\U00016b3b\\U00016b44\\U00016e97-\\U00016e9a\\U0001bc9f\\U0001da87-\\U0001da8b\\U0001e95e-\\U0001e95f\"\n\nPs = '(\\\\[{\\u0f3a\\u0f3c\\u169b\\u201a\\u201e\\u2045\\u207d\\u208d\\u2308\\u230a\\u2329\\u2768\\u276a\\u276c\\u276e\\u2770\\u2772\\u2774\\u27c5\\u27e6\\u27e8\\u27ea\\u27ec\\u27ee\\u2983\\u2985\\u2987\\u2989\\u298b\\u298d\\u298f\\u2991\\u2993\\u2995\\u2997\\u29d8\\u29da\\u29fc\\u2e22\\u2e24\\u2e26\\u2e28\\u2e42\\u3008\\u300a\\u300c\\u300e\\u3010\\u3014\\u3016\\u3018\\u301a\\u301d\\ufd3f\\ufe17\\ufe35\\ufe37\\ufe39\\ufe3b\\ufe3d\\ufe3f\\ufe41\\ufe43\\ufe47\\ufe59\\ufe5b\\ufe5d\\uff08\\uff3b\\uff5b\\uff5f\\uff62'\n\nSc = '$\\xa2-\\xa5\\u058f\\u060b\\u07fe-\\u07ff\\u09f2-\\u09f3\\u09fb\\u0af1\\u0bf9\\u0e3f\\u17db\\u20a0-\\u20bf\\ua838\\ufdfc\\ufe69\\uff04\\uffe0-\\uffe1\\uffe5-\\uffe6\\U0001ecb0'\n\nSk = '\\\\^`\\xa8\\xaf\\xb4\\xb8\\u02c2-\\u02c5\\u02d2-\\u02df\\u02e5-\\u02eb\\u02ed\\u02ef-\\u02ff\\u0375\\u0384-\\u0385\\u1fbd\\u1fbf-\\u1fc1\\u1fcd-\\u1fcf\\u1fdd-\\u1fdf\\u1fed-\\u1fef\\u1ffd-\\u1ffe\\u309b-\\u309c\\ua700-\\ua716\\ua720-\\ua721\\ua789-\\ua78a\\uab5b\\ufbb2-\\ufbc1\\uff3e\\uff40\\uffe3\\U0001f3fb-\\U0001f3ff'\n\nSm = '+<->|~\\xac\\xb1\\xd7\\xf7\\u03f6\\u0606-\\u0608\\u2044\\u2052\\u207a-\\u207c\\u208a-\\u208c\\u2118\\u2140-\\u2144\\u214b\\u2190-\\u2194\\u219a-\\u219b\\u21a0\\u21a3\\u21a6\\u21ae\\u21ce-\\u21cf\\u21d2\\u21d4\\u21f4-\\u22ff\\u2320-\\u2321\\u237c\\u239b-\\u23b3\\u23dc-\\u23e1\\u25b7\\u25c1\\u25f8-\\u25ff\\u266f\\u27c0-\\u27c4\\u27c7-\\u27e5\\u27f0-\\u27ff\\u2900-\\u2982\\u2999-\\u29d7\\u29dc-\\u29fb\\u29fe-\\u2aff\\u2b30-\\u2b44\\u2b47-\\u2b4c\\ufb29\\ufe62\\ufe64-\\ufe66\\uff0b\\uff1c-\\uff1e\\uff5c\\uff5e\\uffe2\\uffe9-\\uffec\\U0001d6c1\\U0001d6db\\U0001d6fb\\U0001d715\\U0001d735\\U0001d74f\\U0001d76f\\U0001d789\\U0001d7a9\\U0001d7c3\\U0001eef0-\\U0001eef1'\n\nSo = '\\xa6\\xa9\\xae\\xb0\\u0482\\u058d-\\u058e\\u060e-\\u060f\\u06de\\u06e9\\u06fd-\\u06fe\\u07f6\\u09fa\\u0b70\\u0bf3-\\u0bf8\\u0bfa\\u0c7f\\u0d4f\\u0d79\\u0f01-\\u0f03\\u0f13\\u0f15-\\u0f17\\u0f1a-\\u0f1f\\u0f34\\u0f36\\u0f38\\u0fbe-\\u0fc5\\u0fc7-\\u0fcc\\u0fce-\\u0fcf\\u0fd5-\\u0fd8\\u109e-\\u109f\\u1390-\\u1399\\u1940\\u19de-\\u19ff\\u1b61-\\u1b6a\\u1b74-\\u1b7c\\u2100-\\u2101\\u2103-\\u2106\\u2108-\\u2109\\u2114\\u2116-\\u2117\\u211e-\\u2123\\u2125\\u2127\\u2129\\u212e\\u213a-\\u213b\\u214a\\u214c-\\u214d\\u214f\\u218a-\\u218b\\u2195-\\u2199\\u219c-\\u219f\\u21a1-\\u21a2\\u21a4-\\u21a5\\u21a7-\\u21ad\\u21af-\\u21cd\\u21d0-\\u21d1\\u21d3\\u21d5-\\u21f3\\u2300-\\u2307\\u230c-\\u231f\\u2322-\\u2328\\u232b-\\u237b\\u237d-\\u239a\\u23b4-\\u23db\\u23e2-\\u2426\\u2440-\\u244a\\u249c-\\u24e9\\u2500-\\u25b6\\u25b8-\\u25c0\\u25c2-\\u25f7\\u2600-\\u266e\\u2670-\\u2767\\u2794-\\u27bf\\u2800-\\u28ff\\u2b00-\\u2b2f\\u2b45-\\u2b46\\u2b4d-\\u2b73\\u2b76-\\u2b95\\u2b98-\\u2bc8\\u2bca-\\u2bfe\\u2ce5-\\u2cea\\u2e80-\\u2e99\\u2e9b-\\u2ef3\\u2f00-\\u2fd5\\u2ff0-\\u2ffb\\u3004\\u3012-\\u3013\\u3020\\u3036-\\u3037\\u303e-\\u303f\\u3190-\\u3191\\u3196-\\u319f\\u31c0-\\u31e3\\u3200-\\u321e\\u322a-\\u3247\\u3250\\u3260-\\u327f\\u328a-\\u32b0\\u32c0-\\u32fe\\u3300-\\u33ff\\u4dc0-\\u4dff\\ua490-\\ua4c6\\ua828-\\ua82b\\ua836-\\ua837\\ua839\\uaa77-\\uaa79\\ufdfd\\uffe4\\uffe8\\uffed-\\uffee\\ufffc-\\ufffd\\U00010137-\\U0001013f\\U00010179-\\U00010189\\U0001018c-\\U0001018e\\U00010190-\\U0001019b\\U000101a0\\U000101d0-\\U000101fc\\U00010877-\\U00010878\\U00010ac8\\U0001173f\\U00016b3c-\\U00016b3f\\U00016b45\\U0001bc9c\\U0001d000-\\U0001d0f5\\U0001d100-\\U0001d126\\U0001d129-\\U0001d164\\U0001d16a-\\U0001d16c\\U0001d183-\\U0001d184\\U0001d18c-\\U0001d1a9\\U0001d1ae-\\U0001d1e8\\U0001d200-\\U0001d241\\U0001d245\\U0001d300-\\U0001d356\\U0001d800-\\U0001d9ff\\U0001da37-\\U0001da3a\\U0001da6d-\\U0001da74\\U0001da76-\\U0001da83\\U0001da85-\\U0001da86\\U0001ecac\\U0001f000-\\U0001f02b\\U0001f030-\\U0001f093\\U0001f0a0-\\U0001f0ae\\U0001f0b1-\\U0001f0bf\\U0001f0c1-\\U0001f0cf\\U0001f0d1-\\U0001f0f5\\U0001f110-\\U0001f16b\\U0001f170-\\U0001f1ac\\U0001f1e6-\\U0001f202\\U0001f210-\\U0001f23b\\U0001f240-\\U0001f248\\U0001f250-\\U0001f251\\U0001f260-\\U0001f265\\U0001f300-\\U0001f3fa\\U0001f400-\\U0001f6d4\\U0001f6e0-\\U0001f6ec\\U0001f6f0-\\U0001f6f9\\U0001f700-\\U0001f773\\U0001f780-\\U0001f7d8\\U0001f800-\\U0001f80b\\U0001f810-\\U0001f847\\U0001f850-\\U0001f859\\U0001f860-\\U0001f887\\U0001f890-\\U0001f8ad\\U0001f900-\\U0001f90b\\U0001f910-\\U0001f93e\\U0001f940-\\U0001f970\\U0001f973-\\U0001f976\\U0001f97a\\U0001f97c-\\U0001f9a2\\U0001f9b0-\\U0001f9b9\\U0001f9c0-\\U0001f9c2\\U0001f9d0-\\U0001f9ff\\U0001fa60-\\U0001fa6d'\n\nZl = '\\u2028'\n\nZp = '\\u2029'\n\nZs = ' \\xa0\\u1680\\u2000-\\u200a\\u202f\\u205f\\u3000'\n\nxid_continue = '0-9A-Z_a-z\\xaa\\xb5\\xb7\\xba\\xc0-\\xd6\\xd8-\\xf6\\xf8-\\u02c1\\u02c6-\\u02d1\\u02e0-\\u02e4\\u02ec\\u02ee\\u0300-\\u0374\\u0376-\\u0377\\u037b-\\u037d\\u037f\\u0386-\\u038a\\u038c\\u038e-\\u03a1\\u03a3-\\u03f5\\u03f7-\\u0481\\u0483-\\u0487\\u048a-\\u052f\\u0531-\\u0556\\u0559\\u0560-\\u0588\\u0591-\\u05bd\\u05bf\\u05c1-\\u05c2\\u05c4-\\u05c5\\u05c7\\u05d0-\\u05ea\\u05ef-\\u05f2\\u0610-\\u061a\\u0620-\\u0669\\u066e-\\u06d3\\u06d5-\\u06dc\\u06df-\\u06e8\\u06ea-\\u06fc\\u06ff\\u0710-\\u074a\\u074d-\\u07b1\\u07c0-\\u07f5\\u07fa\\u07fd\\u0800-\\u082d\\u0840-\\u085b\\u0860-\\u086a\\u08a0-\\u08b4\\u08b6-\\u08bd\\u08d3-\\u08e1\\u08e3-\\u0963\\u0966-\\u096f\\u0971-\\u0983\\u0985-\\u098c\\u098f-\\u0990\\u0993-\\u09a8\\u09aa-\\u09b0\\u09b2\\u09b6-\\u09b9\\u09bc-\\u09c4\\u09c7-\\u09c8\\u09cb-\\u09ce\\u09d7\\u09dc-\\u09dd\\u09df-\\u09e3\\u09e6-\\u09f1\\u09fc\\u09fe\\u0a01-\\u0a03\\u0a05-\\u0a0a\\u0a0f-\\u0a10\\u0a13-\\u0a28\\u0a2a-\\u0a30\\u0a32-\\u0a33\\u0a35-\\u0a36\\u0a38-\\u0a39\\u0a3c\\u0a3e-\\u0a42\\u0a47-\\u0a48\\u0a4b-\\u0a4d\\u0a51\\u0a59-\\u0a5c\\u0a5e\\u0a66-\\u0a75\\u0a81-\\u0a83\\u0a85-\\u0a8d\\u0a8f-\\u0a91\\u0a93-\\u0aa8\\u0aaa-\\u0ab0\\u0ab2-\\u0ab3\\u0ab5-\\u0ab9\\u0abc-\\u0ac5\\u0ac7-\\u0ac9\\u0acb-\\u0acd\\u0ad0\\u0ae0-\\u0ae3\\u0ae6-\\u0aef\\u0af9-\\u0aff\\u0b01-\\u0b03\\u0b05-\\u0b0c\\u0b0f-\\u0b10\\u0b13-\\u0b28\\u0b2a-\\u0b30\\u0b32-\\u0b33\\u0b35-\\u0b39\\u0b3c-\\u0b44\\u0b47-\\u0b48\\u0b4b-\\u0b4d\\u0b56-\\u0b57\\u0b5c-\\u0b5d\\u0b5f-\\u0b63\\u0b66-\\u0b6f\\u0b71\\u0b82-\\u0b83\\u0b85-\\u0b8a\\u0b8e-\\u0b90\\u0b92-\\u0b95\\u0b99-\\u0b9a\\u0b9c\\u0b9e-\\u0b9f\\u0ba3-\\u0ba4\\u0ba8-\\u0baa\\u0bae-\\u0bb9\\u0bbe-\\u0bc2\\u0bc6-\\u0bc8\\u0bca-\\u0bcd\\u0bd0\\u0bd7\\u0be6-\\u0bef\\u0c00-\\u0c0c\\u0c0e-\\u0c10\\u0c12-\\u0c28\\u0c2a-\\u0c39\\u0c3d-\\u0c44\\u0c46-\\u0c48\\u0c4a-\\u0c4d\\u0c55-\\u0c56\\u0c58-\\u0c5a\\u0c60-\\u0c63\\u0c66-\\u0c6f\\u0c80-\\u0c83\\u0c85-\\u0c8c\\u0c8e-\\u0c90\\u0c92-\\u0ca8\\u0caa-\\u0cb3\\u0cb5-\\u0cb9\\u0cbc-\\u0cc4\\u0cc6-\\u0cc8\\u0cca-\\u0ccd\\u0cd5-\\u0cd6\\u0cde\\u0ce0-\\u0ce3\\u0ce6-\\u0cef\\u0cf1-\\u0cf2\\u0d00-\\u0d03\\u0d05-\\u0d0c\\u0d0e-\\u0d10\\u0d12-\\u0d44\\u0d46-\\u0d48\\u0d4a-\\u0d4e\\u0d54-\\u0d57\\u0d5f-\\u0d63\\u0d66-\\u0d6f\\u0d7a-\\u0d7f\\u0d82-\\u0d83\\u0d85-\\u0d96\\u0d9a-\\u0db1\\u0db3-\\u0dbb\\u0dbd\\u0dc0-\\u0dc6\\u0dca\\u0dcf-\\u0dd4\\u0dd6\\u0dd8-\\u0ddf\\u0de6-\\u0def\\u0df2-\\u0df3\\u0e01-\\u0e3a\\u0e40-\\u0e4e\\u0e50-\\u0e59\\u0e81-\\u0e82\\u0e84\\u0e87-\\u0e88\\u0e8a\\u0e8d\\u0e94-\\u0e97\\u0e99-\\u0e9f\\u0ea1-\\u0ea3\\u0ea5\\u0ea7\\u0eaa-\\u0eab\\u0ead-\\u0eb9\\u0ebb-\\u0ebd\\u0ec0-\\u0ec4\\u0ec6\\u0ec8-\\u0ecd\\u0ed0-\\u0ed9\\u0edc-\\u0edf\\u0f00\\u0f18-\\u0f19\\u0f20-\\u0f29\\u0f35\\u0f37\\u0f39\\u0f3e-\\u0f47\\u0f49-\\u0f6c\\u0f71-\\u0f84\\u0f86-\\u0f97\\u0f99-\\u0fbc\\u0fc6\\u1000-\\u1049\\u1050-\\u109d\\u10a0-\\u10c5\\u10c7\\u10cd\\u10d0-\\u10fa\\u10fc-\\u1248\\u124a-\\u124d\\u1250-\\u1256\\u1258\\u125a-\\u125d\\u1260-\\u1288\\u128a-\\u128d\\u1290-\\u12b0\\u12b2-\\u12b5\\u12b8-\\u12be\\u12c0\\u12c2-\\u12c5\\u12c8-\\u12d6\\u12d8-\\u1310\\u1312-\\u1315\\u1318-\\u135a\\u135d-\\u135f\\u1369-\\u1371\\u1380-\\u138f\\u13a0-\\u13f5\\u13f8-\\u13fd\\u1401-\\u166c\\u166f-\\u167f\\u1681-\\u169a\\u16a0-\\u16ea\\u16ee-\\u16f8\\u1700-\\u170c\\u170e-\\u1714\\u1720-\\u1734\\u1740-\\u1753\\u1760-\\u176c\\u176e-\\u1770\\u1772-\\u1773\\u1780-\\u17d3\\u17d7\\u17dc-\\u17dd\\u17e0-\\u17e9\\u180b-\\u180d\\u1810-\\u1819\\u1820-\\u1878\\u1880-\\u18aa\\u18b0-\\u18f5\\u1900-\\u191e\\u1920-\\u192b\\u1930-\\u193b\\u1946-\\u196d\\u1970-\\u1974\\u1980-\\u19ab\\u19b0-\\u19c9\\u19d0-\\u19da\\u1a00-\\u1a1b\\u1a20-\\u1a5e\\u1a60-\\u1a7c\\u1a7f-\\u1a89\\u1a90-\\u1a99\\u1aa7\\u1ab0-\\u1abd\\u1b00-\\u1b4b\\u1b50-\\u1b59\\u1b6b-\\u1b73\\u1b80-\\u1bf3\\u1c00-\\u1c37\\u1c40-\\u1c49\\u1c4d-\\u1c7d\\u1c80-\\u1c88\\u1c90-\\u1cba\\u1cbd-\\u1cbf\\u1cd0-\\u1cd2\\u1cd4-\\u1cf9\\u1d00-\\u1df9\\u1dfb-\\u1f15\\u1f18-\\u1f1d\\u1f20-\\u1f45\\u1f48-\\u1f4d\\u1f50-\\u1f57\\u1f59\\u1f5b\\u1f5d\\u1f5f-\\u1f7d\\u1f80-\\u1fb4\\u1fb6-\\u1fbc\\u1fbe\\u1fc2-\\u1fc4\\u1fc6-\\u1fcc\\u1fd0-\\u1fd3\\u1fd6-\\u1fdb\\u1fe0-\\u1fec\\u1ff2-\\u1ff4\\u1ff6-\\u1ffc\\u203f-\\u2040\\u2054\\u2071\\u207f\\u2090-\\u209c\\u20d0-\\u20dc\\u20e1\\u20e5-\\u20f0\\u2102\\u2107\\u210a-\\u2113\\u2115\\u2118-\\u211d\\u2124\\u2126\\u2128\\u212a-\\u2139\\u213c-\\u213f\\u2145-\\u2149\\u214e\\u2160-\\u2188\\u2c00-\\u2c2e\\u2c30-\\u2c5e\\u2c60-\\u2ce4\\u2ceb-\\u2cf3\\u2d00-\\u2d25\\u2d27\\u2d2d\\u2d30-\\u2d67\\u2d6f\\u2d7f-\\u2d96\\u2da0-\\u2da6\\u2da8-\\u2dae\\u2db0-\\u2db6\\u2db8-\\u2dbe\\u2dc0-\\u2dc6\\u2dc8-\\u2dce\\u2dd0-\\u2dd6\\u2dd8-\\u2dde\\u2de0-\\u2dff\\u3005-\\u3007\\u3021-\\u302f\\u3031-\\u3035\\u3038-\\u303c\\u3041-\\u3096\\u3099-\\u309a\\u309d-\\u309f\\u30a1-\\u30fa\\u30fc-\\u30ff\\u3105-\\u312f\\u3131-\\u318e\\u31a0-\\u31ba\\u31f0-\\u31ff\\u3400-\\u4db5\\u4e00-\\u9fef\\ua000-\\ua48c\\ua4d0-\\ua4fd\\ua500-\\ua60c\\ua610-\\ua62b\\ua640-\\ua66f\\ua674-\\ua67d\\ua67f-\\ua6f1\\ua717-\\ua71f\\ua722-\\ua788\\ua78b-\\ua7b9\\ua7f7-\\ua827\\ua840-\\ua873\\ua880-\\ua8c5\\ua8d0-\\ua8d9\\ua8e0-\\ua8f7\\ua8fb\\ua8fd-\\ua92d\\ua930-\\ua953\\ua960-\\ua97c\\ua980-\\ua9c0\\ua9cf-\\ua9d9\\ua9e0-\\ua9fe\\uaa00-\\uaa36\\uaa40-\\uaa4d\\uaa50-\\uaa59\\uaa60-\\uaa76\\uaa7a-\\uaac2\\uaadb-\\uaadd\\uaae0-\\uaaef\\uaaf2-\\uaaf6\\uab01-\\uab06\\uab09-\\uab0e\\uab11-\\uab16\\uab20-\\uab26\\uab28-\\uab2e\\uab30-\\uab5a\\uab5c-\\uab65\\uab70-\\uabea\\uabec-\\uabed\\uabf0-\\uabf9\\uac00-\\ud7a3\\ud7b0-\\ud7c6\\ud7cb-\\ud7fb\\uf900-\\ufa6d\\ufa70-\\ufad9\\ufb00-\\ufb06\\ufb13-\\ufb17\\ufb1d-\\ufb28\\ufb2a-\\ufb36\\ufb38-\\ufb3c\\ufb3e\\ufb40-\\ufb41\\ufb43-\\ufb44\\ufb46-\\ufbb1\\ufbd3-\\ufc5d\\ufc64-\\ufd3d\\ufd50-\\ufd8f\\ufd92-\\ufdc7\\ufdf0-\\ufdf9\\ufe00-\\ufe0f\\ufe20-\\ufe2f\\ufe33-\\ufe34\\ufe4d-\\ufe4f\\ufe71\\ufe73\\ufe77\\ufe79\\ufe7b\\ufe7d\\ufe7f-\\ufefc\\uff10-\\uff19\\uff21-\\uff3a\\uff3f\\uff41-\\uff5a\\uff66-\\uffbe\\uffc2-\\uffc7\\uffca-\\uffcf\\uffd2-\\uffd7\\uffda-\\uffdc\\U00010000-\\U0001000b\\U0001000d-\\U00010026\\U00010028-\\U0001003a\\U0001003c-\\U0001003d\\U0001003f-\\U0001004d\\U00010050-\\U0001005d\\U00010080-\\U000100fa\\U00010140-\\U00010174\\U000101fd\\U00010280-\\U0001029c\\U000102a0-\\U000102d0\\U000102e0\\U00010300-\\U0001031f\\U0001032d-\\U0001034a\\U00010350-\\U0001037a\\U00010380-\\U0001039d\\U000103a0-\\U000103c3\\U000103c8-\\U000103cf\\U000103d1-\\U000103d5\\U00010400-\\U0001049d\\U000104a0-\\U000104a9\\U000104b0-\\U000104d3\\U000104d8-\\U000104fb\\U00010500-\\U00010527\\U00010530-\\U00010563\\U00010600-\\U00010736\\U00010740-\\U00010755\\U00010760-\\U00010767\\U00010800-\\U00010805\\U00010808\\U0001080a-\\U00010835\\U00010837-\\U00010838\\U0001083c\\U0001083f-\\U00010855\\U00010860-\\U00010876\\U00010880-\\U0001089e\\U000108e0-\\U000108f2\\U000108f4-\\U000108f5\\U00010900-\\U00010915\\U00010920-\\U00010939\\U00010980-\\U000109b7\\U000109be-\\U000109bf\\U00010a00-\\U00010a03\\U00010a05-\\U00010a06\\U00010a0c-\\U00010a13\\U00010a15-\\U00010a17\\U00010a19-\\U00010a35\\U00010a38-\\U00010a3a\\U00010a3f\\U00010a60-\\U00010a7c\\U00010a80-\\U00010a9c\\U00010ac0-\\U00010ac7\\U00010ac9-\\U00010ae6\\U00010b00-\\U00010b35\\U00010b40-\\U00010b55\\U00010b60-\\U00010b72\\U00010b80-\\U00010b91\\U00010c00-\\U00010c48\\U00010c80-\\U00010cb2\\U00010cc0-\\U00010cf2\\U00010d00-\\U00010d27\\U00010d30-\\U00010d39\\U00010f00-\\U00010f1c\\U00010f27\\U00010f30-\\U00010f50\\U00011000-\\U00011046\\U00011066-\\U0001106f\\U0001107f-\\U000110ba\\U000110d0-\\U000110e8\\U000110f0-\\U000110f9\\U00011100-\\U00011134\\U00011136-\\U0001113f\\U00011144-\\U00011146\\U00011150-\\U00011173\\U00011176\\U00011180-\\U000111c4\\U000111c9-\\U000111cc\\U000111d0-\\U000111da\\U000111dc\\U00011200-\\U00011211\\U00011213-\\U00011237\\U0001123e\\U00011280-\\U00011286\\U00011288\\U0001128a-\\U0001128d\\U0001128f-\\U0001129d\\U0001129f-\\U000112a8\\U000112b0-\\U000112ea\\U000112f0-\\U000112f9\\U00011300-\\U00011303\\U00011305-\\U0001130c\\U0001130f-\\U00011310\\U00011313-\\U00011328\\U0001132a-\\U00011330\\U00011332-\\U00011333\\U00011335-\\U00011339\\U0001133b-\\U00011344\\U00011347-\\U00011348\\U0001134b-\\U0001134d\\U00011350\\U00011357\\U0001135d-\\U00011363\\U00011366-\\U0001136c\\U00011370-\\U00011374\\U00011400-\\U0001144a\\U00011450-\\U00011459\\U0001145e\\U00011480-\\U000114c5\\U000114c7\\U000114d0-\\U000114d9\\U00011580-\\U000115b5\\U000115b8-\\U000115c0\\U000115d8-\\U000115dd\\U00011600-\\U00011640\\U00011644\\U00011650-\\U00011659\\U00011680-\\U000116b7\\U000116c0-\\U000116c9\\U00011700-\\U0001171a\\U0001171d-\\U0001172b\\U00011730-\\U00011739\\U00011800-\\U0001183a\\U000118a0-\\U000118e9\\U000118ff\\U00011a00-\\U00011a3e\\U00011a47\\U00011a50-\\U00011a83\\U00011a86-\\U00011a99\\U00011a9d\\U00011ac0-\\U00011af8\\U00011c00-\\U00011c08\\U00011c0a-\\U00011c36\\U00011c38-\\U00011c40\\U00011c50-\\U00011c59\\U00011c72-\\U00011c8f\\U00011c92-\\U00011ca7\\U00011ca9-\\U00011cb6\\U00011d00-\\U00011d06\\U00011d08-\\U00011d09\\U00011d0b-\\U00011d36\\U00011d3a\\U00011d3c-\\U00011d3d\\U00011d3f-\\U00011d47\\U00011d50-\\U00011d59\\U00011d60-\\U00011d65\\U00011d67-\\U00011d68\\U00011d6a-\\U00011d8e\\U00011d90-\\U00011d91\\U00011d93-\\U00011d98\\U00011da0-\\U00011da9\\U00011ee0-\\U00011ef6\\U00012000-\\U00012399\\U00012400-\\U0001246e\\U00012480-\\U00012543\\U00013000-\\U0001342e\\U00014400-\\U00014646\\U00016800-\\U00016a38\\U00016a40-\\U00016a5e\\U00016a60-\\U00016a69\\U00016ad0-\\U00016aed\\U00016af0-\\U00016af4\\U00016b00-\\U00016b36\\U00016b40-\\U00016b43\\U00016b50-\\U00016b59\\U00016b63-\\U00016b77\\U00016b7d-\\U00016b8f\\U00016e40-\\U00016e7f\\U00016f00-\\U00016f44\\U00016f50-\\U00016f7e\\U00016f8f-\\U00016f9f\\U00016fe0-\\U00016fe1\\U00017000-\\U000187f1\\U00018800-\\U00018af2\\U0001b000-\\U0001b11e\\U0001b170-\\U0001b2fb\\U0001bc00-\\U0001bc6a\\U0001bc70-\\U0001bc7c\\U0001bc80-\\U0001bc88\\U0001bc90-\\U0001bc99\\U0001bc9d-\\U0001bc9e\\U0001d165-\\U0001d169\\U0001d16d-\\U0001d172\\U0001d17b-\\U0001d182\\U0001d185-\\U0001d18b\\U0001d1aa-\\U0001d1ad\\U0001d242-\\U0001d244\\U0001d400-\\U0001d454\\U0001d456-\\U0001d49c\\U0001d49e-\\U0001d49f\\U0001d4a2\\U0001d4a5-\\U0001d4a6\\U0001d4a9-\\U0001d4ac\\U0001d4ae-\\U0001d4b9\\U0001d4bb\\U0001d4bd-\\U0001d4c3\\U0001d4c5-\\U0001d505\\U0001d507-\\U0001d50a\\U0001d50d-\\U0001d514\\U0001d516-\\U0001d51c\\U0001d51e-\\U0001d539\\U0001d53b-\\U0001d53e\\U0001d540-\\U0001d544\\U0001d546\\U0001d54a-\\U0001d550\\U0001d552-\\U0001d6a5\\U0001d6a8-\\U0001d6c0\\U0001d6c2-\\U0001d6da\\U0001d6dc-\\U0001d6fa\\U0001d6fc-\\U0001d714\\U0001d716-\\U0001d734\\U0001d736-\\U0001d74e\\U0001d750-\\U0001d76e\\U0001d770-\\U0001d788\\U0001d78a-\\U0001d7a8\\U0001d7aa-\\U0001d7c2\\U0001d7c4-\\U0001d7cb\\U0001d7ce-\\U0001d7ff\\U0001da00-\\U0001da36\\U0001da3b-\\U0001da6c\\U0001da75\\U0001da84\\U0001da9b-\\U0001da9f\\U0001daa1-\\U0001daaf\\U0001e000-\\U0001e006\\U0001e008-\\U0001e018\\U0001e01b-\\U0001e021\\U0001e023-\\U0001e024\\U0001e026-\\U0001e02a\\U0001e800-\\U0001e8c4\\U0001e8d0-\\U0001e8d6\\U0001e900-\\U0001e94a\\U0001e950-\\U0001e959\\U0001ee00-\\U0001ee03\\U0001ee05-\\U0001ee1f\\U0001ee21-\\U0001ee22\\U0001ee24\\U0001ee27\\U0001ee29-\\U0001ee32\\U0001ee34-\\U0001ee37\\U0001ee39\\U0001ee3b\\U0001ee42\\U0001ee47\\U0001ee49\\U0001ee4b\\U0001ee4d-\\U0001ee4f\\U0001ee51-\\U0001ee52\\U0001ee54\\U0001ee57\\U0001ee59\\U0001ee5b\\U0001ee5d\\U0001ee5f\\U0001ee61-\\U0001ee62\\U0001ee64\\U0001ee67-\\U0001ee6a\\U0001ee6c-\\U0001ee72\\U0001ee74-\\U0001ee77\\U0001ee79-\\U0001ee7c\\U0001ee7e\\U0001ee80-\\U0001ee89\\U0001ee8b-\\U0001ee9b\\U0001eea1-\\U0001eea3\\U0001eea5-\\U0001eea9\\U0001eeab-\\U0001eebb\\U00020000-\\U0002a6d6\\U0002a700-\\U0002b734\\U0002b740-\\U0002b81d\\U0002b820-\\U0002cea1\\U0002ceb0-\\U0002ebe0\\U0002f800-\\U0002fa1d\\U000e0100-\\U000e01ef'\n\nxid_start = 'A-Z_a-z\\xaa\\xb5\\xba\\xc0-\\xd6\\xd8-\\xf6\\xf8-\\u02c1\\u02c6-\\u02d1\\u02e0-\\u02e4\\u02ec\\u02ee\\u0370-\\u0374\\u0376-\\u0377\\u037b-\\u037d\\u037f\\u0386\\u0388-\\u038a\\u038c\\u038e-\\u03a1\\u03a3-\\u03f5\\u03f7-\\u0481\\u048a-\\u052f\\u0531-\\u0556\\u0559\\u0560-\\u0588\\u05d0-\\u05ea\\u05ef-\\u05f2\\u0620-\\u064a\\u066e-\\u066f\\u0671-\\u06d3\\u06d5\\u06e5-\\u06e6\\u06ee-\\u06ef\\u06fa-\\u06fc\\u06ff\\u0710\\u0712-\\u072f\\u074d-\\u07a5\\u07b1\\u07ca-\\u07ea\\u07f4-\\u07f5\\u07fa\\u0800-\\u0815\\u081a\\u0824\\u0828\\u0840-\\u0858\\u0860-\\u086a\\u08a0-\\u08b4\\u08b6-\\u08bd\\u0904-\\u0939\\u093d\\u0950\\u0958-\\u0961\\u0971-\\u0980\\u0985-\\u098c\\u098f-\\u0990\\u0993-\\u09a8\\u09aa-\\u09b0\\u09b2\\u09b6-\\u09b9\\u09bd\\u09ce\\u09dc-\\u09dd\\u09df-\\u09e1\\u09f0-\\u09f1\\u09fc\\u0a05-\\u0a0a\\u0a0f-\\u0a10\\u0a13-\\u0a28\\u0a2a-\\u0a30\\u0a32-\\u0a33\\u0a35-\\u0a36\\u0a38-\\u0a39\\u0a59-\\u0a5c\\u0a5e\\u0a72-\\u0a74\\u0a85-\\u0a8d\\u0a8f-\\u0a91\\u0a93-\\u0aa8\\u0aaa-\\u0ab0\\u0ab2-\\u0ab3\\u0ab5-\\u0ab9\\u0abd\\u0ad0\\u0ae0-\\u0ae1\\u0af9\\u0b05-\\u0b0c\\u0b0f-\\u0b10\\u0b13-\\u0b28\\u0b2a-\\u0b30\\u0b32-\\u0b33\\u0b35-\\u0b39\\u0b3d\\u0b5c-\\u0b5d\\u0b5f-\\u0b61\\u0b71\\u0b83\\u0b85-\\u0b8a\\u0b8e-\\u0b90\\u0b92-\\u0b95\\u0b99-\\u0b9a\\u0b9c\\u0b9e-\\u0b9f\\u0ba3-\\u0ba4\\u0ba8-\\u0baa\\u0bae-\\u0bb9\\u0bd0\\u0c05-\\u0c0c\\u0c0e-\\u0c10\\u0c12-\\u0c28\\u0c2a-\\u0c39\\u0c3d\\u0c58-\\u0c5a\\u0c60-\\u0c61\\u0c80\\u0c85-\\u0c8c\\u0c8e-\\u0c90\\u0c92-\\u0ca8\\u0caa-\\u0cb3\\u0cb5-\\u0cb9\\u0cbd\\u0cde\\u0ce0-\\u0ce1\\u0cf1-\\u0cf2\\u0d05-\\u0d0c\\u0d0e-\\u0d10\\u0d12-\\u0d3a\\u0d3d\\u0d4e\\u0d54-\\u0d56\\u0d5f-\\u0d61\\u0d7a-\\u0d7f\\u0d85-\\u0d96\\u0d9a-\\u0db1\\u0db3-\\u0dbb\\u0dbd\\u0dc0-\\u0dc6\\u0e01-\\u0e30\\u0e32\\u0e40-\\u0e46\\u0e81-\\u0e82\\u0e84\\u0e87-\\u0e88\\u0e8a\\u0e8d\\u0e94-\\u0e97\\u0e99-\\u0e9f\\u0ea1-\\u0ea3\\u0ea5\\u0ea7\\u0eaa-\\u0eab\\u0ead-\\u0eb0\\u0eb2\\u0ebd\\u0ec0-\\u0ec4\\u0ec6\\u0edc-\\u0edf\\u0f00\\u0f40-\\u0f47\\u0f49-\\u0f6c\\u0f88-\\u0f8c\\u1000-\\u102a\\u103f\\u1050-\\u1055\\u105a-\\u105d\\u1061\\u1065-\\u1066\\u106e-\\u1070\\u1075-\\u1081\\u108e\\u10a0-\\u10c5\\u10c7\\u10cd\\u10d0-\\u10fa\\u10fc-\\u1248\\u124a-\\u124d\\u1250-\\u1256\\u1258\\u125a-\\u125d\\u1260-\\u1288\\u128a-\\u128d\\u1290-\\u12b0\\u12b2-\\u12b5\\u12b8-\\u12be\\u12c0\\u12c2-\\u12c5\\u12c8-\\u12d6\\u12d8-\\u1310\\u1312-\\u1315\\u1318-\\u135a\\u1380-\\u138f\\u13a0-\\u13f5\\u13f8-\\u13fd\\u1401-\\u166c\\u166f-\\u167f\\u1681-\\u169a\\u16a0-\\u16ea\\u16ee-\\u16f8\\u1700-\\u170c\\u170e-\\u1711\\u1720-\\u1731\\u1740-\\u1751\\u1760-\\u176c\\u176e-\\u1770\\u1780-\\u17b3\\u17d7\\u17dc\\u1820-\\u1878\\u1880-\\u18a8\\u18aa\\u18b0-\\u18f5\\u1900-\\u191e\\u1950-\\u196d\\u1970-\\u1974\\u1980-\\u19ab\\u19b0-\\u19c9\\u1a00-\\u1a16\\u1a20-\\u1a54\\u1aa7\\u1b05-\\u1b33\\u1b45-\\u1b4b\\u1b83-\\u1ba0\\u1bae-\\u1baf\\u1bba-\\u1be5\\u1c00-\\u1c23\\u1c4d-\\u1c4f\\u1c5a-\\u1c7d\\u1c80-\\u1c88\\u1c90-\\u1cba\\u1cbd-\\u1cbf\\u1ce9-\\u1cec\\u1cee-\\u1cf1\\u1cf5-\\u1cf6\\u1d00-\\u1dbf\\u1e00-\\u1f15\\u1f18-\\u1f1d\\u1f20-\\u1f45\\u1f48-\\u1f4d\\u1f50-\\u1f57\\u1f59\\u1f5b\\u1f5d\\u1f5f-\\u1f7d\\u1f80-\\u1fb4\\u1fb6-\\u1fbc\\u1fbe\\u1fc2-\\u1fc4\\u1fc6-\\u1fcc\\u1fd0-\\u1fd3\\u1fd6-\\u1fdb\\u1fe0-\\u1fec\\u1ff2-\\u1ff4\\u1ff6-\\u1ffc\\u2071\\u207f\\u2090-\\u209c\\u2102\\u2107\\u210a-\\u2113\\u2115\\u2118-\\u211d\\u2124\\u2126\\u2128\\u212a-\\u2139\\u213c-\\u213f\\u2145-\\u2149\\u214e\\u2160-\\u2188\\u2c00-\\u2c2e\\u2c30-\\u2c5e\\u2c60-\\u2ce4\\u2ceb-\\u2cee\\u2cf2-\\u2cf3\\u2d00-\\u2d25\\u2d27\\u2d2d\\u2d30-\\u2d67\\u2d6f\\u2d80-\\u2d96\\u2da0-\\u2da6\\u2da8-\\u2dae\\u2db0-\\u2db6\\u2db8-\\u2dbe\\u2dc0-\\u2dc6\\u2dc8-\\u2dce\\u2dd0-\\u2dd6\\u2dd8-\\u2dde\\u3005-\\u3007\\u3021-\\u3029\\u3031-\\u3035\\u3038-\\u303c\\u3041-\\u3096\\u309d-\\u309f\\u30a1-\\u30fa\\u30fc-\\u30ff\\u3105-\\u312f\\u3131-\\u318e\\u31a0-\\u31ba\\u31f0-\\u31ff\\u3400-\\u4db5\\u4e00-\\u9fef\\ua000-\\ua48c\\ua4d0-\\ua4fd\\ua500-\\ua60c\\ua610-\\ua61f\\ua62a-\\ua62b\\ua640-\\ua66e\\ua67f-\\ua69d\\ua6a0-\\ua6ef\\ua717-\\ua71f\\ua722-\\ua788\\ua78b-\\ua7b9\\ua7f7-\\ua801\\ua803-\\ua805\\ua807-\\ua80a\\ua80c-\\ua822\\ua840-\\ua873\\ua882-\\ua8b3\\ua8f2-\\ua8f7\\ua8fb\\ua8fd-\\ua8fe\\ua90a-\\ua925\\ua930-\\ua946\\ua960-\\ua97c\\ua984-\\ua9b2\\ua9cf\\ua9e0-\\ua9e4\\ua9e6-\\ua9ef\\ua9fa-\\ua9fe\\uaa00-\\uaa28\\uaa40-\\uaa42\\uaa44-\\uaa4b\\uaa60-\\uaa76\\uaa7a\\uaa7e-\\uaaaf\\uaab1\\uaab5-\\uaab6\\uaab9-\\uaabd\\uaac0\\uaac2\\uaadb-\\uaadd\\uaae0-\\uaaea\\uaaf2-\\uaaf4\\uab01-\\uab06\\uab09-\\uab0e\\uab11-\\uab16\\uab20-\\uab26\\uab28-\\uab2e\\uab30-\\uab5a\\uab5c-\\uab65\\uab70-\\uabe2\\uac00-\\ud7a3\\ud7b0-\\ud7c6\\ud7cb-\\ud7fb\\uf900-\\ufa6d\\ufa70-\\ufad9\\ufb00-\\ufb06\\ufb13-\\ufb17\\ufb1d\\ufb1f-\\ufb28\\ufb2a-\\ufb36\\ufb38-\\ufb3c\\ufb3e\\ufb40-\\ufb41\\ufb43-\\ufb44\\ufb46-\\ufbb1\\ufbd3-\\ufc5d\\ufc64-\\ufd3d\\ufd50-\\ufd8f\\ufd92-\\ufdc7\\ufdf0-\\ufdf9\\ufe71\\ufe73\\ufe77\\ufe79\\ufe7b\\ufe7d\\ufe7f-\\ufefc\\uff21-\\uff3a\\uff41-\\uff5a\\uff66-\\uff9d\\uffa0-\\uffbe\\uffc2-\\uffc7\\uffca-\\uffcf\\uffd2-\\uffd7\\uffda-\\uffdc\\U00010000-\\U0001000b\\U0001000d-\\U00010026\\U00010028-\\U0001003a\\U0001003c-\\U0001003d\\U0001003f-\\U0001004d\\U00010050-\\U0001005d\\U00010080-\\U000100fa\\U00010140-\\U00010174\\U00010280-\\U0001029c\\U000102a0-\\U000102d0\\U00010300-\\U0001031f\\U0001032d-\\U0001034a\\U00010350-\\U00010375\\U00010380-\\U0001039d\\U000103a0-\\U000103c3\\U000103c8-\\U000103cf\\U000103d1-\\U000103d5\\U00010400-\\U0001049d\\U000104b0-\\U000104d3\\U000104d8-\\U000104fb\\U00010500-\\U00010527\\U00010530-\\U00010563\\U00010600-\\U00010736\\U00010740-\\U00010755\\U00010760-\\U00010767\\U00010800-\\U00010805\\U00010808\\U0001080a-\\U00010835\\U00010837-\\U00010838\\U0001083c\\U0001083f-\\U00010855\\U00010860-\\U00010876\\U00010880-\\U0001089e\\U000108e0-\\U000108f2\\U000108f4-\\U000108f5\\U00010900-\\U00010915\\U00010920-\\U00010939\\U00010980-\\U000109b7\\U000109be-\\U000109bf\\U00010a00\\U00010a10-\\U00010a13\\U00010a15-\\U00010a17\\U00010a19-\\U00010a35\\U00010a60-\\U00010a7c\\U00010a80-\\U00010a9c\\U00010ac0-\\U00010ac7\\U00010ac9-\\U00010ae4\\U00010b00-\\U00010b35\\U00010b40-\\U00010b55\\U00010b60-\\U00010b72\\U00010b80-\\U00010b91\\U00010c00-\\U00010c48\\U00010c80-\\U00010cb2\\U00010cc0-\\U00010cf2\\U00010d00-\\U00010d23\\U00010f00-\\U00010f1c\\U00010f27\\U00010f30-\\U00010f45\\U00011003-\\U00011037\\U00011083-\\U000110af\\U000110d0-\\U000110e8\\U00011103-\\U00011126\\U00011144\\U00011150-\\U00011172\\U00011176\\U00011183-\\U000111b2\\U000111c1-\\U000111c4\\U000111da\\U000111dc\\U00011200-\\U00011211\\U00011213-\\U0001122b\\U00011280-\\U00011286\\U00011288\\U0001128a-\\U0001128d\\U0001128f-\\U0001129d\\U0001129f-\\U000112a8\\U000112b0-\\U000112de\\U00011305-\\U0001130c\\U0001130f-\\U00011310\\U00011313-\\U00011328\\U0001132a-\\U00011330\\U00011332-\\U00011333\\U00011335-\\U00011339\\U0001133d\\U00011350\\U0001135d-\\U00011361\\U00011400-\\U00011434\\U00011447-\\U0001144a\\U00011480-\\U000114af\\U000114c4-\\U000114c5\\U000114c7\\U00011580-\\U000115ae\\U000115d8-\\U000115db\\U00011600-\\U0001162f\\U00011644\\U00011680-\\U000116aa\\U00011700-\\U0001171a\\U00011800-\\U0001182b\\U000118a0-\\U000118df\\U000118ff\\U00011a00\\U00011a0b-\\U00011a32\\U00011a3a\\U00011a50\\U00011a5c-\\U00011a83\\U00011a86-\\U00011a89\\U00011a9d\\U00011ac0-\\U00011af8\\U00011c00-\\U00011c08\\U00011c0a-\\U00011c2e\\U00011c40\\U00011c72-\\U00011c8f\\U00011d00-\\U00011d06\\U00011d08-\\U00011d09\\U00011d0b-\\U00011d30\\U00011d46\\U00011d60-\\U00011d65\\U00011d67-\\U00011d68\\U00011d6a-\\U00011d89\\U00011d98\\U00011ee0-\\U00011ef2\\U00012000-\\U00012399\\U00012400-\\U0001246e\\U00012480-\\U00012543\\U00013000-\\U0001342e\\U00014400-\\U00014646\\U00016800-\\U00016a38\\U00016a40-\\U00016a5e\\U00016ad0-\\U00016aed\\U00016b00-\\U00016b2f\\U00016b40-\\U00016b43\\U00016b63-\\U00016b77\\U00016b7d-\\U00016b8f\\U00016e40-\\U00016e7f\\U00016f00-\\U00016f44\\U00016f50\\U00016f93-\\U00016f9f\\U00016fe0-\\U00016fe1\\U00017000-\\U000187f1\\U00018800-\\U00018af2\\U0001b000-\\U0001b11e\\U0001b170-\\U0001b2fb\\U0001bc00-\\U0001bc6a\\U0001bc70-\\U0001bc7c\\U0001bc80-\\U0001bc88\\U0001bc90-\\U0001bc99\\U0001d400-\\U0001d454\\U0001d456-\\U0001d49c\\U0001d49e-\\U0001d49f\\U0001d4a2\\U0001d4a5-\\U0001d4a6\\U0001d4a9-\\U0001d4ac\\U0001d4ae-\\U0001d4b9\\U0001d4bb\\U0001d4bd-\\U0001d4c3\\U0001d4c5-\\U0001d505\\U0001d507-\\U0001d50a\\U0001d50d-\\U0001d514\\U0001d516-\\U0001d51c\\U0001d51e-\\U0001d539\\U0001d53b-\\U0001d53e\\U0001d540-\\U0001d544\\U0001d546\\U0001d54a-\\U0001d550\\U0001d552-\\U0001d6a5\\U0001d6a8-\\U0001d6c0\\U0001d6c2-\\U0001d6da\\U0001d6dc-\\U0001d6fa\\U0001d6fc-\\U0001d714\\U0001d716-\\U0001d734\\U0001d736-\\U0001d74e\\U0001d750-\\U0001d76e\\U0001d770-\\U0001d788\\U0001d78a-\\U0001d7a8\\U0001d7aa-\\U0001d7c2\\U0001d7c4-\\U0001d7cb\\U0001e800-\\U0001e8c4\\U0001e900-\\U0001e943\\U0001ee00-\\U0001ee03\\U0001ee05-\\U0001ee1f\\U0001ee21-\\U0001ee22\\U0001ee24\\U0001ee27\\U0001ee29-\\U0001ee32\\U0001ee34-\\U0001ee37\\U0001ee39\\U0001ee3b\\U0001ee42\\U0001ee47\\U0001ee49\\U0001ee4b\\U0001ee4d-\\U0001ee4f\\U0001ee51-\\U0001ee52\\U0001ee54\\U0001ee57\\U0001ee59\\U0001ee5b\\U0001ee5d\\U0001ee5f\\U0001ee61-\\U0001ee62\\U0001ee64\\U0001ee67-\\U0001ee6a\\U0001ee6c-\\U0001ee72\\U0001ee74-\\U0001ee77\\U0001ee79-\\U0001ee7c\\U0001ee7e\\U0001ee80-\\U0001ee89\\U0001ee8b-\\U0001ee9b\\U0001eea1-\\U0001eea3\\U0001eea5-\\U0001eea9\\U0001eeab-\\U0001eebb\\U00020000-\\U0002a6d6\\U0002a700-\\U0002b734\\U0002b740-\\U0002b81d\\U0002b820-\\U0002cea1\\U0002ceb0-\\U0002ebe0\\U0002f800-\\U0002fa1d'\n\ncats = ['Cc', 'Cf', 'Cn', 'Co', 'Cs', 'Ll', 'Lm', 'Lo', 'Lt', 'Lu', 'Mc', 'Me', 'Mn', 'Nd', 'Nl', 'No', 'Pc', 'Pd', 'Pe', 'Pf', 'Pi', 'Po', 'Ps', 'Sc', 'Sk', 'Sm', 'So', 'Zl', 'Zp', 'Zs']\n\n# Generated from unidata 11.0.0\n\ndef combine(*args):\n    return ''.join(globals()[cat] for cat in args)\n\n\ndef allexcept(*args):\n    newcats = cats[:]\n    for arg in args:\n        newcats.remove(arg)\n    return ''.join(globals()[cat] for cat in newcats)\n\n\ndef _handle_runs(char_list):  # pragma: no cover\n    buf = []\n    for c in char_list:\n        if len(c) == 1:\n            if buf and buf[-1][1] == chr(ord(c)-1):\n                buf[-1] = (buf[-1][0], c)\n            else:\n                buf.append((c, c))\n        else:\n            buf.append((c, c))\n    for a, b in buf:\n        if a == b:\n            yield a\n        else:\n            yield f'{a}-{b}'\n\n\nif __name__ == '__main__':  # pragma: no cover\n    import unicodedata\n\n    categories = {'xid_start': [], 'xid_continue': []}\n\n    with open(__file__, encoding='utf-8') as fp:\n        content = fp.read()\n\n    header = content[:content.find('Cc =')]\n    footer = content[content.find(\"def combine(\"):]\n\n    for code in range(0x110000):\n        c = chr(code)\n        cat = unicodedata.category(c)\n        if ord(c) == 0xdc00:\n            # Hack to avoid combining this combining with the preceding high\n            # surrogate, 0xdbff, when doing a repr.\n            c = '\\\\' + c\n        elif ord(c) in (0x2d, 0x5b, 0x5c, 0x5d, 0x5e):\n            # Escape regex metachars.\n            c = '\\\\' + c\n        categories.setdefault(cat, []).append(c)\n        # XID_START and XID_CONTINUE are special categories used for matching\n        # identifiers in Python 3.\n        if c.isidentifier():\n            categories['xid_start'].append(c)\n        if ('a' + c).isidentifier():\n            categories['xid_continue'].append(c)\n\n    with open(__file__, 'w', encoding='utf-8') as fp:\n        fp.write(header)\n\n        for cat in sorted(categories):\n            val = ''.join(_handle_runs(categories[cat]))\n            fp.write(f'{cat} = {val!a}\\n\\n')\n\n        cats = sorted(categories)\n        cats.remove('xid_start')\n        cats.remove('xid_continue')\n        fp.write(f'cats = {cats!r}\\n\\n')\n\n        fp.write(f'# Generated from unidata {unicodedata.unidata_version}\\n\\n')\n\n        fp.write(footer)\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/pygments/util.py","size":10031,"sha1":"ce7f22d03f79f5c403c92c35ecae5272d1dc7b54","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\n    pygments.util\n    ~~~~~~~~~~~~~\n\n    Utility functions.\n\n    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nimport re\nfrom io import TextIOWrapper\n\n\nsplit_path_re = re.compile(r'[/\\\\ ]')\ndoctype_lookup_re = re.compile(r'''\n    <!DOCTYPE\\s+(\n     [a-zA-Z_][a-zA-Z0-9]*\n     (?: \\s+      # optional in HTML5\n     [a-zA-Z_][a-zA-Z0-9]*\\s+\n     \"[^\"]*\")?\n     )\n     [^>]*>\n''', re.DOTALL | re.MULTILINE | re.VERBOSE)\ntag_re = re.compile(r'<(.+?)(\\s.*?)?>.*?</.+?>',\n                    re.IGNORECASE | re.DOTALL | re.MULTILINE)\nxml_decl_re = re.compile(r'\\s*<\\?xml[^>]*\\?>', re.I)\n\n\nclass ClassNotFound(ValueError):\n    \"\"\"Raised if one of the lookup functions didn't find a matching class.\"\"\"\n\n\nclass OptionError(Exception):\n    \"\"\"\n    This exception will be raised by all option processing functions if\n    the type or value of the argument is not correct.\n    \"\"\"\n\ndef get_choice_opt(options, optname, allowed, default=None, normcase=False):\n    \"\"\"\n    If the key `optname` from the dictionary is not in the sequence\n    `allowed`, raise an error, otherwise return it.\n    \"\"\"\n    string = options.get(optname, default)\n    if normcase:\n        string = string.lower()\n    if string not in allowed:\n        raise OptionError('Value for option {} must be one of {}'.format(optname, ', '.join(map(str, allowed))))\n    return string\n\n\ndef get_bool_opt(options, optname, default=None):\n    \"\"\"\n    Intuitively, this is `options.get(optname, default)`, but restricted to\n    Boolean value. The Booleans can be represented as string, in order to accept\n    Boolean value from the command line arguments. If the key `optname` is\n    present in the dictionary `options` and is not associated with a Boolean,\n    raise an `OptionError`. If it is absent, `default` is returned instead.\n\n    The valid string values for ``True`` are ``1``, ``yes``, ``true`` and\n    ``on``, the ones for ``False`` are ``0``, ``no``, ``false`` and ``off``\n    (matched case-insensitively).\n    \"\"\"\n    string = options.get(optname, default)\n    if isinstance(string, bool):\n        return string\n    elif isinstance(string, int):\n        return bool(string)\n    elif not isinstance(string, str):\n        raise OptionError(f'Invalid type {string!r} for option {optname}; use '\n                          '1/0, yes/no, true/false, on/off')\n    elif string.lower() in ('1', 'yes', 'true', 'on'):\n        return True\n    elif string.lower() in ('0', 'no', 'false', 'off'):\n        return False\n    else:\n        raise OptionError(f'Invalid value {string!r} for option {optname}; use '\n                          '1/0, yes/no, true/false, on/off')\n\n\ndef get_int_opt(options, optname, default=None):\n    \"\"\"As :func:`get_bool_opt`, but interpret the value as an integer.\"\"\"\n    string = options.get(optname, default)\n    try:\n        return int(string)\n    except TypeError:\n        raise OptionError(f'Invalid type {string!r} for option {optname}; you '\n                          'must give an integer value')\n    except ValueError:\n        raise OptionError(f'Invalid value {string!r} for option {optname}; you '\n                          'must give an integer value')\n\ndef get_list_opt(options, optname, default=None):\n    \"\"\"\n    If the key `optname` from the dictionary `options` is a string,\n    split it at whitespace and return it. If it is already a list\n    or a tuple, it is returned as a list.\n    \"\"\"\n    val = options.get(optname, default)\n    if isinstance(val, str):\n        return val.split()\n    elif isinstance(val, (list, tuple)):\n        return list(val)\n    else:\n        raise OptionError(f'Invalid type {val!r} for option {optname}; you '\n                          'must give a list value')\n\n\ndef docstring_headline(obj):\n    if not obj.__doc__:\n        return ''\n    res = []\n    for line in obj.__doc__.strip().splitlines():\n        if line.strip():\n            res.append(\" \" + line.strip())\n        else:\n            break\n    return ''.join(res).lstrip()\n\n\ndef make_analysator(f):\n    \"\"\"Return a static text analyser function that returns float values.\"\"\"\n    def text_analyse(text):\n        try:\n            rv = f(text)\n        except Exception:\n            return 0.0\n        if not rv:\n            return 0.0\n        try:\n            return min(1.0, max(0.0, float(rv)))\n        except (ValueError, TypeError):\n            return 0.0\n    text_analyse.__doc__ = f.__doc__\n    return staticmethod(text_analyse)\n\n\ndef shebang_matches(text, regex):\n    r\"\"\"Check if the given regular expression matches the last part of the\n    shebang if one exists.\n\n        >>> from pygments.util import shebang_matches\n        >>> shebang_matches('#!/usr/bin/env python', r'python(2\\.\\d)?')\n        True\n        >>> shebang_matches('#!/usr/bin/python2.4', r'python(2\\.\\d)?')\n        True\n        >>> shebang_matches('#!/usr/bin/python-ruby', r'python(2\\.\\d)?')\n        False\n        >>> shebang_matches('#!/usr/bin/python/ruby', r'python(2\\.\\d)?')\n        False\n        >>> shebang_matches('#!/usr/bin/startsomethingwith python',\n        ...                 r'python(2\\.\\d)?')\n        True\n\n    It also checks for common windows executable file extensions::\n\n        >>> shebang_matches('#!C:\\\\Python2.4\\\\Python.exe', r'python(2\\.\\d)?')\n        True\n\n    Parameters (``'-f'`` or ``'--foo'`` are ignored so ``'perl'`` does\n    the same as ``'perl -e'``)\n\n    Note that this method automatically searches the whole string (eg:\n    the regular expression is wrapped in ``'^$'``)\n    \"\"\"\n    index = text.find('\\n')\n    if index >= 0:\n        first_line = text[:index].lower()\n    else:\n        first_line = text.lower()\n    if first_line.startswith('#!'):\n        try:\n            found = [x for x in split_path_re.split(first_line[2:].strip())\n                     if x and not x.startswith('-')][-1]\n        except IndexError:\n            return False\n        regex = re.compile(rf'^{regex}(\\.(exe|cmd|bat|bin))?$', re.IGNORECASE)\n        if regex.search(found) is not None:\n            return True\n    return False\n\n\ndef doctype_matches(text, regex):\n    \"\"\"Check if the doctype matches a regular expression (if present).\n\n    Note that this method only checks the first part of a DOCTYPE.\n    eg: 'html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\"'\n    \"\"\"\n    m = doctype_lookup_re.search(text)\n    if m is None:\n        return False\n    doctype = m.group(1)\n    return re.compile(regex, re.I).match(doctype.strip()) is not None\n\n\ndef html_doctype_matches(text):\n    \"\"\"Check if the file looks like it has a html doctype.\"\"\"\n    return doctype_matches(text, r'html')\n\n\n_looks_like_xml_cache = {}\n\n\ndef looks_like_xml(text):\n    \"\"\"Check if a doctype exists or if we have some tags.\"\"\"\n    if xml_decl_re.match(text):\n        return True\n    key = hash(text)\n    try:\n        return _looks_like_xml_cache[key]\n    except KeyError:\n        m = doctype_lookup_re.search(text)\n        if m is not None:\n            return True\n        rv = tag_re.search(text[:1000]) is not None\n        _looks_like_xml_cache[key] = rv\n        return rv\n\n\ndef surrogatepair(c):\n    \"\"\"Given a unicode character code with length greater than 16 bits,\n    return the two 16 bit surrogate pair.\n    \"\"\"\n    # From example D28 of:\n    # http://www.unicode.org/book/ch03.pdf\n    return (0xd7c0 + (c >> 10), (0xdc00 + (c & 0x3ff)))\n\n\ndef format_lines(var_name, seq, raw=False, indent_level=0):\n    \"\"\"Formats a sequence of strings for output.\"\"\"\n    lines = []\n    base_indent = ' ' * indent_level * 4\n    inner_indent = ' ' * (indent_level + 1) * 4\n    lines.append(base_indent + var_name + ' = (')\n    if raw:\n        # These should be preformatted reprs of, say, tuples.\n        for i in seq:\n            lines.append(inner_indent + i + ',')\n    else:\n        for i in seq:\n            # Force use of single quotes\n            r = repr(i + '\"')\n            lines.append(inner_indent + r[:-2] + r[-1] + ',')\n    lines.append(base_indent + ')')\n    return '\\n'.join(lines)\n\n\ndef duplicates_removed(it, already_seen=()):\n    \"\"\"\n    Returns a list with duplicates removed from the iterable `it`.\n\n    Order is preserved.\n    \"\"\"\n    lst = []\n    seen = set()\n    for i in it:\n        if i in seen or i in already_seen:\n            continue\n        lst.append(i)\n        seen.add(i)\n    return lst\n\n\nclass Future:\n    \"\"\"Generic class to defer some work.\n\n    Handled specially in RegexLexerMeta, to support regex string construction at\n    first use.\n    \"\"\"\n    def get(self):\n        raise NotImplementedError\n\n\ndef guess_decode(text):\n    \"\"\"Decode *text* with guessed encoding.\n\n    First try UTF-8; this should fail for non-UTF-8 encodings.\n    Then try the preferred locale encoding.\n    Fall back to latin-1, which always works.\n    \"\"\"\n    try:\n        text = text.decode('utf-8')\n        return text, 'utf-8'\n    except UnicodeDecodeError:\n        try:\n            import locale\n            prefencoding = locale.getpreferredencoding()\n            text = text.decode()\n            return text, prefencoding\n        except (UnicodeDecodeError, LookupError):\n            text = text.decode('latin1')\n            return text, 'latin1'\n\n\ndef guess_decode_from_terminal(text, term):\n    \"\"\"Decode *text* coming from terminal *term*.\n\n    First try the terminal encoding, if given.\n    Then try UTF-8.  Then try the preferred locale encoding.\n    Fall back to latin-1, which always works.\n    \"\"\"\n    if getattr(term, 'encoding', None):\n        try:\n            text = text.decode(term.encoding)\n        except UnicodeDecodeError:\n            pass\n        else:\n            return text, term.encoding\n    return guess_decode(text)\n\n\ndef terminal_encoding(term):\n    \"\"\"Return our best guess of encoding for the given *term*.\"\"\"\n    if getattr(term, 'encoding', None):\n        return term.encoding\n    import locale\n    return locale.getpreferredencoding()\n\n\nclass UnclosingTextIOWrapper(TextIOWrapper):\n    # Don't close underlying buffer on destruction.\n    def close(self):\n        self.flush()\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/pyproject_hooks/__init__.py","size":691,"sha1":"bf82c531b8deb584e025e045b36a5aca55061522","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"Wrappers to call pyproject.toml-based build backend hooks.\n\"\"\"\n\nfrom typing import TYPE_CHECKING\n\nfrom ._impl import (\n    BackendUnavailable,\n    BuildBackendHookCaller,\n    HookMissing,\n    UnsupportedOperation,\n    default_subprocess_runner,\n    quiet_subprocess_runner,\n)\n\n__version__ = \"1.2.0\"\n__all__ = [\n    \"BackendUnavailable\",\n    \"BackendInvalid\",\n    \"HookMissing\",\n    \"UnsupportedOperation\",\n    \"default_subprocess_runner\",\n    \"quiet_subprocess_runner\",\n    \"BuildBackendHookCaller\",\n]\n\nBackendInvalid = BackendUnavailable  # Deprecated alias, previously a separate exception\n\nif TYPE_CHECKING:\n    from ._impl import SubprocessRunner\n\n    __all__ += [\"SubprocessRunner\"]\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/pyproject_hooks/_impl.py","size":14936,"sha1":"823d53ff5e068473c585da74eda7361085b9ca9c","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"import json\nimport os\nimport sys\nimport tempfile\nfrom contextlib import contextmanager\nfrom os.path import abspath\nfrom os.path import join as pjoin\nfrom subprocess import STDOUT, check_call, check_output\nfrom typing import TYPE_CHECKING, Any, Iterator, Mapping, Optional, Sequence\n\nfrom ._in_process import _in_proc_script_path\n\nif TYPE_CHECKING:\n    from typing import Protocol\n\n    class SubprocessRunner(Protocol):\n        \"\"\"A protocol for the subprocess runner.\"\"\"\n\n        def __call__(\n            self,\n            cmd: Sequence[str],\n            cwd: Optional[str] = None,\n            extra_environ: Optional[Mapping[str, str]] = None,\n        ) -> None:\n            ...\n\n\ndef write_json(obj: Mapping[str, Any], path: str, **kwargs) -> None:\n    with open(path, \"w\", encoding=\"utf-8\") as f:\n        json.dump(obj, f, **kwargs)\n\n\ndef read_json(path: str) -> Mapping[str, Any]:\n    with open(path, encoding=\"utf-8\") as f:\n        return json.load(f)\n\n\nclass BackendUnavailable(Exception):\n    \"\"\"Will be raised if the backend cannot be imported in the hook process.\"\"\"\n\n    def __init__(\n        self,\n        traceback: str,\n        message: Optional[str] = None,\n        backend_name: Optional[str] = None,\n        backend_path: Optional[Sequence[str]] = None,\n    ) -> None:\n        # Preserving arg order for the sake of API backward compatibility.\n        self.backend_name = backend_name\n        self.backend_path = backend_path\n        self.traceback = traceback\n        super().__init__(message or \"Error while importing backend\")\n\n\nclass HookMissing(Exception):\n    \"\"\"Will be raised on missing hooks (if a fallback can't be used).\"\"\"\n\n    def __init__(self, hook_name: str) -> None:\n        super().__init__(hook_name)\n        self.hook_name = hook_name\n\n\nclass UnsupportedOperation(Exception):\n    \"\"\"May be raised by build_sdist if the backend indicates that it can't.\"\"\"\n\n    def __init__(self, traceback: str) -> None:\n        self.traceback = traceback\n\n\ndef default_subprocess_runner(\n    cmd: Sequence[str],\n    cwd: Optional[str] = None,\n    extra_environ: Optional[Mapping[str, str]] = None,\n) -> None:\n    \"\"\"The default method of calling the wrapper subprocess.\n\n    This uses :func:`subprocess.check_call` under the hood.\n    \"\"\"\n    env = os.environ.copy()\n    if extra_environ:\n        env.update(extra_environ)\n\n    check_call(cmd, cwd=cwd, env=env)\n\n\ndef quiet_subprocess_runner(\n    cmd: Sequence[str],\n    cwd: Optional[str] = None,\n    extra_environ: Optional[Mapping[str, str]] = None,\n) -> None:\n    \"\"\"Call the subprocess while suppressing output.\n\n    This uses :func:`subprocess.check_output` under the hood.\n    \"\"\"\n    env = os.environ.copy()\n    if extra_environ:\n        env.update(extra_environ)\n\n    check_output(cmd, cwd=cwd, env=env, stderr=STDOUT)\n\n\ndef norm_and_check(source_tree: str, requested: str) -> str:\n    \"\"\"Normalise and check a backend path.\n\n    Ensure that the requested backend path is specified as a relative path,\n    and resolves to a location under the given source tree.\n\n    Return an absolute version of the requested path.\n    \"\"\"\n    if os.path.isabs(requested):\n        raise ValueError(\"paths must be relative\")\n\n    abs_source = os.path.abspath(source_tree)\n    abs_requested = os.path.normpath(os.path.join(abs_source, requested))\n    # We have to use commonprefix for Python 2.7 compatibility. So we\n    # normalise case to avoid problems because commonprefix is a character\n    # based comparison :-(\n    norm_source = os.path.normcase(abs_source)\n    norm_requested = os.path.normcase(abs_requested)\n    if os.path.commonprefix([norm_source, norm_requested]) != norm_source:\n        raise ValueError(\"paths must be inside source tree\")\n\n    return abs_requested\n\n\nclass BuildBackendHookCaller:\n    \"\"\"A wrapper to call the build backend hooks for a source directory.\"\"\"\n\n    def __init__(\n        self,\n        source_dir: str,\n        build_backend: str,\n        backend_path: Optional[Sequence[str]] = None,\n        runner: Optional[\"SubprocessRunner\"] = None,\n        python_executable: Optional[str] = None,\n    ) -> None:\n        \"\"\"\n        :param source_dir: The source directory to invoke the build backend for\n        :param build_backend: The build backend spec\n        :param backend_path: Additional path entries for the build backend spec\n        :param runner: The :ref:`subprocess runner <Subprocess Runners>` to use\n        :param python_executable:\n            The Python executable used to invoke the build backend\n        \"\"\"\n        if runner is None:\n            runner = default_subprocess_runner\n\n        self.source_dir = abspath(source_dir)\n        self.build_backend = build_backend\n        if backend_path:\n            backend_path = [norm_and_check(self.source_dir, p) for p in backend_path]\n        self.backend_path = backend_path\n        self._subprocess_runner = runner\n        if not python_executable:\n            python_executable = sys.executable\n        self.python_executable = python_executable\n\n    @contextmanager\n    def subprocess_runner(self, runner: \"SubprocessRunner\") -> Iterator[None]:\n        \"\"\"A context manager for temporarily overriding the default\n        :ref:`subprocess runner <Subprocess Runners>`.\n\n        :param runner: The new subprocess runner to use within the context.\n\n        .. code-block:: python\n\n            hook_caller = BuildBackendHookCaller(...)\n            with hook_caller.subprocess_runner(quiet_subprocess_runner):\n                ...\n        \"\"\"\n        prev = self._subprocess_runner\n        self._subprocess_runner = runner\n        try:\n            yield\n        finally:\n            self._subprocess_runner = prev\n\n    def _supported_features(self) -> Sequence[str]:\n        \"\"\"Return the list of optional features supported by the backend.\"\"\"\n        return self._call_hook(\"_supported_features\", {})\n\n    def get_requires_for_build_wheel(\n        self,\n        config_settings: Optional[Mapping[str, Any]] = None,\n    ) -> Sequence[str]:\n        \"\"\"Get additional dependencies required for building a wheel.\n\n        :param config_settings: The configuration settings for the build backend\n        :returns: A list of :pep:`dependency specifiers <508>`.\n\n        .. admonition:: Fallback\n\n            If the build backend does not defined a hook with this name, an\n            empty list will be returned.\n        \"\"\"\n        return self._call_hook(\n            \"get_requires_for_build_wheel\", {\"config_settings\": config_settings}\n        )\n\n    def prepare_metadata_for_build_wheel(\n        self,\n        metadata_directory: str,\n        config_settings: Optional[Mapping[str, Any]] = None,\n        _allow_fallback: bool = True,\n    ) -> str:\n        \"\"\"Prepare a ``*.dist-info`` folder with metadata for this project.\n\n        :param metadata_directory: The directory to write the metadata to\n        :param config_settings: The configuration settings for the build backend\n        :param _allow_fallback:\n            Whether to allow the fallback to building a wheel and extracting\n            the metadata from it. Should be passed as a keyword argument only.\n\n        :returns: Name of the newly created subfolder within\n                  ``metadata_directory``, containing the metadata.\n\n        .. admonition:: Fallback\n\n            If the build backend does not define a hook with this name and\n            ``_allow_fallback`` is truthy, the backend will be asked to build a\n            wheel via the ``build_wheel`` hook and the dist-info extracted from\n            that will be returned.\n        \"\"\"\n        return self._call_hook(\n            \"prepare_metadata_for_build_wheel\",\n            {\n                \"metadata_directory\": abspath(metadata_directory),\n                \"config_settings\": config_settings,\n                \"_allow_fallback\": _allow_fallback,\n            },\n        )\n\n    def build_wheel(\n        self,\n        wheel_directory: str,\n        config_settings: Optional[Mapping[str, Any]] = None,\n        metadata_directory: Optional[str] = None,\n    ) -> str:\n        \"\"\"Build a wheel from this project.\n\n        :param wheel_directory: The directory to write the wheel to\n        :param config_settings: The configuration settings for the build backend\n        :param metadata_directory: The directory to reuse existing metadata from\n        :returns:\n            The name of the newly created wheel within ``wheel_directory``.\n\n        .. admonition:: Interaction with fallback\n\n            If the ``build_wheel`` hook was called in the fallback for\n            :meth:`prepare_metadata_for_build_wheel`, the build backend would\n            not be invoked. Instead, the previously built wheel will be copied\n            to ``wheel_directory`` and the name of that file will be returned.\n        \"\"\"\n        if metadata_directory is not None:\n            metadata_directory = abspath(metadata_directory)\n        return self._call_hook(\n            \"build_wheel\",\n            {\n                \"wheel_directory\": abspath(wheel_directory),\n                \"config_settings\": config_settings,\n                \"metadata_directory\": metadata_directory,\n            },\n        )\n\n    def get_requires_for_build_editable(\n        self,\n        config_settings: Optional[Mapping[str, Any]] = None,\n    ) -> Sequence[str]:\n        \"\"\"Get additional dependencies required for building an editable wheel.\n\n        :param config_settings: The configuration settings for the build backend\n        :returns: A list of :pep:`dependency specifiers <508>`.\n\n        .. admonition:: Fallback\n\n            If the build backend does not defined a hook with this name, an\n            empty list will be returned.\n        \"\"\"\n        return self._call_hook(\n            \"get_requires_for_build_editable\", {\"config_settings\": config_settings}\n        )\n\n    def prepare_metadata_for_build_editable(\n        self,\n        metadata_directory: str,\n        config_settings: Optional[Mapping[str, Any]] = None,\n        _allow_fallback: bool = True,\n    ) -> Optional[str]:\n        \"\"\"Prepare a ``*.dist-info`` folder with metadata for this project.\n\n        :param metadata_directory: The directory to write the metadata to\n        :param config_settings: The configuration settings for the build backend\n        :param _allow_fallback:\n            Whether to allow the fallback to building a wheel and extracting\n            the metadata from it. Should be passed as a keyword argument only.\n        :returns: Name of the newly created subfolder within\n                  ``metadata_directory``, containing the metadata.\n\n        .. admonition:: Fallback\n\n            If the build backend does not define a hook with this name and\n            ``_allow_fallback`` is truthy, the backend will be asked to build a\n            wheel via the ``build_editable`` hook and the dist-info\n            extracted from that will be returned.\n        \"\"\"\n        return self._call_hook(\n            \"prepare_metadata_for_build_editable\",\n            {\n                \"metadata_directory\": abspath(metadata_directory),\n                \"config_settings\": config_settings,\n                \"_allow_fallback\": _allow_fallback,\n            },\n        )\n\n    def build_editable(\n        self,\n        wheel_directory: str,\n        config_settings: Optional[Mapping[str, Any]] = None,\n        metadata_directory: Optional[str] = None,\n    ) -> str:\n        \"\"\"Build an editable wheel from this project.\n\n        :param wheel_directory: The directory to write the wheel to\n        :param config_settings: The configuration settings for the build backend\n        :param metadata_directory: The directory to reuse existing metadata from\n        :returns:\n            The name of the newly created wheel within ``wheel_directory``.\n\n        .. admonition:: Interaction with fallback\n\n            If the ``build_editable`` hook was called in the fallback for\n            :meth:`prepare_metadata_for_build_editable`, the build backend\n            would not be invoked. Instead, the previously built wheel will be\n            copied to ``wheel_directory`` and the name of that file will be\n            returned.\n        \"\"\"\n        if metadata_directory is not None:\n            metadata_directory = abspath(metadata_directory)\n        return self._call_hook(\n            \"build_editable\",\n            {\n                \"wheel_directory\": abspath(wheel_directory),\n                \"config_settings\": config_settings,\n                \"metadata_directory\": metadata_directory,\n            },\n        )\n\n    def get_requires_for_build_sdist(\n        self,\n        config_settings: Optional[Mapping[str, Any]] = None,\n    ) -> Sequence[str]:\n        \"\"\"Get additional dependencies required for building an sdist.\n\n        :returns: A list of :pep:`dependency specifiers <508>`.\n        \"\"\"\n        return self._call_hook(\n            \"get_requires_for_build_sdist\", {\"config_settings\": config_settings}\n        )\n\n    def build_sdist(\n        self,\n        sdist_directory: str,\n        config_settings: Optional[Mapping[str, Any]] = None,\n    ) -> str:\n        \"\"\"Build an sdist from this project.\n\n        :returns:\n            The name of the newly created sdist within ``wheel_directory``.\n        \"\"\"\n        return self._call_hook(\n            \"build_sdist\",\n            {\n                \"sdist_directory\": abspath(sdist_directory),\n                \"config_settings\": config_settings,\n            },\n        )\n\n    def _call_hook(self, hook_name: str, kwargs: Mapping[str, Any]) -> Any:\n        extra_environ = {\"_PYPROJECT_HOOKS_BUILD_BACKEND\": self.build_backend}\n\n        if self.backend_path:\n            backend_path = os.pathsep.join(self.backend_path)\n            extra_environ[\"_PYPROJECT_HOOKS_BACKEND_PATH\"] = backend_path\n\n        with tempfile.TemporaryDirectory() as td:\n            hook_input = {\"kwargs\": kwargs}\n            write_json(hook_input, pjoin(td, \"input.json\"), indent=2)\n\n            # Run the hook in a subprocess\n            with _in_proc_script_path() as script:\n                python = self.python_executable\n                self._subprocess_runner(\n                    [python, abspath(str(script)), hook_name, td],\n                    cwd=self.source_dir,\n                    extra_environ=extra_environ,\n                )\n\n            data = read_json(pjoin(td, \"output.json\"))\n            if data.get(\"unsupported\"):\n                raise UnsupportedOperation(data.get(\"traceback\", \"\"))\n            if data.get(\"no_backend\"):\n                raise BackendUnavailable(\n                    data.get(\"traceback\", \"\"),\n                    message=data.get(\"backend_error\", \"\"),\n                    backend_name=self.build_backend,\n                    backend_path=self.backend_path,\n                )\n            if data.get(\"hook_missing\"):\n                raise HookMissing(data.get(\"missing_hook_name\") or hook_name)\n            return data[\"return_val\"]\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/pyproject_hooks/_in_process/__init__.py","size":557,"sha1":"f3d8f7bc5567728129ea80fb2fb4351a2cb728a8","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"This is a subpackage because the directory is on sys.path for _in_process.py\n\nThe subpackage should stay as empty as possible to avoid shadowing modules that\nthe backend might import.\n\"\"\"\n\nimport importlib.resources as resources\n\ntry:\n    resources.files\nexcept AttributeError:\n    # Python 3.8 compatibility\n    def _in_proc_script_path():\n        return resources.path(__package__, \"_in_process.py\")\n\nelse:\n\n    def _in_proc_script_path():\n        return resources.as_file(\n            resources.files(__package__).joinpath(\"_in_process.py\")\n        )\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/pyproject_hooks/_in_process/_in_process.py","size":12216,"sha1":"6cf78aa27d0ca36aa0fc5b775eef63767e7c4abb","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"This is invoked in a subprocess to call the build backend hooks.\n\nIt expects:\n- Command line args: hook_name, control_dir\n- Environment variables:\n      _PYPROJECT_HOOKS_BUILD_BACKEND=entry.point:spec\n      _PYPROJECT_HOOKS_BACKEND_PATH=paths (separated with os.pathsep)\n- control_dir/input.json:\n  - {\"kwargs\": {...}}\n\nResults:\n- control_dir/output.json\n  - {\"return_val\": ...}\n\"\"\"\nimport json\nimport os\nimport os.path\nimport re\nimport shutil\nimport sys\nimport traceback\nfrom glob import glob\nfrom importlib import import_module\nfrom importlib.machinery import PathFinder\nfrom os.path import join as pjoin\n\n# This file is run as a script, and `import wrappers` is not zip-safe, so we\n# include write_json() and read_json() from wrappers.py.\n\n\ndef write_json(obj, path, **kwargs):\n    with open(path, \"w\", encoding=\"utf-8\") as f:\n        json.dump(obj, f, **kwargs)\n\n\ndef read_json(path):\n    with open(path, encoding=\"utf-8\") as f:\n        return json.load(f)\n\n\nclass BackendUnavailable(Exception):\n    \"\"\"Raised if we cannot import the backend\"\"\"\n\n    def __init__(self, message, traceback=None):\n        super().__init__(message)\n        self.message = message\n        self.traceback = traceback\n\n\nclass HookMissing(Exception):\n    \"\"\"Raised if a hook is missing and we are not executing the fallback\"\"\"\n\n    def __init__(self, hook_name=None):\n        super().__init__(hook_name)\n        self.hook_name = hook_name\n\n\ndef _build_backend():\n    \"\"\"Find and load the build backend\"\"\"\n    backend_path = os.environ.get(\"_PYPROJECT_HOOKS_BACKEND_PATH\")\n    ep = os.environ[\"_PYPROJECT_HOOKS_BUILD_BACKEND\"]\n    mod_path, _, obj_path = ep.partition(\":\")\n\n    if backend_path:\n        # Ensure in-tree backend directories have the highest priority when importing.\n        extra_pathitems = backend_path.split(os.pathsep)\n        sys.meta_path.insert(0, _BackendPathFinder(extra_pathitems, mod_path))\n\n    try:\n        obj = import_module(mod_path)\n    except ImportError:\n        msg = f\"Cannot import {mod_path!r}\"\n        raise BackendUnavailable(msg, traceback.format_exc())\n\n    if obj_path:\n        for path_part in obj_path.split(\".\"):\n            obj = getattr(obj, path_part)\n    return obj\n\n\nclass _BackendPathFinder:\n    \"\"\"Implements the MetaPathFinder interface to locate modules in ``backend-path``.\n\n    Since the environment provided by the frontend can contain all sorts of\n    MetaPathFinders, the only way to ensure the backend is loaded from the\n    right place is to prepend our own.\n    \"\"\"\n\n    def __init__(self, backend_path, backend_module):\n        self.backend_path = backend_path\n        self.backend_module = backend_module\n        self.backend_parent, _, _ = backend_module.partition(\".\")\n\n    def find_spec(self, fullname, _path, _target=None):\n        if \".\" in fullname:\n            # Rely on importlib to find nested modules based on parent's path\n            return None\n\n        # Ignore other items in _path or sys.path and use backend_path instead:\n        spec = PathFinder.find_spec(fullname, path=self.backend_path)\n        if spec is None and fullname == self.backend_parent:\n            # According to the spec, the backend MUST be loaded from backend-path.\n            # Therefore, we can halt the import machinery and raise a clean error.\n            msg = f\"Cannot find module {self.backend_module!r} in {self.backend_path!r}\"\n            raise BackendUnavailable(msg)\n\n        return spec\n\n    if sys.version_info >= (3, 8):\n\n        def find_distributions(self, context=None):\n            # Delayed import: Python 3.7 does not contain importlib.metadata\n            from importlib.metadata import DistributionFinder, MetadataPathFinder\n\n            context = DistributionFinder.Context(path=self.backend_path)\n            return MetadataPathFinder.find_distributions(context=context)\n\n\ndef _supported_features():\n    \"\"\"Return the list of options features supported by the backend.\n\n    Returns a list of strings.\n    The only possible value is 'build_editable'.\n    \"\"\"\n    backend = _build_backend()\n    features = []\n    if hasattr(backend, \"build_editable\"):\n        features.append(\"build_editable\")\n    return features\n\n\ndef get_requires_for_build_wheel(config_settings):\n    \"\"\"Invoke the optional get_requires_for_build_wheel hook\n\n    Returns [] if the hook is not defined.\n    \"\"\"\n    backend = _build_backend()\n    try:\n        hook = backend.get_requires_for_build_wheel\n    except AttributeError:\n        return []\n    else:\n        return hook(config_settings)\n\n\ndef get_requires_for_build_editable(config_settings):\n    \"\"\"Invoke the optional get_requires_for_build_editable hook\n\n    Returns [] if the hook is not defined.\n    \"\"\"\n    backend = _build_backend()\n    try:\n        hook = backend.get_requires_for_build_editable\n    except AttributeError:\n        return []\n    else:\n        return hook(config_settings)\n\n\ndef prepare_metadata_for_build_wheel(\n    metadata_directory, config_settings, _allow_fallback\n):\n    \"\"\"Invoke optional prepare_metadata_for_build_wheel\n\n    Implements a fallback by building a wheel if the hook isn't defined,\n    unless _allow_fallback is False in which case HookMissing is raised.\n    \"\"\"\n    backend = _build_backend()\n    try:\n        hook = backend.prepare_metadata_for_build_wheel\n    except AttributeError:\n        if not _allow_fallback:\n            raise HookMissing()\n    else:\n        return hook(metadata_directory, config_settings)\n    # fallback to build_wheel outside the try block to avoid exception chaining\n    # which can be confusing to users and is not relevant\n    whl_basename = backend.build_wheel(metadata_directory, config_settings)\n    return _get_wheel_metadata_from_wheel(\n        whl_basename, metadata_directory, config_settings\n    )\n\n\ndef prepare_metadata_for_build_editable(\n    metadata_directory, config_settings, _allow_fallback\n):\n    \"\"\"Invoke optional prepare_metadata_for_build_editable\n\n    Implements a fallback by building an editable wheel if the hook isn't\n    defined, unless _allow_fallback is False in which case HookMissing is\n    raised.\n    \"\"\"\n    backend = _build_backend()\n    try:\n        hook = backend.prepare_metadata_for_build_editable\n    except AttributeError:\n        if not _allow_fallback:\n            raise HookMissing()\n        try:\n            build_hook = backend.build_editable\n        except AttributeError:\n            raise HookMissing(hook_name=\"build_editable\")\n        else:\n            whl_basename = build_hook(metadata_directory, config_settings)\n            return _get_wheel_metadata_from_wheel(\n                whl_basename, metadata_directory, config_settings\n            )\n    else:\n        return hook(metadata_directory, config_settings)\n\n\nWHEEL_BUILT_MARKER = \"PYPROJECT_HOOKS_ALREADY_BUILT_WHEEL\"\n\n\ndef _dist_info_files(whl_zip):\n    \"\"\"Identify the .dist-info folder inside a wheel ZipFile.\"\"\"\n    res = []\n    for path in whl_zip.namelist():\n        m = re.match(r\"[^/\\\\]+-[^/\\\\]+\\.dist-info/\", path)\n        if m:\n            res.append(path)\n    if res:\n        return res\n    raise Exception(\"No .dist-info folder found in wheel\")\n\n\ndef _get_wheel_metadata_from_wheel(whl_basename, metadata_directory, config_settings):\n    \"\"\"Extract the metadata from a wheel.\n\n    Fallback for when the build backend does not\n    define the 'get_wheel_metadata' hook.\n    \"\"\"\n    from zipfile import ZipFile\n\n    with open(os.path.join(metadata_directory, WHEEL_BUILT_MARKER), \"wb\"):\n        pass  # Touch marker file\n\n    whl_file = os.path.join(metadata_directory, whl_basename)\n    with ZipFile(whl_file) as zipf:\n        dist_info = _dist_info_files(zipf)\n        zipf.extractall(path=metadata_directory, members=dist_info)\n    return dist_info[0].split(\"/\")[0]\n\n\ndef _find_already_built_wheel(metadata_directory):\n    \"\"\"Check for a wheel already built during the get_wheel_metadata hook.\"\"\"\n    if not metadata_directory:\n        return None\n    metadata_parent = os.path.dirname(metadata_directory)\n    if not os.path.isfile(pjoin(metadata_parent, WHEEL_BUILT_MARKER)):\n        return None\n\n    whl_files = glob(os.path.join(metadata_parent, \"*.whl\"))\n    if not whl_files:\n        print(\"Found wheel built marker, but no .whl files\")\n        return None\n    if len(whl_files) > 1:\n        print(\n            \"Found multiple .whl files; unspecified behaviour. \"\n            \"Will call build_wheel.\"\n        )\n        return None\n\n    # Exactly one .whl file\n    return whl_files[0]\n\n\ndef build_wheel(wheel_directory, config_settings, metadata_directory=None):\n    \"\"\"Invoke the mandatory build_wheel hook.\n\n    If a wheel was already built in the\n    prepare_metadata_for_build_wheel fallback, this\n    will copy it rather than rebuilding the wheel.\n    \"\"\"\n    prebuilt_whl = _find_already_built_wheel(metadata_directory)\n    if prebuilt_whl:\n        shutil.copy2(prebuilt_whl, wheel_directory)\n        return os.path.basename(prebuilt_whl)\n\n    return _build_backend().build_wheel(\n        wheel_directory, config_settings, metadata_directory\n    )\n\n\ndef build_editable(wheel_directory, config_settings, metadata_directory=None):\n    \"\"\"Invoke the optional build_editable hook.\n\n    If a wheel was already built in the\n    prepare_metadata_for_build_editable fallback, this\n    will copy it rather than rebuilding the wheel.\n    \"\"\"\n    backend = _build_backend()\n    try:\n        hook = backend.build_editable\n    except AttributeError:\n        raise HookMissing()\n    else:\n        prebuilt_whl = _find_already_built_wheel(metadata_directory)\n        if prebuilt_whl:\n            shutil.copy2(prebuilt_whl, wheel_directory)\n            return os.path.basename(prebuilt_whl)\n\n        return hook(wheel_directory, config_settings, metadata_directory)\n\n\ndef get_requires_for_build_sdist(config_settings):\n    \"\"\"Invoke the optional get_requires_for_build_wheel hook\n\n    Returns [] if the hook is not defined.\n    \"\"\"\n    backend = _build_backend()\n    try:\n        hook = backend.get_requires_for_build_sdist\n    except AttributeError:\n        return []\n    else:\n        return hook(config_settings)\n\n\nclass _DummyException(Exception):\n    \"\"\"Nothing should ever raise this exception\"\"\"\n\n\nclass GotUnsupportedOperation(Exception):\n    \"\"\"For internal use when backend raises UnsupportedOperation\"\"\"\n\n    def __init__(self, traceback):\n        self.traceback = traceback\n\n\ndef build_sdist(sdist_directory, config_settings):\n    \"\"\"Invoke the mandatory build_sdist hook.\"\"\"\n    backend = _build_backend()\n    try:\n        return backend.build_sdist(sdist_directory, config_settings)\n    except getattr(backend, \"UnsupportedOperation\", _DummyException):\n        raise GotUnsupportedOperation(traceback.format_exc())\n\n\nHOOK_NAMES = {\n    \"get_requires_for_build_wheel\",\n    \"prepare_metadata_for_build_wheel\",\n    \"build_wheel\",\n    \"get_requires_for_build_editable\",\n    \"prepare_metadata_for_build_editable\",\n    \"build_editable\",\n    \"get_requires_for_build_sdist\",\n    \"build_sdist\",\n    \"_supported_features\",\n}\n\n\ndef main():\n    if len(sys.argv) < 3:\n        sys.exit(\"Needs args: hook_name, control_dir\")\n    hook_name = sys.argv[1]\n    control_dir = sys.argv[2]\n    if hook_name not in HOOK_NAMES:\n        sys.exit(\"Unknown hook: %s\" % hook_name)\n\n    # Remove the parent directory from sys.path to avoid polluting the backend\n    # import namespace with this directory.\n    here = os.path.dirname(__file__)\n    if here in sys.path:\n        sys.path.remove(here)\n\n    hook = globals()[hook_name]\n\n    hook_input = read_json(pjoin(control_dir, \"input.json\"))\n\n    json_out = {\"unsupported\": False, \"return_val\": None}\n    try:\n        json_out[\"return_val\"] = hook(**hook_input[\"kwargs\"])\n    except BackendUnavailable as e:\n        json_out[\"no_backend\"] = True\n        json_out[\"traceback\"] = e.traceback\n        json_out[\"backend_error\"] = e.message\n    except GotUnsupportedOperation as e:\n        json_out[\"unsupported\"] = True\n        json_out[\"traceback\"] = e.traceback\n    except HookMissing as e:\n        json_out[\"hook_missing\"] = True\n        json_out[\"missing_hook_name\"] = e.hook_name or hook_name\n\n    write_json(json_out, pjoin(control_dir, \"output.json\"), indent=2)\n\n\nif __name__ == \"__main__\":\n    main()\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/requests/__init__.py","size":5057,"sha1":"bf0ac9f844a59f5289e771352e5e7445964caf78","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"#   __\n#  /__)  _  _     _   _ _/   _\n# / (   (- (/ (/ (- _)  /  _)\n#          /\n\n\"\"\"\nRequests HTTP Library\n~~~~~~~~~~~~~~~~~~~~~\n\nRequests is an HTTP library, written in Python, for human beings.\nBasic GET usage:\n\n   >>> import requests\n   >>> r = requests.get('https://www.python.org')\n   >>> r.status_code\n   200\n   >>> b'Python is a programming language' in r.content\n   True\n\n... or POST:\n\n   >>> payload = dict(key1='value1', key2='value2')\n   >>> r = requests.post('https://httpbin.org/post', data=payload)\n   >>> print(r.text)\n   {\n     ...\n     \"form\": {\n       \"key1\": \"value1\",\n       \"key2\": \"value2\"\n     },\n     ...\n   }\n\nThe other HTTP methods are supported - see `requests.api`. Full documentation\nis at <https://requests.readthedocs.io>.\n\n:copyright: (c) 2017 by Kenneth Reitz.\n:license: Apache 2.0, see LICENSE for more details.\n\"\"\"\n\nimport warnings\n\nfrom pip._vendor import urllib3\n\nfrom .exceptions import RequestsDependencyWarning\n\ncharset_normalizer_version = None\nchardet_version = None\n\n\ndef check_compatibility(urllib3_version, chardet_version, charset_normalizer_version):\n    urllib3_version = urllib3_version.split(\".\")\n    assert urllib3_version != [\"dev\"]  # Verify urllib3 isn't installed from git.\n\n    # Sometimes, urllib3 only reports its version as 16.1.\n    if len(urllib3_version) == 2:\n        urllib3_version.append(\"0\")\n\n    # Check urllib3 for compatibility.\n    major, minor, patch = urllib3_version  # noqa: F811\n    major, minor, patch = int(major), int(minor), int(patch)\n    # urllib3 >= 1.21.1\n    assert major >= 1\n    if major == 1:\n        assert minor >= 21\n\n    # Check charset_normalizer for compatibility.\n    if chardet_version:\n        major, minor, patch = chardet_version.split(\".\")[:3]\n        major, minor, patch = int(major), int(minor), int(patch)\n        # chardet_version >= 3.0.2, < 6.0.0\n        assert (3, 0, 2) <= (major, minor, patch) < (6, 0, 0)\n    elif charset_normalizer_version:\n        major, minor, patch = charset_normalizer_version.split(\".\")[:3]\n        major, minor, patch = int(major), int(minor), int(patch)\n        # charset_normalizer >= 2.0.0 < 4.0.0\n        assert (2, 0, 0) <= (major, minor, patch) < (4, 0, 0)\n    else:\n        # pip does not need or use character detection\n        pass\n\n\ndef _check_cryptography(cryptography_version):\n    # cryptography < 1.3.4\n    try:\n        cryptography_version = list(map(int, cryptography_version.split(\".\")))\n    except ValueError:\n        return\n\n    if cryptography_version < [1, 3, 4]:\n        warning = \"Old version of cryptography ({}) may cause slowdown.\".format(\n            cryptography_version\n        )\n        warnings.warn(warning, RequestsDependencyWarning)\n\n\n# Check imported dependencies for compatibility.\ntry:\n    check_compatibility(\n        urllib3.__version__, chardet_version, charset_normalizer_version\n    )\nexcept (AssertionError, ValueError):\n    warnings.warn(\n        \"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n        \"version!\".format(\n            urllib3.__version__, chardet_version, charset_normalizer_version\n        ),\n        RequestsDependencyWarning,\n    )\n\n# Attempt to enable urllib3's fallback for SNI support\n# if the standard library doesn't support SNI or the\n# 'ssl' library isn't available.\ntry:\n    # Note: This logic prevents upgrading cryptography on Windows, if imported\n    #       as part of pip.\n    from pip._internal.utils.compat import WINDOWS\n    if not WINDOWS:\n        raise ImportError(\"pip internals: don't import cryptography on Windows\")\n    try:\n        import ssl\n    except ImportError:\n        ssl = None\n\n    if not getattr(ssl, \"HAS_SNI\", False):\n        from pip._vendor.urllib3.contrib import pyopenssl\n\n        pyopenssl.inject_into_urllib3()\n\n        # Check cryptography version\n        from cryptography import __version__ as cryptography_version\n\n        _check_cryptography(cryptography_version)\nexcept ImportError:\n    pass\n\n# urllib3's DependencyWarnings should be silenced.\nfrom pip._vendor.urllib3.exceptions import DependencyWarning\n\nwarnings.simplefilter(\"ignore\", DependencyWarning)\n\n# Set default logging handler to avoid \"No handler found\" warnings.\nimport logging\nfrom logging import NullHandler\n\nfrom . import packages, utils\nfrom .__version__ import (\n    __author__,\n    __author_email__,\n    __build__,\n    __cake__,\n    __copyright__,\n    __description__,\n    __license__,\n    __title__,\n    __url__,\n    __version__,\n)\nfrom .api import delete, get, head, options, patch, post, put, request\nfrom .exceptions import (\n    ConnectionError,\n    ConnectTimeout,\n    FileModeWarning,\n    HTTPError,\n    JSONDecodeError,\n    ReadTimeout,\n    RequestException,\n    Timeout,\n    TooManyRedirects,\n    URLRequired,\n)\nfrom .models import PreparedRequest, Request, Response\nfrom .sessions import Session, session\nfrom .status_codes import codes\n\nlogging.getLogger(__name__).addHandler(NullHandler())\n\n# FileModeWarnings go off per the default.\nwarnings.simplefilter(\"default\", FileModeWarning, append=True)\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/requests/__version__.py","size":435,"sha1":"c4d5e1c3654e68dbef42e721f0b77cc6cdf50d75","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"# .-. .-. .-. . . .-. .-. .-. .-.\n# |(  |-  |.| | | |-  `-.  |  `-.\n# ' ' `-' `-`.`-' `-' `-'  '  `-'\n\n__title__ = \"requests\"\n__description__ = \"Python HTTP for Humans.\"\n__url__ = \"https://requests.readthedocs.io\"\n__version__ = \"2.32.3\"\n__build__ = 0x023203\n__author__ = \"Kenneth Reitz\"\n__author_email__ = \"me@kennethreitz.org\"\n__license__ = \"Apache-2.0\"\n__copyright__ = \"Copyright Kenneth Reitz\"\n__cake__ = \"\\u2728 \\U0001f370 \\u2728\"\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/requests/_internal_utils.py","size":1495,"sha1":"83a8612a7fe67477b5d61a8c4358d22d5b099f7e","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\nrequests._internal_utils\n~~~~~~~~~~~~~~\n\nProvides utility functions that are consumed internally by Requests\nwhich depend on extremely few external helpers (such as compat)\n\"\"\"\nimport re\n\nfrom .compat import builtin_str\n\n_VALID_HEADER_NAME_RE_BYTE = re.compile(rb\"^[^:\\s][^:\\r\\n]*$\")\n_VALID_HEADER_NAME_RE_STR = re.compile(r\"^[^:\\s][^:\\r\\n]*$\")\n_VALID_HEADER_VALUE_RE_BYTE = re.compile(rb\"^\\S[^\\r\\n]*$|^$\")\n_VALID_HEADER_VALUE_RE_STR = re.compile(r\"^\\S[^\\r\\n]*$|^$\")\n\n_HEADER_VALIDATORS_STR = (_VALID_HEADER_NAME_RE_STR, _VALID_HEADER_VALUE_RE_STR)\n_HEADER_VALIDATORS_BYTE = (_VALID_HEADER_NAME_RE_BYTE, _VALID_HEADER_VALUE_RE_BYTE)\nHEADER_VALIDATORS = {\n    bytes: _HEADER_VALIDATORS_BYTE,\n    str: _HEADER_VALIDATORS_STR,\n}\n\n\ndef to_native_string(string, encoding=\"ascii\"):\n    \"\"\"Given a string object, regardless of type, returns a representation of\n    that string in the native string type, encoding and decoding where\n    necessary. This assumes ASCII unless told otherwise.\n    \"\"\"\n    if isinstance(string, builtin_str):\n        out = string\n    else:\n        out = string.decode(encoding)\n\n    return out\n\n\ndef unicode_is_ascii(u_string):\n    \"\"\"Determine if unicode string only contains ASCII characters.\n\n    :param str u_string: unicode string to check. Must be unicode\n        and not Python 2 `str`.\n    :rtype: bool\n    \"\"\"\n    assert isinstance(u_string, str)\n    try:\n        u_string.encode(\"ascii\")\n        return True\n    except UnicodeEncodeError:\n        return False\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/requests/adapters.py","size":27607,"sha1":"1d9144b5df4978594c052edac5d2dd4601c1550d","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\nrequests.adapters\n~~~~~~~~~~~~~~~~~\n\nThis module contains the transport adapters that Requests uses to define\nand maintain connections.\n\"\"\"\n\nimport os.path\nimport socket  # noqa: F401\nimport typing\nimport warnings\n\nfrom pip._vendor.urllib3.exceptions import ClosedPoolError, ConnectTimeoutError\nfrom pip._vendor.urllib3.exceptions import HTTPError as _HTTPError\nfrom pip._vendor.urllib3.exceptions import InvalidHeader as _InvalidHeader\nfrom pip._vendor.urllib3.exceptions import (\n    LocationValueError,\n    MaxRetryError,\n    NewConnectionError,\n    ProtocolError,\n)\nfrom pip._vendor.urllib3.exceptions import ProxyError as _ProxyError\nfrom pip._vendor.urllib3.exceptions import ReadTimeoutError, ResponseError\nfrom pip._vendor.urllib3.exceptions import SSLError as _SSLError\nfrom pip._vendor.urllib3.poolmanager import PoolManager, proxy_from_url\nfrom pip._vendor.urllib3.util import Timeout as TimeoutSauce\nfrom pip._vendor.urllib3.util import parse_url\nfrom pip._vendor.urllib3.util.retry import Retry\nfrom pip._vendor.urllib3.util.ssl_ import create_urllib3_context\n\nfrom .auth import _basic_auth_str\nfrom .compat import basestring, urlparse\nfrom .cookies import extract_cookies_to_jar\nfrom .exceptions import (\n    ConnectionError,\n    ConnectTimeout,\n    InvalidHeader,\n    InvalidProxyURL,\n    InvalidSchema,\n    InvalidURL,\n    ProxyError,\n    ReadTimeout,\n    RetryError,\n    SSLError,\n)\nfrom .models import Response\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (\n    DEFAULT_CA_BUNDLE_PATH,\n    extract_zipped_paths,\n    get_auth_from_url,\n    get_encoding_from_headers,\n    prepend_scheme_if_needed,\n    select_proxy,\n    urldefragauth,\n)\n\ntry:\n    from pip._vendor.urllib3.contrib.socks import SOCKSProxyManager\nexcept ImportError:\n\n    def SOCKSProxyManager(*args, **kwargs):\n        raise InvalidSchema(\"Missing dependencies for SOCKS support.\")\n\n\nif typing.TYPE_CHECKING:\n    from .models import PreparedRequest\n\n\nDEFAULT_POOLBLOCK = False\nDEFAULT_POOLSIZE = 10\nDEFAULT_RETRIES = 0\nDEFAULT_POOL_TIMEOUT = None\n\n\ntry:\n    import ssl  # noqa: F401\n\n    _preloaded_ssl_context = create_urllib3_context()\n    _preloaded_ssl_context.load_verify_locations(\n        extract_zipped_paths(DEFAULT_CA_BUNDLE_PATH)\n    )\nexcept ImportError:\n    # Bypass default SSLContext creation when Python\n    # interpreter isn't built with the ssl module.\n    _preloaded_ssl_context = None\n\n\ndef _urllib3_request_context(\n    request: \"PreparedRequest\",\n    verify: \"bool | str | None\",\n    client_cert: \"typing.Tuple[str, str] | str | None\",\n    poolmanager: \"PoolManager\",\n) -> \"(typing.Dict[str, typing.Any], typing.Dict[str, typing.Any])\":\n    host_params = {}\n    pool_kwargs = {}\n    parsed_request_url = urlparse(request.url)\n    scheme = parsed_request_url.scheme.lower()\n    port = parsed_request_url.port\n\n    # Determine if we have and should use our default SSLContext\n    # to optimize performance on standard requests.\n    poolmanager_kwargs = getattr(poolmanager, \"connection_pool_kw\", {})\n    has_poolmanager_ssl_context = poolmanager_kwargs.get(\"ssl_context\")\n    should_use_default_ssl_context = (\n        _preloaded_ssl_context is not None and not has_poolmanager_ssl_context\n    )\n\n    cert_reqs = \"CERT_REQUIRED\"\n    if verify is False:\n        cert_reqs = \"CERT_NONE\"\n    elif verify is True and should_use_default_ssl_context:\n        pool_kwargs[\"ssl_context\"] = _preloaded_ssl_context\n    elif isinstance(verify, str):\n        if not os.path.isdir(verify):\n            pool_kwargs[\"ca_certs\"] = verify\n        else:\n            pool_kwargs[\"ca_cert_dir\"] = verify\n    pool_kwargs[\"cert_reqs\"] = cert_reqs\n    if client_cert is not None:\n        if isinstance(client_cert, tuple) and len(client_cert) == 2:\n            pool_kwargs[\"cert_file\"] = client_cert[0]\n            pool_kwargs[\"key_file\"] = client_cert[1]\n        else:\n            # According to our docs, we allow users to specify just the client\n            # cert path\n            pool_kwargs[\"cert_file\"] = client_cert\n    host_params = {\n        \"scheme\": scheme,\n        \"host\": parsed_request_url.hostname,\n        \"port\": port,\n    }\n    return host_params, pool_kwargs\n\n\nclass BaseAdapter:\n    \"\"\"The Base Transport Adapter\"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple\n        :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        \"\"\"\n        raise NotImplementedError\n\n    def close(self):\n        \"\"\"Cleans up adapter specific items.\"\"\"\n        raise NotImplementedError\n\n\nclass HTTPAdapter(BaseAdapter):\n    \"\"\"The built-in HTTP Adapter for urllib3.\n\n    Provides a general-case interface for Requests sessions to contact HTTP and\n    HTTPS urls by implementing the Transport Adapter interface. This class will\n    usually be created by the :class:`Session <Session>` class under the\n    covers.\n\n    :param pool_connections: The number of urllib3 connection pools to cache.\n    :param pool_maxsize: The maximum number of connections to save in the pool.\n    :param max_retries: The maximum number of retries each connection\n        should attempt. Note, this applies only to failed DNS lookups, socket\n        connections and connection timeouts, never to requests where data has\n        made it to the server. By default, Requests does not retry failed\n        connections. If you need granular control over the conditions under\n        which we retry a request, import urllib3's ``Retry`` class and pass\n        that instead.\n    :param pool_block: Whether the connection pool should block for connections.\n\n    Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> a = requests.adapters.HTTPAdapter(max_retries=3)\n      >>> s.mount('http://', a)\n    \"\"\"\n\n    __attrs__ = [\n        \"max_retries\",\n        \"config\",\n        \"_pool_connections\",\n        \"_pool_maxsize\",\n        \"_pool_block\",\n    ]\n\n    def __init__(\n        self,\n        pool_connections=DEFAULT_POOLSIZE,\n        pool_maxsize=DEFAULT_POOLSIZE,\n        max_retries=DEFAULT_RETRIES,\n        pool_block=DEFAULT_POOLBLOCK,\n    ):\n        if max_retries == DEFAULT_RETRIES:\n            self.max_retries = Retry(0, read=False)\n        else:\n            self.max_retries = Retry.from_int(max_retries)\n        self.config = {}\n        self.proxy_manager = {}\n\n        super().__init__()\n\n        self._pool_connections = pool_connections\n        self._pool_maxsize = pool_maxsize\n        self._pool_block = pool_block\n\n        self.init_poolmanager(pool_connections, pool_maxsize, block=pool_block)\n\n    def __getstate__(self):\n        return {attr: getattr(self, attr, None) for attr in self.__attrs__}\n\n    def __setstate__(self, state):\n        # Can't handle by adding 'proxy_manager' to self.__attrs__ because\n        # self.poolmanager uses a lambda function, which isn't pickleable.\n        self.proxy_manager = {}\n        self.config = {}\n\n        for attr, value in state.items():\n            setattr(self, attr, value)\n\n        self.init_poolmanager(\n            self._pool_connections, self._pool_maxsize, block=self._pool_block\n        )\n\n    def init_poolmanager(\n        self, connections, maxsize, block=DEFAULT_POOLBLOCK, **pool_kwargs\n    ):\n        \"\"\"Initializes a urllib3 PoolManager.\n\n        This method should not be called from user code, and is only\n        exposed for use when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param connections: The number of urllib3 connection pools to cache.\n        :param maxsize: The maximum number of connections to save in the pool.\n        :param block: Block when no free connections are available.\n        :param pool_kwargs: Extra keyword arguments used to initialize the Pool Manager.\n        \"\"\"\n        # save these values for pickling\n        self._pool_connections = connections\n        self._pool_maxsize = maxsize\n        self._pool_block = block\n\n        self.poolmanager = PoolManager(\n            num_pools=connections,\n            maxsize=maxsize,\n            block=block,\n            **pool_kwargs,\n        )\n\n    def proxy_manager_for(self, proxy, **proxy_kwargs):\n        \"\"\"Return urllib3 ProxyManager for the given proxy.\n\n        This method should not be called from user code, and is only\n        exposed for use when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param proxy: The proxy to return a urllib3 ProxyManager for.\n        :param proxy_kwargs: Extra keyword arguments used to configure the Proxy Manager.\n        :returns: ProxyManager\n        :rtype: urllib3.ProxyManager\n        \"\"\"\n        if proxy in self.proxy_manager:\n            manager = self.proxy_manager[proxy]\n        elif proxy.lower().startswith(\"socks\"):\n            username, password = get_auth_from_url(proxy)\n            manager = self.proxy_manager[proxy] = SOCKSProxyManager(\n                proxy,\n                username=username,\n                password=password,\n                num_pools=self._pool_connections,\n                maxsize=self._pool_maxsize,\n                block=self._pool_block,\n                **proxy_kwargs,\n            )\n        else:\n            proxy_headers = self.proxy_headers(proxy)\n            manager = self.proxy_manager[proxy] = proxy_from_url(\n                proxy,\n                proxy_headers=proxy_headers,\n                num_pools=self._pool_connections,\n                maxsize=self._pool_maxsize,\n                block=self._pool_block,\n                **proxy_kwargs,\n            )\n\n        return manager\n\n    def cert_verify(self, conn, url, verify, cert):\n        \"\"\"Verify a SSL certificate. This method should not be called from user\n        code, and is only exposed for use when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param conn: The urllib3 connection object associated with the cert.\n        :param url: The requested URL.\n        :param verify: Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use\n        :param cert: The SSL certificate to verify.\n        \"\"\"\n        if url.lower().startswith(\"https\") and verify:\n            conn.cert_reqs = \"CERT_REQUIRED\"\n\n            # Only load the CA certificates if 'verify' is a string indicating the CA bundle to use.\n            # Otherwise, if verify is a boolean, we don't load anything since\n            # the connection will be using a context with the default certificates already loaded,\n            # and this avoids a call to the slow load_verify_locations()\n            if verify is not True:\n                # `verify` must be a str with a path then\n                cert_loc = verify\n\n                if not os.path.exists(cert_loc):\n                    raise OSError(\n                        f\"Could not find a suitable TLS CA certificate bundle, \"\n                        f\"invalid path: {cert_loc}\"\n                    )\n\n                if not os.path.isdir(cert_loc):\n                    conn.ca_certs = cert_loc\n                else:\n                    conn.ca_cert_dir = cert_loc\n        else:\n            conn.cert_reqs = \"CERT_NONE\"\n            conn.ca_certs = None\n            conn.ca_cert_dir = None\n\n        if cert:\n            if not isinstance(cert, basestring):\n                conn.cert_file = cert[0]\n                conn.key_file = cert[1]\n            else:\n                conn.cert_file = cert\n                conn.key_file = None\n            if conn.cert_file and not os.path.exists(conn.cert_file):\n                raise OSError(\n                    f\"Could not find the TLS certificate file, \"\n                    f\"invalid path: {conn.cert_file}\"\n                )\n            if conn.key_file and not os.path.exists(conn.key_file):\n                raise OSError(\n                    f\"Could not find the TLS key file, invalid path: {conn.key_file}\"\n                )\n\n    def build_response(self, req, resp):\n        \"\"\"Builds a :class:`Response <requests.Response>` object from a urllib3\n        response. This should not be called from user code, and is only exposed\n        for use when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`\n\n        :param req: The :class:`PreparedRequest <PreparedRequest>` used to generate the response.\n        :param resp: The urllib3 response object.\n        :rtype: requests.Response\n        \"\"\"\n        response = Response()\n\n        # Fallback to None if there's no status_code, for whatever reason.\n        response.status_code = getattr(resp, \"status\", None)\n\n        # Make headers case-insensitive.\n        response.headers = CaseInsensitiveDict(getattr(resp, \"headers\", {}))\n\n        # Set encoding.\n        response.encoding = get_encoding_from_headers(response.headers)\n        response.raw = resp\n        response.reason = response.raw.reason\n\n        if isinstance(req.url, bytes):\n            response.url = req.url.decode(\"utf-8\")\n        else:\n            response.url = req.url\n\n        # Add new cookies from the server.\n        extract_cookies_to_jar(response.cookies, req, resp)\n\n        # Give the Response some context.\n        response.request = req\n        response.connection = self\n\n        return response\n\n    def build_connection_pool_key_attributes(self, request, verify, cert=None):\n        \"\"\"Build the PoolKey attributes used by urllib3 to return a connection.\n\n        This looks at the PreparedRequest, the user-specified verify value,\n        and the value of the cert parameter to determine what PoolKey values\n        to use to select a connection from a given urllib3 Connection Pool.\n\n        The SSL related pool key arguments are not consistently set. As of\n        this writing, use the following to determine what keys may be in that\n        dictionary:\n\n        * If ``verify`` is ``True``, ``\"ssl_context\"`` will be set and will be the\n          default Requests SSL Context\n        * If ``verify`` is ``False``, ``\"ssl_context\"`` will not be set but\n          ``\"cert_reqs\"`` will be set\n        * If ``verify`` is a string, (i.e., it is a user-specified trust bundle)\n          ``\"ca_certs\"`` will be set if the string is not a directory recognized\n          by :py:func:`os.path.isdir`, otherwise ``\"ca_certs_dir\"`` will be\n          set.\n        * If ``\"cert\"`` is specified, ``\"cert_file\"`` will always be set. If\n          ``\"cert\"`` is a tuple with a second item, ``\"key_file\"`` will also\n          be present\n\n        To override these settings, one may subclass this class, call this\n        method and use the above logic to change parameters as desired. For\n        example, if one wishes to use a custom :py:class:`ssl.SSLContext` one\n        must both set ``\"ssl_context\"`` and based on what else they require,\n        alter the other keys to ensure the desired behaviour.\n\n        :param request:\n            The PreparedReqest being sent over the connection.\n        :type request:\n            :class:`~requests.models.PreparedRequest`\n        :param verify:\n            Either a boolean, in which case it controls whether\n            we verify the server's TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use.\n        :param cert:\n            (optional) Any user-provided SSL certificate for client\n            authentication (a.k.a., mTLS). This may be a string (i.e., just\n            the path to a file which holds both certificate and key) or a\n            tuple of length 2 with the certificate file path and key file\n            path.\n        :returns:\n            A tuple of two dictionaries. The first is the \"host parameters\"\n            portion of the Pool Key including scheme, hostname, and port. The\n            second is a dictionary of SSLContext related parameters.\n        \"\"\"\n        return _urllib3_request_context(request, verify, cert, self.poolmanager)\n\n    def get_connection_with_tls_context(self, request, verify, proxies=None, cert=None):\n        \"\"\"Returns a urllib3 connection for the given request and TLS settings.\n        This should not be called from user code, and is only exposed for use\n        when subclassing the :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param request:\n            The :class:`PreparedRequest <PreparedRequest>` object to be sent\n            over the connection.\n        :param verify:\n            Either a boolean, in which case it controls whether we verify the\n            server's TLS certificate, or a string, in which case it must be a\n            path to a CA bundle to use.\n        :param proxies:\n            (optional) The proxies dictionary to apply to the request.\n        :param cert:\n            (optional) Any user-provided SSL certificate to be used for client\n            authentication (a.k.a., mTLS).\n        :rtype:\n            urllib3.ConnectionPool\n        \"\"\"\n        proxy = select_proxy(request.url, proxies)\n        try:\n            host_params, pool_kwargs = self.build_connection_pool_key_attributes(\n                request,\n                verify,\n                cert,\n            )\n        except ValueError as e:\n            raise InvalidURL(e, request=request)\n        if proxy:\n            proxy = prepend_scheme_if_needed(proxy, \"http\")\n            proxy_url = parse_url(proxy)\n            if not proxy_url.host:\n                raise InvalidProxyURL(\n                    \"Please check proxy URL. It is malformed \"\n                    \"and could be missing the host.\"\n                )\n            proxy_manager = self.proxy_manager_for(proxy)\n            conn = proxy_manager.connection_from_host(\n                **host_params, pool_kwargs=pool_kwargs\n            )\n        else:\n            # Only scheme should be lower case\n            conn = self.poolmanager.connection_from_host(\n                **host_params, pool_kwargs=pool_kwargs\n            )\n\n        return conn\n\n    def get_connection(self, url, proxies=None):\n        \"\"\"DEPRECATED: Users should move to `get_connection_with_tls_context`\n        for all subclasses of HTTPAdapter using Requests>=2.32.2.\n\n        Returns a urllib3 connection for the given URL. This should not be\n        called from user code, and is only exposed for use when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param url: The URL to connect to.\n        :param proxies: (optional) A Requests-style dictionary of proxies used on this request.\n        :rtype: urllib3.ConnectionPool\n        \"\"\"\n        warnings.warn(\n            (\n                \"`get_connection` has been deprecated in favor of \"\n                \"`get_connection_with_tls_context`. Custom HTTPAdapter subclasses \"\n                \"will need to migrate for Requests>=2.32.2. Please see \"\n                \"https://github.com/psf/requests/pull/6710 for more details.\"\n            ),\n            DeprecationWarning,\n        )\n        proxy = select_proxy(url, proxies)\n\n        if proxy:\n            proxy = prepend_scheme_if_needed(proxy, \"http\")\n            proxy_url = parse_url(proxy)\n            if not proxy_url.host:\n                raise InvalidProxyURL(\n                    \"Please check proxy URL. It is malformed \"\n                    \"and could be missing the host.\"\n                )\n            proxy_manager = self.proxy_manager_for(proxy)\n            conn = proxy_manager.connection_from_url(url)\n        else:\n            # Only scheme should be lower case\n            parsed = urlparse(url)\n            url = parsed.geturl()\n            conn = self.poolmanager.connection_from_url(url)\n\n        return conn\n\n    def close(self):\n        \"\"\"Disposes of any internal state.\n\n        Currently, this closes the PoolManager and any active ProxyManager,\n        which closes any pooled connections.\n        \"\"\"\n        self.poolmanager.clear()\n        for proxy in self.proxy_manager.values():\n            proxy.clear()\n\n    def request_url(self, request, proxies):\n        \"\"\"Obtain the url to use when making the final request.\n\n        If the message is being sent through a HTTP proxy, the full URL has to\n        be used. Otherwise, we should only use the path portion of the URL.\n\n        This should not be called from user code, and is only exposed for use\n        when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs.\n        :rtype: str\n        \"\"\"\n        proxy = select_proxy(request.url, proxies)\n        scheme = urlparse(request.url).scheme\n\n        is_proxied_http_request = proxy and scheme != \"https\"\n        using_socks_proxy = False\n        if proxy:\n            proxy_scheme = urlparse(proxy).scheme.lower()\n            using_socks_proxy = proxy_scheme.startswith(\"socks\")\n\n        url = request.path_url\n        if url.startswith(\"//\"):  # Don't confuse urllib3\n            url = f\"/{url.lstrip('/')}\"\n\n        if is_proxied_http_request and not using_socks_proxy:\n            url = urldefragauth(request.url)\n\n        return url\n\n    def add_headers(self, request, **kwargs):\n        \"\"\"Add any headers needed by the connection. As of v2.0 this does\n        nothing by default, but is left for overriding by users that subclass\n        the :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        This should not be called from user code, and is only exposed for use\n        when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` to add headers to.\n        :param kwargs: The keyword arguments from the call to send().\n        \"\"\"\n        pass\n\n    def proxy_headers(self, proxy):\n        \"\"\"Returns a dictionary of the headers to add to any request sent\n        through a proxy. This works with urllib3 magic to ensure that they are\n        correctly sent to the proxy, rather than in a tunnelled request if\n        CONNECT is being used.\n\n        This should not be called from user code, and is only exposed for use\n        when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param proxy: The url of the proxy being used for this request.\n        :rtype: dict\n        \"\"\"\n        headers = {}\n        username, password = get_auth_from_url(proxy)\n\n        if username:\n            headers[\"Proxy-Authorization\"] = _basic_auth_str(username, password)\n\n        return headers\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server's TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        :rtype: requests.Response\n        \"\"\"\n\n        try:\n            conn = self.get_connection_with_tls_context(\n                request, verify, proxies=proxies, cert=cert\n            )\n        except LocationValueError as e:\n            raise InvalidURL(e, request=request)\n\n        self.cert_verify(conn, request.url, verify, cert)\n        url = self.request_url(request, proxies)\n        self.add_headers(\n            request,\n            stream=stream,\n            timeout=timeout,\n            verify=verify,\n            cert=cert,\n            proxies=proxies,\n        )\n\n        chunked = not (request.body is None or \"Content-Length\" in request.headers)\n\n        if isinstance(timeout, tuple):\n            try:\n                connect, read = timeout\n                timeout = TimeoutSauce(connect=connect, read=read)\n            except ValueError:\n                raise ValueError(\n                    f\"Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, \"\n                    f\"or a single float to set both timeouts to the same value.\"\n                )\n        elif isinstance(timeout, TimeoutSauce):\n            pass\n        else:\n            timeout = TimeoutSauce(connect=timeout, read=timeout)\n\n        try:\n            resp = conn.urlopen(\n                method=request.method,\n                url=url,\n                body=request.body,\n                headers=request.headers,\n                redirect=False,\n                assert_same_host=False,\n                preload_content=False,\n                decode_content=False,\n                retries=self.max_retries,\n                timeout=timeout,\n                chunked=chunked,\n            )\n\n        except (ProtocolError, OSError) as err:\n            raise ConnectionError(err, request=request)\n\n        except MaxRetryError as e:\n            if isinstance(e.reason, ConnectTimeoutError):\n                # TODO: Remove this in 3.0.0: see #2811\n                if not isinstance(e.reason, NewConnectionError):\n                    raise ConnectTimeout(e, request=request)\n\n            if isinstance(e.reason, ResponseError):\n                raise RetryError(e, request=request)\n\n            if isinstance(e.reason, _ProxyError):\n                raise ProxyError(e, request=request)\n\n            if isinstance(e.reason, _SSLError):\n                # This branch is for urllib3 v1.22 and later.\n                raise SSLError(e, request=request)\n\n            raise ConnectionError(e, request=request)\n\n        except ClosedPoolError as e:\n            raise ConnectionError(e, request=request)\n\n        except _ProxyError as e:\n            raise ProxyError(e)\n\n        except (_SSLError, _HTTPError) as e:\n            if isinstance(e, _SSLError):\n                # This branch is for urllib3 versions earlier than v1.22\n                raise SSLError(e, request=request)\n            elif isinstance(e, ReadTimeoutError):\n                raise ReadTimeout(e, request=request)\n            elif isinstance(e, _InvalidHeader):\n                raise InvalidHeader(e, request=request)\n            else:\n                raise\n\n        return self.build_response(request, resp)\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/requests/api.py","size":6449,"sha1":"e2acc6d4ace747f71ed20a4135f6664a93bcd2fa","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\nrequests.api\n~~~~~~~~~~~~\n\nThis module implements the Requests API.\n\n:copyright: (c) 2012 by Kenneth Reitz.\n:license: Apache2, see LICENSE for more details.\n\"\"\"\n\nfrom . import sessions\n\n\ndef request(method, url, **kwargs):\n    \"\"\"Constructs and sends a :class:`Request <Request>`.\n\n    :param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.\n    :param url: URL for the new :class:`Request` object.\n    :param params: (optional) Dictionary, list of tuples or bytes to send\n        in the query string for the :class:`Request`.\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n        object to send in the body of the :class:`Request`.\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n    :param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.\n    :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.\n    :param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.\n        ``file-tuple`` can be a 2-tuple ``('filename', fileobj)``, 3-tuple ``('filename', fileobj, 'content_type')``\n        or a 4-tuple ``('filename', fileobj, 'content_type', custom_headers)``, where ``'content_type'`` is a string\n        defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers\n        to add for the file.\n    :param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.\n    :param timeout: (optional) How many seconds to wait for the server to send data\n        before giving up, as a float, or a :ref:`(connect timeout, read\n        timeout) <timeouts>` tuple.\n    :type timeout: float or tuple\n    :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``.\n    :type allow_redirects: bool\n    :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.\n    :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use. Defaults to ``True``.\n    :param stream: (optional) if ``False``, the response content will be immediately downloaded.\n    :param cert: (optional) if String, path to ssl client cert file (.pem). If Tuple, ('cert', 'key') pair.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n\n    Usage::\n\n      >>> import requests\n      >>> req = requests.request('GET', 'https://httpbin.org/get')\n      >>> req\n      <Response [200]>\n    \"\"\"\n\n    # By using the 'with' statement we are sure the session is closed, thus we\n    # avoid leaving sockets open which can trigger a ResourceWarning in some\n    # cases, and look like a memory leak in others.\n    with sessions.Session() as session:\n        return session.request(method=method, url=url, **kwargs)\n\n\ndef get(url, params=None, **kwargs):\n    r\"\"\"Sends a GET request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param params: (optional) Dictionary, list of tuples or bytes to send\n        in the query string for the :class:`Request`.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"get\", url, params=params, **kwargs)\n\n\ndef options(url, **kwargs):\n    r\"\"\"Sends an OPTIONS request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"options\", url, **kwargs)\n\n\ndef head(url, **kwargs):\n    r\"\"\"Sends a HEAD request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes. If\n        `allow_redirects` is not provided, it will be set to `False` (as\n        opposed to the default :meth:`request` behavior).\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    kwargs.setdefault(\"allow_redirects\", False)\n    return request(\"head\", url, **kwargs)\n\n\ndef post(url, data=None, json=None, **kwargs):\n    r\"\"\"Sends a POST request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n        object to send in the body of the :class:`Request`.\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"post\", url, data=data, json=json, **kwargs)\n\n\ndef put(url, data=None, **kwargs):\n    r\"\"\"Sends a PUT request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n        object to send in the body of the :class:`Request`.\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"put\", url, data=data, **kwargs)\n\n\ndef patch(url, data=None, **kwargs):\n    r\"\"\"Sends a PATCH request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n        object to send in the body of the :class:`Request`.\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"patch\", url, data=data, **kwargs)\n\n\ndef delete(url, **kwargs):\n    r\"\"\"Sends a DELETE request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"delete\", url, **kwargs)\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/requests/auth.py","size":10186,"sha1":"bd96146ba4180f816dbd9c693f0b11ecc21ee214","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\nrequests.auth\n~~~~~~~~~~~~~\n\nThis module contains the authentication handlers for Requests.\n\"\"\"\n\nimport hashlib\nimport os\nimport re\nimport threading\nimport time\nimport warnings\nfrom base64 import b64encode\n\nfrom ._internal_utils import to_native_string\nfrom .compat import basestring, str, urlparse\nfrom .cookies import extract_cookies_to_jar\nfrom .utils import parse_dict_header\n\nCONTENT_TYPE_FORM_URLENCODED = \"application/x-www-form-urlencoded\"\nCONTENT_TYPE_MULTI_PART = \"multipart/form-data\"\n\n\ndef _basic_auth_str(username, password):\n    \"\"\"Returns a Basic Auth string.\"\"\"\n\n    # \"I want us to put a big-ol' comment on top of it that\n    # says that this behaviour is dumb but we need to preserve\n    # it because people are relying on it.\"\n    #    - Lukasa\n    #\n    # These are here solely to maintain backwards compatibility\n    # for things like ints. This will be removed in 3.0.0.\n    if not isinstance(username, basestring):\n        warnings.warn(\n            \"Non-string usernames will no longer be supported in Requests \"\n            \"3.0.0. Please convert the object you've passed in ({!r}) to \"\n            \"a string or bytes object in the near future to avoid \"\n            \"problems.\".format(username),\n            category=DeprecationWarning,\n        )\n        username = str(username)\n\n    if not isinstance(password, basestring):\n        warnings.warn(\n            \"Non-string passwords will no longer be supported in Requests \"\n            \"3.0.0. Please convert the object you've passed in ({!r}) to \"\n            \"a string or bytes object in the near future to avoid \"\n            \"problems.\".format(type(password)),\n            category=DeprecationWarning,\n        )\n        password = str(password)\n    # -- End Removal --\n\n    if isinstance(username, str):\n        username = username.encode(\"latin1\")\n\n    if isinstance(password, str):\n        password = password.encode(\"latin1\")\n\n    authstr = \"Basic \" + to_native_string(\n        b64encode(b\":\".join((username, password))).strip()\n    )\n\n    return authstr\n\n\nclass AuthBase:\n    \"\"\"Base class that all auth implementations derive from\"\"\"\n\n    def __call__(self, r):\n        raise NotImplementedError(\"Auth hooks must be callable.\")\n\n\nclass HTTPBasicAuth(AuthBase):\n    \"\"\"Attaches HTTP Basic Authentication to the given Request object.\"\"\"\n\n    def __init__(self, username, password):\n        self.username = username\n        self.password = password\n\n    def __eq__(self, other):\n        return all(\n            [\n                self.username == getattr(other, \"username\", None),\n                self.password == getattr(other, \"password\", None),\n            ]\n        )\n\n    def __ne__(self, other):\n        return not self == other\n\n    def __call__(self, r):\n        r.headers[\"Authorization\"] = _basic_auth_str(self.username, self.password)\n        return r\n\n\nclass HTTPProxyAuth(HTTPBasicAuth):\n    \"\"\"Attaches HTTP Proxy Authentication to a given Request object.\"\"\"\n\n    def __call__(self, r):\n        r.headers[\"Proxy-Authorization\"] = _basic_auth_str(self.username, self.password)\n        return r\n\n\nclass HTTPDigestAuth(AuthBase):\n    \"\"\"Attaches HTTP Digest Authentication to the given Request object.\"\"\"\n\n    def __init__(self, username, password):\n        self.username = username\n        self.password = password\n        # Keep state in per-thread local storage\n        self._thread_local = threading.local()\n\n    def init_per_thread_state(self):\n        # Ensure state is initialized just once per-thread\n        if not hasattr(self._thread_local, \"init\"):\n            self._thread_local.init = True\n            self._thread_local.last_nonce = \"\"\n            self._thread_local.nonce_count = 0\n            self._thread_local.chal = {}\n            self._thread_local.pos = None\n            self._thread_local.num_401_calls = None\n\n    def build_digest_header(self, method, url):\n        \"\"\"\n        :rtype: str\n        \"\"\"\n\n        realm = self._thread_local.chal[\"realm\"]\n        nonce = self._thread_local.chal[\"nonce\"]\n        qop = self._thread_local.chal.get(\"qop\")\n        algorithm = self._thread_local.chal.get(\"algorithm\")\n        opaque = self._thread_local.chal.get(\"opaque\")\n        hash_utf8 = None\n\n        if algorithm is None:\n            _algorithm = \"MD5\"\n        else:\n            _algorithm = algorithm.upper()\n        # lambdas assume digest modules are imported at the top level\n        if _algorithm == \"MD5\" or _algorithm == \"MD5-SESS\":\n\n            def md5_utf8(x):\n                if isinstance(x, str):\n                    x = x.encode(\"utf-8\")\n                return hashlib.md5(x).hexdigest()\n\n            hash_utf8 = md5_utf8\n        elif _algorithm == \"SHA\":\n\n            def sha_utf8(x):\n                if isinstance(x, str):\n                    x = x.encode(\"utf-8\")\n                return hashlib.sha1(x).hexdigest()\n\n            hash_utf8 = sha_utf8\n        elif _algorithm == \"SHA-256\":\n\n            def sha256_utf8(x):\n                if isinstance(x, str):\n                    x = x.encode(\"utf-8\")\n                return hashlib.sha256(x).hexdigest()\n\n            hash_utf8 = sha256_utf8\n        elif _algorithm == \"SHA-512\":\n\n            def sha512_utf8(x):\n                if isinstance(x, str):\n                    x = x.encode(\"utf-8\")\n                return hashlib.sha512(x).hexdigest()\n\n            hash_utf8 = sha512_utf8\n\n        KD = lambda s, d: hash_utf8(f\"{s}:{d}\")  # noqa:E731\n\n        if hash_utf8 is None:\n            return None\n\n        # XXX not implemented yet\n        entdig = None\n        p_parsed = urlparse(url)\n        #: path is request-uri defined in RFC 2616 which should not be empty\n        path = p_parsed.path or \"/\"\n        if p_parsed.query:\n            path += f\"?{p_parsed.query}\"\n\n        A1 = f\"{self.username}:{realm}:{self.password}\"\n        A2 = f\"{method}:{path}\"\n\n        HA1 = hash_utf8(A1)\n        HA2 = hash_utf8(A2)\n\n        if nonce == self._thread_local.last_nonce:\n            self._thread_local.nonce_count += 1\n        else:\n            self._thread_local.nonce_count = 1\n        ncvalue = f\"{self._thread_local.nonce_count:08x}\"\n        s = str(self._thread_local.nonce_count).encode(\"utf-8\")\n        s += nonce.encode(\"utf-8\")\n        s += time.ctime().encode(\"utf-8\")\n        s += os.urandom(8)\n\n        cnonce = hashlib.sha1(s).hexdigest()[:16]\n        if _algorithm == \"MD5-SESS\":\n            HA1 = hash_utf8(f\"{HA1}:{nonce}:{cnonce}\")\n\n        if not qop:\n            respdig = KD(HA1, f\"{nonce}:{HA2}\")\n        elif qop == \"auth\" or \"auth\" in qop.split(\",\"):\n            noncebit = f\"{nonce}:{ncvalue}:{cnonce}:auth:{HA2}\"\n            respdig = KD(HA1, noncebit)\n        else:\n            # XXX handle auth-int.\n            return None\n\n        self._thread_local.last_nonce = nonce\n\n        # XXX should the partial digests be encoded too?\n        base = (\n            f'username=\"{self.username}\", realm=\"{realm}\", nonce=\"{nonce}\", '\n            f'uri=\"{path}\", response=\"{respdig}\"'\n        )\n        if opaque:\n            base += f', opaque=\"{opaque}\"'\n        if algorithm:\n            base += f', algorithm=\"{algorithm}\"'\n        if entdig:\n            base += f', digest=\"{entdig}\"'\n        if qop:\n            base += f', qop=\"auth\", nc={ncvalue}, cnonce=\"{cnonce}\"'\n\n        return f\"Digest {base}\"\n\n    def handle_redirect(self, r, **kwargs):\n        \"\"\"Reset num_401_calls counter on redirects.\"\"\"\n        if r.is_redirect:\n            self._thread_local.num_401_calls = 1\n\n    def handle_401(self, r, **kwargs):\n        \"\"\"\n        Takes the given response and tries digest-auth, if needed.\n\n        :rtype: requests.Response\n        \"\"\"\n\n        # If response is not 4xx, do not auth\n        # See https://github.com/psf/requests/issues/3772\n        if not 400 <= r.status_code < 500:\n            self._thread_local.num_401_calls = 1\n            return r\n\n        if self._thread_local.pos is not None:\n            # Rewind the file position indicator of the body to where\n            # it was to resend the request.\n            r.request.body.seek(self._thread_local.pos)\n        s_auth = r.headers.get(\"www-authenticate\", \"\")\n\n        if \"digest\" in s_auth.lower() and self._thread_local.num_401_calls < 2:\n            self._thread_local.num_401_calls += 1\n            pat = re.compile(r\"digest \", flags=re.IGNORECASE)\n            self._thread_local.chal = parse_dict_header(pat.sub(\"\", s_auth, count=1))\n\n            # Consume content and release the original connection\n            # to allow our new request to reuse the same one.\n            r.content\n            r.close()\n            prep = r.request.copy()\n            extract_cookies_to_jar(prep._cookies, r.request, r.raw)\n            prep.prepare_cookies(prep._cookies)\n\n            prep.headers[\"Authorization\"] = self.build_digest_header(\n                prep.method, prep.url\n            )\n            _r = r.connection.send(prep, **kwargs)\n            _r.history.append(r)\n            _r.request = prep\n\n            return _r\n\n        self._thread_local.num_401_calls = 1\n        return r\n\n    def __call__(self, r):\n        # Initialize per-thread state, if needed\n        self.init_per_thread_state()\n        # If we have a saved nonce, skip the 401\n        if self._thread_local.last_nonce:\n            r.headers[\"Authorization\"] = self.build_digest_header(r.method, r.url)\n        try:\n            self._thread_local.pos = r.body.tell()\n        except AttributeError:\n            # In the case of HTTPDigestAuth being reused and the body of\n            # the previous request was a file-like object, pos has the\n            # file position of the previous body. Ensure it's set to\n            # None.\n            self._thread_local.pos = None\n        r.register_hook(\"response\", self.handle_401)\n        r.register_hook(\"response\", self.handle_redirect)\n        self._thread_local.num_401_calls = 1\n\n        return r\n\n    def __eq__(self, other):\n        return all(\n            [\n                self.username == getattr(other, \"username\", None),\n                self.password == getattr(other, \"password\", None),\n            ]\n        )\n\n    def __ne__(self, other):\n        return not self == other\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/requests/certs.py","size":441,"sha1":"21c177768e833e681383df7caec530ac11bc0ba4","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"#!/usr/bin/env python\n\n\"\"\"\nrequests.certs\n~~~~~~~~~~~~~~\n\nThis module returns the preferred default CA certificate bundle. There is\nonly one — the one from the certifi package.\n\nIf you are packaging Requests, e.g., for a Linux distribution or a managed\nenvironment, you can change the definition of where() to return a separately\npackaged CA bundle.\n\"\"\"\nfrom pip._vendor.certifi import where\n\nif __name__ == \"__main__\":\n    print(where())\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/requests/compat.py","size":1485,"sha1":"bce2e637b16736668b8ae7cb1e3f2c1dc836d9b3","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\nrequests.compat\n~~~~~~~~~~~~~~~\n\nThis module previously handled import compatibility issues\nbetween Python 2 and Python 3. It remains for backwards\ncompatibility until the next major version.\n\"\"\"\n\nimport sys\n\n# -------------------\n# Character Detection\n# -------------------\n\n\ndef _resolve_char_detection():\n    \"\"\"Find supported character detection libraries.\"\"\"\n    chardet = None\n    return chardet\n\n\nchardet = _resolve_char_detection()\n\n# -------\n# Pythons\n# -------\n\n# Syntax sugar.\n_ver = sys.version_info\n\n#: Python 2.x?\nis_py2 = _ver[0] == 2\n\n#: Python 3.x?\nis_py3 = _ver[0] == 3\n\n# Note: We've patched out simplejson support in pip because it prevents\n#       upgrading simplejson on Windows.\nimport json\nfrom json import JSONDecodeError\n\n# Keep OrderedDict for backwards compatibility.\nfrom collections import OrderedDict\nfrom collections.abc import Callable, Mapping, MutableMapping\nfrom http import cookiejar as cookielib\nfrom http.cookies import Morsel\nfrom io import StringIO\n\n# --------------\n# Legacy Imports\n# --------------\nfrom urllib.parse import (\n    quote,\n    quote_plus,\n    unquote,\n    unquote_plus,\n    urldefrag,\n    urlencode,\n    urljoin,\n    urlparse,\n    urlsplit,\n    urlunparse,\n)\nfrom urllib.request import (\n    getproxies,\n    getproxies_environment,\n    parse_http_list,\n    proxy_bypass,\n    proxy_bypass_environment,\n)\n\nbuiltin_str = str\nstr = str\nbytes = bytes\nbasestring = (str, bytes)\nnumeric_types = (int, float)\ninteger_types = (int,)\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/requests/cookies.py","size":18590,"sha1":"904a118f4c9b48d637c5cce657018c2486513527","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\nrequests.cookies\n~~~~~~~~~~~~~~~~\n\nCompatibility code to be able to use `http.cookiejar.CookieJar` with requests.\n\nrequests.utils imports from here, so be careful with imports.\n\"\"\"\n\nimport calendar\nimport copy\nimport time\n\nfrom ._internal_utils import to_native_string\nfrom .compat import Morsel, MutableMapping, cookielib, urlparse, urlunparse\n\ntry:\n    import threading\nexcept ImportError:\n    import dummy_threading as threading\n\n\nclass MockRequest:\n    \"\"\"Wraps a `requests.Request` to mimic a `urllib2.Request`.\n\n    The code in `http.cookiejar.CookieJar` expects this interface in order to correctly\n    manage cookie policies, i.e., determine whether a cookie can be set, given the\n    domains of the request and the cookie.\n\n    The original request object is read-only. The client is responsible for collecting\n    the new headers via `get_new_headers()` and interpreting them appropriately. You\n    probably want `get_cookie_header`, defined below.\n    \"\"\"\n\n    def __init__(self, request):\n        self._r = request\n        self._new_headers = {}\n        self.type = urlparse(self._r.url).scheme\n\n    def get_type(self):\n        return self.type\n\n    def get_host(self):\n        return urlparse(self._r.url).netloc\n\n    def get_origin_req_host(self):\n        return self.get_host()\n\n    def get_full_url(self):\n        # Only return the response's URL if the user hadn't set the Host\n        # header\n        if not self._r.headers.get(\"Host\"):\n            return self._r.url\n        # If they did set it, retrieve it and reconstruct the expected domain\n        host = to_native_string(self._r.headers[\"Host\"], encoding=\"utf-8\")\n        parsed = urlparse(self._r.url)\n        # Reconstruct the URL as we expect it\n        return urlunparse(\n            [\n                parsed.scheme,\n                host,\n                parsed.path,\n                parsed.params,\n                parsed.query,\n                parsed.fragment,\n            ]\n        )\n\n    def is_unverifiable(self):\n        return True\n\n    def has_header(self, name):\n        return name in self._r.headers or name in self._new_headers\n\n    def get_header(self, name, default=None):\n        return self._r.headers.get(name, self._new_headers.get(name, default))\n\n    def add_header(self, key, val):\n        \"\"\"cookiejar has no legitimate use for this method; add it back if you find one.\"\"\"\n        raise NotImplementedError(\n            \"Cookie headers should be added with add_unredirected_header()\"\n        )\n\n    def add_unredirected_header(self, name, value):\n        self._new_headers[name] = value\n\n    def get_new_headers(self):\n        return self._new_headers\n\n    @property\n    def unverifiable(self):\n        return self.is_unverifiable()\n\n    @property\n    def origin_req_host(self):\n        return self.get_origin_req_host()\n\n    @property\n    def host(self):\n        return self.get_host()\n\n\nclass MockResponse:\n    \"\"\"Wraps a `httplib.HTTPMessage` to mimic a `urllib.addinfourl`.\n\n    ...what? Basically, expose the parsed HTTP headers from the server response\n    the way `http.cookiejar` expects to see them.\n    \"\"\"\n\n    def __init__(self, headers):\n        \"\"\"Make a MockResponse for `cookiejar` to read.\n\n        :param headers: a httplib.HTTPMessage or analogous carrying the headers\n        \"\"\"\n        self._headers = headers\n\n    def info(self):\n        return self._headers\n\n    def getheaders(self, name):\n        self._headers.getheaders(name)\n\n\ndef extract_cookies_to_jar(jar, request, response):\n    \"\"\"Extract the cookies from the response into a CookieJar.\n\n    :param jar: http.cookiejar.CookieJar (not necessarily a RequestsCookieJar)\n    :param request: our own requests.Request object\n    :param response: urllib3.HTTPResponse object\n    \"\"\"\n    if not (hasattr(response, \"_original_response\") and response._original_response):\n        return\n    # the _original_response field is the wrapped httplib.HTTPResponse object,\n    req = MockRequest(request)\n    # pull out the HTTPMessage with the headers and put it in the mock:\n    res = MockResponse(response._original_response.msg)\n    jar.extract_cookies(res, req)\n\n\ndef get_cookie_header(jar, request):\n    \"\"\"\n    Produce an appropriate Cookie header string to be sent with `request`, or None.\n\n    :rtype: str\n    \"\"\"\n    r = MockRequest(request)\n    jar.add_cookie_header(r)\n    return r.get_new_headers().get(\"Cookie\")\n\n\ndef remove_cookie_by_name(cookiejar, name, domain=None, path=None):\n    \"\"\"Unsets a cookie by name, by default over all domains and paths.\n\n    Wraps CookieJar.clear(), is O(n).\n    \"\"\"\n    clearables = []\n    for cookie in cookiejar:\n        if cookie.name != name:\n            continue\n        if domain is not None and domain != cookie.domain:\n            continue\n        if path is not None and path != cookie.path:\n            continue\n        clearables.append((cookie.domain, cookie.path, cookie.name))\n\n    for domain, path, name in clearables:\n        cookiejar.clear(domain, path, name)\n\n\nclass CookieConflictError(RuntimeError):\n    \"\"\"There are two cookies that meet the criteria specified in the cookie jar.\n    Use .get and .set and include domain and path args in order to be more specific.\n    \"\"\"\n\n\nclass RequestsCookieJar(cookielib.CookieJar, MutableMapping):\n    \"\"\"Compatibility class; is a http.cookiejar.CookieJar, but exposes a dict\n    interface.\n\n    This is the CookieJar we create by default for requests and sessions that\n    don't specify one, since some clients may expect response.cookies and\n    session.cookies to support dict operations.\n\n    Requests does not use the dict interface internally; it's just for\n    compatibility with external client code. All requests code should work\n    out of the box with externally provided instances of ``CookieJar``, e.g.\n    ``LWPCookieJar`` and ``FileCookieJar``.\n\n    Unlike a regular CookieJar, this class is pickleable.\n\n    .. warning:: dictionary operations that are normally O(1) may be O(n).\n    \"\"\"\n\n    def get(self, name, default=None, domain=None, path=None):\n        \"\"\"Dict-like get() that also supports optional domain and path args in\n        order to resolve naming collisions from using one cookie jar over\n        multiple domains.\n\n        .. warning:: operation is O(n), not O(1).\n        \"\"\"\n        try:\n            return self._find_no_duplicates(name, domain, path)\n        except KeyError:\n            return default\n\n    def set(self, name, value, **kwargs):\n        \"\"\"Dict-like set() that also supports optional domain and path args in\n        order to resolve naming collisions from using one cookie jar over\n        multiple domains.\n        \"\"\"\n        # support client code that unsets cookies by assignment of a None value:\n        if value is None:\n            remove_cookie_by_name(\n                self, name, domain=kwargs.get(\"domain\"), path=kwargs.get(\"path\")\n            )\n            return\n\n        if isinstance(value, Morsel):\n            c = morsel_to_cookie(value)\n        else:\n            c = create_cookie(name, value, **kwargs)\n        self.set_cookie(c)\n        return c\n\n    def iterkeys(self):\n        \"\"\"Dict-like iterkeys() that returns an iterator of names of cookies\n        from the jar.\n\n        .. seealso:: itervalues() and iteritems().\n        \"\"\"\n        for cookie in iter(self):\n            yield cookie.name\n\n    def keys(self):\n        \"\"\"Dict-like keys() that returns a list of names of cookies from the\n        jar.\n\n        .. seealso:: values() and items().\n        \"\"\"\n        return list(self.iterkeys())\n\n    def itervalues(self):\n        \"\"\"Dict-like itervalues() that returns an iterator of values of cookies\n        from the jar.\n\n        .. seealso:: iterkeys() and iteritems().\n        \"\"\"\n        for cookie in iter(self):\n            yield cookie.value\n\n    def values(self):\n        \"\"\"Dict-like values() that returns a list of values of cookies from the\n        jar.\n\n        .. seealso:: keys() and items().\n        \"\"\"\n        return list(self.itervalues())\n\n    def iteritems(self):\n        \"\"\"Dict-like iteritems() that returns an iterator of name-value tuples\n        from the jar.\n\n        .. seealso:: iterkeys() and itervalues().\n        \"\"\"\n        for cookie in iter(self):\n            yield cookie.name, cookie.value\n\n    def items(self):\n        \"\"\"Dict-like items() that returns a list of name-value tuples from the\n        jar. Allows client-code to call ``dict(RequestsCookieJar)`` and get a\n        vanilla python dict of key value pairs.\n\n        .. seealso:: keys() and values().\n        \"\"\"\n        return list(self.iteritems())\n\n    def list_domains(self):\n        \"\"\"Utility method to list all the domains in the jar.\"\"\"\n        domains = []\n        for cookie in iter(self):\n            if cookie.domain not in domains:\n                domains.append(cookie.domain)\n        return domains\n\n    def list_paths(self):\n        \"\"\"Utility method to list all the paths in the jar.\"\"\"\n        paths = []\n        for cookie in iter(self):\n            if cookie.path not in paths:\n                paths.append(cookie.path)\n        return paths\n\n    def multiple_domains(self):\n        \"\"\"Returns True if there are multiple domains in the jar.\n        Returns False otherwise.\n\n        :rtype: bool\n        \"\"\"\n        domains = []\n        for cookie in iter(self):\n            if cookie.domain is not None and cookie.domain in domains:\n                return True\n            domains.append(cookie.domain)\n        return False  # there is only one domain in jar\n\n    def get_dict(self, domain=None, path=None):\n        \"\"\"Takes as an argument an optional domain and path and returns a plain\n        old Python dict of name-value pairs of cookies that meet the\n        requirements.\n\n        :rtype: dict\n        \"\"\"\n        dictionary = {}\n        for cookie in iter(self):\n            if (domain is None or cookie.domain == domain) and (\n                path is None or cookie.path == path\n            ):\n                dictionary[cookie.name] = cookie.value\n        return dictionary\n\n    def __contains__(self, name):\n        try:\n            return super().__contains__(name)\n        except CookieConflictError:\n            return True\n\n    def __getitem__(self, name):\n        \"\"\"Dict-like __getitem__() for compatibility with client code. Throws\n        exception if there are more than one cookie with name. In that case,\n        use the more explicit get() method instead.\n\n        .. warning:: operation is O(n), not O(1).\n        \"\"\"\n        return self._find_no_duplicates(name)\n\n    def __setitem__(self, name, value):\n        \"\"\"Dict-like __setitem__ for compatibility with client code. Throws\n        exception if there is already a cookie of that name in the jar. In that\n        case, use the more explicit set() method instead.\n        \"\"\"\n        self.set(name, value)\n\n    def __delitem__(self, name):\n        \"\"\"Deletes a cookie given a name. Wraps ``http.cookiejar.CookieJar``'s\n        ``remove_cookie_by_name()``.\n        \"\"\"\n        remove_cookie_by_name(self, name)\n\n    def set_cookie(self, cookie, *args, **kwargs):\n        if (\n            hasattr(cookie.value, \"startswith\")\n            and cookie.value.startswith('\"')\n            and cookie.value.endswith('\"')\n        ):\n            cookie.value = cookie.value.replace('\\\\\"', \"\")\n        return super().set_cookie(cookie, *args, **kwargs)\n\n    def update(self, other):\n        \"\"\"Updates this jar with cookies from another CookieJar or dict-like\"\"\"\n        if isinstance(other, cookielib.CookieJar):\n            for cookie in other:\n                self.set_cookie(copy.copy(cookie))\n        else:\n            super().update(other)\n\n    def _find(self, name, domain=None, path=None):\n        \"\"\"Requests uses this method internally to get cookie values.\n\n        If there are conflicting cookies, _find arbitrarily chooses one.\n        See _find_no_duplicates if you want an exception thrown if there are\n        conflicting cookies.\n\n        :param name: a string containing name of cookie\n        :param domain: (optional) string containing domain of cookie\n        :param path: (optional) string containing path of cookie\n        :return: cookie.value\n        \"\"\"\n        for cookie in iter(self):\n            if cookie.name == name:\n                if domain is None or cookie.domain == domain:\n                    if path is None or cookie.path == path:\n                        return cookie.value\n\n        raise KeyError(f\"name={name!r}, domain={domain!r}, path={path!r}\")\n\n    def _find_no_duplicates(self, name, domain=None, path=None):\n        \"\"\"Both ``__get_item__`` and ``get`` call this function: it's never\n        used elsewhere in Requests.\n\n        :param name: a string containing name of cookie\n        :param domain: (optional) string containing domain of cookie\n        :param path: (optional) string containing path of cookie\n        :raises KeyError: if cookie is not found\n        :raises CookieConflictError: if there are multiple cookies\n            that match name and optionally domain and path\n        :return: cookie.value\n        \"\"\"\n        toReturn = None\n        for cookie in iter(self):\n            if cookie.name == name:\n                if domain is None or cookie.domain == domain:\n                    if path is None or cookie.path == path:\n                        if toReturn is not None:\n                            # if there are multiple cookies that meet passed in criteria\n                            raise CookieConflictError(\n                                f\"There are multiple cookies with name, {name!r}\"\n                            )\n                        # we will eventually return this as long as no cookie conflict\n                        toReturn = cookie.value\n\n        if toReturn:\n            return toReturn\n        raise KeyError(f\"name={name!r}, domain={domain!r}, path={path!r}\")\n\n    def __getstate__(self):\n        \"\"\"Unlike a normal CookieJar, this class is pickleable.\"\"\"\n        state = self.__dict__.copy()\n        # remove the unpickleable RLock object\n        state.pop(\"_cookies_lock\")\n        return state\n\n    def __setstate__(self, state):\n        \"\"\"Unlike a normal CookieJar, this class is pickleable.\"\"\"\n        self.__dict__.update(state)\n        if \"_cookies_lock\" not in self.__dict__:\n            self._cookies_lock = threading.RLock()\n\n    def copy(self):\n        \"\"\"Return a copy of this RequestsCookieJar.\"\"\"\n        new_cj = RequestsCookieJar()\n        new_cj.set_policy(self.get_policy())\n        new_cj.update(self)\n        return new_cj\n\n    def get_policy(self):\n        \"\"\"Return the CookiePolicy instance used.\"\"\"\n        return self._policy\n\n\ndef _copy_cookie_jar(jar):\n    if jar is None:\n        return None\n\n    if hasattr(jar, \"copy\"):\n        # We're dealing with an instance of RequestsCookieJar\n        return jar.copy()\n    # We're dealing with a generic CookieJar instance\n    new_jar = copy.copy(jar)\n    new_jar.clear()\n    for cookie in jar:\n        new_jar.set_cookie(copy.copy(cookie))\n    return new_jar\n\n\ndef create_cookie(name, value, **kwargs):\n    \"\"\"Make a cookie from underspecified parameters.\n\n    By default, the pair of `name` and `value` will be set for the domain ''\n    and sent on every request (this is sometimes called a \"supercookie\").\n    \"\"\"\n    result = {\n        \"version\": 0,\n        \"name\": name,\n        \"value\": value,\n        \"port\": None,\n        \"domain\": \"\",\n        \"path\": \"/\",\n        \"secure\": False,\n        \"expires\": None,\n        \"discard\": True,\n        \"comment\": None,\n        \"comment_url\": None,\n        \"rest\": {\"HttpOnly\": None},\n        \"rfc2109\": False,\n    }\n\n    badargs = set(kwargs) - set(result)\n    if badargs:\n        raise TypeError(\n            f\"create_cookie() got unexpected keyword arguments: {list(badargs)}\"\n        )\n\n    result.update(kwargs)\n    result[\"port_specified\"] = bool(result[\"port\"])\n    result[\"domain_specified\"] = bool(result[\"domain\"])\n    result[\"domain_initial_dot\"] = result[\"domain\"].startswith(\".\")\n    result[\"path_specified\"] = bool(result[\"path\"])\n\n    return cookielib.Cookie(**result)\n\n\ndef morsel_to_cookie(morsel):\n    \"\"\"Convert a Morsel object into a Cookie containing the one k/v pair.\"\"\"\n\n    expires = None\n    if morsel[\"max-age\"]:\n        try:\n            expires = int(time.time() + int(morsel[\"max-age\"]))\n        except ValueError:\n            raise TypeError(f\"max-age: {morsel['max-age']} must be integer\")\n    elif morsel[\"expires\"]:\n        time_template = \"%a, %d-%b-%Y %H:%M:%S GMT\"\n        expires = calendar.timegm(time.strptime(morsel[\"expires\"], time_template))\n    return create_cookie(\n        comment=morsel[\"comment\"],\n        comment_url=bool(morsel[\"comment\"]),\n        discard=False,\n        domain=morsel[\"domain\"],\n        expires=expires,\n        name=morsel.key,\n        path=morsel[\"path\"],\n        port=None,\n        rest={\"HttpOnly\": morsel[\"httponly\"]},\n        rfc2109=False,\n        secure=bool(morsel[\"secure\"]),\n        value=morsel.value,\n        version=morsel[\"version\"] or 0,\n    )\n\n\ndef cookiejar_from_dict(cookie_dict, cookiejar=None, overwrite=True):\n    \"\"\"Returns a CookieJar from a key/value dictionary.\n\n    :param cookie_dict: Dict of key/values to insert into CookieJar.\n    :param cookiejar: (optional) A cookiejar to add the cookies to.\n    :param overwrite: (optional) If False, will not replace cookies\n        already in the jar with new ones.\n    :rtype: CookieJar\n    \"\"\"\n    if cookiejar is None:\n        cookiejar = RequestsCookieJar()\n\n    if cookie_dict is not None:\n        names_from_jar = [cookie.name for cookie in cookiejar]\n        for name in cookie_dict:\n            if overwrite or (name not in names_from_jar):\n                cookiejar.set_cookie(create_cookie(name, cookie_dict[name]))\n\n    return cookiejar\n\n\ndef merge_cookies(cookiejar, cookies):\n    \"\"\"Add cookies to cookiejar and returns a merged CookieJar.\n\n    :param cookiejar: CookieJar object to add the cookies to.\n    :param cookies: Dictionary or CookieJar object to be added.\n    :rtype: CookieJar\n    \"\"\"\n    if not isinstance(cookiejar, cookielib.CookieJar):\n        raise ValueError(\"You can only merge into CookieJar\")\n\n    if isinstance(cookies, dict):\n        cookiejar = cookiejar_from_dict(cookies, cookiejar=cookiejar, overwrite=False)\n    elif isinstance(cookies, cookielib.CookieJar):\n        try:\n            cookiejar.update(cookies)\n        except AttributeError:\n            for cookie_in_jar in cookies:\n                cookiejar.set_cookie(cookie_in_jar)\n\n    return cookiejar\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/requests/exceptions.py","size":4272,"sha1":"34d85bda13b63a95dbf53fe4c6b667d2a284fa24","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\nrequests.exceptions\n~~~~~~~~~~~~~~~~~~~\n\nThis module contains the set of Requests' exceptions.\n\"\"\"\nfrom pip._vendor.urllib3.exceptions import HTTPError as BaseHTTPError\n\nfrom .compat import JSONDecodeError as CompatJSONDecodeError\n\n\nclass RequestException(IOError):\n    \"\"\"There was an ambiguous exception that occurred while handling your\n    request.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        \"\"\"Initialize RequestException with `request` and `response` objects.\"\"\"\n        response = kwargs.pop(\"response\", None)\n        self.response = response\n        self.request = kwargs.pop(\"request\", None)\n        if response is not None and not self.request and hasattr(response, \"request\"):\n            self.request = self.response.request\n        super().__init__(*args, **kwargs)\n\n\nclass InvalidJSONError(RequestException):\n    \"\"\"A JSON error occurred.\"\"\"\n\n\nclass JSONDecodeError(InvalidJSONError, CompatJSONDecodeError):\n    \"\"\"Couldn't decode the text into json\"\"\"\n\n    def __init__(self, *args, **kwargs):\n        \"\"\"\n        Construct the JSONDecodeError instance first with all\n        args. Then use it's args to construct the IOError so that\n        the json specific args aren't used as IOError specific args\n        and the error message from JSONDecodeError is preserved.\n        \"\"\"\n        CompatJSONDecodeError.__init__(self, *args)\n        InvalidJSONError.__init__(self, *self.args, **kwargs)\n\n    def __reduce__(self):\n        \"\"\"\n        The __reduce__ method called when pickling the object must\n        be the one from the JSONDecodeError (be it json/simplejson)\n        as it expects all the arguments for instantiation, not just\n        one like the IOError, and the MRO would by default call the\n        __reduce__ method from the IOError due to the inheritance order.\n        \"\"\"\n        return CompatJSONDecodeError.__reduce__(self)\n\n\nclass HTTPError(RequestException):\n    \"\"\"An HTTP error occurred.\"\"\"\n\n\nclass ConnectionError(RequestException):\n    \"\"\"A Connection error occurred.\"\"\"\n\n\nclass ProxyError(ConnectionError):\n    \"\"\"A proxy error occurred.\"\"\"\n\n\nclass SSLError(ConnectionError):\n    \"\"\"An SSL error occurred.\"\"\"\n\n\nclass Timeout(RequestException):\n    \"\"\"The request timed out.\n\n    Catching this error will catch both\n    :exc:`~requests.exceptions.ConnectTimeout` and\n    :exc:`~requests.exceptions.ReadTimeout` errors.\n    \"\"\"\n\n\nclass ConnectTimeout(ConnectionError, Timeout):\n    \"\"\"The request timed out while trying to connect to the remote server.\n\n    Requests that produced this error are safe to retry.\n    \"\"\"\n\n\nclass ReadTimeout(Timeout):\n    \"\"\"The server did not send any data in the allotted amount of time.\"\"\"\n\n\nclass URLRequired(RequestException):\n    \"\"\"A valid URL is required to make a request.\"\"\"\n\n\nclass TooManyRedirects(RequestException):\n    \"\"\"Too many redirects.\"\"\"\n\n\nclass MissingSchema(RequestException, ValueError):\n    \"\"\"The URL scheme (e.g. http or https) is missing.\"\"\"\n\n\nclass InvalidSchema(RequestException, ValueError):\n    \"\"\"The URL scheme provided is either invalid or unsupported.\"\"\"\n\n\nclass InvalidURL(RequestException, ValueError):\n    \"\"\"The URL provided was somehow invalid.\"\"\"\n\n\nclass InvalidHeader(RequestException, ValueError):\n    \"\"\"The header value provided was somehow invalid.\"\"\"\n\n\nclass InvalidProxyURL(InvalidURL):\n    \"\"\"The proxy URL provided is invalid.\"\"\"\n\n\nclass ChunkedEncodingError(RequestException):\n    \"\"\"The server declared chunked encoding but sent an invalid chunk.\"\"\"\n\n\nclass ContentDecodingError(RequestException, BaseHTTPError):\n    \"\"\"Failed to decode response content.\"\"\"\n\n\nclass StreamConsumedError(RequestException, TypeError):\n    \"\"\"The content for this response was already consumed.\"\"\"\n\n\nclass RetryError(RequestException):\n    \"\"\"Custom retries logic failed\"\"\"\n\n\nclass UnrewindableBodyError(RequestException):\n    \"\"\"Requests encountered an error when trying to rewind a body.\"\"\"\n\n\n# Warnings\n\n\nclass RequestsWarning(Warning):\n    \"\"\"Base warning for Requests.\"\"\"\n\n\nclass FileModeWarning(RequestsWarning, DeprecationWarning):\n    \"\"\"A file was opened in text mode, but Requests determined its binary length.\"\"\"\n\n\nclass RequestsDependencyWarning(RequestsWarning):\n    \"\"\"An imported dependency doesn't match the expected version range.\"\"\"\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/requests/help.py","size":3813,"sha1":"bb23ad839cb6ba79e4cc055f90a925b0e9a3b908","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"Module containing bug report helper(s).\"\"\"\n\nimport json\nimport platform\nimport ssl\nimport sys\n\nfrom pip._vendor import idna\nfrom pip._vendor import urllib3\n\nfrom . import __version__ as requests_version\n\ncharset_normalizer = None\nchardet = None\n\ntry:\n    from pip._vendor.urllib3.contrib import pyopenssl\nexcept ImportError:\n    pyopenssl = None\n    OpenSSL = None\n    cryptography = None\nelse:\n    import cryptography\n    import OpenSSL\n\n\ndef _implementation():\n    \"\"\"Return a dict with the Python implementation and version.\n\n    Provide both the name and the version of the Python implementation\n    currently running. For example, on CPython 3.10.3 it will return\n    {'name': 'CPython', 'version': '3.10.3'}.\n\n    This function works best on CPython and PyPy: in particular, it probably\n    doesn't work for Jython or IronPython. Future investigation should be done\n    to work out the correct shape of the code for those platforms.\n    \"\"\"\n    implementation = platform.python_implementation()\n\n    if implementation == \"CPython\":\n        implementation_version = platform.python_version()\n    elif implementation == \"PyPy\":\n        implementation_version = \"{}.{}.{}\".format(\n            sys.pypy_version_info.major,\n            sys.pypy_version_info.minor,\n            sys.pypy_version_info.micro,\n        )\n        if sys.pypy_version_info.releaselevel != \"final\":\n            implementation_version = \"\".join(\n                [implementation_version, sys.pypy_version_info.releaselevel]\n            )\n    elif implementation == \"Jython\":\n        implementation_version = platform.python_version()  # Complete Guess\n    elif implementation == \"IronPython\":\n        implementation_version = platform.python_version()  # Complete Guess\n    else:\n        implementation_version = \"Unknown\"\n\n    return {\"name\": implementation, \"version\": implementation_version}\n\n\ndef info():\n    \"\"\"Generate information for a bug report.\"\"\"\n    try:\n        platform_info = {\n            \"system\": platform.system(),\n            \"release\": platform.release(),\n        }\n    except OSError:\n        platform_info = {\n            \"system\": \"Unknown\",\n            \"release\": \"Unknown\",\n        }\n\n    implementation_info = _implementation()\n    urllib3_info = {\"version\": urllib3.__version__}\n    charset_normalizer_info = {\"version\": None}\n    chardet_info = {\"version\": None}\n    if charset_normalizer:\n        charset_normalizer_info = {\"version\": charset_normalizer.__version__}\n    if chardet:\n        chardet_info = {\"version\": chardet.__version__}\n\n    pyopenssl_info = {\n        \"version\": None,\n        \"openssl_version\": \"\",\n    }\n    if OpenSSL:\n        pyopenssl_info = {\n            \"version\": OpenSSL.__version__,\n            \"openssl_version\": f\"{OpenSSL.SSL.OPENSSL_VERSION_NUMBER:x}\",\n        }\n    cryptography_info = {\n        \"version\": getattr(cryptography, \"__version__\", \"\"),\n    }\n    idna_info = {\n        \"version\": getattr(idna, \"__version__\", \"\"),\n    }\n\n    system_ssl = ssl.OPENSSL_VERSION_NUMBER\n    system_ssl_info = {\"version\": f\"{system_ssl:x}\" if system_ssl is not None else \"\"}\n\n    return {\n        \"platform\": platform_info,\n        \"implementation\": implementation_info,\n        \"system_ssl\": system_ssl_info,\n        \"using_pyopenssl\": pyopenssl is not None,\n        \"using_charset_normalizer\": chardet is None,\n        \"pyOpenSSL\": pyopenssl_info,\n        \"urllib3\": urllib3_info,\n        \"chardet\": chardet_info,\n        \"charset_normalizer\": charset_normalizer_info,\n        \"cryptography\": cryptography_info,\n        \"idna\": idna_info,\n        \"requests\": {\n            \"version\": requests_version,\n        },\n    }\n\n\ndef main():\n    \"\"\"Pretty-print the bug information as JSON.\"\"\"\n    print(json.dumps(info(), sort_keys=True, indent=2))\n\n\nif __name__ == \"__main__\":\n    main()\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/requests/hooks.py","size":733,"sha1":"6c2aebe642d6471e70534c45e039df709b23435d","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\nrequests.hooks\n~~~~~~~~~~~~~~\n\nThis module provides the capabilities for the Requests hooks system.\n\nAvailable hooks:\n\n``response``:\n    The response generated from a Request.\n\"\"\"\nHOOKS = [\"response\"]\n\n\ndef default_hooks():\n    return {event: [] for event in HOOKS}\n\n\n# TODO: response is the only one\n\n\ndef dispatch_hook(key, hooks, hook_data, **kwargs):\n    \"\"\"Dispatches a hook dictionary on a given piece of data.\"\"\"\n    hooks = hooks or {}\n    hooks = hooks.get(key)\n    if hooks:\n        if hasattr(hooks, \"__call__\"):\n            hooks = [hooks]\n        for hook in hooks:\n            _hook_data = hook(hook_data, **kwargs)\n            if _hook_data is not None:\n                hook_data = _hook_data\n    return hook_data\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/requests/models.py","size":35483,"sha1":"43d0af325a937498eb00dd2447c5e314fdbd3b06","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\nrequests.models\n~~~~~~~~~~~~~~~\n\nThis module contains the primary objects that power Requests.\n\"\"\"\n\nimport datetime\n\n# Import encoding now, to avoid implicit import later.\n# Implicit import within threads may cause LookupError when standard library is in a ZIP,\n# such as in Embedded Python. See https://github.com/psf/requests/issues/3578.\nimport encodings.idna  # noqa: F401\nfrom io import UnsupportedOperation\n\nfrom pip._vendor.urllib3.exceptions import (\n    DecodeError,\n    LocationParseError,\n    ProtocolError,\n    ReadTimeoutError,\n    SSLError,\n)\nfrom pip._vendor.urllib3.fields import RequestField\nfrom pip._vendor.urllib3.filepost import encode_multipart_formdata\nfrom pip._vendor.urllib3.util import parse_url\n\nfrom ._internal_utils import to_native_string, unicode_is_ascii\nfrom .auth import HTTPBasicAuth\nfrom .compat import (\n    Callable,\n    JSONDecodeError,\n    Mapping,\n    basestring,\n    builtin_str,\n    chardet,\n    cookielib,\n)\nfrom .compat import json as complexjson\nfrom .compat import urlencode, urlsplit, urlunparse\nfrom .cookies import _copy_cookie_jar, cookiejar_from_dict, get_cookie_header\nfrom .exceptions import (\n    ChunkedEncodingError,\n    ConnectionError,\n    ContentDecodingError,\n    HTTPError,\n    InvalidJSONError,\n    InvalidURL,\n)\nfrom .exceptions import JSONDecodeError as RequestsJSONDecodeError\nfrom .exceptions import MissingSchema\nfrom .exceptions import SSLError as RequestsSSLError\nfrom .exceptions import StreamConsumedError\nfrom .hooks import default_hooks\nfrom .status_codes import codes\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (\n    check_header_validity,\n    get_auth_from_url,\n    guess_filename,\n    guess_json_utf,\n    iter_slices,\n    parse_header_links,\n    requote_uri,\n    stream_decode_response_unicode,\n    super_len,\n    to_key_val_list,\n)\n\n#: The set of HTTP status codes that indicate an automatically\n#: processable redirect.\nREDIRECT_STATI = (\n    codes.moved,  # 301\n    codes.found,  # 302\n    codes.other,  # 303\n    codes.temporary_redirect,  # 307\n    codes.permanent_redirect,  # 308\n)\n\nDEFAULT_REDIRECT_LIMIT = 30\nCONTENT_CHUNK_SIZE = 10 * 1024\nITER_CHUNK_SIZE = 512\n\n\nclass RequestEncodingMixin:\n    @property\n    def path_url(self):\n        \"\"\"Build the path URL to use.\"\"\"\n\n        url = []\n\n        p = urlsplit(self.url)\n\n        path = p.path\n        if not path:\n            path = \"/\"\n\n        url.append(path)\n\n        query = p.query\n        if query:\n            url.append(\"?\")\n            url.append(query)\n\n        return \"\".join(url)\n\n    @staticmethod\n    def _encode_params(data):\n        \"\"\"Encode parameters in a piece of data.\n\n        Will successfully encode parameters when passed as a dict or a list of\n        2-tuples. Order is retained if data is a list of 2-tuples but arbitrary\n        if parameters are supplied as a dict.\n        \"\"\"\n\n        if isinstance(data, (str, bytes)):\n            return data\n        elif hasattr(data, \"read\"):\n            return data\n        elif hasattr(data, \"__iter__\"):\n            result = []\n            for k, vs in to_key_val_list(data):\n                if isinstance(vs, basestring) or not hasattr(vs, \"__iter__\"):\n                    vs = [vs]\n                for v in vs:\n                    if v is not None:\n                        result.append(\n                            (\n                                k.encode(\"utf-8\") if isinstance(k, str) else k,\n                                v.encode(\"utf-8\") if isinstance(v, str) else v,\n                            )\n                        )\n            return urlencode(result, doseq=True)\n        else:\n            return data\n\n    @staticmethod\n    def _encode_files(files, data):\n        \"\"\"Build the body for a multipart/form-data request.\n\n        Will successfully encode files when passed as a dict or a list of\n        tuples. Order is retained if data is a list of tuples but arbitrary\n        if parameters are supplied as a dict.\n        The tuples may be 2-tuples (filename, fileobj), 3-tuples (filename, fileobj, contentype)\n        or 4-tuples (filename, fileobj, contentype, custom_headers).\n        \"\"\"\n        if not files:\n            raise ValueError(\"Files must be provided.\")\n        elif isinstance(data, basestring):\n            raise ValueError(\"Data must not be a string.\")\n\n        new_fields = []\n        fields = to_key_val_list(data or {})\n        files = to_key_val_list(files or {})\n\n        for field, val in fields:\n            if isinstance(val, basestring) or not hasattr(val, \"__iter__\"):\n                val = [val]\n            for v in val:\n                if v is not None:\n                    # Don't call str() on bytestrings: in Py3 it all goes wrong.\n                    if not isinstance(v, bytes):\n                        v = str(v)\n\n                    new_fields.append(\n                        (\n                            field.decode(\"utf-8\")\n                            if isinstance(field, bytes)\n                            else field,\n                            v.encode(\"utf-8\") if isinstance(v, str) else v,\n                        )\n                    )\n\n        for k, v in files:\n            # support for explicit filename\n            ft = None\n            fh = None\n            if isinstance(v, (tuple, list)):\n                if len(v) == 2:\n                    fn, fp = v\n                elif len(v) == 3:\n                    fn, fp, ft = v\n                else:\n                    fn, fp, ft, fh = v\n            else:\n                fn = guess_filename(v) or k\n                fp = v\n\n            if isinstance(fp, (str, bytes, bytearray)):\n                fdata = fp\n            elif hasattr(fp, \"read\"):\n                fdata = fp.read()\n            elif fp is None:\n                continue\n            else:\n                fdata = fp\n\n            rf = RequestField(name=k, data=fdata, filename=fn, headers=fh)\n            rf.make_multipart(content_type=ft)\n            new_fields.append(rf)\n\n        body, content_type = encode_multipart_formdata(new_fields)\n\n        return body, content_type\n\n\nclass RequestHooksMixin:\n    def register_hook(self, event, hook):\n        \"\"\"Properly register a hook.\"\"\"\n\n        if event not in self.hooks:\n            raise ValueError(f'Unsupported event specified, with event name \"{event}\"')\n\n        if isinstance(hook, Callable):\n            self.hooks[event].append(hook)\n        elif hasattr(hook, \"__iter__\"):\n            self.hooks[event].extend(h for h in hook if isinstance(h, Callable))\n\n    def deregister_hook(self, event, hook):\n        \"\"\"Deregister a previously registered hook.\n        Returns True if the hook existed, False if not.\n        \"\"\"\n\n        try:\n            self.hooks[event].remove(hook)\n            return True\n        except ValueError:\n            return False\n\n\nclass Request(RequestHooksMixin):\n    \"\"\"A user-created :class:`Request <Request>` object.\n\n    Used to prepare a :class:`PreparedRequest <PreparedRequest>`, which is sent to the server.\n\n    :param method: HTTP method to use.\n    :param url: URL to send.\n    :param headers: dictionary of headers to send.\n    :param files: dictionary of {filename: fileobject} files to multipart upload.\n    :param data: the body to attach to the request. If a dictionary or\n        list of tuples ``[(key, value)]`` is provided, form-encoding will\n        take place.\n    :param json: json for the body to attach to the request (if files or data is not specified).\n    :param params: URL parameters to append to the URL. If a dictionary or\n        list of tuples ``[(key, value)]`` is provided, form-encoding will\n        take place.\n    :param auth: Auth handler or (user, pass) tuple.\n    :param cookies: dictionary or CookieJar of cookies to attach to this request.\n    :param hooks: dictionary of callback hooks, for internal usage.\n\n    Usage::\n\n      >>> import requests\n      >>> req = requests.Request('GET', 'https://httpbin.org/get')\n      >>> req.prepare()\n      <PreparedRequest [GET]>\n    \"\"\"\n\n    def __init__(\n        self,\n        method=None,\n        url=None,\n        headers=None,\n        files=None,\n        data=None,\n        params=None,\n        auth=None,\n        cookies=None,\n        hooks=None,\n        json=None,\n    ):\n        # Default empty dicts for dict params.\n        data = [] if data is None else data\n        files = [] if files is None else files\n        headers = {} if headers is None else headers\n        params = {} if params is None else params\n        hooks = {} if hooks is None else hooks\n\n        self.hooks = default_hooks()\n        for k, v in list(hooks.items()):\n            self.register_hook(event=k, hook=v)\n\n        self.method = method\n        self.url = url\n        self.headers = headers\n        self.files = files\n        self.data = data\n        self.json = json\n        self.params = params\n        self.auth = auth\n        self.cookies = cookies\n\n    def __repr__(self):\n        return f\"<Request [{self.method}]>\"\n\n    def prepare(self):\n        \"\"\"Constructs a :class:`PreparedRequest <PreparedRequest>` for transmission and returns it.\"\"\"\n        p = PreparedRequest()\n        p.prepare(\n            method=self.method,\n            url=self.url,\n            headers=self.headers,\n            files=self.files,\n            data=self.data,\n            json=self.json,\n            params=self.params,\n            auth=self.auth,\n            cookies=self.cookies,\n            hooks=self.hooks,\n        )\n        return p\n\n\nclass PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n    \"\"\"The fully mutable :class:`PreparedRequest <PreparedRequest>` object,\n    containing the exact bytes that will be sent to the server.\n\n    Instances are generated from a :class:`Request <Request>` object, and\n    should not be instantiated manually; doing so may produce undesirable\n    effects.\n\n    Usage::\n\n      >>> import requests\n      >>> req = requests.Request('GET', 'https://httpbin.org/get')\n      >>> r = req.prepare()\n      >>> r\n      <PreparedRequest [GET]>\n\n      >>> s = requests.Session()\n      >>> s.send(r)\n      <Response [200]>\n    \"\"\"\n\n    def __init__(self):\n        #: HTTP verb to send to the server.\n        self.method = None\n        #: HTTP URL to send the request to.\n        self.url = None\n        #: dictionary of HTTP headers.\n        self.headers = None\n        # The `CookieJar` used to create the Cookie header will be stored here\n        # after prepare_cookies is called\n        self._cookies = None\n        #: request body to send to the server.\n        self.body = None\n        #: dictionary of callback hooks, for internal usage.\n        self.hooks = default_hooks()\n        #: integer denoting starting position of a readable file-like body.\n        self._body_position = None\n\n    def prepare(\n        self,\n        method=None,\n        url=None,\n        headers=None,\n        files=None,\n        data=None,\n        params=None,\n        auth=None,\n        cookies=None,\n        hooks=None,\n        json=None,\n    ):\n        \"\"\"Prepares the entire request with the given parameters.\"\"\"\n\n        self.prepare_method(method)\n        self.prepare_url(url, params)\n        self.prepare_headers(headers)\n        self.prepare_cookies(cookies)\n        self.prepare_body(data, files, json)\n        self.prepare_auth(auth, url)\n\n        # Note that prepare_auth must be last to enable authentication schemes\n        # such as OAuth to work on a fully prepared request.\n\n        # This MUST go after prepare_auth. Authenticators could add a hook\n        self.prepare_hooks(hooks)\n\n    def __repr__(self):\n        return f\"<PreparedRequest [{self.method}]>\"\n\n    def copy(self):\n        p = PreparedRequest()\n        p.method = self.method\n        p.url = self.url\n        p.headers = self.headers.copy() if self.headers is not None else None\n        p._cookies = _copy_cookie_jar(self._cookies)\n        p.body = self.body\n        p.hooks = self.hooks\n        p._body_position = self._body_position\n        return p\n\n    def prepare_method(self, method):\n        \"\"\"Prepares the given HTTP method.\"\"\"\n        self.method = method\n        if self.method is not None:\n            self.method = to_native_string(self.method.upper())\n\n    @staticmethod\n    def _get_idna_encoded_host(host):\n        from pip._vendor import idna\n\n        try:\n            host = idna.encode(host, uts46=True).decode(\"utf-8\")\n        except idna.IDNAError:\n            raise UnicodeError\n        return host\n\n    def prepare_url(self, url, params):\n        \"\"\"Prepares the given HTTP URL.\"\"\"\n        #: Accept objects that have string representations.\n        #: We're unable to blindly call unicode/str functions\n        #: as this will include the bytestring indicator (b'')\n        #: on python 3.x.\n        #: https://github.com/psf/requests/pull/2238\n        if isinstance(url, bytes):\n            url = url.decode(\"utf8\")\n        else:\n            url = str(url)\n\n        # Remove leading whitespaces from url\n        url = url.lstrip()\n\n        # Don't do any URL preparation for non-HTTP schemes like `mailto`,\n        # `data` etc to work around exceptions from `url_parse`, which\n        # handles RFC 3986 only.\n        if \":\" in url and not url.lower().startswith(\"http\"):\n            self.url = url\n            return\n\n        # Support for unicode domain names and paths.\n        try:\n            scheme, auth, host, port, path, query, fragment = parse_url(url)\n        except LocationParseError as e:\n            raise InvalidURL(*e.args)\n\n        if not scheme:\n            raise MissingSchema(\n                f\"Invalid URL {url!r}: No scheme supplied. \"\n                f\"Perhaps you meant https://{url}?\"\n            )\n\n        if not host:\n            raise InvalidURL(f\"Invalid URL {url!r}: No host supplied\")\n\n        # In general, we want to try IDNA encoding the hostname if the string contains\n        # non-ASCII characters. This allows users to automatically get the correct IDNA\n        # behaviour. For strings containing only ASCII characters, we need to also verify\n        # it doesn't start with a wildcard (*), before allowing the unencoded hostname.\n        if not unicode_is_ascii(host):\n            try:\n                host = self._get_idna_encoded_host(host)\n            except UnicodeError:\n                raise InvalidURL(\"URL has an invalid label.\")\n        elif host.startswith((\"*\", \".\")):\n            raise InvalidURL(\"URL has an invalid label.\")\n\n        # Carefully reconstruct the network location\n        netloc = auth or \"\"\n        if netloc:\n            netloc += \"@\"\n        netloc += host\n        if port:\n            netloc += f\":{port}\"\n\n        # Bare domains aren't valid URLs.\n        if not path:\n            path = \"/\"\n\n        if isinstance(params, (str, bytes)):\n            params = to_native_string(params)\n\n        enc_params = self._encode_params(params)\n        if enc_params:\n            if query:\n                query = f\"{query}&{enc_params}\"\n            else:\n                query = enc_params\n\n        url = requote_uri(urlunparse([scheme, netloc, path, None, query, fragment]))\n        self.url = url\n\n    def prepare_headers(self, headers):\n        \"\"\"Prepares the given HTTP headers.\"\"\"\n\n        self.headers = CaseInsensitiveDict()\n        if headers:\n            for header in headers.items():\n                # Raise exception on invalid header value.\n                check_header_validity(header)\n                name, value = header\n                self.headers[to_native_string(name)] = value\n\n    def prepare_body(self, data, files, json=None):\n        \"\"\"Prepares the given HTTP body data.\"\"\"\n\n        # Check if file, fo, generator, iterator.\n        # If not, run through normal process.\n\n        # Nottin' on you.\n        body = None\n        content_type = None\n\n        if not data and json is not None:\n            # urllib3 requires a bytes-like body. Python 2's json.dumps\n            # provides this natively, but Python 3 gives a Unicode string.\n            content_type = \"application/json\"\n\n            try:\n                body = complexjson.dumps(json, allow_nan=False)\n            except ValueError as ve:\n                raise InvalidJSONError(ve, request=self)\n\n            if not isinstance(body, bytes):\n                body = body.encode(\"utf-8\")\n\n        is_stream = all(\n            [\n                hasattr(data, \"__iter__\"),\n                not isinstance(data, (basestring, list, tuple, Mapping)),\n            ]\n        )\n\n        if is_stream:\n            try:\n                length = super_len(data)\n            except (TypeError, AttributeError, UnsupportedOperation):\n                length = None\n\n            body = data\n\n            if getattr(body, \"tell\", None) is not None:\n                # Record the current file position before reading.\n                # This will allow us to rewind a file in the event\n                # of a redirect.\n                try:\n                    self._body_position = body.tell()\n                except OSError:\n                    # This differentiates from None, allowing us to catch\n                    # a failed `tell()` later when trying to rewind the body\n                    self._body_position = object()\n\n            if files:\n                raise NotImplementedError(\n                    \"Streamed bodies and files are mutually exclusive.\"\n                )\n\n            if length:\n                self.headers[\"Content-Length\"] = builtin_str(length)\n            else:\n                self.headers[\"Transfer-Encoding\"] = \"chunked\"\n        else:\n            # Multi-part file uploads.\n            if files:\n                (body, content_type) = self._encode_files(files, data)\n            else:\n                if data:\n                    body = self._encode_params(data)\n                    if isinstance(data, basestring) or hasattr(data, \"read\"):\n                        content_type = None\n                    else:\n                        content_type = \"application/x-www-form-urlencoded\"\n\n            self.prepare_content_length(body)\n\n            # Add content-type if it wasn't explicitly provided.\n            if content_type and (\"content-type\" not in self.headers):\n                self.headers[\"Content-Type\"] = content_type\n\n        self.body = body\n\n    def prepare_content_length(self, body):\n        \"\"\"Prepare Content-Length header based on request method and body\"\"\"\n        if body is not None:\n            length = super_len(body)\n            if length:\n                # If length exists, set it. Otherwise, we fallback\n                # to Transfer-Encoding: chunked.\n                self.headers[\"Content-Length\"] = builtin_str(length)\n        elif (\n            self.method not in (\"GET\", \"HEAD\")\n            and self.headers.get(\"Content-Length\") is None\n        ):\n            # Set Content-Length to 0 for methods that can have a body\n            # but don't provide one. (i.e. not GET or HEAD)\n            self.headers[\"Content-Length\"] = \"0\"\n\n    def prepare_auth(self, auth, url=\"\"):\n        \"\"\"Prepares the given HTTP auth data.\"\"\"\n\n        # If no Auth is explicitly provided, extract it from the URL first.\n        if auth is None:\n            url_auth = get_auth_from_url(self.url)\n            auth = url_auth if any(url_auth) else None\n\n        if auth:\n            if isinstance(auth, tuple) and len(auth) == 2:\n                # special-case basic HTTP auth\n                auth = HTTPBasicAuth(*auth)\n\n            # Allow auth to make its changes.\n            r = auth(self)\n\n            # Update self to reflect the auth changes.\n            self.__dict__.update(r.__dict__)\n\n            # Recompute Content-Length\n            self.prepare_content_length(self.body)\n\n    def prepare_cookies(self, cookies):\n        \"\"\"Prepares the given HTTP cookie data.\n\n        This function eventually generates a ``Cookie`` header from the\n        given cookies using cookielib. Due to cookielib's design, the header\n        will not be regenerated if it already exists, meaning this function\n        can only be called once for the life of the\n        :class:`PreparedRequest <PreparedRequest>` object. Any subsequent calls\n        to ``prepare_cookies`` will have no actual effect, unless the \"Cookie\"\n        header is removed beforehand.\n        \"\"\"\n        if isinstance(cookies, cookielib.CookieJar):\n            self._cookies = cookies\n        else:\n            self._cookies = cookiejar_from_dict(cookies)\n\n        cookie_header = get_cookie_header(self._cookies, self)\n        if cookie_header is not None:\n            self.headers[\"Cookie\"] = cookie_header\n\n    def prepare_hooks(self, hooks):\n        \"\"\"Prepares the given hooks.\"\"\"\n        # hooks can be passed as None to the prepare method and to this\n        # method. To prevent iterating over None, simply use an empty list\n        # if hooks is False-y\n        hooks = hooks or []\n        for event in hooks:\n            self.register_hook(event, hooks[event])\n\n\nclass Response:\n    \"\"\"The :class:`Response <Response>` object, which contains a\n    server's response to an HTTP request.\n    \"\"\"\n\n    __attrs__ = [\n        \"_content\",\n        \"status_code\",\n        \"headers\",\n        \"url\",\n        \"history\",\n        \"encoding\",\n        \"reason\",\n        \"cookies\",\n        \"elapsed\",\n        \"request\",\n    ]\n\n    def __init__(self):\n        self._content = False\n        self._content_consumed = False\n        self._next = None\n\n        #: Integer Code of responded HTTP Status, e.g. 404 or 200.\n        self.status_code = None\n\n        #: Case-insensitive Dictionary of Response Headers.\n        #: For example, ``headers['content-encoding']`` will return the\n        #: value of a ``'Content-Encoding'`` response header.\n        self.headers = CaseInsensitiveDict()\n\n        #: File-like object representation of response (for advanced usage).\n        #: Use of ``raw`` requires that ``stream=True`` be set on the request.\n        #: This requirement does not apply for use internally to Requests.\n        self.raw = None\n\n        #: Final URL location of Response.\n        self.url = None\n\n        #: Encoding to decode with when accessing r.text.\n        self.encoding = None\n\n        #: A list of :class:`Response <Response>` objects from\n        #: the history of the Request. Any redirect responses will end\n        #: up here. The list is sorted from the oldest to the most recent request.\n        self.history = []\n\n        #: Textual reason of responded HTTP Status, e.g. \"Not Found\" or \"OK\".\n        self.reason = None\n\n        #: A CookieJar of Cookies the server sent back.\n        self.cookies = cookiejar_from_dict({})\n\n        #: The amount of time elapsed between sending the request\n        #: and the arrival of the response (as a timedelta).\n        #: This property specifically measures the time taken between sending\n        #: the first byte of the request and finishing parsing the headers. It\n        #: is therefore unaffected by consuming the response content or the\n        #: value of the ``stream`` keyword argument.\n        self.elapsed = datetime.timedelta(0)\n\n        #: The :class:`PreparedRequest <PreparedRequest>` object to which this\n        #: is a response.\n        self.request = None\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self.close()\n\n    def __getstate__(self):\n        # Consume everything; accessing the content attribute makes\n        # sure the content has been fully read.\n        if not self._content_consumed:\n            self.content\n\n        return {attr: getattr(self, attr, None) for attr in self.__attrs__}\n\n    def __setstate__(self, state):\n        for name, value in state.items():\n            setattr(self, name, value)\n\n        # pickled objects do not have .raw\n        setattr(self, \"_content_consumed\", True)\n        setattr(self, \"raw\", None)\n\n    def __repr__(self):\n        return f\"<Response [{self.status_code}]>\"\n\n    def __bool__(self):\n        \"\"\"Returns True if :attr:`status_code` is less than 400.\n\n        This attribute checks if the status code of the response is between\n        400 and 600 to see if there was a client error or a server error. If\n        the status code, is between 200 and 400, this will return True. This\n        is **not** a check to see if the response code is ``200 OK``.\n        \"\"\"\n        return self.ok\n\n    def __nonzero__(self):\n        \"\"\"Returns True if :attr:`status_code` is less than 400.\n\n        This attribute checks if the status code of the response is between\n        400 and 600 to see if there was a client error or a server error. If\n        the status code, is between 200 and 400, this will return True. This\n        is **not** a check to see if the response code is ``200 OK``.\n        \"\"\"\n        return self.ok\n\n    def __iter__(self):\n        \"\"\"Allows you to use a response as an iterator.\"\"\"\n        return self.iter_content(128)\n\n    @property\n    def ok(self):\n        \"\"\"Returns True if :attr:`status_code` is less than 400, False if not.\n\n        This attribute checks if the status code of the response is between\n        400 and 600 to see if there was a client error or a server error. If\n        the status code is between 200 and 400, this will return True. This\n        is **not** a check to see if the response code is ``200 OK``.\n        \"\"\"\n        try:\n            self.raise_for_status()\n        except HTTPError:\n            return False\n        return True\n\n    @property\n    def is_redirect(self):\n        \"\"\"True if this Response is a well-formed HTTP redirect that could have\n        been processed automatically (by :meth:`Session.resolve_redirects`).\n        \"\"\"\n        return \"location\" in self.headers and self.status_code in REDIRECT_STATI\n\n    @property\n    def is_permanent_redirect(self):\n        \"\"\"True if this Response one of the permanent versions of redirect.\"\"\"\n        return \"location\" in self.headers and self.status_code in (\n            codes.moved_permanently,\n            codes.permanent_redirect,\n        )\n\n    @property\n    def next(self):\n        \"\"\"Returns a PreparedRequest for the next request in a redirect chain, if there is one.\"\"\"\n        return self._next\n\n    @property\n    def apparent_encoding(self):\n        \"\"\"The apparent encoding, provided by the charset_normalizer or chardet libraries.\"\"\"\n        if chardet is not None:\n            return chardet.detect(self.content)[\"encoding\"]\n        else:\n            # If no character detection library is available, we'll fall back\n            # to a standard Python utf-8 str.\n            return \"utf-8\"\n\n    def iter_content(self, chunk_size=1, decode_unicode=False):\n        \"\"\"Iterates over the response data.  When stream=True is set on the\n        request, this avoids reading the content at once into memory for\n        large responses.  The chunk size is the number of bytes it should\n        read into memory.  This is not necessarily the length of each item\n        returned as decoding can take place.\n\n        chunk_size must be of type int or None. A value of None will\n        function differently depending on the value of `stream`.\n        stream=True will read data as it arrives in whatever size the\n        chunks are received. If stream=False, data is returned as\n        a single chunk.\n\n        If decode_unicode is True, content will be decoded using the best\n        available encoding based on the response.\n        \"\"\"\n\n        def generate():\n            # Special case for urllib3.\n            if hasattr(self.raw, \"stream\"):\n                try:\n                    yield from self.raw.stream(chunk_size, decode_content=True)\n                except ProtocolError as e:\n                    raise ChunkedEncodingError(e)\n                except DecodeError as e:\n                    raise ContentDecodingError(e)\n                except ReadTimeoutError as e:\n                    raise ConnectionError(e)\n                except SSLError as e:\n                    raise RequestsSSLError(e)\n            else:\n                # Standard file-like object.\n                while True:\n                    chunk = self.raw.read(chunk_size)\n                    if not chunk:\n                        break\n                    yield chunk\n\n            self._content_consumed = True\n\n        if self._content_consumed and isinstance(self._content, bool):\n            raise StreamConsumedError()\n        elif chunk_size is not None and not isinstance(chunk_size, int):\n            raise TypeError(\n                f\"chunk_size must be an int, it is instead a {type(chunk_size)}.\"\n            )\n        # simulate reading small chunks of the content\n        reused_chunks = iter_slices(self._content, chunk_size)\n\n        stream_chunks = generate()\n\n        chunks = reused_chunks if self._content_consumed else stream_chunks\n\n        if decode_unicode:\n            chunks = stream_decode_response_unicode(chunks, self)\n\n        return chunks\n\n    def iter_lines(\n        self, chunk_size=ITER_CHUNK_SIZE, decode_unicode=False, delimiter=None\n    ):\n        \"\"\"Iterates over the response data, one line at a time.  When\n        stream=True is set on the request, this avoids reading the\n        content at once into memory for large responses.\n\n        .. note:: This method is not reentrant safe.\n        \"\"\"\n\n        pending = None\n\n        for chunk in self.iter_content(\n            chunk_size=chunk_size, decode_unicode=decode_unicode\n        ):\n            if pending is not None:\n                chunk = pending + chunk\n\n            if delimiter:\n                lines = chunk.split(delimiter)\n            else:\n                lines = chunk.splitlines()\n\n            if lines and lines[-1] and chunk and lines[-1][-1] == chunk[-1]:\n                pending = lines.pop()\n            else:\n                pending = None\n\n            yield from lines\n\n        if pending is not None:\n            yield pending\n\n    @property\n    def content(self):\n        \"\"\"Content of the response, in bytes.\"\"\"\n\n        if self._content is False:\n            # Read the contents.\n            if self._content_consumed:\n                raise RuntimeError(\"The content for this response was already consumed\")\n\n            if self.status_code == 0 or self.raw is None:\n                self._content = None\n            else:\n                self._content = b\"\".join(self.iter_content(CONTENT_CHUNK_SIZE)) or b\"\"\n\n        self._content_consumed = True\n        # don't need to release the connection; that's been handled by urllib3\n        # since we exhausted the data.\n        return self._content\n\n    @property\n    def text(self):\n        \"\"\"Content of the response, in unicode.\n\n        If Response.encoding is None, encoding will be guessed using\n        ``charset_normalizer`` or ``chardet``.\n\n        The encoding of the response content is determined based solely on HTTP\n        headers, following RFC 2616 to the letter. If you can take advantage of\n        non-HTTP knowledge to make a better guess at the encoding, you should\n        set ``r.encoding`` appropriately before accessing this property.\n        \"\"\"\n\n        # Try charset from content-type\n        content = None\n        encoding = self.encoding\n\n        if not self.content:\n            return \"\"\n\n        # Fallback to auto-detected encoding.\n        if self.encoding is None:\n            encoding = self.apparent_encoding\n\n        # Decode unicode from given encoding.\n        try:\n            content = str(self.content, encoding, errors=\"replace\")\n        except (LookupError, TypeError):\n            # A LookupError is raised if the encoding was not found which could\n            # indicate a misspelling or similar mistake.\n            #\n            # A TypeError can be raised if encoding is None\n            #\n            # So we try blindly encoding.\n            content = str(self.content, errors=\"replace\")\n\n        return content\n\n    def json(self, **kwargs):\n        r\"\"\"Returns the json-encoded content of a response, if any.\n\n        :param \\*\\*kwargs: Optional arguments that ``json.loads`` takes.\n        :raises requests.exceptions.JSONDecodeError: If the response body does not\n            contain valid json.\n        \"\"\"\n\n        if not self.encoding and self.content and len(self.content) > 3:\n            # No encoding set. JSON RFC 4627 section 3 states we should expect\n            # UTF-8, -16 or -32. Detect which one to use; If the detection or\n            # decoding fails, fall back to `self.text` (using charset_normalizer to make\n            # a best guess).\n            encoding = guess_json_utf(self.content)\n            if encoding is not None:\n                try:\n                    return complexjson.loads(self.content.decode(encoding), **kwargs)\n                except UnicodeDecodeError:\n                    # Wrong UTF codec detected; usually because it's not UTF-8\n                    # but some other 8-bit codec.  This is an RFC violation,\n                    # and the server didn't bother to tell us what codec *was*\n                    # used.\n                    pass\n                except JSONDecodeError as e:\n                    raise RequestsJSONDecodeError(e.msg, e.doc, e.pos)\n\n        try:\n            return complexjson.loads(self.text, **kwargs)\n        except JSONDecodeError as e:\n            # Catch JSON-related errors and raise as requests.JSONDecodeError\n            # This aliases json.JSONDecodeError and simplejson.JSONDecodeError\n            raise RequestsJSONDecodeError(e.msg, e.doc, e.pos)\n\n    @property\n    def links(self):\n        \"\"\"Returns the parsed header links of the response, if any.\"\"\"\n\n        header = self.headers.get(\"link\")\n\n        resolved_links = {}\n\n        if header:\n            links = parse_header_links(header)\n\n            for link in links:\n                key = link.get(\"rel\") or link.get(\"url\")\n                resolved_links[key] = link\n\n        return resolved_links\n\n    def raise_for_status(self):\n        \"\"\"Raises :class:`HTTPError`, if one occurred.\"\"\"\n\n        http_error_msg = \"\"\n        if isinstance(self.reason, bytes):\n            # We attempt to decode utf-8 first because some servers\n            # choose to localize their reason strings. If the string\n            # isn't utf-8, we fall back to iso-8859-1 for all other\n            # encodings. (See PR #3538)\n            try:\n                reason = self.reason.decode(\"utf-8\")\n            except UnicodeDecodeError:\n                reason = self.reason.decode(\"iso-8859-1\")\n        else:\n            reason = self.reason\n\n        if 400 <= self.status_code < 500:\n            http_error_msg = (\n                f\"{self.status_code} Client Error: {reason} for url: {self.url}\"\n            )\n\n        elif 500 <= self.status_code < 600:\n            http_error_msg = (\n                f\"{self.status_code} Server Error: {reason} for url: {self.url}\"\n            )\n\n        if http_error_msg:\n            raise HTTPError(http_error_msg, response=self)\n\n    def close(self):\n        \"\"\"Releases the connection back to the pool. Once this method has been\n        called the underlying ``raw`` object must not be accessed again.\n\n        *Note: Should not normally need to be called explicitly.*\n        \"\"\"\n        if not self._content_consumed:\n            self.raw.close()\n\n        release_conn = getattr(self.raw, \"release_conn\", None)\n        if release_conn is not None:\n            release_conn()\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/requests/packages.py","size":1057,"sha1":"954cabd8a9501257b5bd8319a4ce6de54796ca26","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"import sys\n\nfrom .compat import chardet\n\n# This code exists for backwards compatibility reasons.\n# I don't like it either. Just look the other way. :)\n\nfor package in (\"urllib3\", \"idna\"):\n    vendored_package = \"pip._vendor.\" + package\n    locals()[package] = __import__(vendored_package)\n    # This traversal is apparently necessary such that the identities are\n    # preserved (requests.packages.urllib3.* is urllib3.*)\n    for mod in list(sys.modules):\n        if mod == vendored_package or mod.startswith(vendored_package + '.'):\n            unprefixed_mod = mod[len(\"pip._vendor.\"):]\n            sys.modules['pip._vendor.requests.packages.' + unprefixed_mod] = sys.modules[mod]\n\nif chardet is not None:\n    target = chardet.__name__\n    for mod in list(sys.modules):\n        if mod == target or mod.startswith(f\"{target}.\"):\n            imported_mod = sys.modules[mod]\n            sys.modules[f\"requests.packages.{mod}\"] = imported_mod\n            mod = mod.replace(target, \"chardet\")\n            sys.modules[f\"requests.packages.{mod}\"] = imported_mod\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/requests/sessions.py","size":30495,"sha1":"93881c774ba82ab62ee50d4a56c7b6f64cd81683","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\nrequests.sessions\n~~~~~~~~~~~~~~~~~\n\nThis module provides a Session object to manage and persist settings across\nrequests (cookies, auth, proxies).\n\"\"\"\nimport os\nimport sys\nimport time\nfrom collections import OrderedDict\nfrom datetime import timedelta\n\nfrom ._internal_utils import to_native_string\nfrom .adapters import HTTPAdapter\nfrom .auth import _basic_auth_str\nfrom .compat import Mapping, cookielib, urljoin, urlparse\nfrom .cookies import (\n    RequestsCookieJar,\n    cookiejar_from_dict,\n    extract_cookies_to_jar,\n    merge_cookies,\n)\nfrom .exceptions import (\n    ChunkedEncodingError,\n    ContentDecodingError,\n    InvalidSchema,\n    TooManyRedirects,\n)\nfrom .hooks import default_hooks, dispatch_hook\n\n# formerly defined here, reexposed here for backward compatibility\nfrom .models import (  # noqa: F401\n    DEFAULT_REDIRECT_LIMIT,\n    REDIRECT_STATI,\n    PreparedRequest,\n    Request,\n)\nfrom .status_codes import codes\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (  # noqa: F401\n    DEFAULT_PORTS,\n    default_headers,\n    get_auth_from_url,\n    get_environ_proxies,\n    get_netrc_auth,\n    requote_uri,\n    resolve_proxies,\n    rewind_body,\n    should_bypass_proxies,\n    to_key_val_list,\n)\n\n# Preferred clock, based on which one is more accurate on a given system.\nif sys.platform == \"win32\":\n    preferred_clock = time.perf_counter\nelse:\n    preferred_clock = time.time\n\n\ndef merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n    \"\"\"Determines appropriate setting for a given request, taking into account\n    the explicit setting on that request, and the setting in the session. If a\n    setting is a dictionary, they will be merged together using `dict_class`\n    \"\"\"\n\n    if session_setting is None:\n        return request_setting\n\n    if request_setting is None:\n        return session_setting\n\n    # Bypass if not a dictionary (e.g. verify)\n    if not (\n        isinstance(session_setting, Mapping) and isinstance(request_setting, Mapping)\n    ):\n        return request_setting\n\n    merged_setting = dict_class(to_key_val_list(session_setting))\n    merged_setting.update(to_key_val_list(request_setting))\n\n    # Remove keys that are set to None. Extract keys first to avoid altering\n    # the dictionary during iteration.\n    none_keys = [k for (k, v) in merged_setting.items() if v is None]\n    for key in none_keys:\n        del merged_setting[key]\n\n    return merged_setting\n\n\ndef merge_hooks(request_hooks, session_hooks, dict_class=OrderedDict):\n    \"\"\"Properly merges both requests and session hooks.\n\n    This is necessary because when request_hooks == {'response': []}, the\n    merge breaks Session hooks entirely.\n    \"\"\"\n    if session_hooks is None or session_hooks.get(\"response\") == []:\n        return request_hooks\n\n    if request_hooks is None or request_hooks.get(\"response\") == []:\n        return session_hooks\n\n    return merge_setting(request_hooks, session_hooks, dict_class)\n\n\nclass SessionRedirectMixin:\n    def get_redirect_target(self, resp):\n        \"\"\"Receives a Response. Returns a redirect URI or ``None``\"\"\"\n        # Due to the nature of how requests processes redirects this method will\n        # be called at least once upon the original response and at least twice\n        # on each subsequent redirect response (if any).\n        # If a custom mixin is used to handle this logic, it may be advantageous\n        # to cache the redirect location onto the response object as a private\n        # attribute.\n        if resp.is_redirect:\n            location = resp.headers[\"location\"]\n            # Currently the underlying http module on py3 decode headers\n            # in latin1, but empirical evidence suggests that latin1 is very\n            # rarely used with non-ASCII characters in HTTP headers.\n            # It is more likely to get UTF8 header rather than latin1.\n            # This causes incorrect handling of UTF8 encoded location headers.\n            # To solve this, we re-encode the location in latin1.\n            location = location.encode(\"latin1\")\n            return to_native_string(location, \"utf8\")\n        return None\n\n    def should_strip_auth(self, old_url, new_url):\n        \"\"\"Decide whether Authorization header should be removed when redirecting\"\"\"\n        old_parsed = urlparse(old_url)\n        new_parsed = urlparse(new_url)\n        if old_parsed.hostname != new_parsed.hostname:\n            return True\n        # Special case: allow http -> https redirect when using the standard\n        # ports. This isn't specified by RFC 7235, but is kept to avoid\n        # breaking backwards compatibility with older versions of requests\n        # that allowed any redirects on the same host.\n        if (\n            old_parsed.scheme == \"http\"\n            and old_parsed.port in (80, None)\n            and new_parsed.scheme == \"https\"\n            and new_parsed.port in (443, None)\n        ):\n            return False\n\n        # Handle default port usage corresponding to scheme.\n        changed_port = old_parsed.port != new_parsed.port\n        changed_scheme = old_parsed.scheme != new_parsed.scheme\n        default_port = (DEFAULT_PORTS.get(old_parsed.scheme, None), None)\n        if (\n            not changed_scheme\n            and old_parsed.port in default_port\n            and new_parsed.port in default_port\n        ):\n            return False\n\n        # Standard case: root URI must match\n        return changed_port or changed_scheme\n\n    def resolve_redirects(\n        self,\n        resp,\n        req,\n        stream=False,\n        timeout=None,\n        verify=True,\n        cert=None,\n        proxies=None,\n        yield_requests=False,\n        **adapter_kwargs,\n    ):\n        \"\"\"Receives a Response. Returns a generator of Responses or Requests.\"\"\"\n\n        hist = []  # keep track of history\n\n        url = self.get_redirect_target(resp)\n        previous_fragment = urlparse(req.url).fragment\n        while url:\n            prepared_request = req.copy()\n\n            # Update history and keep track of redirects.\n            # resp.history must ignore the original request in this loop\n            hist.append(resp)\n            resp.history = hist[1:]\n\n            try:\n                resp.content  # Consume socket so it can be released\n            except (ChunkedEncodingError, ContentDecodingError, RuntimeError):\n                resp.raw.read(decode_content=False)\n\n            if len(resp.history) >= self.max_redirects:\n                raise TooManyRedirects(\n                    f\"Exceeded {self.max_redirects} redirects.\", response=resp\n                )\n\n            # Release the connection back into the pool.\n            resp.close()\n\n            # Handle redirection without scheme (see: RFC 1808 Section 4)\n            if url.startswith(\"//\"):\n                parsed_rurl = urlparse(resp.url)\n                url = \":\".join([to_native_string(parsed_rurl.scheme), url])\n\n            # Normalize url case and attach previous fragment if needed (RFC 7231 7.1.2)\n            parsed = urlparse(url)\n            if parsed.fragment == \"\" and previous_fragment:\n                parsed = parsed._replace(fragment=previous_fragment)\n            elif parsed.fragment:\n                previous_fragment = parsed.fragment\n            url = parsed.geturl()\n\n            # Facilitate relative 'location' headers, as allowed by RFC 7231.\n            # (e.g. '/path/to/resource' instead of 'http://domain.tld/path/to/resource')\n            # Compliant with RFC3986, we percent encode the url.\n            if not parsed.netloc:\n                url = urljoin(resp.url, requote_uri(url))\n            else:\n                url = requote_uri(url)\n\n            prepared_request.url = to_native_string(url)\n\n            self.rebuild_method(prepared_request, resp)\n\n            # https://github.com/psf/requests/issues/1084\n            if resp.status_code not in (\n                codes.temporary_redirect,\n                codes.permanent_redirect,\n            ):\n                # https://github.com/psf/requests/issues/3490\n                purged_headers = (\"Content-Length\", \"Content-Type\", \"Transfer-Encoding\")\n                for header in purged_headers:\n                    prepared_request.headers.pop(header, None)\n                prepared_request.body = None\n\n            headers = prepared_request.headers\n            headers.pop(\"Cookie\", None)\n\n            # Extract any cookies sent on the response to the cookiejar\n            # in the new request. Because we've mutated our copied prepared\n            # request, use the old one that we haven't yet touched.\n            extract_cookies_to_jar(prepared_request._cookies, req, resp.raw)\n            merge_cookies(prepared_request._cookies, self.cookies)\n            prepared_request.prepare_cookies(prepared_request._cookies)\n\n            # Rebuild auth and proxy information.\n            proxies = self.rebuild_proxies(prepared_request, proxies)\n            self.rebuild_auth(prepared_request, resp)\n\n            # A failed tell() sets `_body_position` to `object()`. This non-None\n            # value ensures `rewindable` will be True, allowing us to raise an\n            # UnrewindableBodyError, instead of hanging the connection.\n            rewindable = prepared_request._body_position is not None and (\n                \"Content-Length\" in headers or \"Transfer-Encoding\" in headers\n            )\n\n            # Attempt to rewind consumed file-like object.\n            if rewindable:\n                rewind_body(prepared_request)\n\n            # Override the original request.\n            req = prepared_request\n\n            if yield_requests:\n                yield req\n            else:\n                resp = self.send(\n                    req,\n                    stream=stream,\n                    timeout=timeout,\n                    verify=verify,\n                    cert=cert,\n                    proxies=proxies,\n                    allow_redirects=False,\n                    **adapter_kwargs,\n                )\n\n                extract_cookies_to_jar(self.cookies, prepared_request, resp.raw)\n\n                # extract redirect url, if any, for the next loop\n                url = self.get_redirect_target(resp)\n                yield resp\n\n    def rebuild_auth(self, prepared_request, response):\n        \"\"\"When being redirected we may want to strip authentication from the\n        request to avoid leaking credentials. This method intelligently removes\n        and reapplies authentication where possible to avoid credential loss.\n        \"\"\"\n        headers = prepared_request.headers\n        url = prepared_request.url\n\n        if \"Authorization\" in headers and self.should_strip_auth(\n            response.request.url, url\n        ):\n            # If we get redirected to a new host, we should strip out any\n            # authentication headers.\n            del headers[\"Authorization\"]\n\n        # .netrc might have more auth for us on our new host.\n        new_auth = get_netrc_auth(url) if self.trust_env else None\n        if new_auth is not None:\n            prepared_request.prepare_auth(new_auth)\n\n    def rebuild_proxies(self, prepared_request, proxies):\n        \"\"\"This method re-evaluates the proxy configuration by considering the\n        environment variables. If we are redirected to a URL covered by\n        NO_PROXY, we strip the proxy configuration. Otherwise, we set missing\n        proxy keys for this URL (in case they were stripped by a previous\n        redirect).\n\n        This method also replaces the Proxy-Authorization header where\n        necessary.\n\n        :rtype: dict\n        \"\"\"\n        headers = prepared_request.headers\n        scheme = urlparse(prepared_request.url).scheme\n        new_proxies = resolve_proxies(prepared_request, proxies, self.trust_env)\n\n        if \"Proxy-Authorization\" in headers:\n            del headers[\"Proxy-Authorization\"]\n\n        try:\n            username, password = get_auth_from_url(new_proxies[scheme])\n        except KeyError:\n            username, password = None, None\n\n        # urllib3 handles proxy authorization for us in the standard adapter.\n        # Avoid appending this to TLS tunneled requests where it may be leaked.\n        if not scheme.startswith(\"https\") and username and password:\n            headers[\"Proxy-Authorization\"] = _basic_auth_str(username, password)\n\n        return new_proxies\n\n    def rebuild_method(self, prepared_request, response):\n        \"\"\"When being redirected we may want to change the method of the request\n        based on certain specs or browser behavior.\n        \"\"\"\n        method = prepared_request.method\n\n        # https://tools.ietf.org/html/rfc7231#section-6.4.4\n        if response.status_code == codes.see_other and method != \"HEAD\":\n            method = \"GET\"\n\n        # Do what the browsers do, despite standards...\n        # First, turn 302s into GETs.\n        if response.status_code == codes.found and method != \"HEAD\":\n            method = \"GET\"\n\n        # Second, if a POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == \"POST\":\n            method = \"GET\"\n\n        prepared_request.method = method\n\n\nclass Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n\n    Provides cookie persistence, connection-pooling, and configuration.\n\n    Basic Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('https://httpbin.org/get')\n      <Response [200]>\n\n    Or as a context manager::\n\n      >>> with requests.Session() as s:\n      ...     s.get('https://httpbin.org/get')\n      <Response [200]>\n    \"\"\"\n\n    __attrs__ = [\n        \"headers\",\n        \"cookies\",\n        \"auth\",\n        \"proxies\",\n        \"hooks\",\n        \"params\",\n        \"verify\",\n        \"cert\",\n        \"adapters\",\n        \"stream\",\n        \"trust_env\",\n        \"max_redirects\",\n    ]\n\n    def __init__(self):\n        #: A case-insensitive dictionary of headers to be sent on each\n        #: :class:`Request <Request>` sent from this\n        #: :class:`Session <Session>`.\n        self.headers = default_headers()\n\n        #: Default Authentication tuple or object to attach to\n        #: :class:`Request <Request>`.\n        self.auth = None\n\n        #: Dictionary mapping protocol or protocol and host to the URL of the proxy\n        #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to\n        #: be used on each :class:`Request <Request>`.\n        self.proxies = {}\n\n        #: Event-handling hooks.\n        self.hooks = default_hooks()\n\n        #: Dictionary of querystring data to attach to each\n        #: :class:`Request <Request>`. The dictionary values may be lists for\n        #: representing multivalued query parameters.\n        self.params = {}\n\n        #: Stream response content default.\n        self.stream = False\n\n        #: SSL Verification default.\n        #: Defaults to `True`, requiring requests to verify the TLS certificate at the\n        #: remote end.\n        #: If verify is set to `False`, requests will accept any TLS certificate\n        #: presented by the server, and will ignore hostname mismatches and/or\n        #: expired certificates, which will make your application vulnerable to\n        #: man-in-the-middle (MitM) attacks.\n        #: Only set this to `False` for testing.\n        self.verify = True\n\n        #: SSL client certificate default, if String, path to ssl client\n        #: cert file (.pem). If Tuple, ('cert', 'key') pair.\n        self.cert = None\n\n        #: Maximum number of redirects allowed. If the request exceeds this\n        #: limit, a :class:`TooManyRedirects` exception is raised.\n        #: This defaults to requests.models.DEFAULT_REDIRECT_LIMIT, which is\n        #: 30.\n        self.max_redirects = DEFAULT_REDIRECT_LIMIT\n\n        #: Trust environment settings for proxy configuration, default\n        #: authentication and similar.\n        self.trust_env = True\n\n        #: A CookieJar containing all currently outstanding cookies set on this\n        #: session. By default it is a\n        #: :class:`RequestsCookieJar <requests.cookies.RequestsCookieJar>`, but\n        #: may be any other ``cookielib.CookieJar`` compatible object.\n        self.cookies = cookiejar_from_dict({})\n\n        # Default connection adapters.\n        self.adapters = OrderedDict()\n        self.mount(\"https://\", HTTPAdapter())\n        self.mount(\"http://\", HTTPAdapter())\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self.close()\n\n    def prepare_request(self, request):\n        \"\"\"Constructs a :class:`PreparedRequest <PreparedRequest>` for\n        transmission and returns it. The :class:`PreparedRequest` has settings\n        merged from the :class:`Request <Request>` instance and those of the\n        :class:`Session`.\n\n        :param request: :class:`Request` instance to prepare with this\n            session's settings.\n        :rtype: requests.PreparedRequest\n        \"\"\"\n        cookies = request.cookies or {}\n\n        # Bootstrap CookieJar.\n        if not isinstance(cookies, cookielib.CookieJar):\n            cookies = cookiejar_from_dict(cookies)\n\n        # Merge with session cookies\n        merged_cookies = merge_cookies(\n            merge_cookies(RequestsCookieJar(), self.cookies), cookies\n        )\n\n        # Set environment's basic authentication if not explicitly set.\n        auth = request.auth\n        if self.trust_env and not auth and not self.auth:\n            auth = get_netrc_auth(request.url)\n\n        p = PreparedRequest()\n        p.prepare(\n            method=request.method.upper(),\n            url=request.url,\n            files=request.files,\n            data=request.data,\n            json=request.json,\n            headers=merge_setting(\n                request.headers, self.headers, dict_class=CaseInsensitiveDict\n            ),\n            params=merge_setting(request.params, self.params),\n            auth=merge_setting(auth, self.auth),\n            cookies=merged_cookies,\n            hooks=merge_hooks(request.hooks, self.hooks),\n        )\n        return p\n\n    def request(\n        self,\n        method,\n        url,\n        params=None,\n        data=None,\n        headers=None,\n        cookies=None,\n        files=None,\n        auth=None,\n        timeout=None,\n        allow_redirects=True,\n        proxies=None,\n        hooks=None,\n        stream=None,\n        verify=None,\n        cert=None,\n        json=None,\n    ):\n        \"\"\"Constructs a :class:`Request <Request>`, prepares it and sends it.\n        Returns :class:`Response <Response>` object.\n\n        :param method: method for the new :class:`Request` object.\n        :param url: URL for the new :class:`Request` object.\n        :param params: (optional) Dictionary or bytes to be sent in the query\n            string for the :class:`Request`.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n            object to send in the body of the :class:`Request`.\n        :param json: (optional) json to send in the body of the\n            :class:`Request`.\n        :param headers: (optional) Dictionary of HTTP Headers to send with the\n            :class:`Request`.\n        :param cookies: (optional) Dict or CookieJar object to send with the\n            :class:`Request`.\n        :param files: (optional) Dictionary of ``'filename': file-like-objects``\n            for multipart encoding upload.\n        :param auth: (optional) Auth tuple or callable to enable\n            Basic/Digest/Custom HTTP Auth.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple\n        :param allow_redirects: (optional) Set to True by default.\n        :type allow_redirects: bool\n        :param proxies: (optional) Dictionary mapping protocol or protocol and\n            hostname to the URL of the proxy.\n        :param hooks: (optional) Dictionary mapping hook name to one event or\n            list of events, event must be callable.\n        :param stream: (optional) whether to immediately download the response\n            content. Defaults to ``False``.\n        :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use. Defaults to ``True``. When set to\n            ``False``, requests will accept any TLS certificate presented by\n            the server, and will ignore hostname mismatches and/or expired\n            certificates, which will make your application vulnerable to\n            man-in-the-middle (MitM) attacks. Setting verify to ``False``\n            may be useful during local development or testing.\n        :param cert: (optional) if String, path to ssl client cert file (.pem).\n            If Tuple, ('cert', 'key') pair.\n        :rtype: requests.Response\n        \"\"\"\n        # Create the Request.\n        req = Request(\n            method=method.upper(),\n            url=url,\n            headers=headers,\n            files=files,\n            data=data or {},\n            json=json,\n            params=params or {},\n            auth=auth,\n            cookies=cookies,\n            hooks=hooks,\n        )\n        prep = self.prepare_request(req)\n\n        proxies = proxies or {}\n\n        settings = self.merge_environment_settings(\n            prep.url, proxies, stream, verify, cert\n        )\n\n        # Send the request.\n        send_kwargs = {\n            \"timeout\": timeout,\n            \"allow_redirects\": allow_redirects,\n        }\n        send_kwargs.update(settings)\n        resp = self.send(prep, **send_kwargs)\n\n        return resp\n\n    def get(self, url, **kwargs):\n        r\"\"\"Sends a GET request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        kwargs.setdefault(\"allow_redirects\", True)\n        return self.request(\"GET\", url, **kwargs)\n\n    def options(self, url, **kwargs):\n        r\"\"\"Sends a OPTIONS request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        kwargs.setdefault(\"allow_redirects\", True)\n        return self.request(\"OPTIONS\", url, **kwargs)\n\n    def head(self, url, **kwargs):\n        r\"\"\"Sends a HEAD request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        kwargs.setdefault(\"allow_redirects\", False)\n        return self.request(\"HEAD\", url, **kwargs)\n\n    def post(self, url, data=None, json=None, **kwargs):\n        r\"\"\"Sends a POST request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n            object to send in the body of the :class:`Request`.\n        :param json: (optional) json to send in the body of the :class:`Request`.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        return self.request(\"POST\", url, data=data, json=json, **kwargs)\n\n    def put(self, url, data=None, **kwargs):\n        r\"\"\"Sends a PUT request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n            object to send in the body of the :class:`Request`.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        return self.request(\"PUT\", url, data=data, **kwargs)\n\n    def patch(self, url, data=None, **kwargs):\n        r\"\"\"Sends a PATCH request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n            object to send in the body of the :class:`Request`.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        return self.request(\"PATCH\", url, data=data, **kwargs)\n\n    def delete(self, url, **kwargs):\n        r\"\"\"Sends a DELETE request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        return self.request(\"DELETE\", url, **kwargs)\n\n    def send(self, request, **kwargs):\n        \"\"\"Send a given PreparedRequest.\n\n        :rtype: requests.Response\n        \"\"\"\n        # Set defaults that the hooks can utilize to ensure they always have\n        # the correct parameters to reproduce the previous request.\n        kwargs.setdefault(\"stream\", self.stream)\n        kwargs.setdefault(\"verify\", self.verify)\n        kwargs.setdefault(\"cert\", self.cert)\n        if \"proxies\" not in kwargs:\n            kwargs[\"proxies\"] = resolve_proxies(request, self.proxies, self.trust_env)\n\n        # It's possible that users might accidentally send a Request object.\n        # Guard against that specific failure case.\n        if isinstance(request, Request):\n            raise ValueError(\"You can only send PreparedRequests.\")\n\n        # Set up variables needed for resolve_redirects and dispatching of hooks\n        allow_redirects = kwargs.pop(\"allow_redirects\", True)\n        stream = kwargs.get(\"stream\")\n        hooks = request.hooks\n\n        # Get the appropriate adapter to use\n        adapter = self.get_adapter(url=request.url)\n\n        # Start time (approximately) of the request\n        start = preferred_clock()\n\n        # Send the request\n        r = adapter.send(request, **kwargs)\n\n        # Total elapsed time of the request (approximately)\n        elapsed = preferred_clock() - start\n        r.elapsed = timedelta(seconds=elapsed)\n\n        # Response manipulation hooks\n        r = dispatch_hook(\"response\", hooks, r, **kwargs)\n\n        # Persist cookies\n        if r.history:\n            # If the hooks create history then we want those cookies too\n            for resp in r.history:\n                extract_cookies_to_jar(self.cookies, resp.request, resp.raw)\n\n        extract_cookies_to_jar(self.cookies, request, r.raw)\n\n        # Resolve redirects if allowed.\n        if allow_redirects:\n            # Redirect resolving generator.\n            gen = self.resolve_redirects(r, request, **kwargs)\n            history = [resp for resp in gen]\n        else:\n            history = []\n\n        # Shuffle things around if there's history.\n        if history:\n            # Insert the first (original) request at the start\n            history.insert(0, r)\n            # Get the last request made\n            r = history.pop()\n            r.history = history\n\n        # If redirects aren't being followed, store the response on the Request for Response.next().\n        if not allow_redirects:\n            try:\n                r._next = next(\n                    self.resolve_redirects(r, request, yield_requests=True, **kwargs)\n                )\n            except StopIteration:\n                pass\n\n        if not stream:\n            r.content\n\n        return r\n\n    def merge_environment_settings(self, url, proxies, stream, verify, cert):\n        \"\"\"\n        Check the environment and merge it with some settings.\n\n        :rtype: dict\n        \"\"\"\n        # Gather clues from the surrounding environment.\n        if self.trust_env:\n            # Set environment's proxies.\n            no_proxy = proxies.get(\"no_proxy\") if proxies is not None else None\n            env_proxies = get_environ_proxies(url, no_proxy=no_proxy)\n            for k, v in env_proxies.items():\n                proxies.setdefault(k, v)\n\n            # Look for requests environment configuration\n            # and be compatible with cURL.\n            if verify is True or verify is None:\n                verify = (\n                    os.environ.get(\"REQUESTS_CA_BUNDLE\")\n                    or os.environ.get(\"CURL_CA_BUNDLE\")\n                    or verify\n                )\n\n        # Merge all the kwargs.\n        proxies = merge_setting(proxies, self.proxies)\n        stream = merge_setting(stream, self.stream)\n        verify = merge_setting(verify, self.verify)\n        cert = merge_setting(cert, self.cert)\n\n        return {\"proxies\": proxies, \"stream\": stream, \"verify\": verify, \"cert\": cert}\n\n    def get_adapter(self, url):\n        \"\"\"\n        Returns the appropriate connection adapter for the given URL.\n\n        :rtype: requests.adapters.BaseAdapter\n        \"\"\"\n        for prefix, adapter in self.adapters.items():\n            if url.lower().startswith(prefix.lower()):\n                return adapter\n\n        # Nothing matches :-/\n        raise InvalidSchema(f\"No connection adapters were found for {url!r}\")\n\n    def close(self):\n        \"\"\"Closes all adapters and as such the session\"\"\"\n        for v in self.adapters.values():\n            v.close()\n\n    def mount(self, prefix, adapter):\n        \"\"\"Registers a connection adapter to a prefix.\n\n        Adapters are sorted in descending order by prefix length.\n        \"\"\"\n        self.adapters[prefix] = adapter\n        keys_to_move = [k for k in self.adapters if len(k) < len(prefix)]\n\n        for key in keys_to_move:\n            self.adapters[key] = self.adapters.pop(key)\n\n    def __getstate__(self):\n        state = {attr: getattr(self, attr, None) for attr in self.__attrs__}\n        return state\n\n    def __setstate__(self, state):\n        for attr, value in state.items():\n            setattr(self, attr, value)\n\n\ndef session():\n    \"\"\"\n    Returns a :class:`Session` for context-management.\n\n    .. deprecated:: 1.0.0\n\n        This method has been deprecated since version 1.0.0 and is only kept for\n        backwards compatibility. New code should use :class:`~requests.sessions.Session`\n        to create a session. This may be removed at a future date.\n\n    :rtype: Session\n    \"\"\"\n    return Session()\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/requests/status_codes.py","size":4322,"sha1":"cf59c07d2dfa28475074b8592db1fe8024a02b9b","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"r\"\"\"\nThe ``codes`` object defines a mapping from common names for HTTP statuses\nto their numerical codes, accessible either as attributes or as dictionary\nitems.\n\nExample::\n\n    >>> import requests\n    >>> requests.codes['temporary_redirect']\n    307\n    >>> requests.codes.teapot\n    418\n    >>> requests.codes['\\o/']\n    200\n\nSome codes have multiple names, and both upper- and lower-case versions of\nthe names are allowed. For example, ``codes.ok``, ``codes.OK``, and\n``codes.okay`` all correspond to the HTTP status code 200.\n\"\"\"\n\nfrom .structures import LookupDict\n\n_codes = {\n    # Informational.\n    100: (\"continue\",),\n    101: (\"switching_protocols\",),\n    102: (\"processing\", \"early-hints\"),\n    103: (\"checkpoint\",),\n    122: (\"uri_too_long\", \"request_uri_too_long\"),\n    200: (\"ok\", \"okay\", \"all_ok\", \"all_okay\", \"all_good\", \"\\\\o/\", \"✓\"),\n    201: (\"created\",),\n    202: (\"accepted\",),\n    203: (\"non_authoritative_info\", \"non_authoritative_information\"),\n    204: (\"no_content\",),\n    205: (\"reset_content\", \"reset\"),\n    206: (\"partial_content\", \"partial\"),\n    207: (\"multi_status\", \"multiple_status\", \"multi_stati\", \"multiple_stati\"),\n    208: (\"already_reported\",),\n    226: (\"im_used\",),\n    # Redirection.\n    300: (\"multiple_choices\",),\n    301: (\"moved_permanently\", \"moved\", \"\\\\o-\"),\n    302: (\"found\",),\n    303: (\"see_other\", \"other\"),\n    304: (\"not_modified\",),\n    305: (\"use_proxy\",),\n    306: (\"switch_proxy\",),\n    307: (\"temporary_redirect\", \"temporary_moved\", \"temporary\"),\n    308: (\n        \"permanent_redirect\",\n        \"resume_incomplete\",\n        \"resume\",\n    ),  # \"resume\" and \"resume_incomplete\" to be removed in 3.0\n    # Client Error.\n    400: (\"bad_request\", \"bad\"),\n    401: (\"unauthorized\",),\n    402: (\"payment_required\", \"payment\"),\n    403: (\"forbidden\",),\n    404: (\"not_found\", \"-o-\"),\n    405: (\"method_not_allowed\", \"not_allowed\"),\n    406: (\"not_acceptable\",),\n    407: (\"proxy_authentication_required\", \"proxy_auth\", \"proxy_authentication\"),\n    408: (\"request_timeout\", \"timeout\"),\n    409: (\"conflict\",),\n    410: (\"gone\",),\n    411: (\"length_required\",),\n    412: (\"precondition_failed\", \"precondition\"),\n    413: (\"request_entity_too_large\", \"content_too_large\"),\n    414: (\"request_uri_too_large\", \"uri_too_long\"),\n    415: (\"unsupported_media_type\", \"unsupported_media\", \"media_type\"),\n    416: (\n        \"requested_range_not_satisfiable\",\n        \"requested_range\",\n        \"range_not_satisfiable\",\n    ),\n    417: (\"expectation_failed\",),\n    418: (\"im_a_teapot\", \"teapot\", \"i_am_a_teapot\"),\n    421: (\"misdirected_request\",),\n    422: (\"unprocessable_entity\", \"unprocessable\", \"unprocessable_content\"),\n    423: (\"locked\",),\n    424: (\"failed_dependency\", \"dependency\"),\n    425: (\"unordered_collection\", \"unordered\", \"too_early\"),\n    426: (\"upgrade_required\", \"upgrade\"),\n    428: (\"precondition_required\", \"precondition\"),\n    429: (\"too_many_requests\", \"too_many\"),\n    431: (\"header_fields_too_large\", \"fields_too_large\"),\n    444: (\"no_response\", \"none\"),\n    449: (\"retry_with\", \"retry\"),\n    450: (\"blocked_by_windows_parental_controls\", \"parental_controls\"),\n    451: (\"unavailable_for_legal_reasons\", \"legal_reasons\"),\n    499: (\"client_closed_request\",),\n    # Server Error.\n    500: (\"internal_server_error\", \"server_error\", \"/o\\\\\", \"✗\"),\n    501: (\"not_implemented\",),\n    502: (\"bad_gateway\",),\n    503: (\"service_unavailable\", \"unavailable\"),\n    504: (\"gateway_timeout\",),\n    505: (\"http_version_not_supported\", \"http_version\"),\n    506: (\"variant_also_negotiates\",),\n    507: (\"insufficient_storage\",),\n    509: (\"bandwidth_limit_exceeded\", \"bandwidth\"),\n    510: (\"not_extended\",),\n    511: (\"network_authentication_required\", \"network_auth\", \"network_authentication\"),\n}\n\ncodes = LookupDict(name=\"status_codes\")\n\n\ndef _init():\n    for code, titles in _codes.items():\n        for title in titles:\n            setattr(codes, title, code)\n            if not title.startswith((\"\\\\\", \"/\")):\n                setattr(codes, title.upper(), code)\n\n    def doc(code):\n        names = \", \".join(f\"``{n}``\" for n in _codes[code])\n        return \"* %d: %s\" % (code, names)\n\n    global __doc__\n    __doc__ = (\n        __doc__ + \"\\n\" + \"\\n\".join(doc(code) for code in sorted(_codes))\n        if __doc__ is not None\n        else None\n    )\n\n\n_init()\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/requests/structures.py","size":2912,"sha1":"b5c2c740b9ff7d27a83ac4c80e3ae741aa33b5be","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\nrequests.structures\n~~~~~~~~~~~~~~~~~~~\n\nData structures that power Requests.\n\"\"\"\n\nfrom collections import OrderedDict\n\nfrom .compat import Mapping, MutableMapping\n\n\nclass CaseInsensitiveDict(MutableMapping):\n    \"\"\"A case-insensitive ``dict``-like object.\n\n    Implements all methods and operations of\n    ``MutableMapping`` as well as dict's ``copy``. Also\n    provides ``lower_items``.\n\n    All keys are expected to be strings. The structure remembers the\n    case of the last key to be set, and ``iter(instance)``,\n    ``keys()``, ``items()``, ``iterkeys()``, and ``iteritems()``\n    will contain case-sensitive keys. However, querying and contains\n    testing is case insensitive::\n\n        cid = CaseInsensitiveDict()\n        cid['Accept'] = 'application/json'\n        cid['aCCEPT'] == 'application/json'  # True\n        list(cid) == ['Accept']  # True\n\n    For example, ``headers['content-encoding']`` will return the\n    value of a ``'Content-Encoding'`` response header, regardless\n    of how the header name was originally stored.\n\n    If the constructor, ``.update``, or equality comparison\n    operations are given keys that have equal ``.lower()``s, the\n    behavior is undefined.\n    \"\"\"\n\n    def __init__(self, data=None, **kwargs):\n        self._store = OrderedDict()\n        if data is None:\n            data = {}\n        self.update(data, **kwargs)\n\n    def __setitem__(self, key, value):\n        # Use the lowercased key for lookups, but store the actual\n        # key alongside the value.\n        self._store[key.lower()] = (key, value)\n\n    def __getitem__(self, key):\n        return self._store[key.lower()][1]\n\n    def __delitem__(self, key):\n        del self._store[key.lower()]\n\n    def __iter__(self):\n        return (casedkey for casedkey, mappedvalue in self._store.values())\n\n    def __len__(self):\n        return len(self._store)\n\n    def lower_items(self):\n        \"\"\"Like iteritems(), but with all lowercase keys.\"\"\"\n        return ((lowerkey, keyval[1]) for (lowerkey, keyval) in self._store.items())\n\n    def __eq__(self, other):\n        if isinstance(other, Mapping):\n            other = CaseInsensitiveDict(other)\n        else:\n            return NotImplemented\n        # Compare insensitively\n        return dict(self.lower_items()) == dict(other.lower_items())\n\n    # Copy is required\n    def copy(self):\n        return CaseInsensitiveDict(self._store.values())\n\n    def __repr__(self):\n        return str(dict(self.items()))\n\n\nclass LookupDict(dict):\n    \"\"\"Dictionary lookup object.\"\"\"\n\n    def __init__(self, name=None):\n        self.name = name\n        super().__init__()\n\n    def __repr__(self):\n        return f\"<lookup '{self.name}'>\"\n\n    def __getitem__(self, key):\n        # We allow fall-through here, so values default to None\n\n        return self.__dict__.get(key, None)\n\n    def get(self, key, default=None):\n        return self.__dict__.get(key, default)\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/requests/utils.py","size":33631,"sha1":"735f3ef3c60d3fe922745d1142dc2fae6a61bacc","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"\nrequests.utils\n~~~~~~~~~~~~~~\n\nThis module provides utility functions that are used within Requests\nthat are also useful for external consumption.\n\"\"\"\n\nimport codecs\nimport contextlib\nimport io\nimport os\nimport re\nimport socket\nimport struct\nimport sys\nimport tempfile\nimport warnings\nimport zipfile\nfrom collections import OrderedDict\n\nfrom pip._vendor.urllib3.util import make_headers, parse_url\n\nfrom . import certs\nfrom .__version__ import __version__\n\n# to_native_string is unused here, but imported here for backwards compatibility\nfrom ._internal_utils import (  # noqa: F401\n    _HEADER_VALIDATORS_BYTE,\n    _HEADER_VALIDATORS_STR,\n    HEADER_VALIDATORS,\n    to_native_string,\n)\nfrom .compat import (\n    Mapping,\n    basestring,\n    bytes,\n    getproxies,\n    getproxies_environment,\n    integer_types,\n)\nfrom .compat import parse_http_list as _parse_list_header\nfrom .compat import (\n    proxy_bypass,\n    proxy_bypass_environment,\n    quote,\n    str,\n    unquote,\n    urlparse,\n    urlunparse,\n)\nfrom .cookies import cookiejar_from_dict\nfrom .exceptions import (\n    FileModeWarning,\n    InvalidHeader,\n    InvalidURL,\n    UnrewindableBodyError,\n)\nfrom .structures import CaseInsensitiveDict\n\nNETRC_FILES = (\".netrc\", \"_netrc\")\n\nDEFAULT_CA_BUNDLE_PATH = certs.where()\n\nDEFAULT_PORTS = {\"http\": 80, \"https\": 443}\n\n# Ensure that ', ' is used to preserve previous delimiter behavior.\nDEFAULT_ACCEPT_ENCODING = \", \".join(\n    re.split(r\",\\s*\", make_headers(accept_encoding=True)[\"accept-encoding\"])\n)\n\n\nif sys.platform == \"win32\":\n    # provide a proxy_bypass version on Windows without DNS lookups\n\n    def proxy_bypass_registry(host):\n        try:\n            import winreg\n        except ImportError:\n            return False\n\n        try:\n            internetSettings = winreg.OpenKey(\n                winreg.HKEY_CURRENT_USER,\n                r\"Software\\Microsoft\\Windows\\CurrentVersion\\Internet Settings\",\n            )\n            # ProxyEnable could be REG_SZ or REG_DWORD, normalizing it\n            proxyEnable = int(winreg.QueryValueEx(internetSettings, \"ProxyEnable\")[0])\n            # ProxyOverride is almost always a string\n            proxyOverride = winreg.QueryValueEx(internetSettings, \"ProxyOverride\")[0]\n        except (OSError, ValueError):\n            return False\n        if not proxyEnable or not proxyOverride:\n            return False\n\n        # make a check value list from the registry entry: replace the\n        # '<local>' string by the localhost entry and the corresponding\n        # canonical entry.\n        proxyOverride = proxyOverride.split(\";\")\n        # filter out empty strings to avoid re.match return true in the following code.\n        proxyOverride = filter(None, proxyOverride)\n        # now check if we match one of the registry values.\n        for test in proxyOverride:\n            if test == \"<local>\":\n                if \".\" not in host:\n                    return True\n            test = test.replace(\".\", r\"\\.\")  # mask dots\n            test = test.replace(\"*\", r\".*\")  # change glob sequence\n            test = test.replace(\"?\", r\".\")  # change glob char\n            if re.match(test, host, re.I):\n                return True\n        return False\n\n    def proxy_bypass(host):  # noqa\n        \"\"\"Return True, if the host should be bypassed.\n\n        Checks proxy settings gathered from the environment, if specified,\n        or the registry.\n        \"\"\"\n        if getproxies_environment():\n            return proxy_bypass_environment(host)\n        else:\n            return proxy_bypass_registry(host)\n\n\ndef dict_to_sequence(d):\n    \"\"\"Returns an internal sequence dictionary update.\"\"\"\n\n    if hasattr(d, \"items\"):\n        d = d.items()\n\n    return d\n\n\ndef super_len(o):\n    total_length = None\n    current_position = 0\n\n    if isinstance(o, str):\n        o = o.encode(\"utf-8\")\n\n    if hasattr(o, \"__len__\"):\n        total_length = len(o)\n\n    elif hasattr(o, \"len\"):\n        total_length = o.len\n\n    elif hasattr(o, \"fileno\"):\n        try:\n            fileno = o.fileno()\n        except (io.UnsupportedOperation, AttributeError):\n            # AttributeError is a surprising exception, seeing as how we've just checked\n            # that `hasattr(o, 'fileno')`.  It happens for objects obtained via\n            # `Tarfile.extractfile()`, per issue 5229.\n            pass\n        else:\n            total_length = os.fstat(fileno).st_size\n\n            # Having used fstat to determine the file length, we need to\n            # confirm that this file was opened up in binary mode.\n            if \"b\" not in o.mode:\n                warnings.warn(\n                    (\n                        \"Requests has determined the content-length for this \"\n                        \"request using the binary size of the file: however, the \"\n                        \"file has been opened in text mode (i.e. without the 'b' \"\n                        \"flag in the mode). This may lead to an incorrect \"\n                        \"content-length. In Requests 3.0, support will be removed \"\n                        \"for files in text mode.\"\n                    ),\n                    FileModeWarning,\n                )\n\n    if hasattr(o, \"tell\"):\n        try:\n            current_position = o.tell()\n        except OSError:\n            # This can happen in some weird situations, such as when the file\n            # is actually a special file descriptor like stdin. In this\n            # instance, we don't know what the length is, so set it to zero and\n            # let requests chunk it instead.\n            if total_length is not None:\n                current_position = total_length\n        else:\n            if hasattr(o, \"seek\") and total_length is None:\n                # StringIO and BytesIO have seek but no usable fileno\n                try:\n                    # seek to end of file\n                    o.seek(0, 2)\n                    total_length = o.tell()\n\n                    # seek back to current position to support\n                    # partially read file-like objects\n                    o.seek(current_position or 0)\n                except OSError:\n                    total_length = 0\n\n    if total_length is None:\n        total_length = 0\n\n    return max(0, total_length - current_position)\n\n\ndef get_netrc_auth(url, raise_errors=False):\n    \"\"\"Returns the Requests tuple auth for a given url from netrc.\"\"\"\n\n    netrc_file = os.environ.get(\"NETRC\")\n    if netrc_file is not None:\n        netrc_locations = (netrc_file,)\n    else:\n        netrc_locations = (f\"~/{f}\" for f in NETRC_FILES)\n\n    try:\n        from netrc import NetrcParseError, netrc\n\n        netrc_path = None\n\n        for f in netrc_locations:\n            try:\n                loc = os.path.expanduser(f)\n            except KeyError:\n                # os.path.expanduser can fail when $HOME is undefined and\n                # getpwuid fails. See https://bugs.python.org/issue20164 &\n                # https://github.com/psf/requests/issues/1846\n                return\n\n            if os.path.exists(loc):\n                netrc_path = loc\n                break\n\n        # Abort early if there isn't one.\n        if netrc_path is None:\n            return\n\n        ri = urlparse(url)\n\n        # Strip port numbers from netloc. This weird `if...encode`` dance is\n        # used for Python 3.2, which doesn't support unicode literals.\n        splitstr = b\":\"\n        if isinstance(url, str):\n            splitstr = splitstr.decode(\"ascii\")\n        host = ri.netloc.split(splitstr)[0]\n\n        try:\n            _netrc = netrc(netrc_path).authenticators(host)\n            if _netrc:\n                # Return with login / password\n                login_i = 0 if _netrc[0] else 1\n                return (_netrc[login_i], _netrc[2])\n        except (NetrcParseError, OSError):\n            # If there was a parsing error or a permissions issue reading the file,\n            # we'll just skip netrc auth unless explicitly asked to raise errors.\n            if raise_errors:\n                raise\n\n    # App Engine hackiness.\n    except (ImportError, AttributeError):\n        pass\n\n\ndef guess_filename(obj):\n    \"\"\"Tries to guess the filename of the given object.\"\"\"\n    name = getattr(obj, \"name\", None)\n    if name and isinstance(name, basestring) and name[0] != \"<\" and name[-1] != \">\":\n        return os.path.basename(name)\n\n\ndef extract_zipped_paths(path):\n    \"\"\"Replace nonexistent paths that look like they refer to a member of a zip\n    archive with the location of an extracted copy of the target, or else\n    just return the provided path unchanged.\n    \"\"\"\n    if os.path.exists(path):\n        # this is already a valid path, no need to do anything further\n        return path\n\n    # find the first valid part of the provided path and treat that as a zip archive\n    # assume the rest of the path is the name of a member in the archive\n    archive, member = os.path.split(path)\n    while archive and not os.path.exists(archive):\n        archive, prefix = os.path.split(archive)\n        if not prefix:\n            # If we don't check for an empty prefix after the split (in other words, archive remains unchanged after the split),\n            # we _can_ end up in an infinite loop on a rare corner case affecting a small number of users\n            break\n        member = \"/\".join([prefix, member])\n\n    if not zipfile.is_zipfile(archive):\n        return path\n\n    zip_file = zipfile.ZipFile(archive)\n    if member not in zip_file.namelist():\n        return path\n\n    # we have a valid zip archive and a valid member of that archive\n    tmp = tempfile.gettempdir()\n    extracted_path = os.path.join(tmp, member.split(\"/\")[-1])\n    if not os.path.exists(extracted_path):\n        # use read + write to avoid the creating nested folders, we only want the file, avoids mkdir racing condition\n        with atomic_open(extracted_path) as file_handler:\n            file_handler.write(zip_file.read(member))\n    return extracted_path\n\n\n@contextlib.contextmanager\ndef atomic_open(filename):\n    \"\"\"Write a file to the disk in an atomic fashion\"\"\"\n    tmp_descriptor, tmp_name = tempfile.mkstemp(dir=os.path.dirname(filename))\n    try:\n        with os.fdopen(tmp_descriptor, \"wb\") as tmp_handler:\n            yield tmp_handler\n        os.replace(tmp_name, filename)\n    except BaseException:\n        os.remove(tmp_name)\n        raise\n\n\ndef from_key_val_list(value):\n    \"\"\"Take an object and test to see if it can be represented as a\n    dictionary. Unless it can not be represented as such, return an\n    OrderedDict, e.g.,\n\n    ::\n\n        >>> from_key_val_list([('key', 'val')])\n        OrderedDict([('key', 'val')])\n        >>> from_key_val_list('string')\n        Traceback (most recent call last):\n        ...\n        ValueError: cannot encode objects that are not 2-tuples\n        >>> from_key_val_list({'key': 'val'})\n        OrderedDict([('key', 'val')])\n\n    :rtype: OrderedDict\n    \"\"\"\n    if value is None:\n        return None\n\n    if isinstance(value, (str, bytes, bool, int)):\n        raise ValueError(\"cannot encode objects that are not 2-tuples\")\n\n    return OrderedDict(value)\n\n\ndef to_key_val_list(value):\n    \"\"\"Take an object and test to see if it can be represented as a\n    dictionary. If it can be, return a list of tuples, e.g.,\n\n    ::\n\n        >>> to_key_val_list([('key', 'val')])\n        [('key', 'val')]\n        >>> to_key_val_list({'key': 'val'})\n        [('key', 'val')]\n        >>> to_key_val_list('string')\n        Traceback (most recent call last):\n        ...\n        ValueError: cannot encode objects that are not 2-tuples\n\n    :rtype: list\n    \"\"\"\n    if value is None:\n        return None\n\n    if isinstance(value, (str, bytes, bool, int)):\n        raise ValueError(\"cannot encode objects that are not 2-tuples\")\n\n    if isinstance(value, Mapping):\n        value = value.items()\n\n    return list(value)\n\n\n# From mitsuhiko/werkzeug (used with permission).\ndef parse_list_header(value):\n    \"\"\"Parse lists as described by RFC 2068 Section 2.\n\n    In particular, parse comma-separated lists where the elements of\n    the list may include quoted-strings.  A quoted-string could\n    contain a comma.  A non-quoted string could have quotes in the\n    middle.  Quotes are removed automatically after parsing.\n\n    It basically works like :func:`parse_set_header` just that items\n    may appear multiple times and case sensitivity is preserved.\n\n    The return value is a standard :class:`list`:\n\n    >>> parse_list_header('token, \"quoted value\"')\n    ['token', 'quoted value']\n\n    To create a header from the :class:`list` again, use the\n    :func:`dump_header` function.\n\n    :param value: a string with a list header.\n    :return: :class:`list`\n    :rtype: list\n    \"\"\"\n    result = []\n    for item in _parse_list_header(value):\n        if item[:1] == item[-1:] == '\"':\n            item = unquote_header_value(item[1:-1])\n        result.append(item)\n    return result\n\n\n# From mitsuhiko/werkzeug (used with permission).\ndef parse_dict_header(value):\n    \"\"\"Parse lists of key, value pairs as described by RFC 2068 Section 2 and\n    convert them into a python dict:\n\n    >>> d = parse_dict_header('foo=\"is a fish\", bar=\"as well\"')\n    >>> type(d) is dict\n    True\n    >>> sorted(d.items())\n    [('bar', 'as well'), ('foo', 'is a fish')]\n\n    If there is no value for a key it will be `None`:\n\n    >>> parse_dict_header('key_without_value')\n    {'key_without_value': None}\n\n    To create a header from the :class:`dict` again, use the\n    :func:`dump_header` function.\n\n    :param value: a string with a dict header.\n    :return: :class:`dict`\n    :rtype: dict\n    \"\"\"\n    result = {}\n    for item in _parse_list_header(value):\n        if \"=\" not in item:\n            result[item] = None\n            continue\n        name, value = item.split(\"=\", 1)\n        if value[:1] == value[-1:] == '\"':\n            value = unquote_header_value(value[1:-1])\n        result[name] = value\n    return result\n\n\n# From mitsuhiko/werkzeug (used with permission).\ndef unquote_header_value(value, is_filename=False):\n    r\"\"\"Unquotes a header value.  (Reversal of :func:`quote_header_value`).\n    This does not use the real unquoting but what browsers are actually\n    using for quoting.\n\n    :param value: the header value to unquote.\n    :rtype: str\n    \"\"\"\n    if value and value[0] == value[-1] == '\"':\n        # this is not the real unquoting, but fixing this so that the\n        # RFC is met will result in bugs with internet explorer and\n        # probably some other browsers as well.  IE for example is\n        # uploading files with \"C:\\foo\\bar.txt\" as filename\n        value = value[1:-1]\n\n        # if this is a filename and the starting characters look like\n        # a UNC path, then just return the value without quotes.  Using the\n        # replace sequence below on a UNC path has the effect of turning\n        # the leading double slash into a single slash and then\n        # _fix_ie_filename() doesn't work correctly.  See #458.\n        if not is_filename or value[:2] != \"\\\\\\\\\":\n            return value.replace(\"\\\\\\\\\", \"\\\\\").replace('\\\\\"', '\"')\n    return value\n\n\ndef dict_from_cookiejar(cj):\n    \"\"\"Returns a key/value dictionary from a CookieJar.\n\n    :param cj: CookieJar object to extract cookies from.\n    :rtype: dict\n    \"\"\"\n\n    cookie_dict = {cookie.name: cookie.value for cookie in cj}\n    return cookie_dict\n\n\ndef add_dict_to_cookiejar(cj, cookie_dict):\n    \"\"\"Returns a CookieJar from a key/value dictionary.\n\n    :param cj: CookieJar to insert cookies into.\n    :param cookie_dict: Dict of key/values to insert into CookieJar.\n    :rtype: CookieJar\n    \"\"\"\n\n    return cookiejar_from_dict(cookie_dict, cj)\n\n\ndef get_encodings_from_content(content):\n    \"\"\"Returns encodings from given content string.\n\n    :param content: bytestring to extract encodings from.\n    \"\"\"\n    warnings.warn(\n        (\n            \"In requests 3.0, get_encodings_from_content will be removed. For \"\n            \"more information, please see the discussion on issue #2266. (This\"\n            \" warning should only appear once.)\"\n        ),\n        DeprecationWarning,\n    )\n\n    charset_re = re.compile(r'<meta.*?charset=[\"\\']*(.+?)[\"\\'>]', flags=re.I)\n    pragma_re = re.compile(r'<meta.*?content=[\"\\']*;?charset=(.+?)[\"\\'>]', flags=re.I)\n    xml_re = re.compile(r'^<\\?xml.*?encoding=[\"\\']*(.+?)[\"\\'>]')\n\n    return (\n        charset_re.findall(content)\n        + pragma_re.findall(content)\n        + xml_re.findall(content)\n    )\n\n\ndef _parse_content_type_header(header):\n    \"\"\"Returns content type and parameters from given header\n\n    :param header: string\n    :return: tuple containing content type and dictionary of\n         parameters\n    \"\"\"\n\n    tokens = header.split(\";\")\n    content_type, params = tokens[0].strip(), tokens[1:]\n    params_dict = {}\n    items_to_strip = \"\\\"' \"\n\n    for param in params:\n        param = param.strip()\n        if param:\n            key, value = param, True\n            index_of_equals = param.find(\"=\")\n            if index_of_equals != -1:\n                key = param[:index_of_equals].strip(items_to_strip)\n                value = param[index_of_equals + 1 :].strip(items_to_strip)\n            params_dict[key.lower()] = value\n    return content_type, params_dict\n\n\ndef get_encoding_from_headers(headers):\n    \"\"\"Returns encodings from given HTTP Header Dict.\n\n    :param headers: dictionary to extract encoding from.\n    :rtype: str\n    \"\"\"\n\n    content_type = headers.get(\"content-type\")\n\n    if not content_type:\n        return None\n\n    content_type, params = _parse_content_type_header(content_type)\n\n    if \"charset\" in params:\n        return params[\"charset\"].strip(\"'\\\"\")\n\n    if \"text\" in content_type:\n        return \"ISO-8859-1\"\n\n    if \"application/json\" in content_type:\n        # Assume UTF-8 based on RFC 4627: https://www.ietf.org/rfc/rfc4627.txt since the charset was unset\n        return \"utf-8\"\n\n\ndef stream_decode_response_unicode(iterator, r):\n    \"\"\"Stream decodes an iterator.\"\"\"\n\n    if r.encoding is None:\n        yield from iterator\n        return\n\n    decoder = codecs.getincrementaldecoder(r.encoding)(errors=\"replace\")\n    for chunk in iterator:\n        rv = decoder.decode(chunk)\n        if rv:\n            yield rv\n    rv = decoder.decode(b\"\", final=True)\n    if rv:\n        yield rv\n\n\ndef iter_slices(string, slice_length):\n    \"\"\"Iterate over slices of a string.\"\"\"\n    pos = 0\n    if slice_length is None or slice_length <= 0:\n        slice_length = len(string)\n    while pos < len(string):\n        yield string[pos : pos + slice_length]\n        pos += slice_length\n\n\ndef get_unicode_from_response(r):\n    \"\"\"Returns the requested content back in unicode.\n\n    :param r: Response object to get unicode content from.\n\n    Tried:\n\n    1. charset from content-type\n    2. fall back and replace all unicode characters\n\n    :rtype: str\n    \"\"\"\n    warnings.warn(\n        (\n            \"In requests 3.0, get_unicode_from_response will be removed. For \"\n            \"more information, please see the discussion on issue #2266. (This\"\n            \" warning should only appear once.)\"\n        ),\n        DeprecationWarning,\n    )\n\n    tried_encodings = []\n\n    # Try charset from content-type\n    encoding = get_encoding_from_headers(r.headers)\n\n    if encoding:\n        try:\n            return str(r.content, encoding)\n        except UnicodeError:\n            tried_encodings.append(encoding)\n\n    # Fall back:\n    try:\n        return str(r.content, encoding, errors=\"replace\")\n    except TypeError:\n        return r.content\n\n\n# The unreserved URI characters (RFC 3986)\nUNRESERVED_SET = frozenset(\n    \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\" + \"0123456789-._~\"\n)\n\n\ndef unquote_unreserved(uri):\n    \"\"\"Un-escape any percent-escape sequences in a URI that are unreserved\n    characters. This leaves all reserved, illegal and non-ASCII bytes encoded.\n\n    :rtype: str\n    \"\"\"\n    parts = uri.split(\"%\")\n    for i in range(1, len(parts)):\n        h = parts[i][0:2]\n        if len(h) == 2 and h.isalnum():\n            try:\n                c = chr(int(h, 16))\n            except ValueError:\n                raise InvalidURL(f\"Invalid percent-escape sequence: '{h}'\")\n\n            if c in UNRESERVED_SET:\n                parts[i] = c + parts[i][2:]\n            else:\n                parts[i] = f\"%{parts[i]}\"\n        else:\n            parts[i] = f\"%{parts[i]}\"\n    return \"\".join(parts)\n\n\ndef requote_uri(uri):\n    \"\"\"Re-quote the given URI.\n\n    This function passes the given URI through an unquote/quote cycle to\n    ensure that it is fully and consistently quoted.\n\n    :rtype: str\n    \"\"\"\n    safe_with_percent = \"!#$%&'()*+,/:;=?@[]~\"\n    safe_without_percent = \"!#$&'()*+,/:;=?@[]~\"\n    try:\n        # Unquote only the unreserved characters\n        # Then quote only illegal characters (do not quote reserved,\n        # unreserved, or '%')\n        return quote(unquote_unreserved(uri), safe=safe_with_percent)\n    except InvalidURL:\n        # We couldn't unquote the given URI, so let's try quoting it, but\n        # there may be unquoted '%'s in the URI. We need to make sure they're\n        # properly quoted so they do not cause issues elsewhere.\n        return quote(uri, safe=safe_without_percent)\n\n\ndef address_in_network(ip, net):\n    \"\"\"This function allows you to check if an IP belongs to a network subnet\n\n    Example: returns True if ip = 192.168.1.1 and net = 192.168.1.0/24\n             returns False if ip = 192.168.1.1 and net = 192.168.100.0/24\n\n    :rtype: bool\n    \"\"\"\n    ipaddr = struct.unpack(\"=L\", socket.inet_aton(ip))[0]\n    netaddr, bits = net.split(\"/\")\n    netmask = struct.unpack(\"=L\", socket.inet_aton(dotted_netmask(int(bits))))[0]\n    network = struct.unpack(\"=L\", socket.inet_aton(netaddr))[0] & netmask\n    return (ipaddr & netmask) == (network & netmask)\n\n\ndef dotted_netmask(mask):\n    \"\"\"Converts mask from /xx format to xxx.xxx.xxx.xxx\n\n    Example: if mask is 24 function returns 255.255.255.0\n\n    :rtype: str\n    \"\"\"\n    bits = 0xFFFFFFFF ^ (1 << 32 - mask) - 1\n    return socket.inet_ntoa(struct.pack(\">I\", bits))\n\n\ndef is_ipv4_address(string_ip):\n    \"\"\"\n    :rtype: bool\n    \"\"\"\n    try:\n        socket.inet_aton(string_ip)\n    except OSError:\n        return False\n    return True\n\n\ndef is_valid_cidr(string_network):\n    \"\"\"\n    Very simple check of the cidr format in no_proxy variable.\n\n    :rtype: bool\n    \"\"\"\n    if string_network.count(\"/\") == 1:\n        try:\n            mask = int(string_network.split(\"/\")[1])\n        except ValueError:\n            return False\n\n        if mask < 1 or mask > 32:\n            return False\n\n        try:\n            socket.inet_aton(string_network.split(\"/\")[0])\n        except OSError:\n            return False\n    else:\n        return False\n    return True\n\n\n@contextlib.contextmanager\ndef set_environ(env_name, value):\n    \"\"\"Set the environment variable 'env_name' to 'value'\n\n    Save previous value, yield, and then restore the previous value stored in\n    the environment variable 'env_name'.\n\n    If 'value' is None, do nothing\"\"\"\n    value_changed = value is not None\n    if value_changed:\n        old_value = os.environ.get(env_name)\n        os.environ[env_name] = value\n    try:\n        yield\n    finally:\n        if value_changed:\n            if old_value is None:\n                del os.environ[env_name]\n            else:\n                os.environ[env_name] = old_value\n\n\ndef should_bypass_proxies(url, no_proxy):\n    \"\"\"\n    Returns whether we should bypass proxies or not.\n\n    :rtype: bool\n    \"\"\"\n\n    # Prioritize lowercase environment variables over uppercase\n    # to keep a consistent behaviour with other http projects (curl, wget).\n    def get_proxy(key):\n        return os.environ.get(key) or os.environ.get(key.upper())\n\n    # First check whether no_proxy is defined. If it is, check that the URL\n    # we're getting isn't in the no_proxy list.\n    no_proxy_arg = no_proxy\n    if no_proxy is None:\n        no_proxy = get_proxy(\"no_proxy\")\n    parsed = urlparse(url)\n\n    if parsed.hostname is None:\n        # URLs don't always have hostnames, e.g. file:/// urls.\n        return True\n\n    if no_proxy:\n        # We need to check whether we match here. We need to see if we match\n        # the end of the hostname, both with and without the port.\n        no_proxy = (host for host in no_proxy.replace(\" \", \"\").split(\",\") if host)\n\n        if is_ipv4_address(parsed.hostname):\n            for proxy_ip in no_proxy:\n                if is_valid_cidr(proxy_ip):\n                    if address_in_network(parsed.hostname, proxy_ip):\n                        return True\n                elif parsed.hostname == proxy_ip:\n                    # If no_proxy ip was defined in plain IP notation instead of cidr notation &\n                    # matches the IP of the index\n                    return True\n        else:\n            host_with_port = parsed.hostname\n            if parsed.port:\n                host_with_port += f\":{parsed.port}\"\n\n            for host in no_proxy:\n                if parsed.hostname.endswith(host) or host_with_port.endswith(host):\n                    # The URL does match something in no_proxy, so we don't want\n                    # to apply the proxies on this URL.\n                    return True\n\n    with set_environ(\"no_proxy\", no_proxy_arg):\n        # parsed.hostname can be `None` in cases such as a file URI.\n        try:\n            bypass = proxy_bypass(parsed.hostname)\n        except (TypeError, socket.gaierror):\n            bypass = False\n\n    if bypass:\n        return True\n\n    return False\n\n\ndef get_environ_proxies(url, no_proxy=None):\n    \"\"\"\n    Return a dict of environment proxies.\n\n    :rtype: dict\n    \"\"\"\n    if should_bypass_proxies(url, no_proxy=no_proxy):\n        return {}\n    else:\n        return getproxies()\n\n\ndef select_proxy(url, proxies):\n    \"\"\"Select a proxy for the url, if applicable.\n\n    :param url: The url being for the request\n    :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs\n    \"\"\"\n    proxies = proxies or {}\n    urlparts = urlparse(url)\n    if urlparts.hostname is None:\n        return proxies.get(urlparts.scheme, proxies.get(\"all\"))\n\n    proxy_keys = [\n        urlparts.scheme + \"://\" + urlparts.hostname,\n        urlparts.scheme,\n        \"all://\" + urlparts.hostname,\n        \"all\",\n    ]\n    proxy = None\n    for proxy_key in proxy_keys:\n        if proxy_key in proxies:\n            proxy = proxies[proxy_key]\n            break\n\n    return proxy\n\n\ndef resolve_proxies(request, proxies, trust_env=True):\n    \"\"\"This method takes proxy information from a request and configuration\n    input to resolve a mapping of target proxies. This will consider settings\n    such as NO_PROXY to strip proxy configurations.\n\n    :param request: Request or PreparedRequest\n    :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs\n    :param trust_env: Boolean declaring whether to trust environment configs\n\n    :rtype: dict\n    \"\"\"\n    proxies = proxies if proxies is not None else {}\n    url = request.url\n    scheme = urlparse(url).scheme\n    no_proxy = proxies.get(\"no_proxy\")\n    new_proxies = proxies.copy()\n\n    if trust_env and not should_bypass_proxies(url, no_proxy=no_proxy):\n        environ_proxies = get_environ_proxies(url, no_proxy=no_proxy)\n\n        proxy = environ_proxies.get(scheme, environ_proxies.get(\"all\"))\n\n        if proxy:\n            new_proxies.setdefault(scheme, proxy)\n    return new_proxies\n\n\ndef default_user_agent(name=\"python-requests\"):\n    \"\"\"\n    Return a string representing the default user agent.\n\n    :rtype: str\n    \"\"\"\n    return f\"{name}/{__version__}\"\n\n\ndef default_headers():\n    \"\"\"\n    :rtype: requests.structures.CaseInsensitiveDict\n    \"\"\"\n    return CaseInsensitiveDict(\n        {\n            \"User-Agent\": default_user_agent(),\n            \"Accept-Encoding\": DEFAULT_ACCEPT_ENCODING,\n            \"Accept\": \"*/*\",\n            \"Connection\": \"keep-alive\",\n        }\n    )\n\n\ndef parse_header_links(value):\n    \"\"\"Return a list of parsed link headers proxies.\n\n    i.e. Link: <http:/.../front.jpeg>; rel=front; type=\"image/jpeg\",<http://.../back.jpeg>; rel=back;type=\"image/jpeg\"\n\n    :rtype: list\n    \"\"\"\n\n    links = []\n\n    replace_chars = \" '\\\"\"\n\n    value = value.strip(replace_chars)\n    if not value:\n        return links\n\n    for val in re.split(\", *<\", value):\n        try:\n            url, params = val.split(\";\", 1)\n        except ValueError:\n            url, params = val, \"\"\n\n        link = {\"url\": url.strip(\"<> '\\\"\")}\n\n        for param in params.split(\";\"):\n            try:\n                key, value = param.split(\"=\")\n            except ValueError:\n                break\n\n            link[key.strip(replace_chars)] = value.strip(replace_chars)\n\n        links.append(link)\n\n    return links\n\n\n# Null bytes; no need to recreate these on each call to guess_json_utf\n_null = \"\\x00\".encode(\"ascii\")  # encoding to ASCII for Python 3\n_null2 = _null * 2\n_null3 = _null * 3\n\n\ndef guess_json_utf(data):\n    \"\"\"\n    :rtype: str\n    \"\"\"\n    # JSON always starts with two ASCII characters, so detection is as\n    # easy as counting the nulls and from their location and count\n    # determine the encoding. Also detect a BOM, if present.\n    sample = data[:4]\n    if sample in (codecs.BOM_UTF32_LE, codecs.BOM_UTF32_BE):\n        return \"utf-32\"  # BOM included\n    if sample[:3] == codecs.BOM_UTF8:\n        return \"utf-8-sig\"  # BOM included, MS style (discouraged)\n    if sample[:2] in (codecs.BOM_UTF16_LE, codecs.BOM_UTF16_BE):\n        return \"utf-16\"  # BOM included\n    nullcount = sample.count(_null)\n    if nullcount == 0:\n        return \"utf-8\"\n    if nullcount == 2:\n        if sample[::2] == _null2:  # 1st and 3rd are null\n            return \"utf-16-be\"\n        if sample[1::2] == _null2:  # 2nd and 4th are null\n            return \"utf-16-le\"\n        # Did not detect 2 valid UTF-16 ascii-range characters\n    if nullcount == 3:\n        if sample[:3] == _null3:\n            return \"utf-32-be\"\n        if sample[1:] == _null3:\n            return \"utf-32-le\"\n        # Did not detect a valid UTF-32 ascii-range character\n    return None\n\n\ndef prepend_scheme_if_needed(url, new_scheme):\n    \"\"\"Given a URL that may or may not have a scheme, prepend the given scheme.\n    Does not replace a present scheme with the one provided as an argument.\n\n    :rtype: str\n    \"\"\"\n    parsed = parse_url(url)\n    scheme, auth, host, port, path, query, fragment = parsed\n\n    # A defect in urlparse determines that there isn't a netloc present in some\n    # urls. We previously assumed parsing was overly cautious, and swapped the\n    # netloc and path. Due to a lack of tests on the original defect, this is\n    # maintained with parse_url for backwards compatibility.\n    netloc = parsed.netloc\n    if not netloc:\n        netloc, path = path, netloc\n\n    if auth:\n        # parse_url doesn't provide the netloc with auth\n        # so we'll add it ourselves.\n        netloc = \"@\".join([auth, netloc])\n    if scheme is None:\n        scheme = new_scheme\n    if path is None:\n        path = \"\"\n\n    return urlunparse((scheme, netloc, path, \"\", query, fragment))\n\n\ndef get_auth_from_url(url):\n    \"\"\"Given a url with authentication components, extract them into a tuple of\n    username,password.\n\n    :rtype: (str,str)\n    \"\"\"\n    parsed = urlparse(url)\n\n    try:\n        auth = (unquote(parsed.username), unquote(parsed.password))\n    except (AttributeError, TypeError):\n        auth = (\"\", \"\")\n\n    return auth\n\n\ndef check_header_validity(header):\n    \"\"\"Verifies that header parts don't contain leading whitespace\n    reserved characters, or return characters.\n\n    :param header: tuple, in the format (name, value).\n    \"\"\"\n    name, value = header\n    _validate_header_part(header, name, 0)\n    _validate_header_part(header, value, 1)\n\n\ndef _validate_header_part(header, header_part, header_validator_index):\n    if isinstance(header_part, str):\n        validator = _HEADER_VALIDATORS_STR[header_validator_index]\n    elif isinstance(header_part, bytes):\n        validator = _HEADER_VALIDATORS_BYTE[header_validator_index]\n    else:\n        raise InvalidHeader(\n            f\"Header part ({header_part!r}) from {header} \"\n            f\"must be of type str or bytes, not {type(header_part)}\"\n        )\n\n    if not validator.match(header_part):\n        header_kind = \"name\" if header_validator_index == 0 else \"value\"\n        raise InvalidHeader(\n            f\"Invalid leading whitespace, reserved character(s), or return \"\n            f\"character(s) in header {header_kind}: {header_part!r}\"\n        )\n\n\ndef urldefragauth(url):\n    \"\"\"\n    Given a url remove the fragment and the authentication part.\n\n    :rtype: str\n    \"\"\"\n    scheme, netloc, path, params, query, fragment = urlparse(url)\n\n    # see func:`prepend_scheme_if_needed`\n    if not netloc:\n        netloc, path = path, netloc\n\n    netloc = netloc.rsplit(\"@\", 1)[-1]\n\n    return urlunparse((scheme, netloc, path, params, query, \"\"))\n\n\ndef rewind_body(prepared_request):\n    \"\"\"Move file pointer back to its recorded starting position\n    so it can be read again on redirect.\n    \"\"\"\n    body_seek = getattr(prepared_request.body, \"seek\", None)\n    if body_seek is not None and isinstance(\n        prepared_request._body_position, integer_types\n    ):\n        try:\n            body_seek(prepared_request._body_position)\n        except OSError:\n            raise UnrewindableBodyError(\n                \"An error occurred when rewinding request body for redirect.\"\n            )\n    else:\n        raise UnrewindableBodyError(\"Unable to rewind request body for redirect.\")\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/resolvelib/__init__.py","size":537,"sha1":"c756151b98834a600daf027ed3e9ac9c12a15f6f","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"__all__ = [\n    \"__version__\",\n    \"AbstractProvider\",\n    \"AbstractResolver\",\n    \"BaseReporter\",\n    \"InconsistentCandidate\",\n    \"Resolver\",\n    \"RequirementsConflicted\",\n    \"ResolutionError\",\n    \"ResolutionImpossible\",\n    \"ResolutionTooDeep\",\n]\n\n__version__ = \"1.0.1\"\n\n\nfrom .providers import AbstractProvider, AbstractResolver\nfrom .reporters import BaseReporter\nfrom .resolvers import (\n    InconsistentCandidate,\n    RequirementsConflicted,\n    ResolutionError,\n    ResolutionImpossible,\n    ResolutionTooDeep,\n    Resolver,\n)\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/resolvelib/compat/__init__.py","size":0,"sha1":"da39a3ee5e6b4b0d3255bfef95601890afd80709","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":""},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/resolvelib/compat/collections_abc.py","size":156,"sha1":"707dc63c9b0961b36cc1127216af38de6b1b31e7","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"__all__ = [\"Mapping\", \"Sequence\"]\n\ntry:\n    from collections.abc import Mapping, Sequence\nexcept ImportError:\n    from collections import Mapping, Sequence\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/resolvelib/providers.py","size":5871,"sha1":"d4753f2ce0f84b8ece6709862ca9c5859d391a70","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"class AbstractProvider(object):\n    \"\"\"Delegate class to provide the required interface for the resolver.\"\"\"\n\n    def identify(self, requirement_or_candidate):\n        \"\"\"Given a requirement, return an identifier for it.\n\n        This is used to identify a requirement, e.g. whether two requirements\n        should have their specifier parts merged.\n        \"\"\"\n        raise NotImplementedError\n\n    def get_preference(\n        self,\n        identifier,\n        resolutions,\n        candidates,\n        information,\n        backtrack_causes,\n    ):\n        \"\"\"Produce a sort key for given requirement based on preference.\n\n        The preference is defined as \"I think this requirement should be\n        resolved first\". The lower the return value is, the more preferred\n        this group of arguments is.\n\n        :param identifier: An identifier as returned by ``identify()``. This\n            identifies the dependency matches which should be returned.\n        :param resolutions: Mapping of candidates currently pinned by the\n            resolver. Each key is an identifier, and the value is a candidate.\n            The candidate may conflict with requirements from ``information``.\n        :param candidates: Mapping of each dependency's possible candidates.\n            Each value is an iterator of candidates.\n        :param information: Mapping of requirement information of each package.\n            Each value is an iterator of *requirement information*.\n        :param backtrack_causes: Sequence of requirement information that were\n            the requirements that caused the resolver to most recently backtrack.\n\n        A *requirement information* instance is a named tuple with two members:\n\n        * ``requirement`` specifies a requirement contributing to the current\n          list of candidates.\n        * ``parent`` specifies the candidate that provides (depended on) the\n          requirement, or ``None`` to indicate a root requirement.\n\n        The preference could depend on various issues, including (not\n        necessarily in this order):\n\n        * Is this package pinned in the current resolution result?\n        * How relaxed is the requirement? Stricter ones should probably be\n          worked on first? (I don't know, actually.)\n        * How many possibilities are there to satisfy this requirement? Those\n          with few left should likely be worked on first, I guess?\n        * Are there any known conflicts for this requirement? We should\n          probably work on those with the most known conflicts.\n\n        A sortable value should be returned (this will be used as the ``key``\n        parameter of the built-in sorting function). The smaller the value is,\n        the more preferred this requirement is (i.e. the sorting function\n        is called with ``reverse=False``).\n        \"\"\"\n        raise NotImplementedError\n\n    def find_matches(self, identifier, requirements, incompatibilities):\n        \"\"\"Find all possible candidates that satisfy the given constraints.\n\n        :param identifier: An identifier as returned by ``identify()``. This\n            identifies the dependency matches of which should be returned.\n        :param requirements: A mapping of requirements that all returned\n            candidates must satisfy. Each key is an identifier, and the value\n            an iterator of requirements for that dependency.\n        :param incompatibilities: A mapping of known incompatibilities of\n            each dependency. Each key is an identifier, and the value an\n            iterator of incompatibilities known to the resolver. All\n            incompatibilities *must* be excluded from the return value.\n\n        This should try to get candidates based on the requirements' types.\n        For VCS, local, and archive requirements, the one-and-only match is\n        returned, and for a \"named\" requirement, the index(es) should be\n        consulted to find concrete candidates for this requirement.\n\n        The return value should produce candidates ordered by preference; the\n        most preferred candidate should come first. The return type may be one\n        of the following:\n\n        * A callable that returns an iterator that yields candidates.\n        * An collection of candidates.\n        * An iterable of candidates. This will be consumed immediately into a\n          list of candidates.\n        \"\"\"\n        raise NotImplementedError\n\n    def is_satisfied_by(self, requirement, candidate):\n        \"\"\"Whether the given requirement can be satisfied by a candidate.\n\n        The candidate is guaranteed to have been generated from the\n        requirement.\n\n        A boolean should be returned to indicate whether ``candidate`` is a\n        viable solution to the requirement.\n        \"\"\"\n        raise NotImplementedError\n\n    def get_dependencies(self, candidate):\n        \"\"\"Get dependencies of a candidate.\n\n        This should return a collection of requirements that `candidate`\n        specifies as its dependencies.\n        \"\"\"\n        raise NotImplementedError\n\n\nclass AbstractResolver(object):\n    \"\"\"The thing that performs the actual resolution work.\"\"\"\n\n    base_exception = Exception\n\n    def __init__(self, provider, reporter):\n        self.provider = provider\n        self.reporter = reporter\n\n    def resolve(self, requirements, **kwargs):\n        \"\"\"Take a collection of constraints, spit out the resolution result.\n\n        This returns a representation of the final resolution state, with one\n        guarenteed attribute ``mapping`` that contains resolved candidates as\n        values. The keys are their respective identifiers.\n\n        :param requirements: A collection of constraints.\n        :param kwargs: Additional keyword arguments that subclasses may accept.\n\n        :raises: ``self.base_exception`` or its subclass.\n        \"\"\"\n        raise NotImplementedError\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/resolvelib/reporters.py","size":1601,"sha1":"12fb5db25d45218af1edf7a377251b2c5e493be5","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"class BaseReporter(object):\n    \"\"\"Delegate class to provider progress reporting for the resolver.\"\"\"\n\n    def starting(self):\n        \"\"\"Called before the resolution actually starts.\"\"\"\n\n    def starting_round(self, index):\n        \"\"\"Called before each round of resolution starts.\n\n        The index is zero-based.\n        \"\"\"\n\n    def ending_round(self, index, state):\n        \"\"\"Called before each round of resolution ends.\n\n        This is NOT called if the resolution ends at this round. Use `ending`\n        if you want to report finalization. The index is zero-based.\n        \"\"\"\n\n    def ending(self, state):\n        \"\"\"Called before the resolution ends successfully.\"\"\"\n\n    def adding_requirement(self, requirement, parent):\n        \"\"\"Called when adding a new requirement into the resolve criteria.\n\n        :param requirement: The additional requirement to be applied to filter\n            the available candidaites.\n        :param parent: The candidate that requires ``requirement`` as a\n            dependency, or None if ``requirement`` is one of the root\n            requirements passed in from ``Resolver.resolve()``.\n        \"\"\"\n\n    def resolving_conflicts(self, causes):\n        \"\"\"Called when starting to attempt requirement conflict resolution.\n\n        :param causes: The information on the collision that caused the backtracking.\n        \"\"\"\n\n    def rejecting_candidate(self, criterion, candidate):\n        \"\"\"Called when rejecting a candidate during backtracking.\"\"\"\n\n    def pinning(self, candidate):\n        \"\"\"Called when adding a candidate to the potential solution.\"\"\"\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/resolvelib/resolvers.py","size":20511,"sha1":"81c58b0f42e795a41a832e6edcb0ef3a8667af3e","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"import collections\nimport itertools\nimport operator\n\nfrom .providers import AbstractResolver\nfrom .structs import DirectedGraph, IteratorMapping, build_iter_view\n\nRequirementInformation = collections.namedtuple(\n    \"RequirementInformation\", [\"requirement\", \"parent\"]\n)\n\n\nclass ResolverException(Exception):\n    \"\"\"A base class for all exceptions raised by this module.\n\n    Exceptions derived by this class should all be handled in this module. Any\n    bubbling pass the resolver should be treated as a bug.\n    \"\"\"\n\n\nclass RequirementsConflicted(ResolverException):\n    def __init__(self, criterion):\n        super(RequirementsConflicted, self).__init__(criterion)\n        self.criterion = criterion\n\n    def __str__(self):\n        return \"Requirements conflict: {}\".format(\n            \", \".join(repr(r) for r in self.criterion.iter_requirement()),\n        )\n\n\nclass InconsistentCandidate(ResolverException):\n    def __init__(self, candidate, criterion):\n        super(InconsistentCandidate, self).__init__(candidate, criterion)\n        self.candidate = candidate\n        self.criterion = criterion\n\n    def __str__(self):\n        return \"Provided candidate {!r} does not satisfy {}\".format(\n            self.candidate,\n            \", \".join(repr(r) for r in self.criterion.iter_requirement()),\n        )\n\n\nclass Criterion(object):\n    \"\"\"Representation of possible resolution results of a package.\n\n    This holds three attributes:\n\n    * `information` is a collection of `RequirementInformation` pairs.\n      Each pair is a requirement contributing to this criterion, and the\n      candidate that provides the requirement.\n    * `incompatibilities` is a collection of all known not-to-work candidates\n      to exclude from consideration.\n    * `candidates` is a collection containing all possible candidates deducted\n      from the union of contributing requirements and known incompatibilities.\n      It should never be empty, except when the criterion is an attribute of a\n      raised `RequirementsConflicted` (in which case it is always empty).\n\n    .. note::\n        This class is intended to be externally immutable. **Do not** mutate\n        any of its attribute containers.\n    \"\"\"\n\n    def __init__(self, candidates, information, incompatibilities):\n        self.candidates = candidates\n        self.information = information\n        self.incompatibilities = incompatibilities\n\n    def __repr__(self):\n        requirements = \", \".join(\n            \"({!r}, via={!r})\".format(req, parent)\n            for req, parent in self.information\n        )\n        return \"Criterion({})\".format(requirements)\n\n    def iter_requirement(self):\n        return (i.requirement for i in self.information)\n\n    def iter_parent(self):\n        return (i.parent for i in self.information)\n\n\nclass ResolutionError(ResolverException):\n    pass\n\n\nclass ResolutionImpossible(ResolutionError):\n    def __init__(self, causes):\n        super(ResolutionImpossible, self).__init__(causes)\n        # causes is a list of RequirementInformation objects\n        self.causes = causes\n\n\nclass ResolutionTooDeep(ResolutionError):\n    def __init__(self, round_count):\n        super(ResolutionTooDeep, self).__init__(round_count)\n        self.round_count = round_count\n\n\n# Resolution state in a round.\nState = collections.namedtuple(\"State\", \"mapping criteria backtrack_causes\")\n\n\nclass Resolution(object):\n    \"\"\"Stateful resolution object.\n\n    This is designed as a one-off object that holds information to kick start\n    the resolution process, and holds the results afterwards.\n    \"\"\"\n\n    def __init__(self, provider, reporter):\n        self._p = provider\n        self._r = reporter\n        self._states = []\n\n    @property\n    def state(self):\n        try:\n            return self._states[-1]\n        except IndexError:\n            raise AttributeError(\"state\")\n\n    def _push_new_state(self):\n        \"\"\"Push a new state into history.\n\n        This new state will be used to hold resolution results of the next\n        coming round.\n        \"\"\"\n        base = self._states[-1]\n        state = State(\n            mapping=base.mapping.copy(),\n            criteria=base.criteria.copy(),\n            backtrack_causes=base.backtrack_causes[:],\n        )\n        self._states.append(state)\n\n    def _add_to_criteria(self, criteria, requirement, parent):\n        self._r.adding_requirement(requirement=requirement, parent=parent)\n\n        identifier = self._p.identify(requirement_or_candidate=requirement)\n        criterion = criteria.get(identifier)\n        if criterion:\n            incompatibilities = list(criterion.incompatibilities)\n        else:\n            incompatibilities = []\n\n        matches = self._p.find_matches(\n            identifier=identifier,\n            requirements=IteratorMapping(\n                criteria,\n                operator.methodcaller(\"iter_requirement\"),\n                {identifier: [requirement]},\n            ),\n            incompatibilities=IteratorMapping(\n                criteria,\n                operator.attrgetter(\"incompatibilities\"),\n                {identifier: incompatibilities},\n            ),\n        )\n\n        if criterion:\n            information = list(criterion.information)\n            information.append(RequirementInformation(requirement, parent))\n        else:\n            information = [RequirementInformation(requirement, parent)]\n\n        criterion = Criterion(\n            candidates=build_iter_view(matches),\n            information=information,\n            incompatibilities=incompatibilities,\n        )\n        if not criterion.candidates:\n            raise RequirementsConflicted(criterion)\n        criteria[identifier] = criterion\n\n    def _remove_information_from_criteria(self, criteria, parents):\n        \"\"\"Remove information from parents of criteria.\n\n        Concretely, removes all values from each criterion's ``information``\n        field that have one of ``parents`` as provider of the requirement.\n\n        :param criteria: The criteria to update.\n        :param parents: Identifiers for which to remove information from all criteria.\n        \"\"\"\n        if not parents:\n            return\n        for key, criterion in criteria.items():\n            criteria[key] = Criterion(\n                criterion.candidates,\n                [\n                    information\n                    for information in criterion.information\n                    if (\n                        information.parent is None\n                        or self._p.identify(information.parent) not in parents\n                    )\n                ],\n                criterion.incompatibilities,\n            )\n\n    def _get_preference(self, name):\n        return self._p.get_preference(\n            identifier=name,\n            resolutions=self.state.mapping,\n            candidates=IteratorMapping(\n                self.state.criteria,\n                operator.attrgetter(\"candidates\"),\n            ),\n            information=IteratorMapping(\n                self.state.criteria,\n                operator.attrgetter(\"information\"),\n            ),\n            backtrack_causes=self.state.backtrack_causes,\n        )\n\n    def _is_current_pin_satisfying(self, name, criterion):\n        try:\n            current_pin = self.state.mapping[name]\n        except KeyError:\n            return False\n        return all(\n            self._p.is_satisfied_by(requirement=r, candidate=current_pin)\n            for r in criterion.iter_requirement()\n        )\n\n    def _get_updated_criteria(self, candidate):\n        criteria = self.state.criteria.copy()\n        for requirement in self._p.get_dependencies(candidate=candidate):\n            self._add_to_criteria(criteria, requirement, parent=candidate)\n        return criteria\n\n    def _attempt_to_pin_criterion(self, name):\n        criterion = self.state.criteria[name]\n\n        causes = []\n        for candidate in criterion.candidates:\n            try:\n                criteria = self._get_updated_criteria(candidate)\n            except RequirementsConflicted as e:\n                self._r.rejecting_candidate(e.criterion, candidate)\n                causes.append(e.criterion)\n                continue\n\n            # Check the newly-pinned candidate actually works. This should\n            # always pass under normal circumstances, but in the case of a\n            # faulty provider, we will raise an error to notify the implementer\n            # to fix find_matches() and/or is_satisfied_by().\n            satisfied = all(\n                self._p.is_satisfied_by(requirement=r, candidate=candidate)\n                for r in criterion.iter_requirement()\n            )\n            if not satisfied:\n                raise InconsistentCandidate(candidate, criterion)\n\n            self._r.pinning(candidate=candidate)\n            self.state.criteria.update(criteria)\n\n            # Put newly-pinned candidate at the end. This is essential because\n            # backtracking looks at this mapping to get the last pin.\n            self.state.mapping.pop(name, None)\n            self.state.mapping[name] = candidate\n\n            return []\n\n        # All candidates tried, nothing works. This criterion is a dead\n        # end, signal for backtracking.\n        return causes\n\n    def _backjump(self, causes):\n        \"\"\"Perform backjumping.\n\n        When we enter here, the stack is like this::\n\n            [ state Z ]\n            [ state Y ]\n            [ state X ]\n            .... earlier states are irrelevant.\n\n        1. No pins worked for Z, so it does not have a pin.\n        2. We want to reset state Y to unpinned, and pin another candidate.\n        3. State X holds what state Y was before the pin, but does not\n           have the incompatibility information gathered in state Y.\n\n        Each iteration of the loop will:\n\n        1.  Identify Z. The incompatibility is not always caused by the latest\n            state. For example, given three requirements A, B and C, with\n            dependencies A1, B1 and C1, where A1 and B1 are incompatible: the\n            last state might be related to C, so we want to discard the\n            previous state.\n        2.  Discard Z.\n        3.  Discard Y but remember its incompatibility information gathered\n            previously, and the failure we're dealing with right now.\n        4.  Push a new state Y' based on X, and apply the incompatibility\n            information from Y to Y'.\n        5a. If this causes Y' to conflict, we need to backtrack again. Make Y'\n            the new Z and go back to step 2.\n        5b. If the incompatibilities apply cleanly, end backtracking.\n        \"\"\"\n        incompatible_reqs = itertools.chain(\n            (c.parent for c in causes if c.parent is not None),\n            (c.requirement for c in causes),\n        )\n        incompatible_deps = {self._p.identify(r) for r in incompatible_reqs}\n        while len(self._states) >= 3:\n            # Remove the state that triggered backtracking.\n            del self._states[-1]\n\n            # Ensure to backtrack to a state that caused the incompatibility\n            incompatible_state = False\n            while not incompatible_state:\n                # Retrieve the last candidate pin and known incompatibilities.\n                try:\n                    broken_state = self._states.pop()\n                    name, candidate = broken_state.mapping.popitem()\n                except (IndexError, KeyError):\n                    raise ResolutionImpossible(causes)\n                current_dependencies = {\n                    self._p.identify(d)\n                    for d in self._p.get_dependencies(candidate)\n                }\n                incompatible_state = not current_dependencies.isdisjoint(\n                    incompatible_deps\n                )\n\n            incompatibilities_from_broken = [\n                (k, list(v.incompatibilities))\n                for k, v in broken_state.criteria.items()\n            ]\n\n            # Also mark the newly known incompatibility.\n            incompatibilities_from_broken.append((name, [candidate]))\n\n            # Create a new state from the last known-to-work one, and apply\n            # the previously gathered incompatibility information.\n            def _patch_criteria():\n                for k, incompatibilities in incompatibilities_from_broken:\n                    if not incompatibilities:\n                        continue\n                    try:\n                        criterion = self.state.criteria[k]\n                    except KeyError:\n                        continue\n                    matches = self._p.find_matches(\n                        identifier=k,\n                        requirements=IteratorMapping(\n                            self.state.criteria,\n                            operator.methodcaller(\"iter_requirement\"),\n                        ),\n                        incompatibilities=IteratorMapping(\n                            self.state.criteria,\n                            operator.attrgetter(\"incompatibilities\"),\n                            {k: incompatibilities},\n                        ),\n                    )\n                    candidates = build_iter_view(matches)\n                    if not candidates:\n                        return False\n                    incompatibilities.extend(criterion.incompatibilities)\n                    self.state.criteria[k] = Criterion(\n                        candidates=candidates,\n                        information=list(criterion.information),\n                        incompatibilities=incompatibilities,\n                    )\n                return True\n\n            self._push_new_state()\n            success = _patch_criteria()\n\n            # It works! Let's work on this new state.\n            if success:\n                return True\n\n            # State does not work after applying known incompatibilities.\n            # Try the still previous state.\n\n        # No way to backtrack anymore.\n        return False\n\n    def resolve(self, requirements, max_rounds):\n        if self._states:\n            raise RuntimeError(\"already resolved\")\n\n        self._r.starting()\n\n        # Initialize the root state.\n        self._states = [\n            State(\n                mapping=collections.OrderedDict(),\n                criteria={},\n                backtrack_causes=[],\n            )\n        ]\n        for r in requirements:\n            try:\n                self._add_to_criteria(self.state.criteria, r, parent=None)\n            except RequirementsConflicted as e:\n                raise ResolutionImpossible(e.criterion.information)\n\n        # The root state is saved as a sentinel so the first ever pin can have\n        # something to backtrack to if it fails. The root state is basically\n        # pinning the virtual \"root\" package in the graph.\n        self._push_new_state()\n\n        for round_index in range(max_rounds):\n            self._r.starting_round(index=round_index)\n\n            unsatisfied_names = [\n                key\n                for key, criterion in self.state.criteria.items()\n                if not self._is_current_pin_satisfying(key, criterion)\n            ]\n\n            # All criteria are accounted for. Nothing more to pin, we are done!\n            if not unsatisfied_names:\n                self._r.ending(state=self.state)\n                return self.state\n\n            # keep track of satisfied names to calculate diff after pinning\n            satisfied_names = set(self.state.criteria.keys()) - set(\n                unsatisfied_names\n            )\n\n            # Choose the most preferred unpinned criterion to try.\n            name = min(unsatisfied_names, key=self._get_preference)\n            failure_causes = self._attempt_to_pin_criterion(name)\n\n            if failure_causes:\n                causes = [i for c in failure_causes for i in c.information]\n                # Backjump if pinning fails. The backjump process puts us in\n                # an unpinned state, so we can work on it in the next round.\n                self._r.resolving_conflicts(causes=causes)\n                success = self._backjump(causes)\n                self.state.backtrack_causes[:] = causes\n\n                # Dead ends everywhere. Give up.\n                if not success:\n                    raise ResolutionImpossible(self.state.backtrack_causes)\n            else:\n                # discard as information sources any invalidated names\n                # (unsatisfied names that were previously satisfied)\n                newly_unsatisfied_names = {\n                    key\n                    for key, criterion in self.state.criteria.items()\n                    if key in satisfied_names\n                    and not self._is_current_pin_satisfying(key, criterion)\n                }\n                self._remove_information_from_criteria(\n                    self.state.criteria, newly_unsatisfied_names\n                )\n                # Pinning was successful. Push a new state to do another pin.\n                self._push_new_state()\n\n            self._r.ending_round(index=round_index, state=self.state)\n\n        raise ResolutionTooDeep(max_rounds)\n\n\ndef _has_route_to_root(criteria, key, all_keys, connected):\n    if key in connected:\n        return True\n    if key not in criteria:\n        return False\n    for p in criteria[key].iter_parent():\n        try:\n            pkey = all_keys[id(p)]\n        except KeyError:\n            continue\n        if pkey in connected:\n            connected.add(key)\n            return True\n        if _has_route_to_root(criteria, pkey, all_keys, connected):\n            connected.add(key)\n            return True\n    return False\n\n\nResult = collections.namedtuple(\"Result\", \"mapping graph criteria\")\n\n\ndef _build_result(state):\n    mapping = state.mapping\n    all_keys = {id(v): k for k, v in mapping.items()}\n    all_keys[id(None)] = None\n\n    graph = DirectedGraph()\n    graph.add(None)  # Sentinel as root dependencies' parent.\n\n    connected = {None}\n    for key, criterion in state.criteria.items():\n        if not _has_route_to_root(state.criteria, key, all_keys, connected):\n            continue\n        if key not in graph:\n            graph.add(key)\n        for p in criterion.iter_parent():\n            try:\n                pkey = all_keys[id(p)]\n            except KeyError:\n                continue\n            if pkey not in graph:\n                graph.add(pkey)\n            graph.connect(pkey, key)\n\n    return Result(\n        mapping={k: v for k, v in mapping.items() if k in connected},\n        graph=graph,\n        criteria=state.criteria,\n    )\n\n\nclass Resolver(AbstractResolver):\n    \"\"\"The thing that performs the actual resolution work.\"\"\"\n\n    base_exception = ResolverException\n\n    def resolve(self, requirements, max_rounds=100):\n        \"\"\"Take a collection of constraints, spit out the resolution result.\n\n        The return value is a representation to the final resolution result. It\n        is a tuple subclass with three public members:\n\n        * `mapping`: A dict of resolved candidates. Each key is an identifier\n            of a requirement (as returned by the provider's `identify` method),\n            and the value is the resolved candidate.\n        * `graph`: A `DirectedGraph` instance representing the dependency tree.\n            The vertices are keys of `mapping`, and each edge represents *why*\n            a particular package is included. A special vertex `None` is\n            included to represent parents of user-supplied requirements.\n        * `criteria`: A dict of \"criteria\" that hold detailed information on\n            how edges in the graph are derived. Each key is an identifier of a\n            requirement, and the value is a `Criterion` instance.\n\n        The following exceptions may be raised if a resolution cannot be found:\n\n        * `ResolutionImpossible`: A resolution cannot be found for the given\n            combination of requirements. The `causes` attribute of the\n            exception is a list of (requirement, parent), giving the\n            requirements that could not be satisfied.\n        * `ResolutionTooDeep`: The dependency tree is too deeply nested and\n            the resolver gave up. This is usually caused by a circular\n            dependency, but you can try to resolve this by increasing the\n            `max_rounds` argument.\n        \"\"\"\n        resolution = Resolution(self.provider, self.reporter)\n        state = resolution.resolve(requirements, max_rounds=max_rounds)\n        return _build_result(state)\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/resolvelib/structs.py","size":4963,"sha1":"36dbfdd47591385ccd103148bd024f7a1e81c690","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"import itertools\n\nfrom .compat import collections_abc\n\n\nclass DirectedGraph(object):\n    \"\"\"A graph structure with directed edges.\"\"\"\n\n    def __init__(self):\n        self._vertices = set()\n        self._forwards = {}  # <key> -> Set[<key>]\n        self._backwards = {}  # <key> -> Set[<key>]\n\n    def __iter__(self):\n        return iter(self._vertices)\n\n    def __len__(self):\n        return len(self._vertices)\n\n    def __contains__(self, key):\n        return key in self._vertices\n\n    def copy(self):\n        \"\"\"Return a shallow copy of this graph.\"\"\"\n        other = DirectedGraph()\n        other._vertices = set(self._vertices)\n        other._forwards = {k: set(v) for k, v in self._forwards.items()}\n        other._backwards = {k: set(v) for k, v in self._backwards.items()}\n        return other\n\n    def add(self, key):\n        \"\"\"Add a new vertex to the graph.\"\"\"\n        if key in self._vertices:\n            raise ValueError(\"vertex exists\")\n        self._vertices.add(key)\n        self._forwards[key] = set()\n        self._backwards[key] = set()\n\n    def remove(self, key):\n        \"\"\"Remove a vertex from the graph, disconnecting all edges from/to it.\"\"\"\n        self._vertices.remove(key)\n        for f in self._forwards.pop(key):\n            self._backwards[f].remove(key)\n        for t in self._backwards.pop(key):\n            self._forwards[t].remove(key)\n\n    def connected(self, f, t):\n        return f in self._backwards[t] and t in self._forwards[f]\n\n    def connect(self, f, t):\n        \"\"\"Connect two existing vertices.\n\n        Nothing happens if the vertices are already connected.\n        \"\"\"\n        if t not in self._vertices:\n            raise KeyError(t)\n        self._forwards[f].add(t)\n        self._backwards[t].add(f)\n\n    def iter_edges(self):\n        for f, children in self._forwards.items():\n            for t in children:\n                yield f, t\n\n    def iter_children(self, key):\n        return iter(self._forwards[key])\n\n    def iter_parents(self, key):\n        return iter(self._backwards[key])\n\n\nclass IteratorMapping(collections_abc.Mapping):\n    def __init__(self, mapping, accessor, appends=None):\n        self._mapping = mapping\n        self._accessor = accessor\n        self._appends = appends or {}\n\n    def __repr__(self):\n        return \"IteratorMapping({!r}, {!r}, {!r})\".format(\n            self._mapping,\n            self._accessor,\n            self._appends,\n        )\n\n    def __bool__(self):\n        return bool(self._mapping or self._appends)\n\n    __nonzero__ = __bool__  # XXX: Python 2.\n\n    def __contains__(self, key):\n        return key in self._mapping or key in self._appends\n\n    def __getitem__(self, k):\n        try:\n            v = self._mapping[k]\n        except KeyError:\n            return iter(self._appends[k])\n        return itertools.chain(self._accessor(v), self._appends.get(k, ()))\n\n    def __iter__(self):\n        more = (k for k in self._appends if k not in self._mapping)\n        return itertools.chain(self._mapping, more)\n\n    def __len__(self):\n        more = sum(1 for k in self._appends if k not in self._mapping)\n        return len(self._mapping) + more\n\n\nclass _FactoryIterableView(object):\n    \"\"\"Wrap an iterator factory returned by `find_matches()`.\n\n    Calling `iter()` on this class would invoke the underlying iterator\n    factory, making it a \"collection with ordering\" that can be iterated\n    through multiple times, but lacks random access methods presented in\n    built-in Python sequence types.\n    \"\"\"\n\n    def __init__(self, factory):\n        self._factory = factory\n        self._iterable = None\n\n    def __repr__(self):\n        return \"{}({})\".format(type(self).__name__, list(self))\n\n    def __bool__(self):\n        try:\n            next(iter(self))\n        except StopIteration:\n            return False\n        return True\n\n    __nonzero__ = __bool__  # XXX: Python 2.\n\n    def __iter__(self):\n        iterable = (\n            self._factory() if self._iterable is None else self._iterable\n        )\n        self._iterable, current = itertools.tee(iterable)\n        return current\n\n\nclass _SequenceIterableView(object):\n    \"\"\"Wrap an iterable returned by find_matches().\n\n    This is essentially just a proxy to the underlying sequence that provides\n    the same interface as `_FactoryIterableView`.\n    \"\"\"\n\n    def __init__(self, sequence):\n        self._sequence = sequence\n\n    def __repr__(self):\n        return \"{}({})\".format(type(self).__name__, self._sequence)\n\n    def __bool__(self):\n        return bool(self._sequence)\n\n    __nonzero__ = __bool__  # XXX: Python 2.\n\n    def __iter__(self):\n        return iter(self._sequence)\n\n\ndef build_iter_view(matches):\n    \"\"\"Build an iterable view from the value returned by `find_matches()`.\"\"\"\n    if callable(matches):\n        return _FactoryIterableView(matches)\n    if not isinstance(matches, collections_abc.Sequence):\n        matches = list(matches)\n    return _SequenceIterableView(matches)\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/rich/__init__.py","size":6090,"sha1":"d6b97fece02385eff2b7a6e2145299c171772c80","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"\"\"\"Rich text and beautiful formatting in the terminal.\"\"\"\n\nimport os\nfrom typing import IO, TYPE_CHECKING, Any, Callable, Optional, Union\n\nfrom ._extension import load_ipython_extension  # noqa: F401\n\n__all__ = [\"get_console\", \"reconfigure\", \"print\", \"inspect\", \"print_json\"]\n\nif TYPE_CHECKING:\n    from .console import Console\n\n# Global console used by alternative print\n_console: Optional[\"Console\"] = None\n\ntry:\n    _IMPORT_CWD = os.path.abspath(os.getcwd())\nexcept FileNotFoundError:\n    # Can happen if the cwd has been deleted\n    _IMPORT_CWD = \"\"\n\n\ndef get_console() -> \"Console\":\n    \"\"\"Get a global :class:`~rich.console.Console` instance. This function is used when Rich requires a Console,\n    and hasn't been explicitly given one.\n\n    Returns:\n        Console: A console instance.\n    \"\"\"\n    global _console\n    if _console is None:\n        from .console import Console\n\n        _console = Console()\n\n    return _console\n\n\ndef reconfigure(*args: Any, **kwargs: Any) -> None:\n    \"\"\"Reconfigures the global console by replacing it with another.\n\n    Args:\n        *args (Any): Positional arguments for the replacement :class:`~rich.console.Console`.\n        **kwargs (Any): Keyword arguments for the replacement :class:`~rich.console.Console`.\n    \"\"\"\n    from pip._vendor.rich.console import Console\n\n    new_console = Console(*args, **kwargs)\n    _console = get_console()\n    _console.__dict__ = new_console.__dict__\n\n\ndef print(\n    *objects: Any,\n    sep: str = \" \",\n    end: str = \"\\n\",\n    file: Optional[IO[str]] = None,\n    flush: bool = False,\n) -> None:\n    r\"\"\"Print object(s) supplied via positional arguments.\n    This function has an identical signature to the built-in print.\n    For more advanced features, see the :class:`~rich.console.Console` class.\n\n    Args:\n        sep (str, optional): Separator between printed objects. Defaults to \" \".\n        end (str, optional): Character to write at end of output. Defaults to \"\\\\n\".\n        file (IO[str], optional): File to write to, or None for stdout. Defaults to None.\n        flush (bool, optional): Has no effect as Rich always flushes output. Defaults to False.\n\n    \"\"\"\n    from .console import Console\n\n    write_console = get_console() if file is None else Console(file=file)\n    return write_console.print(*objects, sep=sep, end=end)\n\n\ndef print_json(\n    json: Optional[str] = None,\n    *,\n    data: Any = None,\n    indent: Union[None, int, str] = 2,\n    highlight: bool = True,\n    skip_keys: bool = False,\n    ensure_ascii: bool = False,\n    check_circular: bool = True,\n    allow_nan: bool = True,\n    default: Optional[Callable[[Any], Any]] = None,\n    sort_keys: bool = False,\n) -> None:\n    \"\"\"Pretty prints JSON. Output will be valid JSON.\n\n    Args:\n        json (str): A string containing JSON.\n        data (Any): If json is not supplied, then encode this data.\n        indent (int, optional): Number of spaces to indent. Defaults to 2.\n        highlight (bool, optional): Enable highlighting of output: Defaults to True.\n        skip_keys (bool, optional): Skip keys not of a basic type. Defaults to False.\n        ensure_ascii (bool, optional): Escape all non-ascii characters. Defaults to False.\n        check_circular (bool, optional): Check for circular references. Defaults to True.\n        allow_nan (bool, optional): Allow NaN and Infinity values. Defaults to True.\n        default (Callable, optional): A callable that converts values that can not be encoded\n            in to something that can be JSON encoded. Defaults to None.\n        sort_keys (bool, optional): Sort dictionary keys. Defaults to False.\n    \"\"\"\n\n    get_console().print_json(\n        json,\n        data=data,\n        indent=indent,\n        highlight=highlight,\n        skip_keys=skip_keys,\n        ensure_ascii=ensure_ascii,\n        check_circular=check_circular,\n        allow_nan=allow_nan,\n        default=default,\n        sort_keys=sort_keys,\n    )\n\n\ndef inspect(\n    obj: Any,\n    *,\n    console: Optional[\"Console\"] = None,\n    title: Optional[str] = None,\n    help: bool = False,\n    methods: bool = False,\n    docs: bool = True,\n    private: bool = False,\n    dunder: bool = False,\n    sort: bool = True,\n    all: bool = False,\n    value: bool = True,\n) -> None:\n    \"\"\"Inspect any Python object.\n\n    * inspect(<OBJECT>) to see summarized info.\n    * inspect(<OBJECT>, methods=True) to see methods.\n    * inspect(<OBJECT>, help=True) to see full (non-abbreviated) help.\n    * inspect(<OBJECT>, private=True) to see private attributes (single underscore).\n    * inspect(<OBJECT>, dunder=True) to see attributes beginning with double underscore.\n    * inspect(<OBJECT>, all=True) to see all attributes.\n\n    Args:\n        obj (Any): An object to inspect.\n        title (str, optional): Title to display over inspect result, or None use type. Defaults to None.\n        help (bool, optional): Show full help text rather than just first paragraph. Defaults to False.\n        methods (bool, optional): Enable inspection of callables. Defaults to False.\n        docs (bool, optional): Also render doc strings. Defaults to True.\n        private (bool, optional): Show private attributes (beginning with underscore). Defaults to False.\n        dunder (bool, optional): Show attributes starting with double underscore. Defaults to False.\n        sort (bool, optional): Sort attributes alphabetically. Defaults to True.\n        all (bool, optional): Show all attributes. Defaults to False.\n        value (bool, optional): Pretty print value. Defaults to True.\n    \"\"\"\n    _console = console or get_console()\n    from pip._vendor.rich._inspect import Inspect\n\n    # Special case for inspect(inspect)\n    is_inspect = obj is inspect\n\n    _inspect = Inspect(\n        obj,\n        title=title,\n        help=is_inspect or help,\n        methods=is_inspect or methods,\n        docs=is_inspect or docs,\n        private=private,\n        dunder=dunder,\n        sort=sort,\n        all=all,\n        value=value,\n    )\n    _console.print(_inspect)\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    print(\"Hello, **World**\")\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/rich/__main__.py","size":8477,"sha1":"537e7ddc00cb1ab1cfbbd3cbfccfd50208494521","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"import colorsys\nimport io\nfrom time import process_time\n\nfrom pip._vendor.rich import box\nfrom pip._vendor.rich.color import Color\nfrom pip._vendor.rich.console import Console, ConsoleOptions, Group, RenderableType, RenderResult\nfrom pip._vendor.rich.markdown import Markdown\nfrom pip._vendor.rich.measure import Measurement\nfrom pip._vendor.rich.pretty import Pretty\nfrom pip._vendor.rich.segment import Segment\nfrom pip._vendor.rich.style import Style\nfrom pip._vendor.rich.syntax import Syntax\nfrom pip._vendor.rich.table import Table\nfrom pip._vendor.rich.text import Text\n\n\nclass ColorBox:\n    def __rich_console__(\n        self, console: Console, options: ConsoleOptions\n    ) -> RenderResult:\n        for y in range(0, 5):\n            for x in range(options.max_width):\n                h = x / options.max_width\n                l = 0.1 + ((y / 5) * 0.7)\n                r1, g1, b1 = colorsys.hls_to_rgb(h, l, 1.0)\n                r2, g2, b2 = colorsys.hls_to_rgb(h, l + 0.7 / 10, 1.0)\n                bgcolor = Color.from_rgb(r1 * 255, g1 * 255, b1 * 255)\n                color = Color.from_rgb(r2 * 255, g2 * 255, b2 * 255)\n                yield Segment(\"▄\", Style(color=color, bgcolor=bgcolor))\n            yield Segment.line()\n\n    def __rich_measure__(\n        self, console: \"Console\", options: ConsoleOptions\n    ) -> Measurement:\n        return Measurement(1, options.max_width)\n\n\ndef make_test_card() -> Table:\n    \"\"\"Get a renderable that demonstrates a number of features.\"\"\"\n    table = Table.grid(padding=1, pad_edge=True)\n    table.title = \"Rich features\"\n    table.add_column(\"Feature\", no_wrap=True, justify=\"center\", style=\"bold red\")\n    table.add_column(\"Demonstration\")\n\n    color_table = Table(\n        box=None,\n        expand=False,\n        show_header=False,\n        show_edge=False,\n        pad_edge=False,\n    )\n    color_table.add_row(\n        (\n            \"✓ [bold green]4-bit color[/]\\n\"\n            \"✓ [bold blue]8-bit color[/]\\n\"\n            \"✓ [bold magenta]Truecolor (16.7 million)[/]\\n\"\n            \"✓ [bold yellow]Dumb terminals[/]\\n\"\n            \"✓ [bold cyan]Automatic color conversion\"\n        ),\n        ColorBox(),\n    )\n\n    table.add_row(\"Colors\", color_table)\n\n    table.add_row(\n        \"Styles\",\n        \"All ansi styles: [bold]bold[/], [dim]dim[/], [italic]italic[/italic], [underline]underline[/], [strike]strikethrough[/], [reverse]reverse[/], and even [blink]blink[/].\",\n    )\n\n    lorem = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Quisque in metus sed sapien ultricies pretium a at justo. Maecenas luctus velit et auctor maximus.\"\n    lorem_table = Table.grid(padding=1, collapse_padding=True)\n    lorem_table.pad_edge = False\n    lorem_table.add_row(\n        Text(lorem, justify=\"left\", style=\"green\"),\n        Text(lorem, justify=\"center\", style=\"yellow\"),\n        Text(lorem, justify=\"right\", style=\"blue\"),\n        Text(lorem, justify=\"full\", style=\"red\"),\n    )\n    table.add_row(\n        \"Text\",\n        Group(\n            Text.from_markup(\n                \"\"\"Word wrap text. Justify [green]left[/], [yellow]center[/], [blue]right[/] or [red]full[/].\\n\"\"\"\n            ),\n            lorem_table,\n        ),\n    )\n\n    def comparison(renderable1: RenderableType, renderable2: RenderableType) -> Table:\n        table = Table(show_header=False, pad_edge=False, box=None, expand=True)\n        table.add_column(\"1\", ratio=1)\n        table.add_column(\"2\", ratio=1)\n        table.add_row(renderable1, renderable2)\n        return table\n\n    table.add_row(\n        \"Asian\\nlanguage\\nsupport\",\n        \":flag_for_china:  该库支持中文，日文和韩文文本！\\n:flag_for_japan:  ライブラリは中国語、日本語、韓国語のテキストをサポートしています\\n:flag_for_south_korea:  이 라이브러리는 중국어, 일본어 및 한국어 텍스트를 지원합니다\",\n    )\n\n    markup_example = (\n        \"[bold magenta]Rich[/] supports a simple [i]bbcode[/i]-like [b]markup[/b] for [yellow]color[/], [underline]style[/], and emoji! \"\n        \":+1: :apple: :ant: :bear: :baguette_bread: :bus: \"\n    )\n    table.add_row(\"Markup\", markup_example)\n\n    example_table = Table(\n        show_edge=False,\n        show_header=True,\n        expand=False,\n        row_styles=[\"none\", \"dim\"],\n        box=box.SIMPLE,\n    )\n    example_table.add_column(\"[green]Date\", style=\"green\", no_wrap=True)\n    example_table.add_column(\"[blue]Title\", style=\"blue\")\n    example_table.add_column(\n        \"[cyan]Production Budget\",\n        style=\"cyan\",\n        justify=\"right\",\n        no_wrap=True,\n    )\n    example_table.add_column(\n        \"[magenta]Box Office\",\n        style=\"magenta\",\n        justify=\"right\",\n        no_wrap=True,\n    )\n    example_table.add_row(\n        \"Dec 20, 2019\",\n        \"Star Wars: The Rise of Skywalker\",\n        \"$275,000,000\",\n        \"$375,126,118\",\n    )\n    example_table.add_row(\n        \"May 25, 2018\",\n        \"[b]Solo[/]: A Star Wars Story\",\n        \"$275,000,000\",\n        \"$393,151,347\",\n    )\n    example_table.add_row(\n        \"Dec 15, 2017\",\n        \"Star Wars Ep. VIII: The Last Jedi\",\n        \"$262,000,000\",\n        \"[bold]$1,332,539,889[/bold]\",\n    )\n    example_table.add_row(\n        \"May 19, 1999\",\n        \"Star Wars Ep. [b]I[/b]: [i]The phantom Menace\",\n        \"$115,000,000\",\n        \"$1,027,044,677\",\n    )\n\n    table.add_row(\"Tables\", example_table)\n\n    code = '''\\\ndef iter_last(values: Iterable[T]) -> Iterable[Tuple[bool, T]]:\n    \"\"\"Iterate and generate a tuple with a flag for last value.\"\"\"\n    iter_values = iter(values)\n    try:\n        previous_value = next(iter_values)\n    except StopIteration:\n        return\n    for value in iter_values:\n        yield False, previous_value\n        previous_value = value\n    yield True, previous_value'''\n\n    pretty_data = {\n        \"foo\": [\n            3.1427,\n            (\n                \"Paul Atreides\",\n                \"Vladimir Harkonnen\",\n                \"Thufir Hawat\",\n            ),\n        ],\n        \"atomic\": (False, True, None),\n    }\n    table.add_row(\n        \"Syntax\\nhighlighting\\n&\\npretty\\nprinting\",\n        comparison(\n            Syntax(code, \"python3\", line_numbers=True, indent_guides=True),\n            Pretty(pretty_data, indent_guides=True),\n        ),\n    )\n\n    markdown_example = \"\"\"\\\n# Markdown\n\nSupports much of the *markdown* __syntax__!\n\n- Headers\n- Basic formatting: **bold**, *italic*, `code`\n- Block quotes\n- Lists, and more...\n    \"\"\"\n    table.add_row(\n        \"Markdown\", comparison(\"[cyan]\" + markdown_example, Markdown(markdown_example))\n    )\n\n    table.add_row(\n        \"+more!\",\n        \"\"\"Progress bars, columns, styled logging handler, tracebacks, etc...\"\"\",\n    )\n    return table\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    console = Console(\n        file=io.StringIO(),\n        force_terminal=True,\n    )\n    test_card = make_test_card()\n\n    # Print once to warm cache\n    start = process_time()\n    console.print(test_card)\n    pre_cache_taken = round((process_time() - start) * 1000.0, 1)\n\n    console.file = io.StringIO()\n\n    start = process_time()\n    console.print(test_card)\n    taken = round((process_time() - start) * 1000.0, 1)\n\n    c = Console(record=True)\n    c.print(test_card)\n\n    print(f\"rendered in {pre_cache_taken}ms (cold cache)\")\n    print(f\"rendered in {taken}ms (warm cache)\")\n\n    from pip._vendor.rich.panel import Panel\n\n    console = Console()\n\n    sponsor_message = Table.grid(padding=1)\n    sponsor_message.add_column(style=\"green\", justify=\"right\")\n    sponsor_message.add_column(no_wrap=True)\n\n    sponsor_message.add_row(\n        \"Textualize\",\n        \"[u blue link=https://github.com/textualize]https://github.com/textualize\",\n    )\n    sponsor_message.add_row(\n        \"Twitter\",\n        \"[u blue link=https://twitter.com/willmcgugan]https://twitter.com/willmcgugan\",\n    )\n\n    intro_message = Text.from_markup(\n        \"\"\"\\\nWe hope you enjoy using Rich!\n\nRich is maintained with [red]:heart:[/] by [link=https://www.textualize.io]Textualize.io[/]\n\n- Will McGugan\"\"\"\n    )\n\n    message = Table.grid(padding=2)\n    message.add_column()\n    message.add_column(no_wrap=True)\n    message.add_row(intro_message, sponsor_message)\n\n    console.print(\n        Panel.fit(\n            message,\n            box=box.ROUNDED,\n            padding=(1, 2),\n            title=\"[b red]Thanks for trying out Rich!\",\n            border_style=\"bright_blue\",\n        ),\n        justify=\"center\",\n    )\n"},{"path":".local/share/virtualenv/wheel/3.11/image/1/CopyPipInstall/pip-25.0.1-py3-none-any/pip/_vendor/rich/_cell_widths.py","size":10209,"sha1":"320031d770fca209a850b46571e75a6770e271d0","mtime":1754403963,"is_binary":false,"encoding":"utf-8","content":"# Auto generated by make_terminal_widths.py\n\nCELL_WIDTHS = [\n    (0, 0, 0),\n    (1, 31, -1),\n    (127, 159, -1),\n    (173, 173, 0),\n    (768, 879, 0),\n    (1155, 1161, 0),\n    (1425, 1469, 0),\n    (1471, 1471, 0),\n    (1473, 1474, 0),\n    (1476, 1477, 0),\n    (1479, 1479, 0),\n    (1536, 1541, 0),\n    (1552, 1562, 0),\n    (1564, 1564, 0),\n    (1611, 1631, 0),\n    (1648, 1648, 0),\n    (1750, 1757, 0),\n    (1759, 1764, 0),\n    (1767, 1768, 0),\n    (1770, 1773, 0),\n    (1807, 1807, 0),\n    (1809, 1809, 0),\n    (1840, 1866, 0),\n    (1958, 1968, 0),\n    (2027, 2035, 0),\n    (2045, 2045, 0),\n    (2070, 2073, 0),\n    (2075, 2083, 0),\n    (2085, 2087, 0),\n    (2089, 2093, 0),\n    (2137, 2139, 0),\n    (2192, 2193, 0),\n    (2200, 2207, 0),\n    (2250, 2307, 0),\n    (2362, 2364, 0),\n    (2366, 2383, 0),\n    (2385, 2391, 0),\n    (2402, 2403, 0),\n    (2433, 2435, 0),\n    (2492, 2492, 0),\n    (2494, 2500, 0),\n    (2503, 2504, 0),\n    (2507, 2509, 0),\n    (2519, 2519, 0),\n    (2530, 2531, 0),\n    (2558, 2558, 0),\n    (2561, 2563, 0),\n    (2620, 2620, 0),\n    (2622, 2626, 0),\n    (2631, 2632, 0),\n    (2635, 2637, 0),\n    (2641, 2641, 0),\n    (2672, 2673, 0),\n    (2677, 2677, 0),\n    (2689, 2691, 0),\n    (2748, 2748, 0),\n    (2750, 2757, 0),\n    (2759, 2761, 0),\n    (2763, 2765, 0),\n    (2786, 2787, 0),\n    (2810, 2815, 0),\n    (2817, 2819, 0),\n    (2876, 2876, 0),\n    (2878, 2884, 0),\n    (2887, 2888, 0),\n    (2891, 2893, 0),\n    (2901, 2903, 0),\n    (2914, 2915, 0),\n    (2946, 2946, 0),\n    (3006, 3010, 0),\n    (3014, 3016, 0),\n    (3018, 3021, 0),\n    (3031, 3031, 0),\n    (3072, 3076, 0),\n    (3132, 3132, 0),\n    (3134, 3140, 0),\n    (3142, 3144, 0),\n    (3146, 3149, 0),\n    (3157, 3158, 0),\n    (3170, 3171, 0),\n    (3201, 3203, 0),\n    (3260, 3260, 0),\n    (3262, 3268, 0),\n    (3270, 3272, 0),\n    (3274, 3277, 0),\n    (3285, 3286, 0),\n    (3298, 3299, 0),\n    (3315, 3315, 0),\n    (3328, 3331, 0),\n    (3387, 3388, 0),\n    (3390, 3396, 0),\n    (3398, 3400, 0),\n    (3402, 3405, 0),\n    (3415, 3415, 0),\n    (3426, 3427, 0),\n    (3457, 3459, 0),\n    (3530, 3530, 0),\n    (3535, 3540, 0),\n    (3542, 3542, 0),\n    (3544, 3551, 0),\n    (3570, 3571, 0),\n    (3633, 3633, 0),\n    (3636, 3642, 0),\n    (3655, 3662, 0),\n    (3761, 3761, 0),\n    (3764, 3772, 0),\n    (3784, 3790, 0),\n    (3864, 3865, 0),\n    (3893, 3893, 0),\n    (3895, 3895, 0),\n    (3897, 3897, 0),\n    (3902, 3903, 0),\n    (3953, 3972, 0),\n    (3974, 3975, 0),\n    (3981, 3991, 0),\n    (3993, 4028, 0),\n    (4038, 4038, 0),\n    (4139, 4158, 0),\n    (4182, 4185, 0),\n    (4190, 4192, 0),\n    (4194, 4196, 0),\n    (4199, 4205, 0),\n    (4209, 4212, 0),\n    (4226, 4237, 0),\n    (4239, 4239, 0),\n    (4250, 4253, 0),\n    (4352, 4447, 2),\n    (4448, 4607, 0),\n    (4957, 4959, 0),\n    (5906, 5909, 0),\n    (5938, 5940, 0),\n    (5970, 5971, 0),\n    (6002, 6003, 0),\n    (6068, 6099, 0),\n    (6109, 6109, 0),\n    (6155, 6159, 0),\n    (6277, 6278, 0),\n    (6313, 6313, 0),\n    (6432, 6443, 0),\n    (6448, 6459, 0),\n    (6679, 6683, 0),\n    (6741, 6750, 0),\n    (6752, 6780, 0),\n    (6783, 6783, 0),\n    (6832, 6862, 0),\n    (6912, 6916, 0),\n    (6964, 6980, 0),\n    (7019, 7027, 0),\n    (7040, 7042, 0),\n    (7073, 7085, 0),\n    (7142, 7155, 0),\n    (7204, 7223, 0),\n    (7376, 7378, 0),\n    (7380, 7400, 0),\n    (7405, 7405, 0),\n    (7412, 7412, 0),\n    (7415, 7417, 0),\n    (7616, 7679, 0),\n    (8203, 8207, 0),\n    (8232, 8238, 0),\n    (8288, 8292, 0),\n    (8294, 8303, 0),\n    (8400, 8432, 0),\n    (8986, 8987, 2),\n    (9001, 9002, 2),\n    (9193, 9196, 2),\n    (9200, 9200, 2),\n    (9203, 9203, 2),\n    (9725, 9726, 2),\n    (9748, 9749, 2),\n    (9800, 9811, 2),\n    (9855, 9855, 2),\n    (9875, 9875, 2),\n    (9889, 9889, 2),\n    (9898, 9899, 2),\n    (9917, 9918, 2),\n    (9924, 9925, 2),\n    (9934, 9934, 2),\n    (9940, 9940, 2),\n    (9962, 9962, 2),\n    (9970, 9971, 2),\n    (9973, 9973, 2),\n    (9978, 9978, 2),\n    (9981, 9981, 2),\n    (9989, 9989, 2),\n    (9994, 9995, 2),\n    (10024, 10024, 2),\n    (10060, 10060, 2),\n    (10062, 10062, 2),\n    (10067, 10069, 2),\n    (10071, 10071, 2),\n    (10133, 10135, 2),\n    (10160, 10160, 2),\n    (10175, 10175, 2),\n    (11035, 11036, 2),\n    (11088, 11088, 2),\n    (11093, 11093, 2),\n    (11503, 11505, 0),\n    (11647, 11647, 0),\n    (11744, 11775, 0),\n    (11904, 11929, 2),\n    (11931, 12019, 2),\n    (12032, 12245, 2),\n    (12272, 12329, 2),\n    (12330, 12335, 0),\n    (12336, 12350, 2),\n    (12353, 12438, 2),\n    (12441, 12442, 0),\n    (12443, 12543, 2),\n    (12549, 12591, 2),\n    (12593, 12686, 2),\n    (12688, 12771, 2),\n    (12783, 12830, 2),\n    (12832, 12871, 2),\n    (12880, 19903, 2),\n    (19968, 42124, 2),\n    (42128, 42182, 2),\n    (42607, 42610, 0),\n    (42612, 42621, 0),\n    (42654, 42655, 0),\n    (42736, 42737, 0),\n    (43010, 43010, 0),\n    (43014, 43014, 0),\n    (43019, 43019, 0),\n    (43043, 43047, 0),\n    (43052, 43052, 0),\n    (43136, 43137, 0),\n    (43188, 43205, 0),\n    (43232, 43249, 0),\n    (43263, 43263, 0),\n    (43302, 43309, 0),\n    (43335, 43347, 0),\n    (43360, 43388, 2),\n    (43392, 43395, 0),\n    (43443, 43456, 0),\n    (43493, 43493, 0),\n    (43561, 43574, 0),\n    (43587, 43587, 0),\n    (43596, 43597, 0),\n    (43643, 43645, 0),\n    (43696, 43696, 0),\n    (43698, 43700, 0),\n    (43703, 43704, 0),\n    (43710, 43711, 0),\n    (43713, 43713, 0),\n    (43755, 43759, 0),\n    (43765, 43766, 0),\n    (44003, 44010, 0),\n    (44012, 44013, 0),\n    (44032, 55203, 2),\n    (55216, 55295, 0),\n    (63744, 64255, 2),\n    (64286, 64286, 0),\n    (65024, 65039, 0),\n    (65040, 65049, 2),\n    (65056, 65071, 0),\n    (65072, 65106, 2),\n    (65108, 65126, 2),\n    (65128, 65131, 2),\n    (65279, 65279, 0),\n    (65281, 65376, 2),\n    (65504, 65510, 2),\n    (65529, 65531, 0),\n    (66045, 66045, 0),\n    (66272, 66272, 0),\n    (66422, 66426, 0),\n    (68097, 68099, 0),\n    (68101, 68102, 0),\n    (68108, 68111, 0),\n    (68152, 68154, 0),\n    (68159, 68159, 0),\n    (68325, 68326, 0),\n    (68900, 68903, 0),\n    (69291, 69292, 0),\n    (69373, 69375, 0),\n    (69446, 69456, 0),\n    (69506, 69509, 0),\n    (69632, 69634, 0),\n    (69688, 69702, 0),\n    (69744, 69744, 0),\n    (69747, 69748, 0),\n    (69759, 69762, 0),\n    (69808, 69818, 0),\n    (69821, 69821, 0),\n    (69826, 69826, 0),\n    (69837, 69837, 0),\n    (69888, 69890, 0),\n    (69927, 69940, 0),\n    (69957, 69958, 0),\n    (70003, 70003, 0),\n    (70016, 70018, 0),\n    (70067, 70080, 0),\n    (70089, 70092, 0),\n    (70094, 70095, 0),\n    (70188, 70199, 0),\n    (70206, 70206, 0),\n    (70209, 70209, 0),\n    (70367, 70378, 0),\n    (70400, 70403, 0),\n    (70459, 70460, 0),\n    (70462, 70468, 0),\n    (70471, 70472, 0),\n    (70475, 70477, 0),\n    (70487, 70487, 0),\n    (70498, 70499, 0),\n    (70502, 70508, 0),\n    (70512, 70516, 0),\n    (70709, 70726, 0),\n    (70750, 70750, 0),\n    (70832, 70851, 0),\n    (71087, 71093, 0),\n    (71096, 71104, 0),\n    (71132, 71133, 0),\n    (71216, 71232, 0),\n    (71339, 71351, 0),\n    (71453, 71467, 0),\n    (71724, 71738, 0),\n    (71984, 71989, 0),\n    (71991, 71992, 0),\n    (71995, 71998, 0),\n    (72000, 72000, 0),\n    (72002, 72003, 0),\n    (72145, 72151, 0),\n    (72154, 72160, 0),\n    (72164, 72164, 0),\n    (72193, 72202, 0),\n    (72243, 72249, 0),\n    (72251, 72254, 0),\n    (72263, 72263, 0),\n    (72273, 72283, 0),\n    (72330, 72345, 0),\n    (72751, 72758, 0),\n    (72760, 72767, 0),\n    (72850, 72871, 0),\n    (72873, 72886, 0),\n    (73009, 73014, 0),\n    (73018, 73018, 0),\n    (73020, 73021, 0),\n    (73023, 73029, 0),\n    (73031, 73031, 0),\n    (73098, 73102, 0),\n    (73104, 73105, 0),\n    (73107, 73111, 0),\n    (73459, 73462, 0),\n    (73472, 73473, 0),\n    (73475, 73475, 0),\n    (73524, 73530, 0),\n    (73534, 73538, 0),\n    (78896, 78912, 0),\n    (78919, 78933, 0),\n    (92912, 92916, 0),\n    (92976, 92982, 0),\n    (94031, 94031, 0),\n    (94033, 94087, 0),\n    (94095, 94098, 0),\n    (94176, 94179, 2),\n    (94180, 94180, 0),\n    (94192, 94193, 0),\n    (94208, 100343, 2),\n    (100352, 101589, 2),\n    (101632, 101640, 2),\n    (110576, 110579, 2),\n    (110581, 110587, 2),\n    (110589, 110590, 2),\n    (110592, 110882, 2),\n    (110898, 110898, 2),\n    (110928, 110930, 2),\n    (110933, 110933, 2),\n    (110948, 110951, 2),\n    (110960, 111355, 2),\n    (113821, 113822, 0),\n    (113824, 113827, 0),\n    (118528, 118573, 0),\n    (118576, 118598, 0),\n    (119141, 119145, 0),\n    (119149, 119170, 0),\n    (119173, 119179, 0),\n    (119210, 119213, 0),\n    (119362, 119364, 0),\n    (121344, 121398, 0),\n    (121403, 121452, 0),\n    (121461, 121461, 0),\n    (121476, 121476, 0),\n    (121499, 121503, 0),\n    (121505, 121519, 0),\n    (122880, 122886, 0),\n    (122888, 122904, 0),\n    (122907, 122913, 0),\n    (122915, 122916, 0),\n    (122918, 122922, 0),\n    (123023, 123023, 0),\n    (123184, 123190, 0),\n    (123566, 123566, 0),\n    (123628, 123631, 0),\n    (124140, 124143, 0),\n    (125136, 125142, 0),\n    (125252, 125258, 0),\n    (126980, 126980, 2),\n    (127183, 127183, 2),\n    (127374, 127374, 2),\n    (127377, 127386, 2),\n    (127488, 127490, 2),\n    (127504, 127547, 2),\n    (127552, 127560, 2),\n    (127568, 127569, 2),\n    (127584, 127589, 2),\n    (127744, 127776, 2),\n    (127789, 127797, 2),\n    (127799, 127868, 2),\n    (127870, 127891, 2),\n    (127904, 127946, 2),\n    (127951, 127955, 2),\n    (127968, 127984, 2),\n    (127988, 127988, 2),\n    (127992, 127994, 2),\n    (127995, 127999, 0),\n    (128000, 128062, 2),\n    (128064, 128064, 2),\n    (128066, 128252, 2),\n    (128255, 128317, 2),\n    (128331, 128334, 2),\n    (128336, 128359, 2),\n    (128378, 128378, 2),\n    (128405, 128406, 2),\n    (128420, 128420, 2),\n    (128507, 128591, 2),\n    (128640, 128709, 2),\n    (128716, 128716, 2),\n    (128720, 128722, 2),\n    (128725, 128727, 2),\n    (128732, 128735, 2),\n    (128747, 128748, 2),\n    (128756, 128764, 2),\n    (128992, 129003, 2),\n    (129008, 129008, 2),\n    (129292, 129338, 2),\n    (129340, 129349, 2),\n    (129351, 129535, 2),\n    (129648, 129660, 2),\n    (129664, 129672, 2),\n    (129680, 129725, 2),\n    (129727, 129733, 2),\n    (129742, 129755, 2),\n    (129760, 129768, 2),\n    (129776, 129784, 2),\n    (131072, 196605, 2),\n    (196608, 262141, 2),\n    (917505, 917505, 0),\n    (917536, 917631, 0),\n    (917760, 917999, 0),\n]\n"}]}